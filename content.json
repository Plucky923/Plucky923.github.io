{"meta":{"title":"Plucky","subtitle":"Comfortably Numb","description":"随便记录","author":"Plucky","url":"http://example.com","root":"/"},"pages":[{"title":"about","date":"2022-06-23T08:09:59.000Z","updated":"2023-03-01T09:00:29.431Z","comments":true,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":"饥饿艺术家"},{"title":"categories","date":"2022-06-23T11:37:54.000Z","updated":"2022-06-23T11:44:50.961Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2022-06-23T11:37:08.000Z","updated":"2022-06-23T11:42:25.423Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""},{"title":"links","date":"2023-03-31T04:34:08.000Z","updated":"2023-03-31T05:00:19.831Z","comments":true,"path":"links/index.html","permalink":"http://example.com/links/index.html","excerpt":"","text":"Friend Link Solar1s Hammour"}],"posts":[{"title":"论文阅读 Houdini’s Escape: Breaking the Resource Rein of Linux Control Groups","slug":"论文阅读-Houdini’s-Escape-Breaking-the-Resource-Rein-of-Linux-Control-Groups","date":"2023-04-15T05:08:53.000Z","updated":"2023-04-15T15:09:10.366Z","comments":true,"path":"2023/04/15/论文阅读-Houdini’s-Escape-Breaking-the-Resource-Rein-of-Linux-Control-Groups/","link":"","permalink":"http://example.com/2023/04/15/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-Houdini%E2%80%99s-Escape-Breaking-the-Resource-Rein-of-Linux-Control-Groups/","excerpt":"","text":"摘要 Linux Control Groups，即cgroups，是启用操作系统级容器化的关键构建块。cgroups机制将进程划分为分层的组，并应用不同的控制器来管理系统资源，包括CPU、内存、块I&#x2F;O等。新生成的子进程自动从父进程中复制cgroups属性以加强资源控制。不幸的是，通过进程创建继承的cgroups限制并不总是保证一致和公平的资源核算。在本文中，我们设计了一套利用策略，通过将进程与原始进程组解关联来生成out-of-band工作负载。这样的工作负载所消耗的系统资源不会被计算到适当的cgroup中。 为了进一步证明可行性，我们提供了Docker容器中的五个案例研究，以演示如何在现实场景中打破cgroup的资源限制。更糟糕的是，通过利用这些cgroups在多租户容器环境中的不足，攻击容器能够极大地扩大所消耗的资源数量，显著降低同一主机上的其他容器的速度，并在系统资源上获得额外的不公平优势。我们在本地测试平台和Amazon EC2云专用服务器上进行了大量的实验。实验结果表明，一个容器可以消耗系统资源(例如CPU)高达其极限的200倍，并使其他共存容器中特定工作负载的计算和I&#x2F;O性能降低95%。 CCS CONCEPT Security and privacy → Virtualization and security KEYWORDS Container；Control Group；Docker INTRODUCTION容器技术已广泛应用于各种计算场景，包括边缘计算、微服务架构、无服务器计算和商业云供应商。与虚拟机相比，消除额外的抽象层可以更好地利用资源并提高效率。因此，容器可以实现接近本机的性能。 尽管容器技术具有性能优势，但最近也引起了一些安全和隐私问题，特别是资源隔离、特权升级、混淆代理攻击和隐蔽通道。 在Linux内核中，启用容器资源隔离和管理的两个关键构建块是Linux命名空间(即namespaces)和Linux控制组(即cgroups)。此外，还采用或建议了一组安全机制(例如，Capabilities、SELinux、AppArmor、seccomp和安全命名空间)来进一步增强部署中的容器安全性。 容器依赖于cgroup进行资源管理和控制，以防止一个容器耗尽主机的系统资源。cgroups机制将一组进程及其子进程划分为分层的组，并应用不同的控制器来管理和限制各种系统资源，例如CPU时间、计算机内存、块I&#x2F;O等。通过合理的限制策略，cgroups可以缓解许多已知的拒绝服务漏洞。 容器技术已广泛应用于各种计算场景，包括边缘计算[1]、微服务架构[2]、无服务器计算[3]和商业云供应商[4-6]。与虚拟机相比，消除额外的抽象层可以更好地利用资源并提高效率。因此，容器可以实现接近本机的性能[7,8]。 尽管容器技术具有性能优势，但最近也引起了一些安全和隐私问题，特别是资源隔离[9]、特权升级[10-12]、混淆代理攻击[13]和隐蔽通道[14]。 在Linux内核中，启用容器资源隔离和管理的两个关键构建块是Linux命名空间(即命名空间)和Linux控制组(即cgroups1)。此外，还采用或建议了一组安全机制(例如，Capabilities、SELinux、AppArmor、seccomp和安全命名空间[16])来进一步增强部署中的容器安全性。 容器依赖于cgroup进行资源管理和控制，以防止一个容器耗尽主机的系统资源。cgroups机制将一组进程及其子进程划分为分层的组，并应用不同的控制器来管理和限制各种系统资源，例如CPU时间、计算机内存、块I&#x2F;O等。通过合理的限制策略，cgroups可以缓解许多已知的拒绝服务漏洞 在本文中，我们打算系统地探讨一下来摆脱现有的cgroups机制的资源控制、并了解其对容器的安全影响。新创建的子进程会自动继承其父进程的cgroups属性。这种机制保证了它们将被限制在相同的cgroups策略下。为了打破cgroups的资源约束，我们设计了一套利用策略，通过将进程与其原始cgroups分离，生成了一些带外工作负载。这意味着这些进程不再受到原始cgroups的资源限制，从而可能绕过原本的资源管理策略。这些进程可以从头开始创建，以处理在一个cgroup内发起的系统事件。在其他情况下，这些进程可以是休眠的内核线程或系统服务进程。在整个系统中共享，并将在需要时被激活。因此，相应的消耗的资源将被收取到其他 “受害者 “cgroups中。 为了进一步揭示现有cgroup机制不足的安全风险，我们使用Docker容器进行了五个案例研究，展示了在现实系统设置中逃脱cgroup资源控制的步骤。在这些案例研究中，我们分别利用了异常、文件系统和I&#x2F;O设备、Linux日志系统、容器引擎和softirqs处理的内核处理机制。我们在亚马逊EC2云中的本地测试平台和专用服务器上进行实验。我们的实验表明，即使执行了多个cgroup控制器，一个对抗性去特权容器仍然可以显著耗尽CPU资源或产生大量的I&#x2F;O活动，而不需要任何cgroup控制器。 更糟糕的是，通过在多租户容器环境中利用这些机制，对抗性容器能够极大地扩大所消耗的资源量。由于对抗容器会发动多种攻击(如拒绝服务攻击和资源释放攻击)，可以显著降低同一主机上的其他容器的速度，并在系统资源上获得额外的不公平优势。我们的实验证明，对手仅通过控制少量资源就能显著影响共存容器的性能。例如，一个容器可能会消耗系统资源(例如CPU)，超过其极限200倍，并使其他容器的特定基准的计算和I&#x2F;O性能降低95%。总体而言，本工作的主要贡献总结如下: 我们提出了四种可能导致系统资源错误计算的开发策略，因此我们可以逃避cgroup控制器强制执行的资源约束。 我们在Docker容器环境中进行了五个案例研究，并证明了在现实场景中打破cgroup限制并消耗大量资源是可能的。 我们在两个具有不同配置的试验台上评估了所提出的方法的影响。实验结果表明了安全影响的严重性。 本文的其余部分组织如下。第二节介绍了cgroup的背景。第3节介绍了逃脱cgroups机制控制的策略，并从内核的角度分析了其根本原因。第4节详细介绍了容器的几个案例研究，包括威胁模型、攻击向量以及对多租户容器环境的各种攻击的有效性。第5节从不同方面讨论了潜在的缓解措施。第6节对相关工作进行考察，并在第7节中进行总结。 BACKGROUND在Linux内核中，cgroups是用于管理一组任务及其所有子任务的系统资源(例如CPU、内存、磁盘I&#x2F;O、网络等)的关键特性。它是实现集装箱化的构建块之一。cgroup机制将进程组划分为具有控制行为的分层组。所有的子进程也从它们的父进程继承某些属性(例如，limits)，并由该机制控制。cgroups依赖于不同的资源控制器(或子系统)来限制、解释和隔离各种类型的系统资源，包括CPU时间、系统内存、块I&#x2F;O、网络带宽等。Linux容器利用控制组对每个容器实例应用资源限制，并防止单个容器耗尽主机资源。对于云计算中的计费模型，还可以使用cgroups为每个容器分配相应的资源并测量它们的使用情况。下面我们简要介绍cgroup层次结构的背景知识，现有容器环境中通常应用的四种典型的cgroup控制器，以及新生成进程的cgroup继承过程。 cgroups Hierarchy and Controllers在Linux中，cgroup是按层次结构组织的，其中一组cgroup被排列在树中。每个任务(例如，一个线程)只能与一个层次结构中的一个cgroup相关联，但可以是不同层次结构中的多个cgroup的成员。然后，每个层次结构都有一个或多个附加子系统，以便资源控制器可以对特定的系统资源应用每个cgroup限制。通过分层结构，cgroups机制能够限制一组进程(例如容器)的资源总量。 The cpu controllercpu controller通过利用CFS(完全公平的调度器，在Linux 2.6.23中引入)调度cpu，以两种方式使cpu成为可管理的资源。 第一种方法是保证最少数量的CPU共享:每个组都提供相应的共享，以定义相对权重。该策略在CPU空闲时不限制cgroup的CPU使用率，当多个cgroup竞争相同的CPU资源时，按照权重的比例分配带宽。例如，如果共享为512的一个容器与共享为1024的另一个容器运行在同一个核心上。然后，第一个容器的CPU使用率大致为33.3%，而另一个容器的CPU使用率为66.7%。在Linux 3.2中进一步扩展了cpu控制器，通过指定配额和周期来提供额外的cpu带宽控制。 每个组只能在每个给定的“时间段”(以微秒为单位)内消耗“配额”微秒。如果一个组的CPU带宽消耗(由运行时变量跟踪)超过了限制，控制器将限制该任务，直到下一个时间段，此时容器的运行时被重新充电到其配额。cpu控制器被广泛应用于多租户容器环境，以限制一个容器的cpu使用。如果容器设置的配额为50,000，周期为100,000，则该容器最多可以消耗一个CPU核心总CPU周期的一半。 The cpusets controllercpusets控制器提供了一种机制，用于将一组任务约束到特定的cpu和内存节点。在多租户容器环境中，利用cpusets控制器来限制特定核心上容器的工作负载。容器的每个任务都附加到一个cpuset，其中包含一组允许使用的cpu和内存节点。对于CPU调度，任务的调度(通过系统调用sched_setaffinity)被过滤到任务的cpusset允许的那些CPU。任务的任何进一步的动态迁移也仅限于允许的cpuset。因此，cpusets控制器还可以用于将一个进程固定在特定的核心上。容器用户还可以利用用户空间应用程序(例如，taskset)在cpuset的限制范围内进一步设置亲和性。 The blkio controllerblkio cgroup通过应用I&#x2F;O控制来控制和限制对指定块设备的访问。内核级有两个策略可用。第一个是基于比例权重的基于时间的磁盘策略划分。每个cgroup都被分配了一个blkio。权重值，表示该组占用磁盘时间的比例。第二个是节流策略，它指定I&#x2F;O设备上的上限。 The pid controllerpid cgroup子系统用于对容器的任务数量设置一定的限制。这可以通过在pid.max中设置最大任务数来实现。当前任务数保存在pid .current中。pid cgroup子系统将在达到限制(例如，pid.current&gt; pid .max)停止forking或克隆一个新任务(例如，返回错误信息)。因此，pid控制器可以有效防御多种耗尽攻击，如fork bomb。 cgroups Inheritancecgroups的一个重要特性是子进程从父进程继承cgroups属性。每当一个进程创建一个子进程(例如，fork或clone)时，它都会触发内核中的fork函数来复制初始化进程。当新派生的进程在开始时附加到根cgroup时，在复制寄存器和进程环境的其他适当部分(例如，命名空间)后，调用cgroup复制函数来复制父进程的cgroup。特别是，该函数通过递归遍历所有cgroup子系统，将任务附加到其父cgroup。因此，在复制过程之后，子任务将继承与其父任务完全相同的cgroups成员。 例如，如果cpusets资源控制器将父进程的the CPU affinity设置为第二个核心，那么新派生的子进程也将被固定在第二个核心上。同时，如果cpu子系统将父cgroup上的cpu配额限制为50,000，周期为100,000，那么在第二个核上，cgroup的总cpu利用率(包括新分叉的进程和它的父进程)不能超过50%。 EXPLOITING STRATEGIES在本节中，我们将描述四种逃避cgroups机制的资源控制的策略，并解释现有cgroup无法跟踪所消耗资源的根本原因。如上所述，使用层次结构，cgroups机制可以限制一组进程(例如容器)的资源总量。这是通过附加资源控制器对特定的系统资源应用每cgroup限制来实现的。此外，cgroup中的继承机制确保了同一个cgroup中的所有进程及其子进程都可以被cgroup子系统控制，而不消耗额外的系统资源。 然而，由于Linux内核的复杂性和实现cgroups的难度，我们发现有几个机制没有考虑到，因此可以利用它们来逃避现有cgroups的约束。关键思想是生成工作负载，运行在没有直接从初始化cgroup派生出来的进程上，这导致了cgroup的去关联。特别是，如图所示，用户空间中没有根权限的普通进程可以利用四种策略逃脱cgroups的控制。 Exploiting Upcalls from Kernel在cgroups机制中，所有内核线程都附加到根cgroup，因为内核线程是由内核创建的。因此，内核线程通过fork或clone创建的所有进程也都附加到与其父进程相同的cgroup(根cgroup)中。 因此，一个cgroup中的进程可以利用内核线程作为代理来产生新的进程，从而逃脱cgroup的控制。特别地，如图❶所示，一个进程可以先触发内核来初始化一个内核线程。 这个内核线程充当代理，进一步创建一个新进程。 由于内核线程附加到根cgroup，因此新创建的进程也附加到根cgroup。在新创建的进程上运行的所有工作负载将不受cgroup子系统的限制，从而打破资源控制。 但是，这种机制要求用户空间进程首先调用内核空间中的内核函数，然后从内核空间向上调用用户空间进程。虽然从用户空间调用特定的内核函数(例如系统调用)是很自然的，但相反的方向并不常见。一种可行的方法是通过usermode helper API，该API通过提供可执行变量和环境变量的名称，为在用户空间中创建流程提供了一个简单的接口。这个函数首先调用一个运行在内核线程中的工作队列(例如，kworker)。工作队列的处理函数进一步创建一个内核线程来启动用户进程。最后一步调用内核中的fork函数，将创建的用户进程附加到内核线程的cgroups。 用户模式助手API可用于多种场景，如加载模块、重新启动计算机、生成安全密钥和传递内核事件。虽然在用户空间中触发这些活动通常需要root权限，但仍然可以在用户空间中调用API，这将在4.1节中讨论。 Delegating Workloads to Kernel Threads另一种利用内核线程来打破cgroup约束的方法是将工作负载委托给它们，如图❷所示。同样，由于所有内核线程都附加到根cgroup，因此这些工作负载所消耗的资源量将计入目标内核线程，而不是初始化用户空间进程。 Linux内核运行多个内核线程，处理各种内核函数并在进程上下文中运行内核代码。例如，kthread是内核线程守护进程，用于创建其他内核线程;引入Kworker来处理工作队列任务;Ksoftirqd服务于softirqs;迁移执行迁移作业，将任务从一个核心移动到另一个核心;kswapd管理交换空间。对于这些内核线程，根据它们的功能，内核可能只在系统中运行一个线程(例如kthread)，或者每个内核运行一个线程(例如ksoftirqd)，或者每个内核运行多个线程(例如kworker)。一直有报道称，由于各种bug和问题，内核线程会消耗大量的资源。因此，如果一个进程可以强制内核线程运行委托的工作负载，相应消耗的资源将不受cgroup的限制。 Exploiting Service Processes除了由内核维护的内核线程外，Linux服务器还运行多个系统进程(例如systemd)，用于不同的目的，如进程管理、系统信息日志记录、调试等。这些流程监视其他流程，并在触发特定活动时生成工作负载。同时，许多用户空间进程作为其他进程的依赖关系，同时运行以支持其他进程的正常功能。如果一个用户进程能够在这些进程上生成内核工作负载(图中的策略❸ )，所消耗的资源就不会被分配给初始化进程，从而可以逃脱cgroups机制。 Exploiting Interrupt Context最后一种策略是利用中断上下文中所消耗的资源。cgroup机制只计算在进程上下文中消耗的资源。一旦内核运行在其他上下文(如中断上下文,如图所示的策略❹),所有消耗的资源都不会被计入任何cgroup 特别地，Linux内核服务中断分为两部分:上半部分(即硬件中断)和下半部分(即软件中断)。由于硬件中断可能随时被引发，因此上半部分仅通过响应硬件中断来执行轻量级操作，然后安排(延迟)下半部分的执行。当在下半部分执行中断处理程序时，内核运行在软件中断上下文中，因此它不会为系统资源(例如CPU)收取任何进程的费用。 从内核3.6开始，softirq的处理(硬件中断引发的除外)与生成它们的进程绑定。 这意味着在softirq上下文中所消耗的所有资源都不会消耗所引发进程的任何配额。此外，softirqs的执行将抢占当前进程上的任何工作负载，所有进程将被延迟。 此外，如果处理softirqs的工作负载过重，内核将把它们卸载到内核线程ksoftirqd，这是一个每个CPU(即每个CPU一个线程)的内核线程，并以默认的进程优先级运行。一旦卸载，对softirqs的处理将在ksoftirqd的进程上下文中运行，因此任何资源消耗都将在线程ksoftirqd上计算。在这种情况下，它属于内核线程策略(如图所示的策略❷ )。总之，如果一个进程(称为进程A)能够引发大量的软件中断，内核将不得不在中断上下文或ksoftirqd的进程上下文中花费资源来处理软中断，而不向进程A支付费用。 CASE STUDIES ON CONTAINERS在前一节中，我们讨论了几种可能的策略来逃避cgroups的资源控制。然而，在现实的容器环境中，由于存在其他合作安全策略，开发更具挑战性。在本节中，我们将介绍在Docker容器环境中进行的五个案例研究，以演示利用cgroups弱点的详细步骤。 Threat model 我们考虑一个多租户容器环境，其中属于不同租户的多个Docker容器共享同一台物理机器。目前，边缘和云平台都广泛采用了多租户环境。系统管理员使用cgroups为每个容器设置资源限制。每个容器都是去特权的，设置有有限的CPU时间、系统内存、块I&#x2F;O带宽，并固定到特定的核心。我们假设攻击者控制了一个容器实例，并试图利用cgroups中的不足(1)降低其他容器的性能，(2)获得不公平的优势。 Configuration 我们使用Docker容器通过提供的接口来设置cgroups的配置。此外，Docker还默认确保容器通过namespace隔离。特别是，启用USER namespace后，容器中的根用户将映射到主机上的非特权用户。 因此，容器中的特权操作不会影响主机内核。我们的案例研究就是在这样一个没有特权的容器中进行的。 为了演示每种利用的有效性，我们通过在空闲服务器上设置多个cgroup配置来初始化容器，并测量主机上系统资源的利用率。为了模拟边缘和云环境，我们选择了两个测试平台来进行实验:(1)我们实验室的本地机器;(2) Amazon EC2中的专用主机。特别是，虽然我们的本地测试台配备了7200 rpm的SATA硬盘驱动器，但我们在EC2服务器上选择了更好的I&#x2F;O配置。专用试验台的存储配置了1000iops的SSD(默认为400)，吞吐量比我们本地试验台提高20倍左右。因此，本地测试平台表示可能部署在边缘环境中的性能较低的节点，而强大的专用服务器可以模拟多租户容器云环境。 Ethical hacking concerns 使用cgroup将不可避免地产生主机级的影响，这可能会影响主机服务器上所有容器的性能。因此，对于我们在Amazon EC2上的实验，我们选择使用专用服务器，该服务器仅供我们使用，不与其他租户共享。 此外，它还允许我们模拟多租户容器环境并度量系统范围的影响。 Result summary 表给出了所有案例研究的总体总结、相应的开发策略和影响。第一个案例研究是利用内核中的异常处理机制，这涉及到策略❶。我们发现容器中引发的异常可以调用用户空间进程，其后果是容器可以消耗比cgroups限制多200倍的CPU资源。第二种情况是利用回写机制进行磁盘数据同步，这涉及到策略❷。容器可以不断调用全局数据同步，以降低主机上特定I&#x2F;O工作负载的速度，最高可达95%。第三种情况是利用系统服务日志(通过策略❸)，产生消耗CPU和块设备带宽的工作负载。第四种情况是利用容器引擎在容器引擎进程(策略❸)和内核线程(策略 ❷)上产生额外的未计算的工作负载(大约3倍)。最后一种情况是利用softirq处理机制在内核线程(策略 ❷)和中断上下文(策略❹)上消耗CPU周期。 Case 1:Exception Handling第一种情况是利用内核中的异常处理机制。我们发现可以调用用户模式助手API，并通过异常进一步触发用户空间流程(作为策略❶)。通过反复产生异常，一个容器消耗的CPU资源比限制多约200倍，从而使同一主机(不限于一个核)上其他容器的性能显著降低85% ~ 95%。 Detailed analysis Linux内核为各种异常提供了专用的异常处理程序，包括错误(例如，分割错误)和陷阱(例如，溢出)。内核维护一个中断描述符表(IDT)，其中包含每个中断或异常处理程序的地址。如果CPU在用户模式下引发异常，相应的处理程序将在内核模式下调用。处理器首先在内核堆栈中保存寄存器，然后相应地处理异常，最后返回到用户模式。整个过程在内核空间和触发异常的进程上下文中运行。因此，它将被充电到正确的相应的cgroups。 然而，这些异常将导致初始进程的终止并引发信号。这些信号将进一步触发内核转储功能，生成一个用于调试的内核转储文件。内核中的核心转储代码通过usermode辅助API从内核中调用一个用户空间的应用程序。在Ubuntu中，默认的用户空间核心转储程序是Apport，它将在每个异常情况下被触发。正如上一节所提到的，Apport所消耗的系统资源将不会由容器承担，因为该进程是由内核线程分叉的，而不是由容器化的进程。 新产生的Apport实例将被内核安排到所有的CPU核心，以达到负载平衡的目的，因此打破了cpusets的cgroup。同时，由于Apport进程的运行比轻量级的异常处理（即内核控制路径）消耗更多的资源，如果容器不断引发异常，整个CPU将被Apport进程完全占据。cpu cgroup的逃逸导致分配给容器的系统资源的巨大放大。 Workloads amplification 为了研究这种影响，我们在一个核心上启动并固定一个容器。我们通过调整周期和配额来为容器设置不同的CPU资源限制。 容器进入循环，不断引发异常。我们实现了几种用户空间程序可用的异常类型。由于不同类型的异常的结果是相似的，我们使用div 0异常作为例子。容器是唯一在我们的测试平台中运行的活动程序。我们通过top命令测量测试平台的CPU使用率，通过Docker的统计工具测量容器的CPU使用率。对于主机级别的使用情况，我们将所有内核的CPU使用量汇总在一起（因此12个内核的最大使用量为1200%）。我们将放大系数定义为主机的CPU利用率与容器的CPU利用率的比率。 图演示了用户模式助手API可以触发用户空间程序，从而显著提高容器的CPU使用率。在我们的本地测试平台上，容器使用的一个内核上的CPU利用率只有7.4%，整个12个内核都被占用了。当我们将分配给容器的CPU资源减少到仅10%内核(通过设置period为200,000,quota为20,000)后，这个问题无法缓解。我们进一步将容器的CPU限制降低到20%核心，并最终将12个核心的总利用率限制到1,065%，放大因子为207×。同时，系统内存使用增加了约1GB，而Docker测量的容器内存使用仅为15.58MB。 我们从EC2服务器上获得了类似的结果:容器的22.5%的利用率就可以耗尽36个内核。由于CPU频率不如我们的本地测试平台强大，一旦我们将容器的CPU资源限制为1&#x2F;10内核，它可以在所有36个内核上产生1907%的利用率。放大系数约为192×。 The pid controller 虽然放大要求容器不断抛出异常，但我们进一步使用pid cgroup子系统对容器的任务数量设置一定的限制。同样，如图所示，即使活动进程的数量被限制在50个，pid控制器也不能降低放大结果，这是一个非常小的数字，可能会对容器用户造成巨大的可用性影响。在单核CPU计算能力只有20%的情况下，将pid限制为50，放大系数可以降低到98×。在EC2服务器上，在单核10% CPU计算能力的容器上，通过将pid数量限制在50个，放大系数在144×左右. Denial-of-service(DoS) attacks 当多个容器在同一个核心上运行时，它们将共享和竞争CPU资源。Linux的CFS系统根据每个容器的份额来分配CPU周期。CFS系统确保了完全的公平性，即容器可以完全利用其插槽中的所有资源。然而,如果一个恶意的容器可以在它自己的cgroup之外产生新的工作负载，CFS系统也会将CPU周期分配给这些进程，从而减少其他co-residence容器的使用。同时，CPU使用率的下降也可能影响其他的性能，如内存和I&#x2F;O吞吐量。 在我们的实验中，我们通过利用恶意容器中的异常处理机制来衡量DoS攻击的影响。我们运行两个容器:一个恶意容器和一个受害者。我们将攻击的性能与恶意容器运行正常工作负载(即基线)的情况进行比较。受害容器运行不同的sysbench工作负载来度量性能。 这两个服务器上的结果如表所示。我们首先将两个容器设置在相同的内核上，使用完全相同的CPU共享和配额。我们发现，在我们的本地测试平台上，抛出异常(导致内核转储)可以显著降低95%的CPU和内存性能，并降低17%左右的I&#x2F;O性能。在EC2服务器上，大约85%用于CPU和内存性能，82%用于I&#x2F;O性能。这是合理的，因为引发异常会导致大量用户空间核心转储应用程序与受害容器竞争CPU周期。 通过将容器固定在不同的核心上，我们进一步改变了恶意容器的核心亲缘性。尽管恶意容器不再与受害者竞争同一内核上的CPU资源，但它在受害者的性能上仍然显示出类似的结果。这是因为CPU资源的主要竞争对手不是恶意容器，而是那些触发内核转储的应用程序。 这一结果表明，恶意租户可以很容易地利用容器来显著降低同一主机上所有其他容器的性能，并降低服务供应商的服务质量，从而可能导致巨大的经济损失，而成本很少。 Case 2:Data Synchronization我们的第二个案例是利用磁盘数据同步的回写机制，出于性能考虑，该机制被广泛采用。CPU只会将更新后的数据写入缓存，当缓存被清除时，数据才会写入磁盘。 由于懒惰的磁盘回写机制将启动I&#x2F;O的进程与同步磁盘写入的进程解耦，所以我们的利用可以逃避cgroups。有多种方法可以触发数据同步，包括定期回写和内存不足。它也可以由用户进程通过系统调用故意调用，如sync（将缓存文件数据的所有未决修改写回给底层文件系统）、syncfs（同步开放文件所指的文件系统）和fsync（将文件的所有修改数据传输到其常驻磁盘设备）。这些系统调用对Linux容器是可用的。特别是，我们发现，同步可以被利用来减慢整个系统的I&#x2F;O性能（例如，在序列写入上有超过87%的降级），发起无资源攻击，并建立秘密通道。 Detailed analysis on sync 同步的第一步是启动一个内核线程，它将页缓存中包含的所有脏页刷新到磁盘。它通过扫描所有当前挂载的文件系统来查找要刷新的所有脏索引节点，并刷新相应的脏页。由于同步允许进程将所有脏缓冲区写回磁盘，任何I&#x2F;O操作都必须等待刷新。 更糟糕的是，由其他进程(可能属于另一个容器)生成的脏缓冲区也将被迫写回磁盘。 容器中的进程可以在不执行I&#x2F;O操作的情况下，以少量的工作负载重复调用sync。但是，与此同时，如果在其他共驻留容器上有I&#x2F;O操作，同步将回写所有脏页。在我们的实验中，我们运行了一个不断调用sync的容器。它不会导致超出容器限制的任何额外利用率。然而，一旦我们运行另一个容器，进行一些简单的写操作，同步操作就会导致大量的CPU等待时间，这是同步和写操作的组合所产生的。CPU等待时间用于指示I&#x2F;O等待所消耗的时间，其他工作负载仍然可以使用它。 但是，在其他容器上运行的特定工作负载的性能会受到显著影响。 blkio cgroup 正如2.1节中提到的，blkio cgroup子系统可以对块设备应用I&#x2F;O控制。虽然Docker只支持通过权重来限制相对I&#x2F;O吞吐量，但内核实际上可以为cgroups设置一个上限。我们使用blkio对运行同步的容器应用I&#x2F;O控制。不幸的是，基于Docker的统计工具，容器的I&#x2F;O吞吐量为零。因此，blkio控制器不能减少同步的影响。原因是由sync触发的所有回写工作负载都在内核线程中处理，调用sync的容器没有I&#x2F;O工作负载。 I&#x2F;O-based DoS attacks 不管发出I&#x2F;O操作的进程是否在容器内，在容器内调用系统调用同步将继续调用系统范围的回写。在某些情况下，回写会降低系统性能，因为特定的工作负载需要等待回写完成。为了测试有效性，我们运行两个固定在两个不同核心上的容器。恶意容器所做的唯一任务是调用系统调用sync，因此本身不会招致I&#x2F;O操作。 为了测量受害容器的性能，我们在受害容器内运行FIO基准测试[25]来测量I&#x2F;O性能。特别地，我们进行了四种不同的FIO工作负载，包括序列&#x2F;随机写和序列&#x2F;随机读。我们还运行UnixBenchmark来测试除I&#x2F;O以外对性能的影响。我们通过将结果除以恶意容器中运行空闲循环的基线情况来计算性能下降。结果如图所示。对于UnixBenchmark，我们列出了性能显著下降的工作负载。总的来说，我们可以看到在受害者中运行的FIO基准测试的性能受到了很大的影响。通过在恶意容器中不断调用sync，所有四种类型I&#x2F;O操作的性能都会受到显著影响。对于顺序写入，在我们的本地测试床上性能下降到2%，在EC2服务器上下降到13%。 对于UnixBenchmark，运行shell脚本的性能也严重降低到不到一半。对于其他基准测试，退化约为5%到10%。 Resource-Freeing Attack(RFA) RFA攻击的目标是通过争夺受害者的瓶颈资源来为攻击者的实例释放特定的资源。在容器环境的情况下，两个容器在争夺系统资源，如CPU。恶意容器试图提高其工作负载的性能（被称为beneficiary），以获得更多的系统资源。因此，恶意容器运行另一个轻量级程序（被称为helper）来释放受害者容器使用的资源，以便受益者能够获得更多的资源。帮助者只消耗很少的系统资源（因此它对beneficiary几乎没有影响），但可以显著影响在受害者容器内运行的工作负载。例如，在恶意容器中，受益者程序可以运行CPU密集型的工作负载，并与受害者容器在同一CPU核心上竞争CPU资源。受害者容器运行I&#x2F;O密集型的工作负载，因此CPU活动与I&#x2F;O操作的频率相联系：更多的I&#x2F;O操作使受害者容器消耗更多的CPU周期来处理这些请求。然后，恶意者运行一个辅助程序，定期调用sync，触发回写，并减少受害者的I&#x2F;O活动。这样可以降低受害者容器的CPU使用率，恶意容器可以获得更多的CPU资源。我们通过在同一个核上运行两个容器来模拟实验。在受害容器中，我们模拟了一个网络爬虫的情况，其中容器不断地将一个网页写入一个新文件。 我们使用sysbench来测量恶意容器的CPU和内存性能，其中值越高表示性能越好。恶意容器还会定期调用sync来触发全局回写。对于基线情况，只有攻击者的容器是活动的，因此不存在对所有系统资源的竞争。然后，我们运行这两个容器，并将攻击者容器的性能与基线情况进行比较。如图，在没有RFA攻击的情况下，由于两个容器争夺同一核上的CPU资源，CPU性能(即白条)约为无竞争情况(即黑条)的一半，内存性能约为无竞争情况的1&#x2F;3。然而，通过发起RFA攻击(即灰色条)，恶意容器内的受益人可以在两个测试平台上获得更好的性能。特别是，在我们的本地服务器上，性能几乎与没有竞争的情况相同。 Covert Channels 最后，我们证明了cgroups中的不足也可能被恶意攻击者利用，在不同的核心之间构建基于时间的隐蔽通道。其思想是利用由磁盘数据同步引起的性能差异。我们测量在一个容器中写入10个文件的时间，同时在另一个内核的另一个容器中运行sync。 我们重复实验100次，所需要的时间分布如图所示。我们可以观察到运行同步和不运行同步之间打开文件的明显时间差异。我们通过利用性能差异构建了一个概念验证通道，能够以2bits&#x2F;s的速率传输数据，错误率为2%。 Case 3:System Process - Journald我们的第三个案例是利用system - Journal服务，它提供了一个系统服务来收集系统日志数据，包括内核日志消息、系统日志消息(例如，syslog调用或Journal API)，以及通过审计子系统的审计记录。所有相关的活动都由系统进程日志记录。在我们的案例研究中，我们发现容器中的三类操作可以迫使日志进程记录日志，导致5%到20%的额外CPU利用率和平均2MB&#x2F;s的I&#x2F;O吞吐量，然后可以利用这些影响其他容器的性能。 Detailed analysis 主机的系统进程被附加到不同于容器中的进程的cgroup中，因为它们是由操作系统维护的，以提供全系统的功能。因此，如果容器内的工作负载可以触发这些系统进程的活动，那么这些活动所消耗的资源将不会被计入容器的cgroup，从而逃避资源控制机制。但是，运行在主机上的系统进程会忽略容器内的大部分操作。例如，在主机上运行的用户空间进程的许多活动将由日志记录。但是如果流程在容器内运行，那么这些活动将被忽略。为了记录容器内的事件，主机上的系统管理员需要更改system -journal服务的配置。 特别是，Docker提供了一个选项来启用日志记录。 然而，我们发现，即使没有启用日志记录选项，在某些特定的情况下，容器仍然能够在日志系统进程上生成不可忽略的工作负载。 特别地，我们介绍了导致系统进程负载的三种类型的操作，从而逃脱了cgroup的控制。 Switch user (su) command su命令提供了一种将登录会话的所有权切换到root用户的方法。 切换到root用户的操作将被记录在日志系统进程中。日志包含进程、用户帐户和环境切换的信息。日志服务也会记录用户的退出。使用USER namespace，容器内的根用户映射到主机上的无特权用户。因此，容器中的进程可能在USER名称空间中拥有完全的特权，但实际上在主机上被剥夺了特权。作为容器中的根用户，su命令可以进入另一个用户。不幸的是，在容器内切换帐户所引起的活动将触发system -journal服务来记录相关信息。 Add user&#x2F;group 在USER namespace中，容器用户可以添加新组或在现有组中添加新帐户。这些活动也将由主机上的日志系统进程记录。 Exception 最后，如前所述，内核无法区分所引发异常的上下文(在容器内部或外部)。因此，容器内异常引起的崩溃信息也会触发主机上系统进程的日志记录活动。 所有上述工作负载都将在日志中触发大量事件日志记录。同样，我们将一个容器设置为具有一个CPU核心计算能力，以继续调用上述命令。在我们的本地测试床上，我们观察到journald上的CPU使用率恒定为3.5%，auditd上的CPU使用率恒定为2.5%，kauditd上的CPU使用率恒定为1%。在EC2服务器中，由于其更好的I&#x2F;O性能，这个数字要大得多:我们观察到平均CPU利用率约为20%。我们还发现，journald进程的平均I&#x2F;O吞吐量约为2MB&#x2F;s，而容器的I&#x2F;O吞吐量为零。如果我们为容器分配更多的计算资源，这个数字将会增加。 DoS attacks 日志journald活动将产生不可忽略的I&#x2F;O操作，这将导致与其他容器的资源竞争。为了衡量结果，我们在主机的不同内核上运行两个容器。在恶意容器中，我们不断切换用户(即su)并退出当前用户(即exit)。在受害容器中，运行与case 2中描述的相同的基准测试。 图显示了结果。总的来说，我们看到整个系统的性能下降。在I&#x2F;O性能较差的服务器(例如，我们的本地测试平台)中，滥用journald的攻击将更加有效。如前所述，它在日志进程中可能导致超过2MB&#x2F;s的I&#x2F;O吞吐量。我们观察到它仍然可以使EC2专用服务器上的其他容器在1000iops(吞吐量约为15MB&#x2F;s)时变慢。在一个具有默认配置的专用服务器中(例如，400 IOPS，吞吐量约为6MB&#x2F;s)，我们可以观察到更明显的结果。 Residual effect 在I&#x2F;O性能较差的服务器上，系统进程的写工作负载可能超过服务器的I&#x2F;O能力。结果，大量的日志事件被排队，等待稍后被记录。这将导致一个残留效应:即使容器停止了它的工作负载(例如su)，系统仍将继续在journald中写入，直到队列中的工作负载完成。残留效应在我们的本地测试平台上很明显，并且持续的时间比工作负载的运行时间长得多。即使容器完全空闲，CPU和I&#x2F;O资源也会被消耗。更糟糕的是，这些写入操作将显著影响其他容器和主机的I&#x2F;O性能。 Case 4:Container Engine容器的第四种情况是通过在内核线程(例如kworker)和容器引擎上触发额外的工作负载来利用容器引擎，容器引擎需要在主机上运行以支持和管理容器实例。特别是，容器引擎作为系统上的特权守护进程运行，因此它作为容器实例附加到不同的cgroup上。容器实例上的cgroup限制将不能控制引擎上消耗的资源。总的来说，通过这种方式，我们发现一个容器可以将资源消耗增加到大约3倍。 Detailed analysis 我们首先简要介绍Docker容器引擎及其cgroup层次结构。Docker创建一个包含所有容器实例的Docker cgroup。每个容器由其ID标识，并保存由fork创建的所有进程。从理论上讲，容器内运行的所有工作负载都将被计入容器cgroup。 此外，Docker构建在Docker引擎之上，其中一个守护进程(即dockerd)在后台运行，处理Docker映像的管理。Docker引擎然后与containd(一个守护进程)通信，以进一步使用runC来运行容器。dockerd进程对于每个容器实例都有多个子进程。这些进程被附加到所有系统服务的默认cgroup中。 此外，用户主要通过命令行接口(CLI)客户端(即Docker进程)控制和管理Docker, Docker进程通过Docker REST API与Docker守护进程交互。Docker CLI为用户提供了创建或执行容器的接口。它还提供了多个命令来设置与底层控制组相关的资源限制的配置。与Docker引擎进程类似，Docker CLI也不属于容器的cgroup。 利用容器引擎来打破cgroups的控制是相当容易的。一种简单的方法是利用终端子系统。当容器用户与tty设备交互时，数据首先经过CLI进程和容器守护进程，然后到达tty驱动程序进行进一步处理。具体来说，数据被发送到LDISC, LDISC连接高级通用接口(例如，读、写、ioctl)和终端系统中的低级设备驱动程序。通过在kworker内核线程中执行工作队列将数据刷新到LDISC。因此，内核线程上的所有工作负载和所有容器引擎进程都不会被计算到容器实例中。 我们通过在终端中反复显示主机中所有加载的模块来测量容器引擎中生成的工作负载，并将结果说明在图中。同样，容器的使用仅限于一个核心(如图中的container)。 总的来说，使用一个核心的计算能力(100%的利用率)，容器可以通过滥用docker引擎进程在主机上造成大约300%的工作负载。 为了细分使用情况，docker进程属于主机的用户cgroup；其他docker进程属于一个系统cgroup：docker.service。其余的（大部分是内核线程kworker，由于流媒体工作负载，如第3.2节所解释）属于根cgroup。我们还在case 1中进行了与表类似的实验。通过利用Docker容器引擎，攻击者能够降低CPU和内存的性能大约15%。 Case 5:Softirq Handling最后一种情况是利用Linux内核中的softirq处理机制。当前内核定义了11种类型的softirq。特别是，硬件中断处理程序通常会引发软中断。 虽然大多数硬件中断可能不是由容器直接引发的，但容器用户能够操作网络接口上的工作负载生成NET softirq，或块设备生成block softirq。处理这些softirq会消耗内核线程进程上下文(例如ksoftirqd)或中断上下文上的CPU资源。 NET softtirq 一旦NIC完成数据包传输，就会引发中断，而softirq负责在驱动程序缓冲区和网络堆栈之间移动数据包。但是，在流量带宽有限的情况下，使用softirqs带来的开销可以忽略不计:在之前的工作中，当网络流量超过1gbps时，开销为1%。 我们发现，由于网络流量引起的开销会被服务器上的防火墙系统(如iptables)大大放大。iptables建立在netfilter的基础上，提供了一个管理层，用于包过滤规则的添加和删除。netfilter将数据包挂在网络驱动程序和网络堆栈之间。所有的网络数据包首先通过过滤规则进行检查，然后进行进一步的操作(例如，转发、丢弃、由网络堆栈处理)。因此，iptables下的网络流量处理是在softirq上下文中处理的，因此不会向生成或接收流量的容器收费。 在Linux上，Docker依赖于配置iptables规则来为容器提供网络隔离。特别是，它可能为提供web或网络服务的容器设置多个规则。即使容器停止，规则也存在。更糟糕的是，在某些情况下，如果相关标志设置为true，容器可以对系统iptables规则进行更改。一旦有相当数量的规则，开销将是不可忽略的。 我们测量了softirq在不同数量的iptables规则下处理网络流量所带来的开销，如图所示。特别是，我们测量了所有ksoftirqd内核线程的CPU使用情况，以及花在中断上下文上的时间(来自top命令的hi和si)。在我们本地的测试台上，网卡的容量为100mbit &#x2F;s，网络流量约为20 ~ 30mbit &#x2F;s，明显小于中的Gbps级别。我们可以清楚地看到，处理网络流量会产生巨大的开销，并且与规则数量密切相关。当规则数量达到5000条时，CPU将浪费大量的时间(约16%)处理软tirq，并且不会向发起网络流量的容器收费。一旦服务器中有10,000条规则，开销约为40%，其中大多数集中在一个核心上。 EC2服务器有一个非常强大的网卡，具有10,000 Mbit&#x2F;s的容量，与我们的本地测试平台相比带宽更高。因此，与我们的本地测试平台相比，开销略小。在我们的实验中，当网络流量约为300mbit &#x2F;s时，流量仍然会浪费不可忽略的CPU周期。如3.4节所述，软件中断的处理要么抢占当前工作，要么在内核线程中消耗CPU周期。因此，同一核心上的所有其他工作负载将被延迟。 BLOCK softirq 处理softirq时增加工作负载的另一个例子是块设备上的I&#x2F;O操作。Linux内核使用队列存储块请求I&#x2F;O，并将新的请求添加到队列中。一旦请求处理完成，它将引发在softirq上下文中处理的softirq，以进一步处理队列。然后，利用BLOCK softirq转义cgroups的基本思想类似于利用NET softirq。 在容器上下文中，可以通过持续查询完成队列中的事件并提交写或读操作来生成这样的工作负载。对于I&#x2F;O性能较差的设备，这种影响尤其明显。为了进一步定量度量影响，我们使用固定在一个内核上的容器，运行fio推荐来执行顺序读写。我们选择小块用于写入，大块用于读取。我们测量多个内核线程(如kworker)的CPU利用率。容器中的工作负载能够在我们的本地测试平台上的内核上生成不可忽略的工作量，包括相同内核的kworker上16.7%的工作负载。此外，对于序列I&#x2F;O读取，文件分配过程在jpd2和kswapd上分别产生了3.9%和3.8%的额外利用率。最后，我们还利用kworker来测量退化。我们在同一个内核上的内核线程kworker上创建工作负载，攻击者能够对受害者造成大约10%的性能损失(根据sysbench基准测试测量)。 MITIGATION DISCUSSION在这一节中，我们将介绍我们在以下方面的初步努力应对现有cgroups机制的不足所带来的安全问题。由于大多数问题涉及多个内核子系统，因此很难部署一个单一的解决方案来全面彻底地解决所有问题。另外，解决一些问题可能需要重新设计当前的资源核算系统。在下文中，我们将从不同角度讨论潜在的缓解方法。 直观地说，通过考虑由一组进程(或容器)直接或间接生成的所有工作负载，cgroups应该具有细粒度的计算机制。例如，如果一个容器通过内核线程调用另一个用户空间进程，容器的cgroup应该由内核线程传递，这样它也会被复制到新的用户空间进程。因此，新调用的进程与容器属于同一个cgroup，而不是与内核线程属于根cgroup。虽然这种方法可以应用于新生成的进程，但很难处理系统中已经存在的进程。内核线程(如kworker、ksoftirqd)是由内核创建的，用于处理特定的内核工作负载，这些工作负载可能由附加到不同cgroup的不同进程触发。journald系统进程的情况也类似:它记录所有进程引发的所有相关事件，因此将整个日志进程附加到特定的cgroup是不合理的。因此，综合机制不应该改变这些线程的cgroup，而是应该跟踪特定工作量的系统资源，并将其收费给初始进程。例如，Iron跟踪处理每个网络数据包的CPU周期，并向相关进程收费。然而，这样的方法无疑需要大量的内核开发工作，并且由于将多个内核函数用于细粒度资源跟踪而带来大量的运行时开销。 对于某些工作负载，另一个有争议的问题是cgroup是否应该向容器收取这些系统资源。从隐私的角度考虑，主机服务器不应该记录容器实例中运行的任何敏感信息。journald提供了特定的选项来启用容器内的日志活动。但是，我们展示了，即使没有启用日志记录选项，主机仍然为容器记录多个事件。日志记录是由主机执行的，因此不应该向容器收费。此外，容器用户无法获得容器内引发的异常的核心转储信息。因此，一种可能的方法是通过区分容器上下文禁用所有潜在的日志记录或记录活动。完全解决这个问题的另一种方法是构建一个额外的cgroup子系统，专门用于日志记录。所有日志记录活动都将由新的日志记录cgroup子系统进行记录。 最后，有些问题即使使用细粒度的会计机制也无法解决。例如，虽然当前的cgroups机制清楚地提到回写工作负载不被计算在内，但Linux内核维护者已经开始开发新的cgroup机制(即cgroup v2)，它利用内存和blkio子系统来跟踪回写并为脏页的容器收费。然而，恶意容器可以在不生成任何I&#x2F;O工作负载的情况下继续调用sync。回写工作负载由具有I&#x2F;O操作的容器承担，而不是由恶意容器承担。同时，向调用数据同步的容器收取所有费用是不公平的。由于简单地禁用所有这些功能将不可避免地影响可用性，一个潜在可行的解决方案是对这些敏感操作施加速率限制。 RELATED WORK在本节中，我们调查了一些启发我们工作的研究工作，并强调了我们的工作与以往研究之间的差异。我们主要讨论以下两个方面的研究工作: Virtual Machine and Container虽然VM已经迎来了云计算时代，但尽管进行了大量的研究工作，其性能仍然不能令人满意。容器正变得越来越流行，因为它提供了一种启用轻量级虚拟化的替代方式，并允许在容器中运行的应用程序完全兼容。因此，研究人员对硬件虚拟化和容器之间的性能比较很好奇。Felter等人表明，通过使用一组涵盖CPU、内存、存储和网络资源的基准测试，Docker在所有情况下都可以实现比KVM更高的性能。 Spoiala等还证明了Docker优于KVM，并且可以使用Kurento Media Server来测试WebRTC服务器的性能，从而支持实时应用程序。Morabito et al进一步比较了传统hypervisor(例如KVM)和os级虚拟化(包括Docker和LXC)在计算、存储、内存和网络方面的性能，并观察到磁盘I&#x2F;O仍然是KVM hypervisor的瓶颈。所有这些工作都表明，基于容器的操作系统级虚拟化是比传统的基于vm的硬件虚拟化更有效的解决方案。虽然以前的大多数研究工作都集中在理解容器的性能上，但很少有人试图调查底层内核机制的资源共享的有效性。我们是第一批系统地研究由Cgroup不足引起的容器的性能和资源核算问题的人。 Container security除了性能，容器的安全性也受到了学术界和业界的广泛关注。Gupta首先简要介绍了Docker安全性。Bui从隔离和相应的内核安全机制方面对Docker容器进行了分析。虽然之前的工作声称Docker容器在默认配置下是相当安全的，但Lin等人发现，大多数现有的漏洞都可以通过默认配置成功地从容器内部发起攻击。Grattafiori等人总结了容器的各种潜在漏洞，包括基于内存的伪文件系统中的问题。Gao等人进一步对基于内存的伪文件系统由于namespace问题而产生的潜在安全影响进行了系统研究。Lei等人提出了一种名为SPEAKER的容器安全机制，以减少对应用程序的可用系统调用数量。Sun等人开发了两个安全命名空间，为容器实现自主安全控制，Arnautov等人提出使用Intel SGX保护Linux容器。 错误配置的能力也可以被利用来建立容器中的秘密通道。我们在cgroup方面的工作进一步补充了以前的的研究工作。 Cloud SecurityCo-residence大量的研究工作也致力于理解云的安全问题，特别是不同租户共享相同计算基础设施的多租户云。在多租户云环境中，攻击者可以将恶意虚拟机与目标虚拟机共同驻留在同一台服务器上，然后发起包括侧通道和隐蔽通道攻击在内的各种攻击。同时，侧面攻击和隐蔽通道攻击是验证同一物理服务器上共存的常用方法。例如，基于缓存的隐蔽通道被广泛采用，因为多个实例共享同一个包上的最后一级缓存。Zhang等人进一步论证了在云上发起真实侧通道攻击的可行性。除了基于缓存的通道，其他方法如内存总线、内存重复数据删除、核心温度也可以有效地构建隐蔽通道。 虽然也提出了多种防御机制，但之前的两项工作表明，在现有的主流云服务中实现合住仍然是可行的(而且成本低廉)。Wang等人对三种无服务器计算服务进行了大规模的测量研究，发现了几个资源核算问题，租户可能会滥用这些问题来运行额外的工作负载。 Denial-of-Service attacks由于底层计算资源在不同的租户之间共享，因此争用是不可避免的。Varadarajan等人提出了资源释放攻击来释放受害者使用的资源，这样攻击者的实例就可以获得额外的利用。Zhang等人调查了内存DoS攻击的影响，并表明恶意云客户可以对电子商务网站造成38倍的延迟。对于针对I&#x2F;O性能的DoS攻击，Huang等提出了级联性能攻击，以耗尽hypervisor的I&#x2F;O处理能力。此外，多种攻击试图耗尽共享的基础设施资源，如电力设施，从而迫使数据中心的服务器关闭。与之前的工作不同，我们的工作表明，cgroups中的不足也可以被利用来在多租户容器环境中发起多次攻击。 CONCLUSION在本文中，我们开发了一套策略来打破Linux控制组的资源控制。我们证明了通过进程创建继承的cgroups限制并不总是保证一致和公平的资源核算。我们可以通过与原始cgroup解关联的进程来生成带外工作负载。 我们进一步提出了五个案例研究，表明在Docker容器环境中实现这些攻击是可行的。恶意容器利用多租户容器环境中cgroups的这些不足，可以极大地耗尽主机的资源，并发起多种攻击，包括拒绝服务攻击、资源释放攻击和秘密通道攻击。我们在亚马逊EC2云中的本地测试平台和专用服务器上进行了实验，并证明了一个容器可以将其工作负载放大200倍以上，并将其他容器的性能降低95%。","categories":[{"name":"论文精读","slug":"论文精读","permalink":"http://example.com/categories/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/"},{"name":"内核安全","slug":"论文精读/内核安全","permalink":"http://example.com/categories/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/%E5%86%85%E6%A0%B8%E5%AE%89%E5%85%A8/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"内核安全","slug":"内核安全","permalink":"http://example.com/tags/%E5%86%85%E6%A0%B8%E5%AE%89%E5%85%A8/"}]},{"title":"C++学习 函数高级","slug":"C++-学习-函数高级","date":"2023-04-15T00:36:52.000Z","updated":"2023-04-15T02:00:47.193Z","comments":true,"path":"2023/04/15/C++-学习-函数高级/","link":"","permalink":"http://example.com/2023/04/15/C++-%E5%AD%A6%E4%B9%A0-%E5%87%BD%E6%95%B0%E9%AB%98%E7%BA%A7/","excerpt":"","text":"函数默认参数在C++中，函数形参列表中的形参是可以有默认值的 语法：返回值类型 函数名 （参数 = 默认值） 123456789101112#include &lt;iostream&gt;using namespace std;int func(int a, int b = 20, int c = 3)&#123; return a + b + c;&#125;int main()&#123; cout &lt;&lt; func(10) &lt;&lt; endl; cout &lt;&lt; func(10, 30) &lt;&lt; endl;&#125; 运行结果如下： 60 70 注意事项 如果某个位置已经有了默认参数，那么从这个位置往后，从左到右都必须有默认值 声明和实现只能有一个有默认参数 12345678910#include &lt;iostream&gt;using namespace std;int func(int a = 10, int b = 10);int func(int a = 10, int b = 10) &#123; return a + b;&#125;int main()&#123; cout &lt;&lt; func() &lt;&lt; endl;&#125; 运行结果为： 函数占位参数C++中函数的形参列表里可以有占位参数，用来做占位，调用参数时必须填补该位置 语法：返回值类型 函数名 (数据类型)&#123;&#125; 1234567891011#include &lt;iostream&gt;using namespace std;void func(int a, int)&#123; cout &lt;&lt; 1 &lt;&lt; endl; return;&#125;int main()&#123; func(10, 10);&#125; 或者 1234567891011#include &lt;iostream&gt;using namespace std;void func(int a, int = 10)&#123; cout &lt;&lt; 1 &lt;&lt; endl; return;&#125;int main()&#123; func(10);&#125; 函数重载函数重载概述作用：函数名可以相同，提高复用性 函数重载满足条件： 同一个作用域下 函数名称相同 函数参数类型不同或者个数不同或者顺序不同 注意：函数的返回值不可以作为函数重载的条件 1234567891011121314151617181920212223242526272829303132333435#include &lt;iostream&gt;using namespace std;void func()&#123; cout &lt;&lt; &quot;func()&quot; &lt;&lt; endl; return;&#125;void func(int a)&#123; cout &lt;&lt; &quot;func(int a)&quot; &lt;&lt; endl; return;&#125;void func(int a,int b)&#123; cout &lt;&lt; &quot;func(int a,int b)&quot; &lt;&lt; endl; return;&#125;void func(int a,double b)&#123; cout &lt;&lt; &quot;func(int a,double b)&quot; &lt;&lt; endl; return;&#125;void func(double a,int b)&#123; cout &lt;&lt; &quot;func(double a,int b)&quot; &lt;&lt; endl; return;&#125;int main()&#123; func(); func(1); func(1, 2); func(1, 3.1); func(3.1, 1);&#125; 运行结果为： func()func(int a)func(int a,int b)func(int a,double b)func(double a,int b) 函数重载注意事项 引用作为函数重载条件 12345678910111213141516171819#include &lt;iostream&gt;using namespace std;void func(int &amp;a)&#123; cout &lt;&lt; &quot;func(int &amp;a)&quot; &lt;&lt; endl; return;&#125;void func(const int &amp;a)&#123; cout &lt;&lt; &quot;func(const int &amp;a)&quot; &lt;&lt; endl; return;&#125;int main()&#123; int a = 10; func(a); func(10);&#125; 运行结果为： func(int &amp;a)func(const int &amp;a) 函数重载碰到默认参数 12345678910111213141516#include &lt;iostream&gt;using namespace std;void func(int a, int b = 10)&#123; cout &lt;&lt; &quot;func(int a, int b = 10)&quot; &lt;&lt; endl;&#125;void func(int a)&#123; cout &lt;&lt; &quot;func(int a)&quot; &lt;&lt; endl;&#125;int main()&#123; func(10);&#125; 运行结果为：","categories":[{"name":"编程语言","slug":"编程语言","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"},{"name":"C++","slug":"编程语言/C","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/C/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://example.com/tags/C/"}]},{"title":"MIT6 S081 Operating System Engineering Lecture05 Calling conventions and stack frames RISC-V(TA)","slug":"MIT6-S081-Operating-System-Engineering-Lecture05-Calling-conventions-and-stack-frames-RISC-V-TA","date":"2023-04-14T07:14:27.000Z","updated":"2023-04-14T12:59:02.805Z","comments":true,"path":"2023/04/14/MIT6-S081-Operating-System-Engineering-Lecture05-Calling-conventions-and-stack-frames-RISC-V-TA/","link":"","permalink":"http://example.com/2023/04/14/MIT6-S081-Operating-System-Engineering-Lecture05-Calling-conventions-and-stack-frames-RISC-V-TA/","excerpt":"","text":"C程序到汇编程序的转换当我们说到一个RISC-V处理器时，意味着这个处理器能够理解RISC-V的指令集。所以，任何一个处理器都有一个关联的ISA（Instruction Sets Architecture），ISA就是处理器能够理解的指令集。每一条指令都有一个对应的二进制编码或者一个Opcode。当处理器在运行时，如果看见了这些编码，那么处理器就知道该做什么样的操作。 所以通常来说，要让C语言能够运行在你的处理器之上。我们首先要写出C程序，之后这个C程序需要被编译成汇编语言。这个过程中有一些链接和其他的步骤，但是因为这门课不是一个编译器的课程，所以我们忽略这些步骤。之后汇编语言会被翻译成二进制文件也就是.obj或者.o文件。 如果你们曾经注意过你们的lab目录，在运行完make qemu之后你会看到一些.o文件，这些就是处理器能够理解的文件。虽然你还没有写任何汇编程序，你们也可以在目录中看到一些.asm文件，这是由C语言编译生成的。 汇编语言不具备C语言的组织结构，在汇编语言中你只能看到一行行的指令，比如add，mult等等。汇编语言中没有很好的控制流程，没有循环（注，但是有基于lable的跳转），虽然有函数但是与你们知道的C语言函数不太一样，汇编语言中的函数是以label的形式存在而不是真正的函数定义。汇编语言是一门非常底层的语言，许多其他语言，比如C++，都会编译成汇编语言。运行任何编译型语言之前都需要先生成汇编语言。 以上就是让计算机能够理解我们的C代码的基本流程。 RISC-V vs X86RISC-V和x86并没有它们第一眼看起来那么相似。RISC-V中的RISC是精简指令集（Reduced Instruction Set Computer）的意思，而x86通常被称为CISC，复杂指令集（Complex Instruction Set Computer）。这两者之间有一些关键的区别： 首先是指令的数量。实际上，创造RISC-V的一个非常大的初衷就是因为Intel手册中指令数量太多了。x86-64指令介绍由3个文档组成，并且新的指令以每个月3条的速度在增加。因为x86-64是在1970年代发布的，所以我认为现在有多于15000条指令。RISC-V指令介绍由两个文档组成。在这节课中，不需要你们记住每一个RISC-V指令，但是如果你感兴趣或者你发现你不能理解某个具体的指令的话，在课程网站的参考页面有RISC-V指令的两个文档链接。这两个文档包含了RISC-V的指令集的所有信息，分别是240页和135页，相比x86的指令集文档要小得多的多。这是有关RISC-V比较好的一个方面。所以在RISC-V中，我们有更少的指令数量。 除此之外，RISC-V指令也更加简单。在x86-64中，很多指令都做了不止一件事情。这些指令中的每一条都执行了一系列复杂的操作并返回结果。但是RISC-V不会这样做，RISC-V的指令趋向于完成更简单的工作，相应的也消耗更少的CPU执行时间。这其实是设计人员的在底层设计时的取舍。并没有一些非常确定的原因说RISC比CISC更好。它们各自有各自的使用场景。 相比x86来说，RISC另一件有意思的事情是它是开源的。这是市场上唯一的一款开源指令集，这意味着任何人都可以为RISC-V开发主板。RISC-V是来自于UC-Berkly的一个研究项目，之后被大量的公司选中并做了支持，网上有这些公司的名单，许多大公司对于支持一个开源指令集都感兴趣。 比如说ARM也是一个精简指令集，高通的Snapdragon处理器就是基于ARM。如果你使用一个Android手机，那么大概率你的手机运行在精简指令集上。如果你使用IOS，苹果公司也实现某种版本的ARM处理器，这些处理器运行在iPad，iPhone和大多数苹果移动设备上，甚至对于Mac，苹果公司也在尝试向ARM做迁移（注，刚刚发布的Macbook）。所以精简指令集出现在各种各样的地方。如果你想在现实世界中找到RISC-V处理器，你可以在一些嵌入式设备中找到。所以RISC-V也是有应用的，当然它可能没有x86那么流行。 在最近几年，由于Intel的指令集是在是太大了，精简指令集的使用越来越多。Intel的指令集之所以这么大，是因为Intel对于向后兼容非常看重。所以一个现代的Intel处理器还可以运行30&#x2F;40年前的指令。Intel并没有下线任何指令。而RISC-V提出的更晚，所以不存在历史包袱的问题。我们需要许多指令来实现向后兼容，向后兼容是否重要因人而异。另一方面，我认为这里许多指令都是cmd指令，用来完成一些特殊的操作。我从来没有见过一个Intel的汇编代码使用了所有的15000个指令。大多数这些指令都是为了向后兼容和cmd的需求创建。 如果查看RISC-V的文档，可以发现RISC-V的特殊之处在于：它区分了Base Integer Instruction Set和Standard Extension Instruction Set。Base Integer Instruction Set包含了所有的常用指令，比如add，mult。除此之外，处理器还可以选择性的支持Standard Extension Instruction Set。例如，一个处理器可以选择支持Standard Extension for Single-Precision Float-Point。这种模式使得RISC-V更容易支持向后兼容。 每一个RISC-V处理器可以声明支持了哪些扩展指令集，然后编译器可以根据支持的指令集来编译代码。 gdb和汇编代码执行这部分还不太会操作 RISC-V寄存器 这个表里面是RISC-V寄存器。寄存器是CPU或者处理器上，预先定义的可以用来存储数据的位置。寄存器之所以重要是因为汇编代码并不是在内存上执行，而是在寄存器上执行，也就是说，当我们在做add，sub时，我们是对寄存器进行操作。所以我们通常看到的汇编代码中的模式是，我们通过load将数据存放在寄存器中，这里的数据源可以是来自内存，也可以来自另一个寄存器。之后我们在寄存器上执行一些操作。如果我们对操作的结果关心的话，我们会将操作的结果store在某个地方。这里的目的地可能是内存中的某个地址，也可能是另一个寄存器。这就是通常使用寄存器的方法。 寄存器进行任何运算和数据读取的最快的方式。当调用函数时，我们调用函数时，我们会用ABI名字。 a0到a7寄存器是用来作为函数的参数。如果一个函数有超过8个参数，我们就需要用内存了。从这里也可以看出，当可以使用寄存器的时候，我们不会使用内存，我们只在不得不使用内存的场景才使用它。 表单中的第4列，Saver列，当我们在讨论寄存器的时候也非常重要。它有两个可能的值Caller，Callee。 Caller Saved寄存器在函数调用的时候不会保存 Callee Saved寄存器在函数调用的时候会保存 这里的意思是，一个Caller Saved寄存器可能被其他函数重写。假设我们在函数a中调用函数b，任何被函数a使用的并且是Caller Saved寄存器，调用函数b可能重写这些寄存器。我认为一个比较好的例子就是Return address寄存器（注，保存的是函数返回的地址），你可以看到ra寄存器是Caller Saved，这一点很重要，它导致了当函数a调用函数b的时侯，b会重写Return address。所以基本上来说，任何一个Caller Saved寄存器，作为调用方的函数要小心可能的数据可能的变化；任何一个Callee Saved寄存器，作为被调用方的函数要小心寄存器的值不会相应的变化。 Stack每一次我们调用一个函数，函数都会为自己创建一个Stack Frame，并且只给自己用。函数通过移动Stack Pointer来完成Stack Frame的空间分配。 对于Stack来说，是从高地址开始向低地址使用。所以栈总是向下增长。当我们想要创建一个新的Stack Frame的时候，总是对当前的Stack Pointer做减法。一个函数的Stack Frame包含了保存的寄存器，本地变量，并且，如果函数的参数多于8个，额外的参数会出现在Stack中。所以Stack Frame大小并不总是一样，即使在这个图里面看起来是一样大的。不同的函数有不同数量的本地变量，不同的寄存器，所以Stack Frame的大小是不一样的。但是有关Stack Frame有两件事情是确定的： Return address总是会出现在Stack Frame的第一位 指向前一个Stack Frame的指针也会出现在栈中的固定位置 有关Stack Frame中有两个重要的寄存器，第一个是SP（Stack Pointer），它指向Stack的底部并代表了当前Stack Frame的位置。第二个是FP（Frame Pointer），它指向当前Stack Frame的顶部。因为Return address和指向前一个Stack Frame的的指针都在当前Stack Frame的固定位置，所以可以通过当前的FP寄存器寻址到这两个数据。 我们保存前一个Stack Frame的指针的原因是为了让我们能跳转回去。所以当前函数返回时，我们可以将前一个Frame Pointer存储到FP寄存器中。所以我们使用Frame Pointer来操纵我们的Stack Frames，并确保我们总是指向正确的函数。 Stack Frame必须要被汇编代码创建，所以是编译器生成了汇编代码，进而创建了Stack Frame。所以通常，在汇编代码中，函数的最开始你们可以看到Function prologue，之后是函数的本体，最后是Epollgue。 struct基本上来说，struct在内存中是一段连续的地址，如果我们有一个struct，并且有f1，f2，f3三个字段。当我们创建这样一个struct时，内存中相应的字段会彼此相邻。你可以认为struct像是一个数组，但是里面的不同字段的类型可以不一样。","categories":[{"name":"课程学习","slug":"课程学习","permalink":"http://example.com/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"MIT6.S081 Operating System Engineering","slug":"课程学习/MIT6-S081-Operating-System-Engineering","permalink":"http://example.com/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/MIT6-S081-Operating-System-Engineering/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"C++学习 引用","slug":"C++-学习-引用","date":"2023-04-14T01:25:57.000Z","updated":"2023-04-14T05:54:56.535Z","comments":true,"path":"2023/04/14/C++-学习-引用/","link":"","permalink":"http://example.com/2023/04/14/C++-%E5%AD%A6%E4%B9%A0-%E5%BC%95%E7%94%A8/","excerpt":"","text":"引用的基本使用作用：给变量起别名 语法：数据类型 &amp;别名 &#x3D; 原名 123456789101112#include &lt;iostream&gt;using namespace std;int main()&#123; int a = 10; int&amp; b = a; cout &lt;&lt; &quot;a = &quot; &lt;&lt; a &lt;&lt; endl; cout &lt;&lt; &quot;b = &quot; &lt;&lt; b &lt;&lt; endl; b = 100; cout &lt;&lt; &quot;a = &quot; &lt;&lt; a &lt;&lt; endl; cout &lt;&lt; &quot;b = &quot; &lt;&lt; b &lt;&lt; endl;&#125; 运行结果为： a &#x3D; 10b &#x3D; 10a &#x3D; 100b &#x3D; 100 引用的注意事项 引用必须初始化 引用在初始化后，不可以改变 123456789101112#include &lt;iostream&gt;using namespace std;int main()&#123; int a = 10; int&amp; b = a; int c = 20; b = c; cout &lt;&lt; &quot;a = &quot; &lt;&lt; a &lt;&lt; endl; cout &lt;&lt; &quot;b = &quot; &lt;&lt; b &lt;&lt; endl; cout &lt;&lt; &quot;c = &quot; &lt;&lt; c &lt;&lt; endl;&#125; 运行结果为： a &#x3D; 20b &#x3D; 20c &#x3D; 20 引用做函数参数作用：函数传参时，可以利用引用的技术让形参修饰实参 优点：可以简化指针修改实参 123456789101112131415161718#include &lt;iostream&gt;using namespace std;void swap(int&amp; a, int&amp; b)&#123; int temp = a; a = b; b = temp; cout &lt;&lt; &quot;swap a = &quot; &lt;&lt; a &lt;&lt; endl; cout &lt;&lt; &quot;swap b = &quot; &lt;&lt; b &lt;&lt; endl;&#125;int main()&#123; int a = 10; int b = 20; swap(a, b); cout &lt;&lt; &quot;a = &quot; &lt;&lt; a &lt;&lt; endl; cout &lt;&lt; &quot;b = &quot; &lt;&lt; b &lt;&lt; endl;&#125; 运行结果为： swap a &#x3D; 20swap b &#x3D; 10a &#x3D; 20b &#x3D; 10 引用传递，形参会修饰实参 地址传递，形参会修饰实参 值传递，形参不会修饰实参 引用做函数返回值作用：引用是可以作为函数的返回值存在的 注意：不要返回局部变量引用 用法：函数调用作为左值 1234567891011121314#include &lt;iostream&gt;using namespace std;int&amp; test()&#123; static int a = 10; return a;&#125;int main()&#123; int&amp; ref = test(); cout &lt;&lt; &quot;ref = &quot; &lt;&lt; ref &lt;&lt; endl; test() = 1000; cout &lt;&lt; &quot;ref = &quot; &lt;&lt; ref &lt;&lt; endl;&#125; 运行结果如下： ref &#x3D; 10ref &#x3D; 1000 引用的本质本质：引用的本质是在C++内部实现一个指针常量 int&amp; ref = a;等价于int* const ref = a; ref = 20当编译器发现ref是引用，会自动帮我们解引用转换为*ref = 20 常量引用作用：常量引用主要用来修饰形参，防止误操作。 在函数形参列表中，可以加const 修饰形参，防止形参改变实参","categories":[{"name":"编程语言","slug":"编程语言","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"},{"name":"C++","slug":"编程语言/C","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/C/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://example.com/tags/C/"}]},{"title":"Linux v5.3.1 /fs/inode.c","slug":"Linux-v5-3-1-fs-inode-c","date":"2023-04-13T02:25:01.000Z","updated":"2023-04-13T02:56:01.649Z","comments":true,"path":"2023/04/13/Linux-v5-3-1-fs-inode-c/","link":"","permalink":"http://example.com/2023/04/13/Linux-v5-3-1-fs-inode-c/","excerpt":"","text":"1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871881891901911921931941951961971981992002012022032042052062072082092102112122132142152162172182192202212222232242252262272282292302312322332342352362372382392402412422432442452462472482492502512522532542552562572582592602612622632642652662672682692702712722732742752762772782792802812822832842852862872882892902912922932942952962972982993003013023033043053063073083093103113123133143153163173183193203213223233243253263273283293303313323333343353363373383393403413423433443453463473483493503513523533543553563573583593603613623633643653663673683693703713723733743753763773783793803813823833843853863873883893903913923933943953963973983994004014024034044054064074084094104114124134144154164174184194204214224234244254264274284294304314324334344354364374384394404414424434444454464474484494504514524534544554564574584594604614624634644654664674684694704714724734744754764774784794804814824834844854864874884894904914924934944954964974984995005015025035045055065075085095105115125135145155165175185195205215225235245255265275285295305315325335345355365375385395405415425435445455465475485495505515525535545555565575585595605615625635645655665675685695705715725735745755765775785795805815825835845855865875885895905915925935945955965975985996006016026036046056066076086096106116126136146156166176186196206216226236246256266276286296306316326336346356366376386396406416426436446456466476486496506516526536546556566576586596606616626636646656666676686696706716726736746756766776786796806816826836846856866876886896906916926936946956966976986997007017027037047057067077087097107117127137147157167177187197207217227237247257267277287297307317327337347357367377387397407417427437447457467477487497507517527537547557567577587597607617627637647657667677687697707717727737747757767777787797807817827837847857867877887897907917927937947957967977987998008018028038048058068078088098108118128138148158168178188198208218228238248258268278288298308318328338348358368378388398408418428438448458468478488498508518528538548558568578588598608618628638648658668678688698708718728738748758768778788798808818828838848858868878888898908918928938948958968978988999009019029039049059069079089099109119129139149159169179189199209219229239249259269279289299309319329339349359369379389399409419429439449459469479489499509519529539549559569579589599609619629639649659669679689699709719729739749759769779789799809819829839849859869879889899909919929939949959969979989991000100110021003100410051006100710081009101010111012101310141015101610171018101910201021102210231024102510261027102810291030103110321033103410351036103710381039104010411042104310441045104610471048104910501051105210531054105510561057105810591060106110621063106410651066106710681069107010711072107310741075107610771078107910801081108210831084108510861087108810891090109110921093109410951096109710981099110011011102110311041105110611071108110911101111111211131114111511161117111811191120112111221123112411251126112711281129113011311132113311341135113611371138113911401141114211431144114511461147114811491150115111521153115411551156115711581159116011611162116311641165116611671168116911701171117211731174117511761177117811791180118111821183118411851186118711881189119011911192119311941195119611971198119912001201120212031204120512061207120812091210121112121213121412151216121712181219122012211222122312241225122612271228122912301231123212331234123512361237123812391240124112421243124412451246124712481249125012511252125312541255125612571258125912601261126212631264126512661267126812691270127112721273127412751276127712781279128012811282128312841285128612871288128912901291129212931294129512961297129812991300130113021303130413051306130713081309131013111312131313141315131613171318131913201321132213231324132513261327132813291330133113321333133413351336133713381339134013411342134313441345134613471348134913501351135213531354135513561357135813591360136113621363136413651366136713681369137013711372137313741375137613771378137913801381138213831384138513861387138813891390139113921393139413951396139713981399140014011402140314041405140614071408140914101411141214131414141514161417141814191420142114221423142414251426142714281429143014311432143314341435143614371438143914401441144214431444144514461447144814491450145114521453145414551456145714581459146014611462146314641465146614671468146914701471147214731474147514761477147814791480148114821483148414851486148714881489149014911492149314941495149614971498149915001501150215031504150515061507150815091510151115121513151415151516151715181519152015211522152315241525152615271528152915301531153215331534153515361537153815391540154115421543154415451546154715481549155015511552155315541555155615571558155915601561156215631564156515661567156815691570157115721573157415751576157715781579158015811582158315841585158615871588158915901591159215931594159515961597159815991600160116021603160416051606160716081609161016111612161316141615161616171618161916201621162216231624162516261627162816291630163116321633163416351636163716381639164016411642164316441645164616471648164916501651165216531654165516561657165816591660166116621663166416651666166716681669167016711672167316741675167616771678167916801681168216831684168516861687168816891690169116921693169416951696169716981699170017011702170317041705170617071708170917101711171217131714171517161717171817191720172117221723172417251726172717281729173017311732173317341735173617371738173917401741174217431744174517461747174817491750175117521753175417551756175717581759176017611762176317641765176617671768176917701771177217731774177517761777177817791780178117821783178417851786178717881789179017911792179317941795179617971798179918001801180218031804180518061807180818091810181118121813181418151816181718181819182018211822182318241825182618271828182918301831183218331834183518361837183818391840184118421843184418451846184718481849185018511852185318541855185618571858185918601861186218631864186518661867186818691870187118721873187418751876187718781879188018811882188318841885188618871888188918901891189218931894189518961897189818991900190119021903190419051906190719081909191019111912191319141915191619171918191919201921192219231924192519261927192819291930193119321933193419351936193719381939194019411942194319441945194619471948194919501951195219531954195519561957195819591960196119621963196419651966196719681969197019711972197319741975197619771978197919801981198219831984198519861987198819891990199119921993199419951996199719981999200020012002200320042005200620072008200920102011201220132014201520162017201820192020202120222023202420252026202720282029203020312032203320342035203620372038203920402041204220432044204520462047204820492050205120522053205420552056205720582059206020612062206320642065206620672068206920702071207220732074207520762077207820792080208120822083208420852086208720882089209020912092209320942095209620972098209921002101210221032104210521062107210821092110211121122113211421152116211721182119212021212122212321242125212621272128212921302131213221332134213521362137213821392140214121422143214421452146214721482149215021512152215321542155215621572158215921602161216221632164216521662167216821692170217121722173217421752176217721782179218021812182218321842185218621872188218921902191219221932194219521962197219821992200220122022203220422052206220722082209221022112212221322142215221622172218221922202221222222232224222522262227222822292230223122322233223422352236223722382239224022412242224322442245224622472248224922502251225222532254225522562257225822592260226122622263226422652266226722682269227022712272227322742275227622772278// SPDX-License-Identifier: GPL-2.0-only/* * (C) 1997 Linus Torvalds * (C) 1999 Andrea Arcangeli &lt;andrea@suse.de&gt; (dynamic inode allocation) */#include &lt;linux/export.h&gt;#include &lt;linux/fs.h&gt;#include &lt;linux/mm.h&gt;#include &lt;linux/backing-dev.h&gt;#include &lt;linux/hash.h&gt;#include &lt;linux/swap.h&gt;#include &lt;linux/security.h&gt;#include &lt;linux/cdev.h&gt;#include &lt;linux/memblock.h&gt;#include &lt;linux/fsnotify.h&gt;#include &lt;linux/mount.h&gt;#include &lt;linux/posix_acl.h&gt;#include &lt;linux/prefetch.h&gt;#include &lt;linux/buffer_head.h&gt; /* for inode_has_buffers */#include &lt;linux/ratelimit.h&gt;#include &lt;linux/list_lru.h&gt;#include &lt;linux/iversion.h&gt;#include &lt;trace/events/writeback.h&gt;#include &quot;internal.h&quot;/* * Inode locking rules: * * inode-&gt;i_lock protects: * inode-&gt;i_state, inode-&gt;i_hash, __iget() * Inode LRU list locks protect: * inode-&gt;i_sb-&gt;s_inode_lru, inode-&gt;i_lru * inode-&gt;i_sb-&gt;s_inode_list_lock protects: * inode-&gt;i_sb-&gt;s_inodes, inode-&gt;i_sb_list * bdi-&gt;wb.list_lock protects: * bdi-&gt;wb.b_&#123;dirty,io,more_io,dirty_time&#125;, inode-&gt;i_io_list * inode_hash_lock protects: * inode_hashtable, inode-&gt;i_hash * * Lock ordering: * * inode-&gt;i_sb-&gt;s_inode_list_lock * inode-&gt;i_lock * Inode LRU list locks * * bdi-&gt;wb.list_lock * inode-&gt;i_lock * * inode_hash_lock * inode-&gt;i_sb-&gt;s_inode_list_lock * inode-&gt;i_lock * * iunique_lock * inode_hash_lock */static unsigned int i_hash_mask __read_mostly;static unsigned int i_hash_shift __read_mostly;static struct hlist_head *inode_hashtable __read_mostly;static __cacheline_aligned_in_smp DEFINE_SPINLOCK(inode_hash_lock);/* * Empty aops. Can be used for the cases where the user does not * define any of the address_space operations. */const struct address_space_operations empty_aops = &#123;&#125;;EXPORT_SYMBOL(empty_aops);/* * Statistics gathering.. */struct inodes_stat_t inodes_stat;static DEFINE_PER_CPU(unsigned long, nr_inodes);static DEFINE_PER_CPU(unsigned long, nr_unused);static struct kmem_cache *inode_cachep __read_mostly;static long get_nr_inodes(void)&#123; int i; long sum = 0; for_each_possible_cpu(i) sum += per_cpu(nr_inodes, i); return sum &lt; 0 ? 0 : sum;&#125;static inline long get_nr_inodes_unused(void)&#123; int i; long sum = 0; for_each_possible_cpu(i) sum += per_cpu(nr_unused, i); return sum &lt; 0 ? 0 : sum;&#125;long get_nr_dirty_inodes(void)&#123; /* not actually dirty inodes, but a wild approximation */ long nr_dirty = get_nr_inodes() - get_nr_inodes_unused(); return nr_dirty &gt; 0 ? nr_dirty : 0;&#125;/* * Handle nr_inode sysctl */#ifdef CONFIG_SYSCTLint proc_nr_inodes(struct ctl_table *table, int write, void __user *buffer, size_t *lenp, loff_t *ppos)&#123; inodes_stat.nr_inodes = get_nr_inodes(); inodes_stat.nr_unused = get_nr_inodes_unused(); return proc_doulongvec_minmax(table, write, buffer, lenp, ppos);&#125;#endifstatic int no_open(struct inode *inode, struct file *file)&#123; return -ENXIO;&#125;/** * inode_init_always - perform inode structure initialisation * @sb: superblock inode belongs to * @inode: inode to initialise * * These are initializations that need to be done on every inode * allocation as the fields are not initialised by slab allocation. */int inode_init_always(struct super_block *sb, struct inode *inode)&#123; static const struct inode_operations empty_iops; static const struct file_operations no_open_fops = &#123;.open = no_open&#125;; struct address_space *const mapping = &amp;inode-&gt;i_data; inode-&gt;i_sb = sb; inode-&gt;i_blkbits = sb-&gt;s_blocksize_bits; inode-&gt;i_flags = 0; atomic_set(&amp;inode-&gt;i_count, 1); inode-&gt;i_op = &amp;empty_iops; inode-&gt;i_fop = &amp;no_open_fops; inode-&gt;__i_nlink = 1; inode-&gt;i_opflags = 0; if (sb-&gt;s_xattr) inode-&gt;i_opflags |= IOP_XATTR; i_uid_write(inode, 0); i_gid_write(inode, 0); atomic_set(&amp;inode-&gt;i_writecount, 0); inode-&gt;i_size = 0; inode-&gt;i_write_hint = WRITE_LIFE_NOT_SET; inode-&gt;i_blocks = 0; inode-&gt;i_bytes = 0; inode-&gt;i_generation = 0; inode-&gt;i_pipe = NULL; inode-&gt;i_bdev = NULL; inode-&gt;i_cdev = NULL; inode-&gt;i_link = NULL; inode-&gt;i_dir_seq = 0; inode-&gt;i_rdev = 0; inode-&gt;dirtied_when = 0;#ifdef CONFIG_CGROUP_WRITEBACK inode-&gt;i_wb_frn_winner = 0; inode-&gt;i_wb_frn_avg_time = 0; inode-&gt;i_wb_frn_history = 0;#endif if (security_inode_alloc(inode)) goto out; spin_lock_init(&amp;inode-&gt;i_lock); lockdep_set_class(&amp;inode-&gt;i_lock, &amp;sb-&gt;s_type-&gt;i_lock_key); init_rwsem(&amp;inode-&gt;i_rwsem); lockdep_set_class(&amp;inode-&gt;i_rwsem, &amp;sb-&gt;s_type-&gt;i_mutex_key); atomic_set(&amp;inode-&gt;i_dio_count, 0); mapping-&gt;a_ops = &amp;empty_aops; mapping-&gt;host = inode; mapping-&gt;flags = 0; mapping-&gt;wb_err = 0; atomic_set(&amp;mapping-&gt;i_mmap_writable, 0); mapping_set_gfp_mask(mapping, GFP_HIGHUSER_MOVABLE); mapping-&gt;private_data = NULL; mapping-&gt;writeback_index = 0; inode-&gt;i_private = NULL; inode-&gt;i_mapping = mapping; INIT_HLIST_HEAD(&amp;inode-&gt;i_dentry); /* buggered by rcu freeing */#ifdef CONFIG_FS_POSIX_ACL inode-&gt;i_acl = inode-&gt;i_default_acl = ACL_NOT_CACHED;#endif#ifdef CONFIG_FSNOTIFY inode-&gt;i_fsnotify_mask = 0;#endif inode-&gt;i_flctx = NULL; this_cpu_inc(nr_inodes); return 0;out: return -ENOMEM;&#125;EXPORT_SYMBOL(inode_init_always);void free_inode_nonrcu(struct inode *inode)&#123; kmem_cache_free(inode_cachep, inode);&#125;EXPORT_SYMBOL(free_inode_nonrcu);static void i_callback(struct rcu_head *head)&#123; struct inode *inode = container_of(head, struct inode, i_rcu); if (inode-&gt;free_inode) inode-&gt;free_inode(inode); else free_inode_nonrcu(inode);&#125;static struct inode *alloc_inode(struct super_block *sb)&#123; const struct super_operations *ops = sb-&gt;s_op; struct inode *inode; if (ops-&gt;alloc_inode) inode = ops-&gt;alloc_inode(sb); else inode = kmem_cache_alloc(inode_cachep, GFP_KERNEL); if (!inode) return NULL; if (unlikely(inode_init_always(sb, inode))) &#123;//初始化inode，如果inode初始化失败，则销毁此inode if (ops-&gt;destroy_inode) &#123; ops-&gt;destroy_inode(inode); if (!ops-&gt;free_inode) return NULL; &#125; inode-&gt;free_inode = ops-&gt;free_inode; i_callback(&amp;inode-&gt;i_rcu); return NULL; &#125; return inode;&#125;void __destroy_inode(struct inode *inode)&#123; BUG_ON(inode_has_buffers(inode)); inode_detach_wb(inode); security_inode_free(inode); fsnotify_inode_delete(inode); locks_free_lock_context(inode); if (!inode-&gt;i_nlink) &#123; WARN_ON(atomic_long_read(&amp;inode-&gt;i_sb-&gt;s_remove_count) == 0); atomic_long_dec(&amp;inode-&gt;i_sb-&gt;s_remove_count); &#125;#ifdef CONFIG_FS_POSIX_ACL if (inode-&gt;i_acl &amp;&amp; !is_uncached_acl(inode-&gt;i_acl)) posix_acl_release(inode-&gt;i_acl); if (inode-&gt;i_default_acl &amp;&amp; !is_uncached_acl(inode-&gt;i_default_acl)) posix_acl_release(inode-&gt;i_default_acl);#endif this_cpu_dec(nr_inodes);&#125;EXPORT_SYMBOL(__destroy_inode);static void destroy_inode(struct inode *inode)&#123; const struct super_operations *ops = inode-&gt;i_sb-&gt;s_op; BUG_ON(!list_empty(&amp;inode-&gt;i_lru)); __destroy_inode(inode); if (ops-&gt;destroy_inode) &#123; ops-&gt;destroy_inode(inode); if (!ops-&gt;free_inode) return; &#125; inode-&gt;free_inode = ops-&gt;free_inode; call_rcu(&amp;inode-&gt;i_rcu, i_callback);&#125;/** * drop_nlink - directly drop an inode&#x27;s link count * @inode: inode * * This is a low-level filesystem helper to replace any * direct filesystem manipulation of i_nlink. In cases * where we are attempting to track writes to the * filesystem, a decrement to zero means an imminent * write when the file is truncated and actually unlinked * on the filesystem. */void drop_nlink(struct inode *inode)&#123; WARN_ON(inode-&gt;i_nlink == 0); inode-&gt;__i_nlink--; if (!inode-&gt;i_nlink) atomic_long_inc(&amp;inode-&gt;i_sb-&gt;s_remove_count);&#125;EXPORT_SYMBOL(drop_nlink);/** * clear_nlink - directly zero an inode&#x27;s link count * @inode: inode * * This is a low-level filesystem helper to replace any * direct filesystem manipulation of i_nlink. See * drop_nlink() for why we care about i_nlink hitting zero. */void clear_nlink(struct inode *inode)&#123; if (inode-&gt;i_nlink) &#123; inode-&gt;__i_nlink = 0; atomic_long_inc(&amp;inode-&gt;i_sb-&gt;s_remove_count); &#125;&#125;EXPORT_SYMBOL(clear_nlink);/** * set_nlink - directly set an inode&#x27;s link count * @inode: inode * @nlink: new nlink (should be non-zero) * * This is a low-level filesystem helper to replace any * direct filesystem manipulation of i_nlink. */void set_nlink(struct inode *inode, unsigned int nlink)&#123; if (!nlink) &#123; clear_nlink(inode); &#125; else &#123; /* Yes, some filesystems do change nlink from zero to one */ if (inode-&gt;i_nlink == 0) atomic_long_dec(&amp;inode-&gt;i_sb-&gt;s_remove_count); inode-&gt;__i_nlink = nlink; &#125;&#125;EXPORT_SYMBOL(set_nlink);/** * inc_nlink - directly increment an inode&#x27;s link count * @inode: inode * * This is a low-level filesystem helper to replace any * direct filesystem manipulation of i_nlink. Currently, * it is only here for parity with dec_nlink(). */void inc_nlink(struct inode *inode)&#123; if (unlikely(inode-&gt;i_nlink == 0)) &#123; WARN_ON(!(inode-&gt;i_state &amp; I_LINKABLE)); atomic_long_dec(&amp;inode-&gt;i_sb-&gt;s_remove_count); &#125; inode-&gt;__i_nlink++;&#125;EXPORT_SYMBOL(inc_nlink);static void __address_space_init_once(struct address_space *mapping)&#123; xa_init_flags(&amp;mapping-&gt;i_pages, XA_FLAGS_LOCK_IRQ | XA_FLAGS_ACCOUNT); init_rwsem(&amp;mapping-&gt;i_mmap_rwsem); INIT_LIST_HEAD(&amp;mapping-&gt;private_list); spin_lock_init(&amp;mapping-&gt;private_lock); mapping-&gt;i_mmap = RB_ROOT_CACHED;&#125;void address_space_init_once(struct address_space *mapping)&#123; memset(mapping, 0, sizeof(*mapping)); __address_space_init_once(mapping);&#125;EXPORT_SYMBOL(address_space_init_once);/* * These are initializations that only need to be done * once, because the fields are idempotent across use * of the inode, so let the slab aware of that. */void inode_init_once(struct inode *inode)&#123; memset(inode, 0, sizeof(*inode)); INIT_HLIST_NODE(&amp;inode-&gt;i_hash); INIT_LIST_HEAD(&amp;inode-&gt;i_devices); INIT_LIST_HEAD(&amp;inode-&gt;i_io_list); INIT_LIST_HEAD(&amp;inode-&gt;i_wb_list); INIT_LIST_HEAD(&amp;inode-&gt;i_lru); __address_space_init_once(&amp;inode-&gt;i_data); i_size_ordered_init(inode);&#125;EXPORT_SYMBOL(inode_init_once);static void init_once(void *foo)&#123; struct inode *inode = (struct inode *) foo; inode_init_once(inode);&#125;/* * inode-&gt;i_lock must be held */void __iget(struct inode *inode)&#123; atomic_inc(&amp;inode-&gt;i_count);&#125;/* * get additional reference to inode; caller must already hold one. */void ihold(struct inode *inode)&#123; WARN_ON(atomic_inc_return(&amp;inode-&gt;i_count) &lt; 2);&#125;EXPORT_SYMBOL(ihold);static void inode_lru_list_add(struct inode *inode)&#123; if (list_lru_add(&amp;inode-&gt;i_sb-&gt;s_inode_lru, &amp;inode-&gt;i_lru)) this_cpu_inc(nr_unused); else inode-&gt;i_state |= I_REFERENCED;&#125;/* * Add inode to LRU if needed (inode is unused and clean). * * Needs inode-&gt;i_lock held. */void inode_add_lru(struct inode *inode)&#123; if (!(inode-&gt;i_state &amp; (I_DIRTY_ALL | I_SYNC | I_FREEING | I_WILL_FREE)) &amp;&amp; !atomic_read(&amp;inode-&gt;i_count) &amp;&amp; inode-&gt;i_sb-&gt;s_flags &amp; SB_ACTIVE) inode_lru_list_add(inode);&#125;static void inode_lru_list_del(struct inode *inode)&#123; if (list_lru_del(&amp;inode-&gt;i_sb-&gt;s_inode_lru, &amp;inode-&gt;i_lru)) this_cpu_dec(nr_unused);&#125;/** * inode_sb_list_add - add inode to the superblock list of inodes * @inode: inode to add */void inode_sb_list_add(struct inode *inode)&#123; spin_lock(&amp;inode-&gt;i_sb-&gt;s_inode_list_lock); list_add(&amp;inode-&gt;i_sb_list, &amp;inode-&gt;i_sb-&gt;s_inodes); spin_unlock(&amp;inode-&gt;i_sb-&gt;s_inode_list_lock);&#125;EXPORT_SYMBOL_GPL(inode_sb_list_add);static inline void inode_sb_list_del(struct inode *inode)&#123; if (!list_empty(&amp;inode-&gt;i_sb_list)) &#123; spin_lock(&amp;inode-&gt;i_sb-&gt;s_inode_list_lock); list_del_init(&amp;inode-&gt;i_sb_list); spin_unlock(&amp;inode-&gt;i_sb-&gt;s_inode_list_lock); &#125;&#125;static unsigned long hash(struct super_block *sb, unsigned long hashval)&#123; unsigned long tmp; tmp = (hashval * (unsigned long)sb) ^ (GOLDEN_RATIO_PRIME + hashval) / L1_CACHE_BYTES; tmp = tmp ^ ((tmp ^ GOLDEN_RATIO_PRIME) &gt;&gt; i_hash_shift); return tmp &amp; i_hash_mask;&#125;/** * __insert_inode_hash - hash an inode * @inode: unhashed inode * @hashval: unsigned long value used to locate this object in the * inode_hashtable. * * Add an inode to the inode hash for this superblock. */void __insert_inode_hash(struct inode *inode, unsigned long hashval)&#123; struct hlist_head *b = inode_hashtable + hash(inode-&gt;i_sb, hashval); spin_lock(&amp;inode_hash_lock); spin_lock(&amp;inode-&gt;i_lock); hlist_add_head(&amp;inode-&gt;i_hash, b); spin_unlock(&amp;inode-&gt;i_lock); spin_unlock(&amp;inode_hash_lock);&#125;EXPORT_SYMBOL(__insert_inode_hash);/** * __remove_inode_hash - remove an inode from the hash * @inode: inode to unhash * * Remove an inode from the superblock. */void __remove_inode_hash(struct inode *inode)&#123; spin_lock(&amp;inode_hash_lock); spin_lock(&amp;inode-&gt;i_lock); hlist_del_init(&amp;inode-&gt;i_hash); spin_unlock(&amp;inode-&gt;i_lock); spin_unlock(&amp;inode_hash_lock);&#125;EXPORT_SYMBOL(__remove_inode_hash);void clear_inode(struct inode *inode)&#123; /* * We have to cycle the i_pages lock here because reclaim can be in the * process of removing the last page (in __delete_from_page_cache()) * and we must not free the mapping under it. */ xa_lock_irq(&amp;inode-&gt;i_data.i_pages); BUG_ON(inode-&gt;i_data.nrpages); BUG_ON(inode-&gt;i_data.nrexceptional); xa_unlock_irq(&amp;inode-&gt;i_data.i_pages); BUG_ON(!list_empty(&amp;inode-&gt;i_data.private_list)); BUG_ON(!(inode-&gt;i_state &amp; I_FREEING)); BUG_ON(inode-&gt;i_state &amp; I_CLEAR); BUG_ON(!list_empty(&amp;inode-&gt;i_wb_list)); /* don&#x27;t need i_lock here, no concurrent mods to i_state */ inode-&gt;i_state = I_FREEING | I_CLEAR;&#125;EXPORT_SYMBOL(clear_inode);/* * Free the inode passed in, removing it from the lists it is still connected * to. We remove any pages still attached to the inode and wait for any IO that * is still in progress before finally destroying the inode. * * An inode must already be marked I_FREEING so that we avoid the inode being * moved back onto lists if we race with other code that manipulates the lists * (e.g. writeback_single_inode). The caller is responsible for setting this. * * An inode must already be removed from the LRU list before being evicted from * the cache. This should occur atomically with setting the I_FREEING state * flag, so no inodes here should ever be on the LRU when being evicted. */static void evict(struct inode *inode)&#123; const struct super_operations *op = inode-&gt;i_sb-&gt;s_op; BUG_ON(!(inode-&gt;i_state &amp; I_FREEING)); BUG_ON(!list_empty(&amp;inode-&gt;i_lru)); if (!list_empty(&amp;inode-&gt;i_io_list)) inode_io_list_del(inode); inode_sb_list_del(inode); /* * Wait for flusher thread to be done with the inode so that filesystem * does not start destroying it while writeback is still running. Since * the inode has I_FREEING set, flusher thread won&#x27;t start new work on * the inode. We just have to wait for running writeback to finish. */ inode_wait_for_writeback(inode); if (op-&gt;evict_inode) &#123; op-&gt;evict_inode(inode); &#125; else &#123; truncate_inode_pages_final(&amp;inode-&gt;i_data); clear_inode(inode); &#125; if (S_ISBLK(inode-&gt;i_mode) &amp;&amp; inode-&gt;i_bdev) bd_forget(inode); if (S_ISCHR(inode-&gt;i_mode) &amp;&amp; inode-&gt;i_cdev) cd_forget(inode); remove_inode_hash(inode); spin_lock(&amp;inode-&gt;i_lock); wake_up_bit(&amp;inode-&gt;i_state, __I_NEW); BUG_ON(inode-&gt;i_state != (I_FREEING | I_CLEAR)); spin_unlock(&amp;inode-&gt;i_lock); destroy_inode(inode);&#125;/* * dispose_list - dispose of the contents of a local list * @head: the head of the list to free * * Dispose-list gets a local list with local inodes in it, so it doesn&#x27;t * need to worry about list corruption and SMP locks. */static void dispose_list(struct list_head *head)&#123; while (!list_empty(head)) &#123; struct inode *inode; inode = list_first_entry(head, struct inode, i_lru); list_del_init(&amp;inode-&gt;i_lru); evict(inode); cond_resched(); &#125;&#125;/** * evict_inodes - evict all evictable inodes for a superblock * @sb: superblock to operate on * * Make sure that no inodes with zero refcount are retained. This is * called by superblock shutdown after having SB_ACTIVE flag removed, * so any inode reaching zero refcount during or after that call will * be immediately evicted. */void evict_inodes(struct super_block *sb)&#123; struct inode *inode, *next; LIST_HEAD(dispose);again: spin_lock(&amp;sb-&gt;s_inode_list_lock); list_for_each_entry_safe(inode, next, &amp;sb-&gt;s_inodes, i_sb_list) &#123; if (atomic_read(&amp;inode-&gt;i_count)) continue; spin_lock(&amp;inode-&gt;i_lock); if (inode-&gt;i_state &amp; (I_NEW | I_FREEING | I_WILL_FREE)) &#123; spin_unlock(&amp;inode-&gt;i_lock); continue; &#125; inode-&gt;i_state |= I_FREEING; inode_lru_list_del(inode); spin_unlock(&amp;inode-&gt;i_lock); list_add(&amp;inode-&gt;i_lru, &amp;dispose); /* * We can have a ton of inodes to evict at unmount time given * enough memory, check to see if we need to go to sleep for a * bit so we don&#x27;t livelock. */ if (need_resched()) &#123; spin_unlock(&amp;sb-&gt;s_inode_list_lock); cond_resched(); dispose_list(&amp;dispose); goto again; &#125; &#125; spin_unlock(&amp;sb-&gt;s_inode_list_lock); dispose_list(&amp;dispose);&#125;EXPORT_SYMBOL_GPL(evict_inodes);/** * invalidate_inodes - attempt to free all inodes on a superblock * @sb: superblock to operate on * @kill_dirty: flag to guide handling of dirty inodes * * Attempts to free all inodes for a given superblock. If there were any * busy inodes return a non-zero value, else zero. * If @kill_dirty is set, discard dirty inodes too, otherwise treat * them as busy. */int invalidate_inodes(struct super_block *sb, bool kill_dirty)&#123; int busy = 0; struct inode *inode, *next; LIST_HEAD(dispose); spin_lock(&amp;sb-&gt;s_inode_list_lock); list_for_each_entry_safe(inode, next, &amp;sb-&gt;s_inodes, i_sb_list) &#123; spin_lock(&amp;inode-&gt;i_lock); if (inode-&gt;i_state &amp; (I_NEW | I_FREEING | I_WILL_FREE)) &#123; spin_unlock(&amp;inode-&gt;i_lock); continue; &#125; if (inode-&gt;i_state &amp; I_DIRTY_ALL &amp;&amp; !kill_dirty) &#123; spin_unlock(&amp;inode-&gt;i_lock); busy = 1; continue; &#125; if (atomic_read(&amp;inode-&gt;i_count)) &#123; spin_unlock(&amp;inode-&gt;i_lock); busy = 1; continue; &#125; inode-&gt;i_state |= I_FREEING; inode_lru_list_del(inode); spin_unlock(&amp;inode-&gt;i_lock); list_add(&amp;inode-&gt;i_lru, &amp;dispose); &#125; spin_unlock(&amp;sb-&gt;s_inode_list_lock); dispose_list(&amp;dispose); return busy;&#125;/* * Isolate the inode from the LRU in preparation for freeing it. * * Any inodes which are pinned purely because of attached pagecache have their * pagecache removed. If the inode has metadata buffers attached to * mapping-&gt;private_list then try to remove them. * * If the inode has the I_REFERENCED flag set, then it means that it has been * used recently - the flag is set in iput_final(). When we encounter such an * inode, clear the flag and move it to the back of the LRU so it gets another * pass through the LRU before it gets reclaimed. This is necessary because of * the fact we are doing lazy LRU updates to minimise lock contention so the * LRU does not have strict ordering. Hence we don&#x27;t want to reclaim inodes * with this flag set because they are the inodes that are out of order. */static enum lru_status inode_lru_isolate(struct list_head *item, struct list_lru_one *lru, spinlock_t *lru_lock, void *arg)&#123; struct list_head *freeable = arg; struct inode *inode = container_of(item, struct inode, i_lru); /* * we are inverting the lru lock/inode-&gt;i_lock here, so use a trylock. * If we fail to get the lock, just skip it. */ if (!spin_trylock(&amp;inode-&gt;i_lock)) return LRU_SKIP; /* * Referenced or dirty inodes are still in use. Give them another pass * through the LRU as we canot reclaim them now. */ if (atomic_read(&amp;inode-&gt;i_count) || (inode-&gt;i_state &amp; ~I_REFERENCED)) &#123; list_lru_isolate(lru, &amp;inode-&gt;i_lru); spin_unlock(&amp;inode-&gt;i_lock); this_cpu_dec(nr_unused); return LRU_REMOVED; &#125; /* recently referenced inodes get one more pass */ if (inode-&gt;i_state &amp; I_REFERENCED) &#123; inode-&gt;i_state &amp;= ~I_REFERENCED; spin_unlock(&amp;inode-&gt;i_lock); return LRU_ROTATE; &#125; if (inode_has_buffers(inode) || inode-&gt;i_data.nrpages) &#123; __iget(inode); spin_unlock(&amp;inode-&gt;i_lock); spin_unlock(lru_lock); if (remove_inode_buffers(inode)) &#123; unsigned long reap; reap = invalidate_mapping_pages(&amp;inode-&gt;i_data, 0, -1); if (current_is_kswapd()) __count_vm_events(KSWAPD_INODESTEAL, reap); else __count_vm_events(PGINODESTEAL, reap); if (current-&gt;reclaim_state) current-&gt;reclaim_state-&gt;reclaimed_slab += reap; &#125; iput(inode); spin_lock(lru_lock); return LRU_RETRY; &#125; WARN_ON(inode-&gt;i_state &amp; I_NEW); inode-&gt;i_state |= I_FREEING; list_lru_isolate_move(lru, &amp;inode-&gt;i_lru, freeable); spin_unlock(&amp;inode-&gt;i_lock); this_cpu_dec(nr_unused); return LRU_REMOVED;&#125;/* * Walk the superblock inode LRU for freeable inodes and attempt to free them. * This is called from the superblock shrinker function with a number of inodes * to trim from the LRU. Inodes to be freed are moved to a temporary list and * then are freed outside inode_lock by dispose_list(). */long prune_icache_sb(struct super_block *sb, struct shrink_control *sc)&#123; LIST_HEAD(freeable); long freed; freed = list_lru_shrink_walk(&amp;sb-&gt;s_inode_lru, sc, inode_lru_isolate, &amp;freeable); dispose_list(&amp;freeable); return freed;&#125;static void __wait_on_freeing_inode(struct inode *inode);/* * Called with the inode lock held. */static struct inode *find_inode(struct super_block *sb, struct hlist_head *head, int (*test)(struct inode *, void *), void *data)&#123; struct inode *inode = NULL;repeat: hlist_for_each_entry(inode, head, i_hash) &#123; if (inode-&gt;i_sb != sb) continue; if (!test(inode, data)) continue; spin_lock(&amp;inode-&gt;i_lock); if (inode-&gt;i_state &amp; (I_FREEING|I_WILL_FREE)) &#123; __wait_on_freeing_inode(inode); goto repeat; &#125; if (unlikely(inode-&gt;i_state &amp; I_CREATING)) &#123; spin_unlock(&amp;inode-&gt;i_lock); return ERR_PTR(-ESTALE); &#125; __iget(inode); spin_unlock(&amp;inode-&gt;i_lock); return inode; &#125; return NULL;&#125;/* * find_inode_fast is the fast path version of find_inode, see the comment at * iget_locked for details. */static struct inode *find_inode_fast(struct super_block *sb, struct hlist_head *head, unsigned long ino)&#123; struct inode *inode = NULL;repeat: hlist_for_each_entry(inode, head, i_hash) &#123; if (inode-&gt;i_ino != ino) continue; if (inode-&gt;i_sb != sb) continue; spin_lock(&amp;inode-&gt;i_lock); if (inode-&gt;i_state &amp; (I_FREEING|I_WILL_FREE)) &#123; __wait_on_freeing_inode(inode); goto repeat; &#125; if (unlikely(inode-&gt;i_state &amp; I_CREATING)) &#123; spin_unlock(&amp;inode-&gt;i_lock); return ERR_PTR(-ESTALE); &#125; __iget(inode); spin_unlock(&amp;inode-&gt;i_lock); return inode; &#125; return NULL;&#125;/* * Each cpu owns a range of LAST_INO_BATCH numbers. * &#x27;shared_last_ino&#x27; is dirtied only once out of LAST_INO_BATCH allocations, * to renew the exhausted range. * * This does not significantly increase overflow rate because every CPU can * consume at most LAST_INO_BATCH-1 unused inode numbers. So there is * NR_CPUS*(LAST_INO_BATCH-1) wastage. At 4096 and 1024, this is ~0.1% of the * 2^32 range, and is a worst-case. Even a 50% wastage would only increase * overflow rate by 2x, which does not seem too significant. * * On a 32bit, non LFS stat() call, glibc will generate an EOVERFLOW * error if st_ino won&#x27;t fit in target struct field. Use 32bit counter * here to attempt to avoid that. */#define LAST_INO_BATCH 1024static DEFINE_PER_CPU(unsigned int, last_ino);unsigned int get_next_ino(void)&#123; unsigned int *p = &amp;get_cpu_var(last_ino); unsigned int res = *p;#ifdef CONFIG_SMP if (unlikely((res &amp; (LAST_INO_BATCH-1)) == 0)) &#123; static atomic_t shared_last_ino; int next = atomic_add_return(LAST_INO_BATCH, &amp;shared_last_ino); res = next - LAST_INO_BATCH; &#125;#endif res++; /* get_next_ino should not provide a 0 inode number */ if (unlikely(!res)) res++; *p = res; put_cpu_var(last_ino); return res;&#125;EXPORT_SYMBOL(get_next_ino);/** * new_inode_pseudo - obtain an inode * @sb: superblock * * Allocates a new inode for given superblock. * Inode wont be chained in superblock s_inodes list * This means : * - fs can&#x27;t be unmount * - quotas, fsnotify, writeback can&#x27;t work */struct inode *new_inode_pseudo(struct super_block *sb)&#123; struct inode *inode = alloc_inode(sb); if (inode) &#123; spin_lock(&amp;inode-&gt;i_lock); inode-&gt;i_state = 0; spin_unlock(&amp;inode-&gt;i_lock); INIT_LIST_HEAD(&amp;inode-&gt;i_sb_list); &#125; return inode;&#125;/** * new_inode - obtain an inode * @sb: superblock * * Allocates a new inode for given superblock. The default gfp_mask * for allocations related to inode-&gt;i_mapping is GFP_HIGHUSER_MOVABLE. * If HIGHMEM pages are unsuitable or it is known that pages allocated * for the page cache are not reclaimable or migratable, * mapping_set_gfp_mask() must be called with suitable flags on the * newly created inode&#x27;s mapping * */struct inode *new_inode(struct super_block *sb)&#123; struct inode *inode; spin_lock_prefetch(&amp;sb-&gt;s_inode_list_lock); inode = new_inode_pseudo(sb); if (inode) inode_sb_list_add(inode); return inode;&#125;EXPORT_SYMBOL(new_inode);#ifdef CONFIG_DEBUG_LOCK_ALLOCvoid lockdep_annotate_inode_mutex_key(struct inode *inode)&#123; if (S_ISDIR(inode-&gt;i_mode)) &#123; struct file_system_type *type = inode-&gt;i_sb-&gt;s_type; /* Set new key only if filesystem hasn&#x27;t already changed it */ if (lockdep_match_class(&amp;inode-&gt;i_rwsem, &amp;type-&gt;i_mutex_key)) &#123; /* * ensure nobody is actually holding i_mutex */ // mutex_destroy(&amp;inode-&gt;i_mutex); init_rwsem(&amp;inode-&gt;i_rwsem); lockdep_set_class(&amp;inode-&gt;i_rwsem, &amp;type-&gt;i_mutex_dir_key); &#125; &#125;&#125;EXPORT_SYMBOL(lockdep_annotate_inode_mutex_key);#endif/** * unlock_new_inode - clear the I_NEW state and wake up any waiters * @inode: new inode to unlock * * Called when the inode is fully initialised to clear the new state of the * inode and wake up anyone waiting for the inode to finish initialisation. */void unlock_new_inode(struct inode *inode)&#123; lockdep_annotate_inode_mutex_key(inode); spin_lock(&amp;inode-&gt;i_lock); WARN_ON(!(inode-&gt;i_state &amp; I_NEW)); inode-&gt;i_state &amp;= ~I_NEW &amp; ~I_CREATING; smp_mb(); wake_up_bit(&amp;inode-&gt;i_state, __I_NEW); spin_unlock(&amp;inode-&gt;i_lock);&#125;EXPORT_SYMBOL(unlock_new_inode);void discard_new_inode(struct inode *inode)&#123; lockdep_annotate_inode_mutex_key(inode); spin_lock(&amp;inode-&gt;i_lock); WARN_ON(!(inode-&gt;i_state &amp; I_NEW)); inode-&gt;i_state &amp;= ~I_NEW; smp_mb(); wake_up_bit(&amp;inode-&gt;i_state, __I_NEW); spin_unlock(&amp;inode-&gt;i_lock); iput(inode);&#125;EXPORT_SYMBOL(discard_new_inode);/** * lock_two_nondirectories - take two i_mutexes on non-directory objects * * Lock any non-NULL argument that is not a directory. * Zero, one or two objects may be locked by this function. * * @inode1: first inode to lock * @inode2: second inode to lock */void lock_two_nondirectories(struct inode *inode1, struct inode *inode2)&#123; if (inode1 &gt; inode2) swap(inode1, inode2); if (inode1 &amp;&amp; !S_ISDIR(inode1-&gt;i_mode)) inode_lock(inode1); if (inode2 &amp;&amp; !S_ISDIR(inode2-&gt;i_mode) &amp;&amp; inode2 != inode1) inode_lock_nested(inode2, I_MUTEX_NONDIR2);&#125;EXPORT_SYMBOL(lock_two_nondirectories);/** * unlock_two_nondirectories - release locks from lock_two_nondirectories() * @inode1: first inode to unlock * @inode2: second inode to unlock */void unlock_two_nondirectories(struct inode *inode1, struct inode *inode2)&#123; if (inode1 &amp;&amp; !S_ISDIR(inode1-&gt;i_mode)) inode_unlock(inode1); if (inode2 &amp;&amp; !S_ISDIR(inode2-&gt;i_mode) &amp;&amp; inode2 != inode1) inode_unlock(inode2);&#125;EXPORT_SYMBOL(unlock_two_nondirectories);/** * inode_insert5 - obtain an inode from a mounted file system * @inode: pre-allocated inode to use for insert to cache * @hashval: hash value (usually inode number) to get * @test: callback used for comparisons between inodes * @set: callback used to initialize a new struct inode * @data: opaque data pointer to pass to @test and @set * * Search for the inode specified by @hashval and @data in the inode cache, * and if present it is return it with an increased reference count. This is * a variant of iget5_locked() for callers that don&#x27;t want to fail on memory * allocation of inode. * * If the inode is not in cache, insert the pre-allocated inode to cache and * return it locked, hashed, and with the I_NEW flag set. The file system gets * to fill it in before unlocking it via unlock_new_inode(). * * Note both @test and @set are called with the inode_hash_lock held, so can&#x27;t * sleep. */struct inode *inode_insert5(struct inode *inode, unsigned long hashval, int (*test)(struct inode *, void *), int (*set)(struct inode *, void *), void *data)&#123; struct hlist_head *head = inode_hashtable + hash(inode-&gt;i_sb, hashval); struct inode *old; bool creating = inode-&gt;i_state &amp; I_CREATING;again: spin_lock(&amp;inode_hash_lock); old = find_inode(inode-&gt;i_sb, head, test, data); if (unlikely(old)) &#123; /* * Uhhuh, somebody else created the same inode under us. * Use the old inode instead of the preallocated one. */ spin_unlock(&amp;inode_hash_lock); if (IS_ERR(old)) return NULL; wait_on_inode(old); if (unlikely(inode_unhashed(old))) &#123; iput(old); goto again; &#125; return old; &#125; if (set &amp;&amp; unlikely(set(inode, data))) &#123; inode = NULL; goto unlock; &#125; /* * Return the locked inode with I_NEW set, the * caller is responsible for filling in the contents */ spin_lock(&amp;inode-&gt;i_lock); inode-&gt;i_state |= I_NEW; hlist_add_head(&amp;inode-&gt;i_hash, head); spin_unlock(&amp;inode-&gt;i_lock); if (!creating) inode_sb_list_add(inode);unlock: spin_unlock(&amp;inode_hash_lock); return inode;&#125;EXPORT_SYMBOL(inode_insert5);/** * iget5_locked - obtain an inode from a mounted file system * @sb: super block of file system * @hashval: hash value (usually inode number) to get * @test: callback used for comparisons between inodes * @set: callback used to initialize a new struct inode * @data: opaque data pointer to pass to @test and @set * * Search for the inode specified by @hashval and @data in the inode cache, * and if present it is return it with an increased reference count. This is * a generalized version of iget_locked() for file systems where the inode * number is not sufficient for unique identification of an inode. * * If the inode is not in cache, allocate a new inode and return it locked, * hashed, and with the I_NEW flag set. The file system gets to fill it in * before unlocking it via unlock_new_inode(). * * Note both @test and @set are called with the inode_hash_lock held, so can&#x27;t * sleep. */struct inode *iget5_locked(struct super_block *sb, unsigned long hashval, int (*test)(struct inode *, void *), int (*set)(struct inode *, void *), void *data)&#123; struct inode *inode = ilookup5(sb, hashval, test, data); if (!inode) &#123; struct inode *new = alloc_inode(sb); if (new) &#123; new-&gt;i_state = 0; inode = inode_insert5(new, hashval, test, set, data); if (unlikely(inode != new)) destroy_inode(new); &#125; &#125; return inode;&#125;EXPORT_SYMBOL(iget5_locked);/** * iget_locked - obtain an inode from a mounted file system * @sb: super block of file system * @ino: inode number to get * * Search for the inode specified by @ino in the inode cache and if present * return it with an increased reference count. This is for file systems * where the inode number is sufficient for unique identification of an inode. * * If the inode is not in cache, allocate a new inode and return it locked, * hashed, and with the I_NEW flag set. The file system gets to fill it in * before unlocking it via unlock_new_inode(). */struct inode *iget_locked(struct super_block *sb, unsigned long ino)&#123; struct hlist_head *head = inode_hashtable + hash(sb, ino); struct inode *inode;again: spin_lock(&amp;inode_hash_lock); inode = find_inode_fast(sb, head, ino); spin_unlock(&amp;inode_hash_lock); if (inode) &#123; if (IS_ERR(inode)) return NULL; wait_on_inode(inode); if (unlikely(inode_unhashed(inode))) &#123; iput(inode); goto again; &#125; return inode; &#125; inode = alloc_inode(sb); if (inode) &#123; struct inode *old; spin_lock(&amp;inode_hash_lock); /* We released the lock, so.. */ old = find_inode_fast(sb, head, ino); if (!old) &#123; inode-&gt;i_ino = ino; spin_lock(&amp;inode-&gt;i_lock); inode-&gt;i_state = I_NEW; hlist_add_head(&amp;inode-&gt;i_hash, head); spin_unlock(&amp;inode-&gt;i_lock); inode_sb_list_add(inode); spin_unlock(&amp;inode_hash_lock); /* Return the locked inode with I_NEW set, the * caller is responsible for filling in the contents */ return inode; &#125; /* * Uhhuh, somebody else created the same inode under * us. Use the old inode instead of the one we just * allocated. */ spin_unlock(&amp;inode_hash_lock); destroy_inode(inode); if (IS_ERR(old)) return NULL; inode = old; wait_on_inode(inode); if (unlikely(inode_unhashed(inode))) &#123; iput(inode); goto again; &#125; &#125; return inode;&#125;EXPORT_SYMBOL(iget_locked);/* * search the inode cache for a matching inode number. * If we find one, then the inode number we are trying to * allocate is not unique and so we should not use it. * * Returns 1 if the inode number is unique, 0 if it is not. */static int test_inode_iunique(struct super_block *sb, unsigned long ino)&#123; struct hlist_head *b = inode_hashtable + hash(sb, ino); struct inode *inode; spin_lock(&amp;inode_hash_lock); hlist_for_each_entry(inode, b, i_hash) &#123; if (inode-&gt;i_ino == ino &amp;&amp; inode-&gt;i_sb == sb) &#123; spin_unlock(&amp;inode_hash_lock); return 0; &#125; &#125; spin_unlock(&amp;inode_hash_lock); return 1;&#125;/** * iunique - get a unique inode number * @sb: superblock * @max_reserved: highest reserved inode number * * Obtain an inode number that is unique on the system for a given * superblock. This is used by file systems that have no natural * permanent inode numbering system. An inode number is returned that * is higher than the reserved limit but unique. * * BUGS: * With a large number of inodes live on the file system this function * currently becomes quite slow. */ino_t iunique(struct super_block *sb, ino_t max_reserved)&#123; /* * On a 32bit, non LFS stat() call, glibc will generate an EOVERFLOW * error if st_ino won&#x27;t fit in target struct field. Use 32bit counter * here to attempt to avoid that. */ static DEFINE_SPINLOCK(iunique_lock); static unsigned int counter; ino_t res; spin_lock(&amp;iunique_lock); do &#123; if (counter &lt;= max_reserved) counter = max_reserved + 1; res = counter++; &#125; while (!test_inode_iunique(sb, res)); spin_unlock(&amp;iunique_lock); return res;&#125;EXPORT_SYMBOL(iunique);struct inode *igrab(struct inode *inode)&#123; spin_lock(&amp;inode-&gt;i_lock); if (!(inode-&gt;i_state &amp; (I_FREEING|I_WILL_FREE))) &#123; __iget(inode); spin_unlock(&amp;inode-&gt;i_lock); &#125; else &#123; spin_unlock(&amp;inode-&gt;i_lock); /* * Handle the case where s_op-&gt;clear_inode is not been * called yet, and somebody is calling igrab * while the inode is getting freed. */ inode = NULL; &#125; return inode;&#125;EXPORT_SYMBOL(igrab);/** * ilookup5_nowait - search for an inode in the inode cache * @sb: super block of file system to search * @hashval: hash value (usually inode number) to search for * @test: callback used for comparisons between inodes * @data: opaque data pointer to pass to @test * * Search for the inode specified by @hashval and @data in the inode cache. * If the inode is in the cache, the inode is returned with an incremented * reference count. * * Note: I_NEW is not waited upon so you have to be very careful what you do * with the returned inode. You probably should be using ilookup5() instead. * * Note2: @test is called with the inode_hash_lock held, so can&#x27;t sleep. */struct inode *ilookup5_nowait(struct super_block *sb, unsigned long hashval, int (*test)(struct inode *, void *), void *data)&#123; struct hlist_head *head = inode_hashtable + hash(sb, hashval); struct inode *inode; spin_lock(&amp;inode_hash_lock); inode = find_inode(sb, head, test, data); spin_unlock(&amp;inode_hash_lock); return IS_ERR(inode) ? NULL : inode;&#125;EXPORT_SYMBOL(ilookup5_nowait);/** * ilookup5 - search for an inode in the inode cache * @sb: super block of file system to search * @hashval: hash value (usually inode number) to search for * @test: callback used for comparisons between inodes * @data: opaque data pointer to pass to @test * * Search for the inode specified by @hashval and @data in the inode cache, * and if the inode is in the cache, return the inode with an incremented * reference count. Waits on I_NEW before returning the inode. * returned with an incremented reference count. * * This is a generalized version of ilookup() for file systems where the * inode number is not sufficient for unique identification of an inode. * * Note: @test is called with the inode_hash_lock held, so can&#x27;t sleep. */struct inode *ilookup5(struct super_block *sb, unsigned long hashval, int (*test)(struct inode *, void *), void *data)&#123; struct inode *inode;again: inode = ilookup5_nowait(sb, hashval, test, data); if (inode) &#123; wait_on_inode(inode); if (unlikely(inode_unhashed(inode))) &#123; iput(inode); goto again; &#125; &#125; return inode;&#125;EXPORT_SYMBOL(ilookup5);/** * ilookup - search for an inode in the inode cache * @sb: super block of file system to search * @ino: inode number to search for * * Search for the inode @ino in the inode cache, and if the inode is in the * cache, the inode is returned with an incremented reference count. */struct inode *ilookup(struct super_block *sb, unsigned long ino)&#123; struct hlist_head *head = inode_hashtable + hash(sb, ino); struct inode *inode;again: spin_lock(&amp;inode_hash_lock); inode = find_inode_fast(sb, head, ino); spin_unlock(&amp;inode_hash_lock); if (inode) &#123; if (IS_ERR(inode)) return NULL; wait_on_inode(inode); if (unlikely(inode_unhashed(inode))) &#123; iput(inode); goto again; &#125; &#125; return inode;&#125;EXPORT_SYMBOL(ilookup);/** * find_inode_nowait - find an inode in the inode cache * @sb: super block of file system to search * @hashval: hash value (usually inode number) to search for * @match: callback used for comparisons between inodes * @data: opaque data pointer to pass to @match * * Search for the inode specified by @hashval and @data in the inode * cache, where the helper function @match will return 0 if the inode * does not match, 1 if the inode does match, and -1 if the search * should be stopped. The @match function must be responsible for * taking the i_lock spin_lock and checking i_state for an inode being * freed or being initialized, and incrementing the reference count * before returning 1. It also must not sleep, since it is called with * the inode_hash_lock spinlock held. * * This is a even more generalized version of ilookup5() when the * function must never block --- find_inode() can block in * __wait_on_freeing_inode() --- or when the caller can not increment * the reference count because the resulting iput() might cause an * inode eviction. The tradeoff is that the @match funtion must be * very carefully implemented. */struct inode *find_inode_nowait(struct super_block *sb, unsigned long hashval, int (*match)(struct inode *, unsigned long, void *), void *data)&#123; struct hlist_head *head = inode_hashtable + hash(sb, hashval); struct inode *inode, *ret_inode = NULL; int mval; spin_lock(&amp;inode_hash_lock); hlist_for_each_entry(inode, head, i_hash) &#123; if (inode-&gt;i_sb != sb) continue; mval = match(inode, hashval, data); if (mval == 0) continue; if (mval == 1) ret_inode = inode; goto out; &#125;out: spin_unlock(&amp;inode_hash_lock); return ret_inode;&#125;EXPORT_SYMBOL(find_inode_nowait);int insert_inode_locked(struct inode *inode)&#123; struct super_block *sb = inode-&gt;i_sb; ino_t ino = inode-&gt;i_ino; struct hlist_head *head = inode_hashtable + hash(sb, ino); while (1) &#123; struct inode *old = NULL; spin_lock(&amp;inode_hash_lock); hlist_for_each_entry(old, head, i_hash) &#123; if (old-&gt;i_ino != ino) continue; if (old-&gt;i_sb != sb) continue; spin_lock(&amp;old-&gt;i_lock); if (old-&gt;i_state &amp; (I_FREEING|I_WILL_FREE)) &#123; spin_unlock(&amp;old-&gt;i_lock); continue; &#125; break; &#125; if (likely(!old)) &#123; spin_lock(&amp;inode-&gt;i_lock); inode-&gt;i_state |= I_NEW | I_CREATING; hlist_add_head(&amp;inode-&gt;i_hash, head); spin_unlock(&amp;inode-&gt;i_lock); spin_unlock(&amp;inode_hash_lock); return 0; &#125; if (unlikely(old-&gt;i_state &amp; I_CREATING)) &#123; spin_unlock(&amp;old-&gt;i_lock); spin_unlock(&amp;inode_hash_lock); return -EBUSY; &#125; __iget(old); spin_unlock(&amp;old-&gt;i_lock); spin_unlock(&amp;inode_hash_lock); wait_on_inode(old); if (unlikely(!inode_unhashed(old))) &#123; iput(old); return -EBUSY; &#125; iput(old); &#125;&#125;EXPORT_SYMBOL(insert_inode_locked);int insert_inode_locked4(struct inode *inode, unsigned long hashval, int (*test)(struct inode *, void *), void *data)&#123; struct inode *old; inode-&gt;i_state |= I_CREATING; old = inode_insert5(inode, hashval, test, NULL, data); if (old != inode) &#123; iput(old); return -EBUSY; &#125; return 0;&#125;EXPORT_SYMBOL(insert_inode_locked4);int generic_delete_inode(struct inode *inode)&#123; return 1;&#125;EXPORT_SYMBOL(generic_delete_inode);/* * Called when we&#x27;re dropping the last reference * to an inode. * * Call the FS &quot;drop_inode()&quot; function, defaulting to * the legacy UNIX filesystem behaviour. If it tells * us to evict inode, do so. Otherwise, retain inode * in cache if fs is alive, sync and evict if fs is * shutting down. */static void iput_final(struct inode *inode)&#123; struct super_block *sb = inode-&gt;i_sb; const struct super_operations *op = inode-&gt;i_sb-&gt;s_op; int drop; WARN_ON(inode-&gt;i_state &amp; I_NEW); if (op-&gt;drop_inode) drop = op-&gt;drop_inode(inode); else drop = generic_drop_inode(inode); if (!drop &amp;&amp; (sb-&gt;s_flags &amp; SB_ACTIVE)) &#123; inode_add_lru(inode); spin_unlock(&amp;inode-&gt;i_lock); return; &#125; if (!drop) &#123; inode-&gt;i_state |= I_WILL_FREE; spin_unlock(&amp;inode-&gt;i_lock); write_inode_now(inode, 1); spin_lock(&amp;inode-&gt;i_lock); WARN_ON(inode-&gt;i_state &amp; I_NEW); inode-&gt;i_state &amp;= ~I_WILL_FREE; &#125; inode-&gt;i_state |= I_FREEING; if (!list_empty(&amp;inode-&gt;i_lru)) inode_lru_list_del(inode); spin_unlock(&amp;inode-&gt;i_lock); evict(inode);&#125;/** * iput - put an inode * @inode: inode to put * * Puts an inode, dropping its usage count. If the inode use count hits * zero, the inode is then freed and may also be destroyed. * * Consequently, iput() can sleep. */void iput(struct inode *inode)&#123; if (!inode) return; BUG_ON(inode-&gt;i_state &amp; I_CLEAR);retry: if (atomic_dec_and_lock(&amp;inode-&gt;i_count, &amp;inode-&gt;i_lock)) &#123; if (inode-&gt;i_nlink &amp;&amp; (inode-&gt;i_state &amp; I_DIRTY_TIME)) &#123; atomic_inc(&amp;inode-&gt;i_count); spin_unlock(&amp;inode-&gt;i_lock); trace_writeback_lazytime_iput(inode); mark_inode_dirty_sync(inode); goto retry; &#125; iput_final(inode); &#125;&#125;EXPORT_SYMBOL(iput);/** * bmap - find a block number in a file * @inode: inode of file * @block: block to find * * Returns the block number on the device holding the inode that * is the disk block number for the block of the file requested. * That is, asked for block 4 of inode 1 the function will return the * disk block relative to the disk start that holds that block of the * file. */sector_t bmap(struct inode *inode, sector_t block)&#123; sector_t res = 0; if (inode-&gt;i_mapping-&gt;a_ops-&gt;bmap) res = inode-&gt;i_mapping-&gt;a_ops-&gt;bmap(inode-&gt;i_mapping, block); return res;&#125;EXPORT_SYMBOL(bmap);/* * With relative atime, only update atime if the previous atime is * earlier than either the ctime or mtime or if at least a day has * passed since the last atime update. */static int relatime_need_update(struct vfsmount *mnt, struct inode *inode, struct timespec64 now)&#123; if (!(mnt-&gt;mnt_flags &amp; MNT_RELATIME)) return 1; /* * Is mtime younger than atime? If yes, update atime: */ if (timespec64_compare(&amp;inode-&gt;i_mtime, &amp;inode-&gt;i_atime) &gt;= 0) return 1; /* * Is ctime younger than atime? If yes, update atime: */ if (timespec64_compare(&amp;inode-&gt;i_ctime, &amp;inode-&gt;i_atime) &gt;= 0) return 1; /* * Is the previous atime value older than a day? If yes, * update atime: */ if ((long)(now.tv_sec - inode-&gt;i_atime.tv_sec) &gt;= 24*60*60) return 1; /* * Good, we can skip the atime update: */ return 0;&#125;int generic_update_time(struct inode *inode, struct timespec64 *time, int flags)&#123; int iflags = I_DIRTY_TIME; bool dirty = false; if (flags &amp; S_ATIME) inode-&gt;i_atime = *time; if (flags &amp; S_VERSION) dirty = inode_maybe_inc_iversion(inode, false); if (flags &amp; S_CTIME) inode-&gt;i_ctime = *time; if (flags &amp; S_MTIME) inode-&gt;i_mtime = *time; if ((flags &amp; (S_ATIME | S_CTIME | S_MTIME)) &amp;&amp; !(inode-&gt;i_sb-&gt;s_flags &amp; SB_LAZYTIME)) dirty = true; if (dirty) iflags |= I_DIRTY_SYNC; __mark_inode_dirty(inode, iflags); return 0;&#125;EXPORT_SYMBOL(generic_update_time);/* * This does the actual work of updating an inodes time or version. Must have * had called mnt_want_write() before calling this. */static int update_time(struct inode *inode, struct timespec64 *time, int flags)&#123; int (*update_time)(struct inode *, struct timespec64 *, int); update_time = inode-&gt;i_op-&gt;update_time ? inode-&gt;i_op-&gt;update_time : generic_update_time; return update_time(inode, time, flags);&#125;/** * touch_atime - update the access time * @path: the &amp;struct path to update * @inode: inode to update * * Update the accessed time on an inode and mark it for writeback. * This function automatically handles read only file systems and media, * as well as the &quot;noatime&quot; flag and inode specific &quot;noatime&quot; markers. */bool atime_needs_update(const struct path *path, struct inode *inode)&#123; struct vfsmount *mnt = path-&gt;mnt; struct timespec64 now; if (inode-&gt;i_flags &amp; S_NOATIME) return false; /* Atime updates will likely cause i_uid and i_gid to be written * back improprely if their true value is unknown to the vfs. */ if (HAS_UNMAPPED_ID(inode)) return false; if (IS_NOATIME(inode)) return false; if ((inode-&gt;i_sb-&gt;s_flags &amp; SB_NODIRATIME) &amp;&amp; S_ISDIR(inode-&gt;i_mode)) return false; if (mnt-&gt;mnt_flags &amp; MNT_NOATIME) return false; if ((mnt-&gt;mnt_flags &amp; MNT_NODIRATIME) &amp;&amp; S_ISDIR(inode-&gt;i_mode)) return false; now = current_time(inode); if (!relatime_need_update(mnt, inode, now)) return false; if (timespec64_equal(&amp;inode-&gt;i_atime, &amp;now)) return false; return true;&#125;void touch_atime(const struct path *path)&#123; struct vfsmount *mnt = path-&gt;mnt; struct inode *inode = d_inode(path-&gt;dentry); struct timespec64 now; if (!atime_needs_update(path, inode)) return; if (!sb_start_write_trylock(inode-&gt;i_sb)) return; if (__mnt_want_write(mnt) != 0) goto skip_update; /* * File systems can error out when updating inodes if they need to * allocate new space to modify an inode (such is the case for * Btrfs), but since we touch atime while walking down the path we * really don&#x27;t care if we failed to update the atime of the file, * so just ignore the return value. * We may also fail on filesystems that have the ability to make parts * of the fs read only, e.g. subvolumes in Btrfs. */ now = current_time(inode); update_time(inode, &amp;now, S_ATIME); __mnt_drop_write(mnt);skip_update: sb_end_write(inode-&gt;i_sb);&#125;EXPORT_SYMBOL(touch_atime);/* * The logic we want is * * if suid or (sgid and xgrp) * remove privs */int should_remove_suid(struct dentry *dentry)&#123; umode_t mode = d_inode(dentry)-&gt;i_mode; int kill = 0; /* suid always must be killed */ if (unlikely(mode &amp; S_ISUID)) kill = ATTR_KILL_SUID; /* * sgid without any exec bits is just a mandatory locking mark; leave * it alone. If some exec bits are set, it&#x27;s a real sgid; kill it. */ if (unlikely((mode &amp; S_ISGID) &amp;&amp; (mode &amp; S_IXGRP))) kill |= ATTR_KILL_SGID; if (unlikely(kill &amp;&amp; !capable(CAP_FSETID) &amp;&amp; S_ISREG(mode))) return kill; return 0;&#125;EXPORT_SYMBOL(should_remove_suid);/* * Return mask of changes for notify_change() that need to be done as a * response to write or truncate. Return 0 if nothing has to be changed. * Negative value on error (change should be denied). */int dentry_needs_remove_privs(struct dentry *dentry)&#123; struct inode *inode = d_inode(dentry); int mask = 0; int ret; if (IS_NOSEC(inode)) return 0; mask = should_remove_suid(dentry); ret = security_inode_need_killpriv(dentry); if (ret &lt; 0) return ret; if (ret) mask |= ATTR_KILL_PRIV; return mask;&#125;static int __remove_privs(struct dentry *dentry, int kill)&#123; struct iattr newattrs; newattrs.ia_valid = ATTR_FORCE | kill; /* * Note we call this on write, so notify_change will not * encounter any conflicting delegations: */ return notify_change(dentry, &amp;newattrs, NULL);&#125;/* * Remove special file priviledges (suid, capabilities) when file is written * to or truncated. */int file_remove_privs(struct file *file)&#123; struct dentry *dentry = file_dentry(file); struct inode *inode = file_inode(file); int kill; int error = 0; /* * Fast path for nothing security related. * As well for non-regular files, e.g. blkdev inodes. * For example, blkdev_write_iter() might get here * trying to remove privs which it is not allowed to. */ if (IS_NOSEC(inode) || !S_ISREG(inode-&gt;i_mode)) return 0; kill = dentry_needs_remove_privs(dentry); if (kill &lt; 0) return kill; if (kill) error = __remove_privs(dentry, kill); if (!error) inode_has_no_xattr(inode); return error;&#125;EXPORT_SYMBOL(file_remove_privs);/** * file_update_time - update mtime and ctime time * @file: file accessed * * Update the mtime and ctime members of an inode and mark the inode * for writeback. Note that this function is meant exclusively for * usage in the file write path of filesystems, and filesystems may * choose to explicitly ignore update via this function with the * S_NOCMTIME inode flag, e.g. for network filesystem where these * timestamps are handled by the server. This can return an error for * file systems who need to allocate space in order to update an inode. */int file_update_time(struct file *file)&#123; struct inode *inode = file_inode(file); struct timespec64 now; int sync_it = 0; int ret; /* First try to exhaust all avenues to not sync */ if (IS_NOCMTIME(inode)) return 0; now = current_time(inode); if (!timespec64_equal(&amp;inode-&gt;i_mtime, &amp;now)) sync_it = S_MTIME; if (!timespec64_equal(&amp;inode-&gt;i_ctime, &amp;now)) sync_it |= S_CTIME; if (IS_I_VERSION(inode) &amp;&amp; inode_iversion_need_inc(inode)) sync_it |= S_VERSION; if (!sync_it) return 0; /* Finally allowed to write? Takes lock. */ if (__mnt_want_write_file(file)) return 0; ret = update_time(inode, &amp;now, sync_it); __mnt_drop_write_file(file); return ret;&#125;EXPORT_SYMBOL(file_update_time);/* Caller must hold the file&#x27;s inode lock */int file_modified(struct file *file)&#123; int err; /* * Clear the security bits if the process is not being run by root. * This keeps people from modifying setuid and setgid binaries. */ err = file_remove_privs(file); if (err) return err; if (unlikely(file-&gt;f_mode &amp; FMODE_NOCMTIME)) return 0; return file_update_time(file);&#125;EXPORT_SYMBOL(file_modified);int inode_needs_sync(struct inode *inode)&#123; if (IS_SYNC(inode)) return 1; if (S_ISDIR(inode-&gt;i_mode) &amp;&amp; IS_DIRSYNC(inode)) return 1; return 0;&#125;EXPORT_SYMBOL(inode_needs_sync);/* * If we try to find an inode in the inode hash while it is being * deleted, we have to wait until the filesystem completes its * deletion before reporting that it isn&#x27;t found. This function waits * until the deletion _might_ have completed. Callers are responsible * to recheck inode state. * * It doesn&#x27;t matter if I_NEW is not set initially, a call to * wake_up_bit(&amp;inode-&gt;i_state, __I_NEW) after removing from the hash list * will DTRT. */static void __wait_on_freeing_inode(struct inode *inode)&#123; wait_queue_head_t *wq; DEFINE_WAIT_BIT(wait, &amp;inode-&gt;i_state, __I_NEW); wq = bit_waitqueue(&amp;inode-&gt;i_state, __I_NEW); prepare_to_wait(wq, &amp;wait.wq_entry, TASK_UNINTERRUPTIBLE); spin_unlock(&amp;inode-&gt;i_lock); spin_unlock(&amp;inode_hash_lock); schedule(); finish_wait(wq, &amp;wait.wq_entry); spin_lock(&amp;inode_hash_lock);&#125;static __initdata unsigned long ihash_entries;static int __init set_ihash_entries(char *str)&#123; if (!str) return 0; ihash_entries = simple_strtoul(str, &amp;str, 0); return 1;&#125;__setup(&quot;ihash_entries=&quot;, set_ihash_entries);/* * Initialize the waitqueues and inode hash table. */void __init inode_init_early(void)&#123; /* If hashes are distributed across NUMA nodes, defer * hash allocation until vmalloc space is available. */ if (hashdist) return; inode_hashtable = alloc_large_system_hash(&quot;Inode-cache&quot;, sizeof(struct hlist_head), ihash_entries, 14, HASH_EARLY | HASH_ZERO, &amp;i_hash_shift, &amp;i_hash_mask, 0, 0);&#125;void __init inode_init(void)&#123; /* inode slab cache */ inode_cachep = kmem_cache_create(&quot;inode_cache&quot;, sizeof(struct inode), 0, (SLAB_RECLAIM_ACCOUNT|SLAB_PANIC| SLAB_MEM_SPREAD|SLAB_ACCOUNT), init_once); /* Hash may have been set up in inode_init_early */ if (!hashdist) return; inode_hashtable = alloc_large_system_hash(&quot;Inode-cache&quot;, sizeof(struct hlist_head), ihash_entries, 14, HASH_ZERO, &amp;i_hash_shift, &amp;i_hash_mask, 0, 0);&#125;void init_special_inode(struct inode *inode, umode_t mode, dev_t rdev)&#123; inode-&gt;i_mode = mode; if (S_ISCHR(mode)) &#123; inode-&gt;i_fop = &amp;def_chr_fops; inode-&gt;i_rdev = rdev; &#125; else if (S_ISBLK(mode)) &#123; inode-&gt;i_fop = &amp;def_blk_fops; inode-&gt;i_rdev = rdev; &#125; else if (S_ISFIFO(mode)) inode-&gt;i_fop = &amp;pipefifo_fops; else if (S_ISSOCK(mode)) ; /* leave it no_open_fops */ else printk(KERN_DEBUG &quot;init_special_inode: bogus i_mode (%o) for&quot; &quot; inode %s:%lu\\n&quot;, mode, inode-&gt;i_sb-&gt;s_id, inode-&gt;i_ino);&#125;EXPORT_SYMBOL(init_special_inode);/** * inode_init_owner - Init uid,gid,mode for new inode according to posix standards * @inode: New inode * @dir: Directory inode * @mode: mode of the new inode */void inode_init_owner(struct inode *inode, const struct inode *dir, umode_t mode)&#123; inode-&gt;i_uid = current_fsuid(); if (dir &amp;&amp; dir-&gt;i_mode &amp; S_ISGID) &#123; inode-&gt;i_gid = dir-&gt;i_gid; /* Directories are special, and always inherit S_ISGID */ if (S_ISDIR(mode)) mode |= S_ISGID; else if ((mode &amp; (S_ISGID | S_IXGRP)) == (S_ISGID | S_IXGRP) &amp;&amp; !in_group_p(inode-&gt;i_gid) &amp;&amp; !capable_wrt_inode_uidgid(dir, CAP_FSETID)) mode &amp;= ~S_ISGID; &#125; else inode-&gt;i_gid = current_fsgid(); inode-&gt;i_mode = mode;&#125;EXPORT_SYMBOL(inode_init_owner);/** * inode_owner_or_capable - check current task permissions to inode * @inode: inode being checked * * Return true if current either has CAP_FOWNER in a namespace with the * inode owner uid mapped, or owns the file. */bool inode_owner_or_capable(const struct inode *inode)&#123; struct user_namespace *ns; if (uid_eq(current_fsuid(), inode-&gt;i_uid)) return true; ns = current_user_ns(); if (kuid_has_mapping(ns, inode-&gt;i_uid) &amp;&amp; ns_capable(ns, CAP_FOWNER)) return true; return false;&#125;EXPORT_SYMBOL(inode_owner_or_capable);/* * Direct i/o helper functions */static void __inode_dio_wait(struct inode *inode)&#123; wait_queue_head_t *wq = bit_waitqueue(&amp;inode-&gt;i_state, __I_DIO_WAKEUP); DEFINE_WAIT_BIT(q, &amp;inode-&gt;i_state, __I_DIO_WAKEUP); do &#123; prepare_to_wait(wq, &amp;q.wq_entry, TASK_UNINTERRUPTIBLE); if (atomic_read(&amp;inode-&gt;i_dio_count)) schedule(); &#125; while (atomic_read(&amp;inode-&gt;i_dio_count)); finish_wait(wq, &amp;q.wq_entry);&#125;/** * inode_dio_wait - wait for outstanding DIO requests to finish * @inode: inode to wait for * * Waits for all pending direct I/O requests to finish so that we can * proceed with a truncate or equivalent operation. * * Must be called under a lock that serializes taking new references * to i_dio_count, usually by inode-&gt;i_mutex. */void inode_dio_wait(struct inode *inode)&#123; if (atomic_read(&amp;inode-&gt;i_dio_count)) __inode_dio_wait(inode);&#125;EXPORT_SYMBOL(inode_dio_wait);/* * inode_set_flags - atomically set some inode flags * * Note: the caller should be holding i_mutex, or else be sure that * they have exclusive access to the inode structure (i.e., while the * inode is being instantiated). The reason for the cmpxchg() loop * --- which wouldn&#x27;t be necessary if all code paths which modify * i_flags actually followed this rule, is that there is at least one * code path which doesn&#x27;t today so we use cmpxchg() out of an abundance * of caution. * * In the long run, i_mutex is overkill, and we should probably look * at using the i_lock spinlock to protect i_flags, and then make sure * it is so documented in include/linux/fs.h and that all code follows * the locking convention!! */void inode_set_flags(struct inode *inode, unsigned int flags, unsigned int mask)&#123; WARN_ON_ONCE(flags &amp; ~mask); set_mask_bits(&amp;inode-&gt;i_flags, mask, flags);&#125;EXPORT_SYMBOL(inode_set_flags);void inode_nohighmem(struct inode *inode)&#123; mapping_set_gfp_mask(inode-&gt;i_mapping, GFP_USER);&#125;EXPORT_SYMBOL(inode_nohighmem);/** * timespec64_trunc - Truncate timespec64 to a granularity * @t: Timespec64 * @gran: Granularity in ns. * * Truncate a timespec64 to a granularity. Always rounds down. gran must * not be 0 nor greater than a second (NSEC_PER_SEC, or 10^9 ns). */struct timespec64 timespec64_trunc(struct timespec64 t, unsigned gran)&#123; /* Avoid division in the common cases 1 ns and 1 s. */ if (gran == 1) &#123; /* nothing */ &#125; else if (gran == NSEC_PER_SEC) &#123; t.tv_nsec = 0; &#125; else if (gran &gt; 1 &amp;&amp; gran &lt; NSEC_PER_SEC) &#123; t.tv_nsec -= t.tv_nsec % gran; &#125; else &#123; WARN(1, &quot;illegal file time granularity: %u&quot;, gran); &#125; return t;&#125;EXPORT_SYMBOL(timespec64_trunc);/** * current_time - Return FS time * @inode: inode. * * Return the current time truncated to the time granularity supported by * the fs. * * Note that inode and inode-&gt;sb cannot be NULL. * Otherwise, the function warns and returns time without truncation. */struct timespec64 current_time(struct inode *inode)&#123; struct timespec64 now; ktime_get_coarse_real_ts64(&amp;now); if (unlikely(!inode-&gt;i_sb)) &#123; WARN(1, &quot;current_time() called with uninitialized super_block in the inode&quot;); return now; &#125; return timespec64_trunc(now, inode-&gt;i_sb-&gt;s_time_gran);&#125;EXPORT_SYMBOL(current_time);/* * Generic function to check FS_IOC_SETFLAGS values and reject any invalid * configurations. * * Note: the caller should be holding i_mutex, or else be sure that they have * exclusive access to the inode structure. */int vfs_ioc_setflags_prepare(struct inode *inode, unsigned int oldflags, unsigned int flags)&#123; /* * The IMMUTABLE and APPEND_ONLY flags can only be changed by * the relevant capability. * * This test looks nicer. Thanks to Pauline Middelink */ if ((flags ^ oldflags) &amp; (FS_APPEND_FL | FS_IMMUTABLE_FL) &amp;&amp; !capable(CAP_LINUX_IMMUTABLE)) return -EPERM; return 0;&#125;EXPORT_SYMBOL(vfs_ioc_setflags_prepare);/* * Generic function to check FS_IOC_FSSETXATTR values and reject any invalid * configurations. * * Note: the caller should be holding i_mutex, or else be sure that they have * exclusive access to the inode structure. */int vfs_ioc_fssetxattr_check(struct inode *inode, const struct fsxattr *old_fa, struct fsxattr *fa)&#123; /* * Can&#x27;t modify an immutable/append-only file unless we have * appropriate permission. */ if ((old_fa-&gt;fsx_xflags ^ fa-&gt;fsx_xflags) &amp; (FS_XFLAG_IMMUTABLE | FS_XFLAG_APPEND) &amp;&amp; !capable(CAP_LINUX_IMMUTABLE)) return -EPERM; /* * Project Quota ID state is only allowed to change from within the init * namespace. Enforce that restriction only if we are trying to change * the quota ID state. Everything else is allowed in user namespaces. */ if (current_user_ns() != &amp;init_user_ns) &#123; if (old_fa-&gt;fsx_projid != fa-&gt;fsx_projid) return -EINVAL; if ((old_fa-&gt;fsx_xflags ^ fa-&gt;fsx_xflags) &amp; FS_XFLAG_PROJINHERIT) return -EINVAL; &#125; /* Check extent size hints. */ if ((fa-&gt;fsx_xflags &amp; FS_XFLAG_EXTSIZE) &amp;&amp; !S_ISREG(inode-&gt;i_mode)) return -EINVAL; if ((fa-&gt;fsx_xflags &amp; FS_XFLAG_EXTSZINHERIT) &amp;&amp; !S_ISDIR(inode-&gt;i_mode)) return -EINVAL; if ((fa-&gt;fsx_xflags &amp; FS_XFLAG_COWEXTSIZE) &amp;&amp; !S_ISREG(inode-&gt;i_mode) &amp;&amp; !S_ISDIR(inode-&gt;i_mode)) return -EINVAL; /* * It is only valid to set the DAX flag on regular files and * directories on filesystems. */ if ((fa-&gt;fsx_xflags &amp; FS_XFLAG_DAX) &amp;&amp; !(S_ISREG(inode-&gt;i_mode) || S_ISDIR(inode-&gt;i_mode))) return -EINVAL; /* Extent size hints of zero turn off the flags. */ if (fa-&gt;fsx_extsize == 0) fa-&gt;fsx_xflags &amp;= ~(FS_XFLAG_EXTSIZE | FS_XFLAG_EXTSZINHERIT); if (fa-&gt;fsx_cowextsize == 0) fa-&gt;fsx_xflags &amp;= ~FS_XFLAG_COWEXTSIZE; return 0;&#125;EXPORT_SYMBOL(vfs_ioc_fssetxattr_check);","categories":[{"name":"Linux源码","slug":"Linux源码","permalink":"http://example.com/categories/Linux%E6%BA%90%E7%A0%81/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"Linux","slug":"Linux","permalink":"http://example.com/tags/Linux/"}]},{"title":"Linux v5.3.1 /fs/ext4/ialloc.c","slug":"Linux-v5-3-1-fs-ext4-ialloc-c","date":"2023-04-13T01:33:35.000Z","updated":"2023-04-13T04:44:06.880Z","comments":true,"path":"2023/04/13/Linux-v5-3-1-fs-ext4-ialloc-c/","link":"","permalink":"http://example.com/2023/04/13/Linux-v5-3-1-fs-ext4-ialloc-c/","excerpt":"","text":"1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871881891901911921931941951961971981992002012022032042052062072082092102112122132142152162172182192202212222232242252262272282292302312322332342352362372382392402412422432442452462472482492502512522532542552562572582592602612622632642652662672682692702712722732742752762772782792802812822832842852862872882892902912922932942952962972982993003013023033043053063073083093103113123133143153163173183193203213223233243253263273283293303313323333343353363373383393403413423433443453463473483493503513523533543553563573583593603613623633643653663673683693703713723733743753763773783793803813823833843853863873883893903913923933943953963973983994004014024034044054064074084094104114124134144154164174184194204214224234244254264274284294304314324334344354364374384394404414424434444454464474484494504514524534544554564574584594604614624634644654664674684694704714724734744754764774784794804814824834844854864874884894904914924934944954964974984995005015025035045055065075085095105115125135145155165175185195205215225235245255265275285295305315325335345355365375385395405415425435445455465475485495505515525535545555565575585595605615625635645655665675685695705715725735745755765775785795805815825835845855865875885895905915925935945955965975985996006016026036046056066076086096106116126136146156166176186196206216226236246256266276286296306316326336346356366376386396406416426436446456466476486496506516526536546556566576586596606616626636646656666676686696706716726736746756766776786796806816826836846856866876886896906916926936946956966976986997007017027037047057067077087097107117127137147157167177187197207217227237247257267277287297307317327337347357367377387397407417427437447457467477487497507517527537547557567577587597607617627637647657667677687697707717727737747757767777787797807817827837847857867877887897907917927937947957967977987998008018028038048058068078088098108118128138148158168178188198208218228238248258268278288298308318328338348358368378388398408418428438448458468478488498508518528538548558568578588598608618628638648658668678688698708718728738748758768778788798808818828838848858868878888898908918928938948958968978988999009019029039049059069079089099109119129139149159169179189199209219229239249259269279289299309319329339349359369379389399409419429439449459469479489499509519529539549559569579589599609619629639649659669679689699709719729739749759769779789799809819829839849859869879889899909919929939949959969979989991000100110021003100410051006100710081009101010111012101310141015101610171018101910201021102210231024102510261027102810291030103110321033103410351036103710381039104010411042104310441045104610471048104910501051105210531054105510561057105810591060106110621063106410651066106710681069107010711072107310741075107610771078107910801081108210831084108510861087108810891090109110921093109410951096109710981099110011011102110311041105110611071108110911101111111211131114111511161117111811191120112111221123112411251126112711281129113011311132113311341135113611371138113911401141114211431144114511461147114811491150115111521153115411551156115711581159116011611162116311641165116611671168116911701171117211731174117511761177117811791180118111821183118411851186118711881189119011911192119311941195119611971198119912001201120212031204120512061207120812091210121112121213121412151216121712181219122012211222122312241225122612271228122912301231123212331234123512361237123812391240124112421243124412451246124712481249125012511252125312541255125612571258125912601261126212631264126512661267126812691270127112721273127412751276127712781279128012811282128312841285128612871288128912901291129212931294129512961297129812991300130113021303130413051306130713081309131013111312131313141315131613171318131913201321132213231324132513261327132813291330133113321333133413351336133713381339134013411342134313441345134613471348134913501351135213531354135513561357135813591360136113621363136413651366136713681369137013711372137313741375137613771378137913801381138213831384138513861387138813891390139113921393139413951396139713981399140014011402140314041405140614071408140914101411141214131414141514161417141814191420142114221423142414251426142714281429143014311432143314341435143614371438143914401441144214431444144514461447144814491450145114521453145414551456145714581459// SPDX-License-Identifier: GPL-2.0/* * linux/fs/ext4/ialloc.c * * Copyright (C) 1992, 1993, 1994, 1995 * Remy Card (card@masi.ibp.fr) * Laboratoire MASI - Institut Blaise Pascal * Universite Pierre et Marie Curie (Paris VI) * * BSD ufs-inspired inode and directory allocation by * Stephen Tweedie (sct@redhat.com), 1993 * Big-endian to little-endian byte-swapping/bitmaps by * David S. Miller (davem@caip.rutgers.edu), 1995 */#include &lt;linux/time.h&gt;#include &lt;linux/fs.h&gt;#include &lt;linux/stat.h&gt;#include &lt;linux/string.h&gt;#include &lt;linux/quotaops.h&gt;#include &lt;linux/buffer_head.h&gt;#include &lt;linux/random.h&gt;#include &lt;linux/bitops.h&gt;#include &lt;linux/blkdev.h&gt;#include &lt;linux/cred.h&gt;#include &lt;asm/byteorder.h&gt;#include &quot;ext4.h&quot;#include &quot;ext4_jbd2.h&quot;#include &quot;xattr.h&quot;#include &quot;acl.h&quot;#include &lt;trace/events/ext4.h&gt;/* * ialloc.c contains the inodes allocation and deallocation routines *//* * The free inodes are managed by bitmaps. A file system contains several * blocks groups. Each group contains 1 bitmap block for blocks, 1 bitmap * block for inodes, N blocks for the inode table and data blocks. * * The file system contains group descriptors which are located after the * super block. Each descriptor contains the number of the bitmap block and * the free blocks count in the block. *//* * To avoid calling the atomic setbit hundreds or thousands of times, we only * need to use it within a single byte (to ensure we get endianness right). * We can use memset for the rest of the bitmap as there are no other users. */void ext4_mark_bitmap_end(int start_bit, int end_bit, char *bitmap)&#123; int i; if (start_bit &gt;= end_bit) return; ext4_debug(&quot;mark end bits +%d through +%d used\\n&quot;, start_bit, end_bit); for (i = start_bit; i &lt; ((start_bit + 7) &amp; ~7UL); i++) ext4_set_bit(i, bitmap); if (i &lt; end_bit) memset(bitmap + (i &gt;&gt; 3), 0xff, (end_bit - i) &gt;&gt; 3);&#125;void ext4_end_bitmap_read(struct buffer_head *bh, int uptodate)&#123; if (uptodate) &#123; set_buffer_uptodate(bh); set_bitmap_uptodate(bh); &#125; unlock_buffer(bh); put_bh(bh);&#125;static int ext4_validate_inode_bitmap(struct super_block *sb, struct ext4_group_desc *desc, ext4_group_t block_group, struct buffer_head *bh)&#123; ext4_fsblk_t blk; struct ext4_group_info *grp = ext4_get_group_info(sb, block_group); if (buffer_verified(bh)) return 0; if (EXT4_MB_GRP_IBITMAP_CORRUPT(grp)) return -EFSCORRUPTED; ext4_lock_group(sb, block_group); if (buffer_verified(bh)) goto verified; blk = ext4_inode_bitmap(sb, desc); if (!ext4_inode_bitmap_csum_verify(sb, block_group, desc, bh, EXT4_INODES_PER_GROUP(sb) / 8)) &#123; ext4_unlock_group(sb, block_group); ext4_error(sb, &quot;Corrupt inode bitmap - block_group = %u, &quot; &quot;inode_bitmap = %llu&quot;, block_group, blk); ext4_mark_group_bitmap_corrupted(sb, block_group, EXT4_GROUP_INFO_IBITMAP_CORRUPT); return -EFSBADCRC; &#125; set_buffer_verified(bh);verified: ext4_unlock_group(sb, block_group); return 0;&#125;/* * Read the inode allocation bitmap for a given block_group, reading * into the specified slot in the superblock&#x27;s bitmap cache. * * Return buffer_head of bitmap on success or NULL. */static struct buffer_head *ext4_read_inode_bitmap(struct super_block *sb, ext4_group_t block_group)&#123; struct ext4_group_desc *desc; struct ext4_sb_info *sbi = EXT4_SB(sb); struct buffer_head *bh = NULL; ext4_fsblk_t bitmap_blk; int err; desc = ext4_get_group_desc(sb, block_group, NULL); if (!desc) return ERR_PTR(-EFSCORRUPTED); bitmap_blk = ext4_inode_bitmap(sb, desc); if ((bitmap_blk &lt;= le32_to_cpu(sbi-&gt;s_es-&gt;s_first_data_block)) || (bitmap_blk &gt;= ext4_blocks_count(sbi-&gt;s_es))) &#123; ext4_error(sb, &quot;Invalid inode bitmap blk %llu in &quot; &quot;block_group %u&quot;, bitmap_blk, block_group); ext4_mark_group_bitmap_corrupted(sb, block_group, EXT4_GROUP_INFO_IBITMAP_CORRUPT); return ERR_PTR(-EFSCORRUPTED); &#125; bh = sb_getblk(sb, bitmap_blk); if (unlikely(!bh)) &#123; ext4_warning(sb, &quot;Cannot read inode bitmap - &quot; &quot;block_group = %u, inode_bitmap = %llu&quot;, block_group, bitmap_blk); return ERR_PTR(-ENOMEM); &#125; if (bitmap_uptodate(bh)) goto verify; lock_buffer(bh); if (bitmap_uptodate(bh)) &#123; unlock_buffer(bh); goto verify; &#125; ext4_lock_group(sb, block_group); if (ext4_has_group_desc_csum(sb) &amp;&amp; (desc-&gt;bg_flags &amp; cpu_to_le16(EXT4_BG_INODE_UNINIT))) &#123; if (block_group == 0) &#123; ext4_unlock_group(sb, block_group); unlock_buffer(bh); ext4_error(sb, &quot;Inode bitmap for bg 0 marked &quot; &quot;uninitialized&quot;); err = -EFSCORRUPTED; goto out; &#125; memset(bh-&gt;b_data, 0, (EXT4_INODES_PER_GROUP(sb) + 7) / 8); ext4_mark_bitmap_end(EXT4_INODES_PER_GROUP(sb), sb-&gt;s_blocksize * 8, bh-&gt;b_data); set_bitmap_uptodate(bh); set_buffer_uptodate(bh); set_buffer_verified(bh); ext4_unlock_group(sb, block_group); unlock_buffer(bh); return bh; &#125; ext4_unlock_group(sb, block_group); if (buffer_uptodate(bh)) &#123; /* * if not uninit if bh is uptodate, * bitmap is also uptodate */ set_bitmap_uptodate(bh); unlock_buffer(bh); goto verify; &#125; /* * submit the buffer_head for reading */ trace_ext4_load_inode_bitmap(sb, block_group); bh-&gt;b_end_io = ext4_end_bitmap_read; get_bh(bh); submit_bh(REQ_OP_READ, REQ_META | REQ_PRIO, bh); wait_on_buffer(bh); if (!buffer_uptodate(bh)) &#123; put_bh(bh); ext4_error(sb, &quot;Cannot read inode bitmap - &quot; &quot;block_group = %u, inode_bitmap = %llu&quot;, block_group, bitmap_blk); ext4_mark_group_bitmap_corrupted(sb, block_group, EXT4_GROUP_INFO_IBITMAP_CORRUPT); return ERR_PTR(-EIO); &#125;verify: err = ext4_validate_inode_bitmap(sb, desc, block_group, bh); if (err) goto out; return bh;out: put_bh(bh); return ERR_PTR(err);&#125;/* * NOTE! When we get the inode, we&#x27;re the only people * that have access to it, and as such there are no * race conditions we have to worry about. The inode * is not on the hash-lists, and it cannot be reached * through the filesystem because the directory entry * has been deleted earlier. * * HOWEVER: we must make sure that we get no aliases, * which means that we have to call &quot;clear_inode()&quot; * _before_ we mark the inode not in use in the inode * bitmaps. Otherwise a newly created file might use * the same inode number (not actually the same pointer * though), and then we&#x27;d have two inodes sharing the * same inode number and space on the harddisk. */void ext4_free_inode(handle_t *handle, struct inode *inode)&#123; struct super_block *sb = inode-&gt;i_sb; int is_directory; unsigned long ino; struct buffer_head *bitmap_bh = NULL; struct buffer_head *bh2; ext4_group_t block_group; unsigned long bit; struct ext4_group_desc *gdp; struct ext4_super_block *es; struct ext4_sb_info *sbi; int fatal = 0, err, count, cleared; struct ext4_group_info *grp; if (!sb) &#123; printk(KERN_ERR &quot;EXT4-fs: %s:%d: inode on &quot; &quot;nonexistent device\\n&quot;, __func__, __LINE__); return; &#125; if (atomic_read(&amp;inode-&gt;i_count) &gt; 1) &#123; ext4_msg(sb, KERN_ERR, &quot;%s:%d: inode #%lu: count=%d&quot;, __func__, __LINE__, inode-&gt;i_ino, atomic_read(&amp;inode-&gt;i_count)); return; &#125; if (inode-&gt;i_nlink) &#123; ext4_msg(sb, KERN_ERR, &quot;%s:%d: inode #%lu: nlink=%d\\n&quot;, __func__, __LINE__, inode-&gt;i_ino, inode-&gt;i_nlink); return; &#125; sbi = EXT4_SB(sb); ino = inode-&gt;i_ino; ext4_debug(&quot;freeing inode %lu\\n&quot;, ino); trace_ext4_free_inode(inode); /* * Note: we must free any quota before locking the superblock, * as writing the quota to disk may need the lock as well. */ dquot_initialize(inode); dquot_free_inode(inode); dquot_drop(inode); is_directory = S_ISDIR(inode-&gt;i_mode); /* Do this BEFORE marking the inode not in use or returning an error */ ext4_clear_inode(inode); es = sbi-&gt;s_es; if (ino &lt; EXT4_FIRST_INO(sb) || ino &gt; le32_to_cpu(es-&gt;s_inodes_count)) &#123; ext4_error(sb, &quot;reserved or nonexistent inode %lu&quot;, ino); goto error_return; &#125; block_group = (ino - 1) / EXT4_INODES_PER_GROUP(sb); bit = (ino - 1) % EXT4_INODES_PER_GROUP(sb); bitmap_bh = ext4_read_inode_bitmap(sb, block_group); /* Don&#x27;t bother if the inode bitmap is corrupt. */ grp = ext4_get_group_info(sb, block_group); if (IS_ERR(bitmap_bh)) &#123; fatal = PTR_ERR(bitmap_bh); bitmap_bh = NULL; goto error_return; &#125; if (unlikely(EXT4_MB_GRP_IBITMAP_CORRUPT(grp))) &#123; fatal = -EFSCORRUPTED; goto error_return; &#125; BUFFER_TRACE(bitmap_bh, &quot;get_write_access&quot;); fatal = ext4_journal_get_write_access(handle, bitmap_bh); if (fatal) goto error_return; fatal = -ESRCH; gdp = ext4_get_group_desc(sb, block_group, &amp;bh2); if (gdp) &#123; BUFFER_TRACE(bh2, &quot;get_write_access&quot;); fatal = ext4_journal_get_write_access(handle, bh2); &#125; ext4_lock_group(sb, block_group); cleared = ext4_test_and_clear_bit(bit, bitmap_bh-&gt;b_data); if (fatal || !cleared) &#123; ext4_unlock_group(sb, block_group); goto out; &#125; count = ext4_free_inodes_count(sb, gdp) + 1; ext4_free_inodes_set(sb, gdp, count); if (is_directory) &#123; count = ext4_used_dirs_count(sb, gdp) - 1; ext4_used_dirs_set(sb, gdp, count); percpu_counter_dec(&amp;sbi-&gt;s_dirs_counter); &#125; ext4_inode_bitmap_csum_set(sb, block_group, gdp, bitmap_bh, EXT4_INODES_PER_GROUP(sb) / 8); ext4_group_desc_csum_set(sb, block_group, gdp); ext4_unlock_group(sb, block_group); percpu_counter_inc(&amp;sbi-&gt;s_freeinodes_counter); if (sbi-&gt;s_log_groups_per_flex) &#123; ext4_group_t f = ext4_flex_group(sbi, block_group); atomic_inc(&amp;sbi-&gt;s_flex_groups[f].free_inodes); if (is_directory) atomic_dec(&amp;sbi-&gt;s_flex_groups[f].used_dirs); &#125; BUFFER_TRACE(bh2, &quot;call ext4_handle_dirty_metadata&quot;); fatal = ext4_handle_dirty_metadata(handle, NULL, bh2);out: if (cleared) &#123; BUFFER_TRACE(bitmap_bh, &quot;call ext4_handle_dirty_metadata&quot;); err = ext4_handle_dirty_metadata(handle, NULL, bitmap_bh); if (!fatal) fatal = err; &#125; else &#123; ext4_error(sb, &quot;bit already cleared for inode %lu&quot;, ino); ext4_mark_group_bitmap_corrupted(sb, block_group, EXT4_GROUP_INFO_IBITMAP_CORRUPT); &#125;error_return: brelse(bitmap_bh); ext4_std_error(sb, fatal);&#125;struct orlov_stats &#123; __u64 free_clusters; __u32 free_inodes; __u32 used_dirs;&#125;;/* * Helper function for Orlov&#x27;s allocator; returns critical information * for a particular block group or flex_bg. If flex_size is 1, then g * is a block group number; otherwise it is flex_bg number. */static void get_orlov_stats(struct super_block *sb, ext4_group_t g, int flex_size, struct orlov_stats *stats)&#123; struct ext4_group_desc *desc; struct flex_groups *flex_group = EXT4_SB(sb)-&gt;s_flex_groups; if (flex_size &gt; 1) &#123; stats-&gt;free_inodes = atomic_read(&amp;flex_group[g].free_inodes); stats-&gt;free_clusters = atomic64_read(&amp;flex_group[g].free_clusters); stats-&gt;used_dirs = atomic_read(&amp;flex_group[g].used_dirs); return; &#125; desc = ext4_get_group_desc(sb, g, NULL); if (desc) &#123; stats-&gt;free_inodes = ext4_free_inodes_count(sb, desc); stats-&gt;free_clusters = ext4_free_group_clusters(sb, desc); stats-&gt;used_dirs = ext4_used_dirs_count(sb, desc); &#125; else &#123; stats-&gt;free_inodes = 0; stats-&gt;free_clusters = 0; stats-&gt;used_dirs = 0; &#125;&#125;/* * Orlov&#x27;s allocator for directories. * * We always try to spread first-level directories. * * If there are blockgroups with both free inodes and free blocks counts * not worse than average we return one with smallest directory count. * Otherwise we simply return a random group. * * For the rest rules look so: * * It&#x27;s OK to put directory into a group unless * it has too many directories already (max_dirs) or * it has too few free inodes left (min_inodes) or * it has too few free blocks left (min_blocks) or * Parent&#x27;s group is preferred, if it doesn&#x27;t satisfy these * conditions we search cyclically through the rest. If none * of the groups look good we just look for a group with more * free inodes than average (starting at parent&#x27;s group). */static int find_group_orlov(struct super_block *sb, struct inode *parent, ext4_group_t *group, umode_t mode, const struct qstr *qstr)&#123; ext4_group_t parent_group = EXT4_I(parent)-&gt;i_block_group; struct ext4_sb_info *sbi = EXT4_SB(sb); ext4_group_t real_ngroups = ext4_get_groups_count(sb); int inodes_per_group = EXT4_INODES_PER_GROUP(sb); unsigned int freei, avefreei, grp_free; ext4_fsblk_t freeb, avefreec; unsigned int ndirs; int max_dirs, min_inodes; ext4_grpblk_t min_clusters; ext4_group_t i, grp, g, ngroups; struct ext4_group_desc *desc; struct orlov_stats stats; int flex_size = ext4_flex_bg_size(sbi); struct dx_hash_info hinfo; ngroups = real_ngroups; if (flex_size &gt; 1) &#123; ngroups = (real_ngroups + flex_size - 1) &gt;&gt; sbi-&gt;s_log_groups_per_flex; parent_group &gt;&gt;= sbi-&gt;s_log_groups_per_flex; &#125; freei = percpu_counter_read_positive(&amp;sbi-&gt;s_freeinodes_counter); avefreei = freei / ngroups; freeb = EXT4_C2B(sbi, percpu_counter_read_positive(&amp;sbi-&gt;s_freeclusters_counter)); avefreec = freeb; do_div(avefreec, ngroups); ndirs = percpu_counter_read_positive(&amp;sbi-&gt;s_dirs_counter); if (S_ISDIR(mode) &amp;&amp; ((parent == d_inode(sb-&gt;s_root)) || (ext4_test_inode_flag(parent, EXT4_INODE_TOPDIR)))) &#123; int best_ndir = inodes_per_group; int ret = -1; if (qstr) &#123; hinfo.hash_version = DX_HASH_HALF_MD4; hinfo.seed = sbi-&gt;s_hash_seed; ext4fs_dirhash(parent, qstr-&gt;name, qstr-&gt;len, &amp;hinfo); grp = hinfo.hash; &#125; else grp = prandom_u32(); parent_group = (unsigned)grp % ngroups; for (i = 0; i &lt; ngroups; i++) &#123; g = (parent_group + i) % ngroups; get_orlov_stats(sb, g, flex_size, &amp;stats); if (!stats.free_inodes) continue; if (stats.used_dirs &gt;= best_ndir) continue; if (stats.free_inodes &lt; avefreei) continue; if (stats.free_clusters &lt; avefreec) continue; grp = g; ret = 0; best_ndir = stats.used_dirs; &#125; if (ret) goto fallback; found_flex_bg: if (flex_size == 1) &#123; *group = grp; return 0; &#125; /* * We pack inodes at the beginning of the flexgroup&#x27;s * inode tables. Block allocation decisions will do * something similar, although regular files will * start at 2nd block group of the flexgroup. See * ext4_ext_find_goal() and ext4_find_near(). */ grp *= flex_size; for (i = 0; i &lt; flex_size; i++) &#123; if (grp+i &gt;= real_ngroups) break; desc = ext4_get_group_desc(sb, grp+i, NULL); if (desc &amp;&amp; ext4_free_inodes_count(sb, desc)) &#123; *group = grp+i; return 0; &#125; &#125; goto fallback; &#125; max_dirs = ndirs / ngroups + inodes_per_group / 16; min_inodes = avefreei - inodes_per_group*flex_size / 4; if (min_inodes &lt; 1) min_inodes = 1; min_clusters = avefreec - EXT4_CLUSTERS_PER_GROUP(sb)*flex_size / 4; /* * Start looking in the flex group where we last allocated an * inode for this parent directory */ if (EXT4_I(parent)-&gt;i_last_alloc_group != ~0) &#123; parent_group = EXT4_I(parent)-&gt;i_last_alloc_group; if (flex_size &gt; 1) parent_group &gt;&gt;= sbi-&gt;s_log_groups_per_flex; &#125; for (i = 0; i &lt; ngroups; i++) &#123; grp = (parent_group + i) % ngroups; get_orlov_stats(sb, grp, flex_size, &amp;stats); if (stats.used_dirs &gt;= max_dirs) continue; if (stats.free_inodes &lt; min_inodes) continue; if (stats.free_clusters &lt; min_clusters) continue; goto found_flex_bg; &#125;fallback: ngroups = real_ngroups; avefreei = freei / ngroups;fallback_retry: parent_group = EXT4_I(parent)-&gt;i_block_group; for (i = 0; i &lt; ngroups; i++) &#123; grp = (parent_group + i) % ngroups; desc = ext4_get_group_desc(sb, grp, NULL); if (desc) &#123; grp_free = ext4_free_inodes_count(sb, desc); if (grp_free &amp;&amp; grp_free &gt;= avefreei) &#123; *group = grp; return 0; &#125; &#125; &#125; if (avefreei) &#123; /* * The free-inodes counter is approximate, and for really small * filesystems the above test can fail to find any blockgroups */ avefreei = 0; goto fallback_retry; &#125; return -1;&#125;static int find_group_other(struct super_block *sb, struct inode *parent, ext4_group_t *group, umode_t mode)&#123; ext4_group_t parent_group = EXT4_I(parent)-&gt;i_block_group; ext4_group_t i, last, ngroups = ext4_get_groups_count(sb); struct ext4_group_desc *desc; int flex_size = ext4_flex_bg_size(EXT4_SB(sb)); /* * Try to place the inode is the same flex group as its * parent. If we can&#x27;t find space, use the Orlov algorithm to * find another flex group, and store that information in the * parent directory&#x27;s inode information so that use that flex * group for future allocations. */ if (flex_size &gt; 1) &#123; int retry = 0; try_again: parent_group &amp;= ~(flex_size-1); last = parent_group + flex_size; if (last &gt; ngroups) last = ngroups; for (i = parent_group; i &lt; last; i++) &#123; desc = ext4_get_group_desc(sb, i, NULL); if (desc &amp;&amp; ext4_free_inodes_count(sb, desc)) &#123; *group = i; return 0; &#125; &#125; if (!retry &amp;&amp; EXT4_I(parent)-&gt;i_last_alloc_group != ~0) &#123; retry = 1; parent_group = EXT4_I(parent)-&gt;i_last_alloc_group; goto try_again; &#125; /* * If this didn&#x27;t work, use the Orlov search algorithm * to find a new flex group; we pass in the mode to * avoid the topdir algorithms. */ *group = parent_group + flex_size; if (*group &gt; ngroups) *group = 0; return find_group_orlov(sb, parent, group, mode, NULL); &#125; /* * Try to place the inode in its parent directory */ *group = parent_group; desc = ext4_get_group_desc(sb, *group, NULL); if (desc &amp;&amp; ext4_free_inodes_count(sb, desc) &amp;&amp; ext4_free_group_clusters(sb, desc)) return 0; /* * We&#x27;re going to place this inode in a different blockgroup from its * parent. We want to cause files in a common directory to all land in * the same blockgroup. But we want files which are in a different * directory which shares a blockgroup with our parent to land in a * different blockgroup. * * So add our directory&#x27;s i_ino into the starting point for the hash. */ *group = (*group + parent-&gt;i_ino) % ngroups; /* * Use a quadratic hash to find a group with a free inode and some free * blocks. */ for (i = 1; i &lt; ngroups; i &lt;&lt;= 1) &#123; *group += i; if (*group &gt;= ngroups) *group -= ngroups; desc = ext4_get_group_desc(sb, *group, NULL); if (desc &amp;&amp; ext4_free_inodes_count(sb, desc) &amp;&amp; ext4_free_group_clusters(sb, desc)) return 0; &#125; /* * That failed: try linear search for a free inode, even if that group * has no free blocks. */ *group = parent_group; for (i = 0; i &lt; ngroups; i++) &#123; if (++*group &gt;= ngroups) *group = 0; desc = ext4_get_group_desc(sb, *group, NULL); if (desc &amp;&amp; ext4_free_inodes_count(sb, desc)) return 0; &#125; return -1;&#125;/* * In no journal mode, if an inode has recently been deleted, we want * to avoid reusing it until we&#x27;re reasonably sure the inode table * block has been written back to disk. (Yes, these values are * somewhat arbitrary...) */#define RECENTCY_MIN 5#define RECENTCY_DIRTY 300static int recently_deleted(struct super_block *sb, ext4_group_t group, int ino)&#123; struct ext4_group_desc *gdp; struct ext4_inode *raw_inode; struct buffer_head *bh; int inodes_per_block = EXT4_SB(sb)-&gt;s_inodes_per_block; int offset, ret = 0; int recentcy = RECENTCY_MIN; u32 dtime, now; gdp = ext4_get_group_desc(sb, group, NULL); if (unlikely(!gdp)) return 0; bh = sb_find_get_block(sb, ext4_inode_table(sb, gdp) + (ino / inodes_per_block)); if (!bh || !buffer_uptodate(bh)) /* * If the block is not in the buffer cache, then it * must have been written out. */ goto out; offset = (ino % inodes_per_block) * EXT4_INODE_SIZE(sb); raw_inode = (struct ext4_inode *) (bh-&gt;b_data + offset); /* i_dtime is only 32 bits on disk, but we only care about relative * times in the range of a few minutes (i.e. long enough to sync a * recently-deleted inode to disk), so using the low 32 bits of the * clock (a 68 year range) is enough, see time_before32() */ dtime = le32_to_cpu(raw_inode-&gt;i_dtime); now = ktime_get_real_seconds(); if (buffer_dirty(bh)) recentcy += RECENTCY_DIRTY; if (dtime &amp;&amp; time_before32(dtime, now) &amp;&amp; time_before32(now, dtime + recentcy)) ret = 1;out: brelse(bh); return ret;&#125;static int find_inode_bit(struct super_block *sb, ext4_group_t group, struct buffer_head *bitmap, unsigned long *ino)&#123;next: *ino = ext4_find_next_zero_bit((unsigned long *) bitmap-&gt;b_data, EXT4_INODES_PER_GROUP(sb), *ino); if (*ino &gt;= EXT4_INODES_PER_GROUP(sb)) return 0; if ((EXT4_SB(sb)-&gt;s_journal == NULL) &amp;&amp; recently_deleted(sb, group, *ino)) &#123; *ino = *ino + 1; if (*ino &lt; EXT4_INODES_PER_GROUP(sb)) goto next; return 0; &#125; return 1;&#125;/* * There are two policies for allocating an inode. If the new inode is * a directory, then a forward search is made for a block group with both * free space and a low directory-to-inode ratio; if that fails, then of * the groups with above-average free space, that group with the fewest * directories already is chosen. * * For other inodes, search forward from the parent directory&#x27;s block * group to find a free inode. */struct inode *__ext4_new_inode(handle_t *handle, struct inode *dir, umode_t mode, const struct qstr *qstr, __u32 goal, uid_t *owner, __u32 i_flags, int handle_type, unsigned int line_no, int nblocks)/*handle: 一个指向日志处理的指针，用于日志操作。dir: 指向父目录inode的指针。mode: 文件模式，指示文件类型和权限。qstr: 指向qstr结构的指针，表示新inode的名称。goal: 新inode的首选块组号。owner: 指向inode所有者的UID（用户ID）的指针。i_flags: Inode标志。handle_type: 表示日志处理类型的整数。line_no: 源代码中调用此函数的行号（用于调试目的）。nblocks: 新inode所需的块数。*/&#123; struct super_block *sb;//指向文件系统的超级块的指针。 struct buffer_head *inode_bitmap_bh = NULL;// 指向inode位图的缓冲区头指针。 struct buffer_head *group_desc_bh;//指向组描述符的缓冲区头指针。 ext4_group_t ngroups, group = 0;// 文件系统中的组总数。 unsigned long ino = 0;//inode编号。 struct inode *inode;//指向正在创建的新inode的指针。 struct ext4_group_desc *gdp = NULL;//指向当前ext4组描述符的指针。 struct ext4_inode_info *ei;//指向ext4 inode信息的指针。 struct ext4_sb_info *sbi;//指向ext4超级块信息的指针。 int ret2, err;//用于错误处理的整数变量。 struct inode *ret;// 指向由函数返回的inode的指针。 ext4_group_t i;// 用于遍历组的循环变量。 ext4_group_t flex_group;//弹性块组号。 struct ext4_group_info *grp;// 指向ext4组信息的指针。 int encrypt = 0;//表示inode是否应加密的整数。 /* Cannot create files in a deleted directory */ if (!dir || !dir-&gt;i_nlink)// 检查dir是否为有效指针，以及是否有硬链接 return ERR_PTR(-EPERM);//如果不是返回权限错误 sb = dir-&gt;i_sb;// 获取指向超级块的指针 sbi = EXT4_SB(sb);// 获取指向ext4超级块信息的指针 if (unlikely(ext4_forced_shutdown(sbi)))// 检查文件系统是否处于强制关闭状态 return ERR_PTR(-EIO);//返回IO错误 if ((IS_ENCRYPTED(dir) || DUMMY_ENCRYPTION_ENABLED(sbi)) &amp;&amp; (S_ISREG(mode) || S_ISDIR(mode) || S_ISLNK(mode)) &amp;&amp; !(i_flags &amp; EXT4_EA_INODE_FL)) &#123;// 检查是否需要对新创建的inode进行加密 // 获取父目录的加密信息 err = fscrypt_get_encryption_info(dir); if (err) return ERR_PTR(err); // 如果发生错误，返回错误指针 if (!fscrypt_has_encryption_key(dir)) // 检查是否存在加密密钥 return ERR_PTR(-ENOKEY);//没有则返回错误 encrypt = 1;// 若满足加密条件，设置加密标志 &#125;// 检查是否需要处理扩展属性 if (!handle &amp;&amp; sbi-&gt;s_journal &amp;&amp; !(i_flags &amp; EXT4_EA_INODE_FL)) &#123;#ifdef CONFIG_EXT4_FS_POSIX_ACL struct posix_acl *p = get_acl(dir, ACL_TYPE_DEFAULT);// 获取父目录的默认POSIX ACL if (IS_ERR(p))// 如果返回错误，直接返回错误指针 return ERR_CAST(p); if (p) &#123;// 计算POSIX ACL所需的空间大小 int acl_size = p-&gt;a_count * sizeof(ext4_acl_entry);// 根据inode类型（目录或其他）增加所需的元数据块计数 nblocks += (S_ISDIR(mode) ? 2 : 1) * __ext4_xattr_set_credits(sb, NULL /* inode */, NULL /* block_bh */, acl_size, true /* is_create */); posix_acl_release(p);// 释放POSIX ACL结构 &#125;#endif#ifdef CONFIG_SECURITY// 如果启用了系统完整性功能，增加安全扩展属性的数量 &#123; int num_security_xattrs = 1;#ifdef CONFIG_INTEGRITY num_security_xattrs++;#endif /* * We assume that security xattrs are never * more than 1k. In practice they are under * 128 bytes. */ // 增加安全扩展属性所需的元数据块计数 nblocks += num_security_xattrs * __ext4_xattr_set_credits(sb, NULL /* inode */, NULL /* block_bh */, 1024, true /* is_create */); &#125;#endif// 如果需要加密，增加加密上下文所需的元数据块计数 if (encrypt) nblocks += __ext4_xattr_set_credits(sb, NULL /* inode */, NULL /* block_bh */, FSCRYPT_SET_CONTEXT_MAX_SIZE, true /* is_create */); &#125; ngroups = ext4_get_groups_count(sb);//ngroups 是超级块（sb）中ext4组的总数。 trace_ext4_request_inode(dir, mode);//trace_ext4_request_inode(dir, mode) 是用于调试文件系统的跟踪事件。 inode = new_inode(sb);//new_inode(sb) 是一个函数调用，用于在超级块中分配一个新的inode。 if (!inode)//块检查inode分配是否成功；如果不成功，它将返回一个带有错误代码 -ENOMEM 的错误指针。 return ERR_PTR(-ENOMEM); ei = EXT4_I(inode); /* * Initialize owners and quota early so that we don&#x27;t have to account * for quota initialization worst case in standard inode creating * transaction */ if (owner) &#123; inode-&gt;i_mode = mode; i_uid_write(inode, owner[0]); i_gid_write(inode, owner[1]); &#125; else if (test_opt(sb, GRPID)) &#123; inode-&gt;i_mode = mode; inode-&gt;i_uid = current_fsuid(); inode-&gt;i_gid = dir-&gt;i_gid; &#125; else inode_init_owner(inode, dir, mode); if (ext4_has_feature_project(sb) &amp;&amp; ext4_test_inode_flag(dir, EXT4_INODE_PROJINHERIT)) ei-&gt;i_projid = EXT4_I(dir)-&gt;i_projid; else ei-&gt;i_projid = make_kprojid(&amp;init_user_ns, EXT4_DEF_PROJID); err = dquot_initialize(inode); if (err) goto out; if (!goal) goal = sbi-&gt;s_inode_goal; if (goal &amp;&amp; goal &lt;= le32_to_cpu(sbi-&gt;s_es-&gt;s_inodes_count)) &#123; group = (goal - 1) / EXT4_INODES_PER_GROUP(sb); ino = (goal - 1) % EXT4_INODES_PER_GROUP(sb); ret2 = 0; goto got_group; &#125; if (S_ISDIR(mode)) ret2 = find_group_orlov(sb, dir, &amp;group, mode, qstr); else ret2 = find_group_other(sb, dir, &amp;group, mode);got_group: EXT4_I(dir)-&gt;i_last_alloc_group = group; err = -ENOSPC; if (ret2 == -1) goto out; /* * Normally we will only go through one pass of this loop, * unless we get unlucky and it turns out the group we selected * had its last inode grabbed by someone else. */ for (i = 0; i &lt; ngroups; i++, ino = 0) &#123; err = -EIO; gdp = ext4_get_group_desc(sb, group, &amp;group_desc_bh); if (!gdp) goto out; /* * Check free inodes count before loading bitmap. */ if (ext4_free_inodes_count(sb, gdp) == 0) goto next_group; grp = ext4_get_group_info(sb, group); /* Skip groups with already-known suspicious inode tables */ if (EXT4_MB_GRP_IBITMAP_CORRUPT(grp)) goto next_group; brelse(inode_bitmap_bh); inode_bitmap_bh = ext4_read_inode_bitmap(sb, group); /* Skip groups with suspicious inode tables */ if (EXT4_MB_GRP_IBITMAP_CORRUPT(grp) || IS_ERR(inode_bitmap_bh)) &#123; inode_bitmap_bh = NULL; goto next_group; &#125;repeat_in_this_group: ret2 = find_inode_bit(sb, group, inode_bitmap_bh, &amp;ino); if (!ret2) goto next_group; if (group == 0 &amp;&amp; (ino + 1) &lt; EXT4_FIRST_INO(sb)) &#123; ext4_error(sb, &quot;reserved inode found cleared - &quot; &quot;inode=%lu&quot;, ino + 1); ext4_mark_group_bitmap_corrupted(sb, group, EXT4_GROUP_INFO_IBITMAP_CORRUPT); goto next_group; &#125; if (!handle) &#123; BUG_ON(nblocks &lt;= 0); handle = __ext4_journal_start_sb(dir-&gt;i_sb, line_no, handle_type, nblocks, 0); if (IS_ERR(handle)) &#123; err = PTR_ERR(handle); ext4_std_error(sb, err); goto out; &#125; &#125; BUFFER_TRACE(inode_bitmap_bh, &quot;get_write_access&quot;); err = ext4_journal_get_write_access(handle, inode_bitmap_bh); if (err) &#123; ext4_std_error(sb, err); goto out; &#125; ext4_lock_group(sb, group); ret2 = ext4_test_and_set_bit(ino, inode_bitmap_bh-&gt;b_data); if (ret2) &#123; /* Someone already took the bit. Repeat the search * with lock held. */ ret2 = find_inode_bit(sb, group, inode_bitmap_bh, &amp;ino); if (ret2) &#123; ext4_set_bit(ino, inode_bitmap_bh-&gt;b_data); ret2 = 0; &#125; else &#123; ret2 = 1; /* we didn&#x27;t grab the inode */ &#125; &#125; ext4_unlock_group(sb, group); ino++; /* the inode bitmap is zero-based */ if (!ret2) goto got; /* we grabbed the inode! */ if (ino &lt; EXT4_INODES_PER_GROUP(sb)) goto repeat_in_this_group;next_group: if (++group == ngroups) group = 0; &#125; err = -ENOSPC; goto out;got: BUFFER_TRACE(inode_bitmap_bh, &quot;call ext4_handle_dirty_metadata&quot;); err = ext4_handle_dirty_metadata(handle, NULL, inode_bitmap_bh); if (err) &#123; ext4_std_error(sb, err); goto out; &#125; BUFFER_TRACE(group_desc_bh, &quot;get_write_access&quot;); err = ext4_journal_get_write_access(handle, group_desc_bh); if (err) &#123; ext4_std_error(sb, err); goto out; &#125; /* We may have to initialize the block bitmap if it isn&#x27;t already */ if (ext4_has_group_desc_csum(sb) &amp;&amp; gdp-&gt;bg_flags &amp; cpu_to_le16(EXT4_BG_BLOCK_UNINIT)) &#123; struct buffer_head *block_bitmap_bh; block_bitmap_bh = ext4_read_block_bitmap(sb, group); if (IS_ERR(block_bitmap_bh)) &#123; err = PTR_ERR(block_bitmap_bh); goto out; &#125; BUFFER_TRACE(block_bitmap_bh, &quot;get block bitmap access&quot;); err = ext4_journal_get_write_access(handle, block_bitmap_bh); if (err) &#123; brelse(block_bitmap_bh); ext4_std_error(sb, err); goto out; &#125; BUFFER_TRACE(block_bitmap_bh, &quot;dirty block bitmap&quot;); err = ext4_handle_dirty_metadata(handle, NULL, block_bitmap_bh); /* recheck and clear flag under lock if we still need to */ ext4_lock_group(sb, group); if (ext4_has_group_desc_csum(sb) &amp;&amp; (gdp-&gt;bg_flags &amp; cpu_to_le16(EXT4_BG_BLOCK_UNINIT))) &#123; gdp-&gt;bg_flags &amp;= cpu_to_le16(~EXT4_BG_BLOCK_UNINIT); ext4_free_group_clusters_set(sb, gdp, ext4_free_clusters_after_init(sb, group, gdp)); ext4_block_bitmap_csum_set(sb, group, gdp, block_bitmap_bh); ext4_group_desc_csum_set(sb, group, gdp); &#125; ext4_unlock_group(sb, group); brelse(block_bitmap_bh); if (err) &#123; ext4_std_error(sb, err); goto out; &#125; &#125; /* Update the relevant bg descriptor fields */ if (ext4_has_group_desc_csum(sb)) &#123; int free; struct ext4_group_info *grp = ext4_get_group_info(sb, group); down_read(&amp;grp-&gt;alloc_sem); /* protect vs itable lazyinit */ ext4_lock_group(sb, group); /* while we modify the bg desc */ free = EXT4_INODES_PER_GROUP(sb) - ext4_itable_unused_count(sb, gdp); if (gdp-&gt;bg_flags &amp; cpu_to_le16(EXT4_BG_INODE_UNINIT)) &#123; gdp-&gt;bg_flags &amp;= cpu_to_le16(~EXT4_BG_INODE_UNINIT); free = 0; &#125; /* * Check the relative inode number against the last used * relative inode number in this group. if it is greater * we need to update the bg_itable_unused count */ if (ino &gt; free) ext4_itable_unused_set(sb, gdp, (EXT4_INODES_PER_GROUP(sb) - ino)); up_read(&amp;grp-&gt;alloc_sem); &#125; else &#123; ext4_lock_group(sb, group); &#125; ext4_free_inodes_set(sb, gdp, ext4_free_inodes_count(sb, gdp) - 1); if (S_ISDIR(mode)) &#123; ext4_used_dirs_set(sb, gdp, ext4_used_dirs_count(sb, gdp) + 1); if (sbi-&gt;s_log_groups_per_flex) &#123; ext4_group_t f = ext4_flex_group(sbi, group); atomic_inc(&amp;sbi-&gt;s_flex_groups[f].used_dirs); &#125; &#125; if (ext4_has_group_desc_csum(sb)) &#123; ext4_inode_bitmap_csum_set(sb, group, gdp, inode_bitmap_bh, EXT4_INODES_PER_GROUP(sb) / 8); ext4_group_desc_csum_set(sb, group, gdp); &#125; ext4_unlock_group(sb, group); BUFFER_TRACE(group_desc_bh, &quot;call ext4_handle_dirty_metadata&quot;); err = ext4_handle_dirty_metadata(handle, NULL, group_desc_bh); if (err) &#123; ext4_std_error(sb, err); goto out; &#125; percpu_counter_dec(&amp;sbi-&gt;s_freeinodes_counter); if (S_ISDIR(mode)) percpu_counter_inc(&amp;sbi-&gt;s_dirs_counter); if (sbi-&gt;s_log_groups_per_flex) &#123; flex_group = ext4_flex_group(sbi, group); atomic_dec(&amp;sbi-&gt;s_flex_groups[flex_group].free_inodes); &#125; inode-&gt;i_ino = ino + group * EXT4_INODES_PER_GROUP(sb); /* This is the optimal IO size (for stat), not the fs block size */ inode-&gt;i_blocks = 0; inode-&gt;i_mtime = inode-&gt;i_atime = inode-&gt;i_ctime = current_time(inode); ei-&gt;i_crtime = inode-&gt;i_mtime; memset(ei-&gt;i_data, 0, sizeof(ei-&gt;i_data)); ei-&gt;i_dir_start_lookup = 0; ei-&gt;i_disksize = 0; /* Don&#x27;t inherit extent flag from directory, amongst others. */ ei-&gt;i_flags = ext4_mask_flags(mode, EXT4_I(dir)-&gt;i_flags &amp; EXT4_FL_INHERITED); ei-&gt;i_flags |= i_flags; ei-&gt;i_file_acl = 0; ei-&gt;i_dtime = 0; ei-&gt;i_block_group = group; ei-&gt;i_last_alloc_group = ~0; ext4_set_inode_flags(inode); if (IS_DIRSYNC(inode)) ext4_handle_sync(handle); if (insert_inode_locked(inode) &lt; 0) &#123; /* * Likely a bitmap corruption causing inode to be allocated * twice. */ err = -EIO; ext4_error(sb, &quot;failed to insert inode %lu: doubly allocated?&quot;, inode-&gt;i_ino); ext4_mark_group_bitmap_corrupted(sb, group, EXT4_GROUP_INFO_IBITMAP_CORRUPT); goto out; &#125; inode-&gt;i_generation = prandom_u32(); /* Precompute checksum seed for inode metadata */ if (ext4_has_metadata_csum(sb)) &#123; __u32 csum; __le32 inum = cpu_to_le32(inode-&gt;i_ino); __le32 gen = cpu_to_le32(inode-&gt;i_generation); csum = ext4_chksum(sbi, sbi-&gt;s_csum_seed, (__u8 *)&amp;inum, sizeof(inum)); ei-&gt;i_csum_seed = ext4_chksum(sbi, csum, (__u8 *)&amp;gen, sizeof(gen)); &#125; ext4_clear_state_flags(ei); /* Only relevant on 32-bit archs */ ext4_set_inode_state(inode, EXT4_STATE_NEW); ei-&gt;i_extra_isize = sbi-&gt;s_want_extra_isize; ei-&gt;i_inline_off = 0; if (ext4_has_feature_inline_data(sb)) ext4_set_inode_state(inode, EXT4_STATE_MAY_INLINE_DATA); ret = inode; err = dquot_alloc_inode(inode); if (err) goto fail_drop; /* * Since the encryption xattr will always be unique, create it first so * that it&#x27;s less likely to end up in an external xattr block and * prevent its deduplication. */ if (encrypt) &#123; err = fscrypt_inherit_context(dir, inode, handle, true); if (err) goto fail_free_drop; &#125; if (!(ei-&gt;i_flags &amp; EXT4_EA_INODE_FL)) &#123; err = ext4_init_acl(handle, inode, dir); if (err) goto fail_free_drop; err = ext4_init_security(handle, inode, dir, qstr); if (err) goto fail_free_drop; &#125; if (ext4_has_feature_extents(sb)) &#123; /* set extent flag only for directory, file and normal symlink*/ if (S_ISDIR(mode) || S_ISREG(mode) || S_ISLNK(mode)) &#123; ext4_set_inode_flag(inode, EXT4_INODE_EXTENTS); ext4_ext_tree_init(handle, inode); &#125; &#125; if (ext4_handle_valid(handle)) &#123; ei-&gt;i_sync_tid = handle-&gt;h_transaction-&gt;t_tid; ei-&gt;i_datasync_tid = handle-&gt;h_transaction-&gt;t_tid; &#125; err = ext4_mark_inode_dirty(handle, inode); if (err) &#123; ext4_std_error(sb, err); goto fail_free_drop; &#125; ext4_debug(&quot;allocating inode %lu\\n&quot;, inode-&gt;i_ino); trace_ext4_allocate_inode(inode, dir, mode); brelse(inode_bitmap_bh); return ret;fail_free_drop: dquot_free_inode(inode);fail_drop: clear_nlink(inode); unlock_new_inode(inode);out: dquot_drop(inode); inode-&gt;i_flags |= S_NOQUOTA; iput(inode); brelse(inode_bitmap_bh); return ERR_PTR(err);&#125;/* Verify that we are loading a valid orphan from disk */struct inode *ext4_orphan_get(struct super_block *sb, unsigned long ino)&#123; unsigned long max_ino = le32_to_cpu(EXT4_SB(sb)-&gt;s_es-&gt;s_inodes_count); ext4_group_t block_group; int bit; struct buffer_head *bitmap_bh = NULL; struct inode *inode = NULL; int err = -EFSCORRUPTED; if (ino &lt; EXT4_FIRST_INO(sb) || ino &gt; max_ino) goto bad_orphan; block_group = (ino - 1) / EXT4_INODES_PER_GROUP(sb); bit = (ino - 1) % EXT4_INODES_PER_GROUP(sb); bitmap_bh = ext4_read_inode_bitmap(sb, block_group); if (IS_ERR(bitmap_bh)) return ERR_CAST(bitmap_bh); /* Having the inode bit set should be a 100% indicator that this * is a valid orphan (no e2fsck run on fs). Orphans also include * inodes that were being truncated, so we can&#x27;t check i_nlink==0. */ if (!ext4_test_bit(bit, bitmap_bh-&gt;b_data)) goto bad_orphan; inode = ext4_iget(sb, ino, EXT4_IGET_NORMAL); if (IS_ERR(inode)) &#123; err = PTR_ERR(inode); ext4_error(sb, &quot;couldn&#x27;t read orphan inode %lu (err %d)&quot;, ino, err); return inode; &#125; /* * If the orphans has i_nlinks &gt; 0 then it should be able to * be truncated, otherwise it won&#x27;t be removed from the orphan * list during processing and an infinite loop will result. * Similarly, it must not be a bad inode. */ if ((inode-&gt;i_nlink &amp;&amp; !ext4_can_truncate(inode)) || is_bad_inode(inode)) goto bad_orphan; if (NEXT_ORPHAN(inode) &gt; max_ino) goto bad_orphan; brelse(bitmap_bh); return inode;bad_orphan: ext4_error(sb, &quot;bad orphan inode %lu&quot;, ino); if (bitmap_bh) printk(KERN_ERR &quot;ext4_test_bit(bit=%d, block=%llu) = %d\\n&quot;, bit, (unsigned long long)bitmap_bh-&gt;b_blocknr, ext4_test_bit(bit, bitmap_bh-&gt;b_data)); if (inode) &#123; printk(KERN_ERR &quot;is_bad_inode(inode)=%d\\n&quot;, is_bad_inode(inode)); printk(KERN_ERR &quot;NEXT_ORPHAN(inode)=%u\\n&quot;, NEXT_ORPHAN(inode)); printk(KERN_ERR &quot;max_ino=%lu\\n&quot;, max_ino); printk(KERN_ERR &quot;i_nlink=%u\\n&quot;, inode-&gt;i_nlink); /* Avoid freeing blocks if we got a bad deleted inode */ if (inode-&gt;i_nlink == 0) inode-&gt;i_blocks = 0; iput(inode); &#125; brelse(bitmap_bh); return ERR_PTR(err);&#125;unsigned long ext4_count_free_inodes(struct super_block *sb)&#123; unsigned long desc_count; struct ext4_group_desc *gdp; ext4_group_t i, ngroups = ext4_get_groups_count(sb);#ifdef EXT4FS_DEBUG struct ext4_super_block *es; unsigned long bitmap_count, x; struct buffer_head *bitmap_bh = NULL; es = EXT4_SB(sb)-&gt;s_es; desc_count = 0; bitmap_count = 0; gdp = NULL; for (i = 0; i &lt; ngroups; i++) &#123; gdp = ext4_get_group_desc(sb, i, NULL); if (!gdp) continue; desc_count += ext4_free_inodes_count(sb, gdp); brelse(bitmap_bh); bitmap_bh = ext4_read_inode_bitmap(sb, i); if (IS_ERR(bitmap_bh)) &#123; bitmap_bh = NULL; continue; &#125; x = ext4_count_free(bitmap_bh-&gt;b_data, EXT4_INODES_PER_GROUP(sb) / 8); printk(KERN_DEBUG &quot;group %lu: stored = %d, counted = %lu\\n&quot;, (unsigned long) i, ext4_free_inodes_count(sb, gdp), x); bitmap_count += x; &#125; brelse(bitmap_bh); printk(KERN_DEBUG &quot;ext4_count_free_inodes: &quot; &quot;stored = %u, computed = %lu, %lu\\n&quot;, le32_to_cpu(es-&gt;s_free_inodes_count), desc_count, bitmap_count); return desc_count;#else desc_count = 0; for (i = 0; i &lt; ngroups; i++) &#123; gdp = ext4_get_group_desc(sb, i, NULL); if (!gdp) continue; desc_count += ext4_free_inodes_count(sb, gdp); cond_resched(); &#125; return desc_count;#endif&#125;/* Called at mount-time, super-block is locked */unsigned long ext4_count_dirs(struct super_block * sb)&#123; unsigned long count = 0; ext4_group_t i, ngroups = ext4_get_groups_count(sb); for (i = 0; i &lt; ngroups; i++) &#123; struct ext4_group_desc *gdp = ext4_get_group_desc(sb, i, NULL); if (!gdp) continue; count += ext4_used_dirs_count(sb, gdp); &#125; return count;&#125;/* * Zeroes not yet zeroed inode table - just write zeroes through the whole * inode table. Must be called without any spinlock held. The only place * where it is called from on active part of filesystem is ext4lazyinit * thread, so we do not need any special locks, however we have to prevent * inode allocation from the current group, so we take alloc_sem lock, to * block ext4_new_inode() until we are finished. */int ext4_init_inode_table(struct super_block *sb, ext4_group_t group, int barrier)&#123; struct ext4_group_info *grp = ext4_get_group_info(sb, group); struct ext4_sb_info *sbi = EXT4_SB(sb); struct ext4_group_desc *gdp = NULL; struct buffer_head *group_desc_bh; handle_t *handle; ext4_fsblk_t blk; int num, ret = 0, used_blks = 0; /* This should not happen, but just to be sure check this */ if (sb_rdonly(sb)) &#123; ret = 1; goto out; &#125; gdp = ext4_get_group_desc(sb, group, &amp;group_desc_bh); if (!gdp) goto out; /* * We do not need to lock this, because we are the only one * handling this flag. */ if (gdp-&gt;bg_flags &amp; cpu_to_le16(EXT4_BG_INODE_ZEROED)) goto out; handle = ext4_journal_start_sb(sb, EXT4_HT_MISC, 1); if (IS_ERR(handle)) &#123; ret = PTR_ERR(handle); goto out; &#125; down_write(&amp;grp-&gt;alloc_sem); /* * If inode bitmap was already initialized there may be some * used inodes so we need to skip blocks with used inodes in * inode table. */ if (!(gdp-&gt;bg_flags &amp; cpu_to_le16(EXT4_BG_INODE_UNINIT))) used_blks = DIV_ROUND_UP((EXT4_INODES_PER_GROUP(sb) - ext4_itable_unused_count(sb, gdp)), sbi-&gt;s_inodes_per_block); if ((used_blks &lt; 0) || (used_blks &gt; sbi-&gt;s_itb_per_group) || ((group == 0) &amp;&amp; ((EXT4_INODES_PER_GROUP(sb) - ext4_itable_unused_count(sb, gdp)) &lt; EXT4_FIRST_INO(sb)))) &#123; ext4_error(sb, &quot;Something is wrong with group %u: &quot; &quot;used itable blocks: %d; &quot; &quot;itable unused count: %u&quot;, group, used_blks, ext4_itable_unused_count(sb, gdp)); ret = 1; goto err_out; &#125; blk = ext4_inode_table(sb, gdp) + used_blks; num = sbi-&gt;s_itb_per_group - used_blks; BUFFER_TRACE(group_desc_bh, &quot;get_write_access&quot;); ret = ext4_journal_get_write_access(handle, group_desc_bh); if (ret) goto err_out; /* * Skip zeroout if the inode table is full. But we set the ZEROED * flag anyway, because obviously, when it is full it does not need * further zeroing. */ if (unlikely(num == 0)) goto skip_zeroout; ext4_debug(&quot;going to zero out inode table in group %d\\n&quot;, group); ret = sb_issue_zeroout(sb, blk, num, GFP_NOFS); if (ret &lt; 0) goto err_out; if (barrier) blkdev_issue_flush(sb-&gt;s_bdev, GFP_NOFS, NULL);skip_zeroout: ext4_lock_group(sb, group); gdp-&gt;bg_flags |= cpu_to_le16(EXT4_BG_INODE_ZEROED); ext4_group_desc_csum_set(sb, group, gdp); ext4_unlock_group(sb, group); BUFFER_TRACE(group_desc_bh, &quot;call ext4_handle_dirty_metadata&quot;); ret = ext4_handle_dirty_metadata(handle, NULL, group_desc_bh);err_out: up_write(&amp;grp-&gt;alloc_sem); ext4_journal_stop(handle);out: return ret;&#125;","categories":[{"name":"Linux源码","slug":"Linux源码","permalink":"http://example.com/categories/Linux%E6%BA%90%E7%A0%81/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"Linux","slug":"Linux","permalink":"http://example.com/tags/Linux/"}]},{"title":"《庄子 秋水》 阅读","slug":"《庄子-秋水》-阅读","date":"2023-04-12T11:43:59.000Z","updated":"2023-04-12T14:23:41.820Z","comments":true,"path":"2023/04/12/《庄子-秋水》-阅读/","link":"","permalink":"http://example.com/2023/04/12/%E3%80%8A%E5%BA%84%E5%AD%90-%E7%A7%8B%E6%B0%B4%E3%80%8B-%E9%98%85%E8%AF%BB/","excerpt":"","text":"秋水时至，百川灌河。泾流之大，两涘渚崖之间，不辩牛马。于是焉河伯欣然自喜，以天下之美为尽在己。顺流而东行，至于北海，东面而视，不见水端。于是焉河伯始旋其面目，望洋向若而叹曰：“野语有之曰：‘闻道百，以为莫己若者。’我之谓也。且夫我尝闻少仲尼之闻而轻伯夷之义者，始吾弗信。今我睹子之难穷也，吾非至于子之门则殆矣，吾长见笑于大方之家。”北海若曰：“井蛙不可以语于海者，拘于虚也；夏虫不可以语于冰者，笃于时也；曲士不可以语于道者，束于教也。今尔出于崖涘，观于大海，乃知尔丑，尔将可与语大理矣。天下之水，莫大于海：万川归之，不知何时止而不盈；尾闾泄之，不知何时已而不虚；春秋不变，水旱不知。此其过江河之流， 不可为量数。而吾未尝以此自多者，自以比形于天地，而受气于阴阳， 吾在于天地之间，犹小石小木之在大山也。方存乎见少，又奚以自多！ 计四海之在天地之间也，不似礨空之在大泽乎？计中国之在海内不似稊米之在太仓乎？号物之数谓之万，人处一焉；人卒九州，谷食之所生，舟车之所通，人处一焉。此其比万物也，不似豪末之在于马体乎？ 五帝之所连，三王之所争，仁人之所忧，任士之所劳，尽此矣！伯夷辞之以为名，仲尼语之以为博。此其自多也，不似尔向之自多于水乎？” 秋汛时节，大大小小的河流都灌入黄河之中，河流水势浩大，两岸之间一片苍茫，分不清是牛是马在那里活动。于是河伯沾沾自喜，认为天下美景都掌握在自己手中。但河伯顺着水流往东走，到达了北海，面朝大海，望着无边无际的海面，他收起了得意的神情，他仰着头向北海若感叹道：听闻许多道理，认为谁都不如自己，说的就是我这种人。而且我曾听说有人小看仲尼的见识，轻视伯夷的义气，如今我终于是相信了，今天我看到这无边无际的大海，如果没有到您这来，我大概要永远贻笑大方了。北海若说：井底之蛙不可以跟他谈论大海，因为他受空间的限制；夏天的虫不可以跟他谈论冰雪，因为他受时间的限制；浅陋的书生不可以跟他谈论大道，以为他受礼教的限制。如今你从河边来到大海，见识到了大海的无边无际，明白了自己的浅陋，那我就可以跟你讲讲大道理了。天下的水域，没有比海洋更辽阔的了，千万条江河不停的汇聚到海洋，但是海洋永远不会满，海洋从尾闾泄水，但是不知道何时才能够流尽，不论是春天还是秋天，干旱还是洪涝，海洋都丝毫不受影响。海洋的容量，比江河不知道大了多少，但是我从来不认为自己了不起。我从天地那里获得了形体，从阴阳那里获得了生气，我在天地间，就像一颗小石头在泰山之上，只会自以为小，又怎么会自满呢。想象一下，四海在天地之间，不就像一个蚁穴在大泽之中吗？一个国家在四海之间，不就像一粒米在粮仓中吗？世间物种千千万万，人只是其中一种。人聚集在九州之内，播种谷物粮食，舟车四通八达，一个人只不过是其一小部分而已。拿人和万物相比，不就像拿马身上的一根毫毛和马相比吗？五帝所继承的，三王所争夺的，仁人所忧虑的，以天下为己任的人所操劳的，其实不过如此。伯夷辞让王位来获得名声，仲尼谈论天下大事以显示知识渊博，他们自以为了不起，不就像你一样吗？ 河伯曰：“然则吾大天地而小豪末，可乎？”北海若曰：“否。夫物，量无穷，时无止，分无常，终始无故。是故大知观于远近，故小而不寡，大而不多：知量无穷。证向今故，故遥而不闷，掇而不跂： 知时无止。察乎盈虚，故得而不喜，失而不忧：知分之无常也。明乎坦涂，故生而不说，死而不祸：知终始之不可故也。计人之所知，不若其所不知；其生之时，不若未生之时；以其至小，求穷其至大之域， 是故迷乱而不能自得也。由此观之，又何以知毫末之足以定至细之倪， 又何以知天地之足以穷至大之域！” 河伯说：那么我以天地为大，以毫毛为小，这也可以吗？北海若说：不行，世间万物，在空间上是无法穷尽的，在时间上是没有止境的，不存在固定的区分，也不存在真正意义上的开始和结束。所以， 拥有大智慧的人，不以小为小，不以大为大，对于遥远的过去和将来，不会感到苦闷，对于切身体会的当下也不会刻意强求，有所得到也不会欣喜，有所失去也不会感到忧愁，因为变化是无常的。不会因为或者而雀跃，也不会因为死亡而悲恐，因为生死是无法解释的。一个人所知道的东西，远远比不上不知道的东西。一个人存活的时间，远远比不上未存活的时间。由试图用极小的事物来探究极大的范围，人们会变得迷惑不解，无法找到自己。从这个角度来看，我们怎么能知道一粒细微的尘埃足以决定最微妙的差别，又怎么能知道天地足以穷尽最大的范围呢？” 河伯曰：“世之议者皆曰：‘至精无形，至大不可围。’是信情乎 ？”北海若曰：“夫自细视大者不尽，自大视细者不明。夫精，小之微也；郛，大之殷也：故异便。此势之有也。夫精粗者，期于有形者也；无形者，数之所不能分也；不可围者，数之所不能穷也。可以言论者，物之粗也；可以意致者，物之精也；言之所不能论，意之所不能察致者，不期精粗焉。是故大人之行：不出乎害人，不多仁恩；动不为利，不贱门隶；货财弗争，不多辞让；事焉不借人，不多食乎力 ，不贱贪污；行殊乎俗，不多辟异；为在从众，不贱佞谄；世之爵禄 不足以为劝，戮耻不足以为辱；知是非之不可为分，细大之不可为倪 。闻曰：‘道人不闻，至德不得，大人无己。’约分之至也。” 河伯问：世上的人都说，最精细的东西没有形体，最宏大的东西没有外围，这是真的吗？北海若说：以小的视角去看大的东西是看不全面的，以大的视角去看小的东西是看不清楚的，所以各有所偏，精是指小而微妙的事物；郛是指大而深远的事物：所以它们是不同的。这是因为事物的规模和形态是有差异的。所谓精和粗是对于有形的东西来说的，无形的东西就是小到无法分辨了，没有外围的东西就是大到无法计算了。可以用语言表达的是粗大的事物，可以想象的是精微的食物。无法用语言表达也不能想象的，则根本不适用于精粗的概念。因此，大人的行为：不伤害他人，不过分施恩；行动不是为了利益，不轻视门下之人；不争夺财物，不过分言辞谦让；做事不依赖他人，不过分依赖自己的力量，不轻视贪污；行为不同于俗人，不过分追求与众不同；处在大众之中，不轻视奉承谄媚；世俗的荣誉和地位不足以激发他的兴趣，屈辱和耻辱不足以使他感到羞耻；懂得是非无法明确区分，大小无法确定边界。有句话说：‘道之人不可闻，至德不可得，大人无己。’这就是对事物极限的了解。” 河伯曰：“若物之外，若物之内，恶至而倪贵贱？恶至而倪小大？ ”北海若曰：“以道观之，物无贵贱；以物观之，自贵而相贱；以俗观之，贵贱不在己。以差观之，因其所大而大之，则万物莫不大；因其所小而小之，则万物莫不小。知天地之为稊米也，知毫末之为丘山也，则差数睹矣。以功观之，因其所有而有之，则万物莫不有； 因其所无而无之，则万物莫不无。知东西之相反而不可以相无，则功分定矣。以趣观之，因其所然而然之，则万物莫不然；因其所非而非 之，则万物莫不非。知尧、桀之自然而相非，则趣操睹矣。昔者尧、 舜让而帝，之、哙让而绝；汤、武争而王，白公争而灭。由此观之， 争让之礼，尧、桀之行，贵贱有时，未可以为常也。梁丽可以冲城而不可以窒穴，言殊器也；骐骥骅骝一日而驰千里，捕鼠不如狸狌，言殊技也；鸱鸺夜撮蚤，察毫末，昼出瞋目而不见丘山，言殊性也。故曰：盖师是而无非，师治而无乱乎？是未明天地之理，万物之情也。 是犹师天而无地，师阴而无阳，其不可行明矣！然且语而不舍，非愚则诬也！帝王殊禅，三代殊继。差其时，逆其俗者，谓之篡夫；当其时，顺其俗者，谓之义之徒。默默乎河伯，女恶知贵贱之门，小大之家！” 河伯问：在万物之外和万物之内，如何判断一件事物的贵贱和大小呢？北海若说：从大道的角度看，万物本无贵贱，从他物的角度看，都是自以为贵而以他物为贱，以世俗的角度看，贵贱不在自己，而在他人眼中，以差别的角度看，顺着大的一面来判断，则万物都是大的，顺着小的一面来判断，则万物都是小的。天地可以像一粒米一样小，毫毛也可以像一座山那么大。如果从万物的功能的角度看，如果以它们具有的功能来衡量，那么万物都有用，如果以它们没有的功能来衡量，那么万物都没有用。没有东就没有西，有和无相反相成，知道这一点，功能的区分也就明白了。如果从取向的一面去判断，如果顺着对的一面去判断，那么万物都是对的，如果顺着错的一面去判断，那么万物都是错的。就像尧、夏桀都认为自己是对的。尧、舜的禅让成为帝王，而燕王姬哙和燕相子之却因为禅让遭到灭顶之灾。商汤和周武王因为争夺而称王，白公胜却因为争斗而灭亡。从这些例子来看，争斗与禅让，尧和夏桀的行为，不能作为永恒的标准来衡量贵贱。攻城的利器不适用于堵塞小洞，这是因为器用不同。千里马可以一日千里，但捉老鼠不如狸狌，这是因为技能不同。猫头鹰虽然能在夜间捕捉跳蚤，看见秋毫之末，但是一到白天就会眼瞎，连山岳都看不到，这是因为秉性不同。人们总是说为什么不学习对的而抛弃错的，效法治世而抛弃乱世呢？这是不明白天地的道理、万物的实情才会说出的话。就像只接受天而不接受地，只接受阴而不接受阳，这显然是行不通的。帝王禅让还是继承，这是因时事而异。顺应时事和世俗，会被称为仁人义士，违背时事和世俗，会被称为大逆不道。沉默吧河伯，你哪知道怎么区分贵贱和大小。 河伯曰：“然则我何为乎？何不为乎？吾辞受趣舍，吾终奈何？” 北海若曰：“以道观之，何贵何贱，是谓反衍；无拘而志，与道大蹇 。何少何多，是谓谢施；无一而行，与道参差。严乎若国之有君，其无私德；繇繇乎若祭之有社，其无私福；泛泛乎其若四方之无穷，其无所畛域。兼怀万物，其孰承翼？是谓无方。万物一齐，孰短孰长？ 道无终始，物有死生，不恃其成。一虚一满，不位乎其形。年不可举 ，时不可止。消息盈虚，终则有始。是所以语大义之方，论万物之理也。物之生也，若骤若驰。无动而不变，无时而不移。何为乎，何不为乎？夫固将自化。” 河伯说：那么我应该做什么，不应该做什么呢？我应该接受什么，不应该接受什么呢？北海若说：从道的角度看，没有贵贱之分，要回归道的本源。要做到无拘无束，心怀大道，顺应大道。不要计较物质的多少，学会舍弃得失。要做到无私，无所谓长短，与道同在。要像国家有君王一样严肃，但要无私地行德。要像祭祀有社稷一样庄重，但要追求无私的福报。要像四方一样无边无际，没有界限。要包容万物，没有固定的方向，这就是无方。不要计较万物的短长，道是无始无终的，万物则有生有死，不依赖于成就。一切的虚实、盈虚都不受形态所限。时间不可挽留，此虚彼赢，此消彼长，这里结束那里就开始，事物产生后，如快马奔驰般急速变化，一刻也不会停止。所以应该做什么不应该做什么？事物本身就在不断变化着啊。 河伯曰：“然则何贵于道邪？”北海若曰：“知道者必达于理，达 于理者必明于权，明于权者不以物害己。至德者，火弗能热，水弗能溺，寒暑弗能害，禽兽弗能贼。非谓其薄之也，言察乎安危，宁于祸福，谨于去就，莫之能害也。故曰：‘天在内，人在外，德在乎天。 ’知天人之行，本乎天，位乎得，踯躅而屈伸，反要而语极。”曰： “何谓天？何谓人？”北海若曰：“牛马四足，是谓天；落马首，穿牛鼻，是谓人。故曰：‘无以人灭天，无以故灭命，无以得殉名。谨守而勿失，是谓反其真。‘“ 河伯说：那么大道有什么用呢？北海若说：知晓大道，就能通达事物的道理，通达事物的道理，就能懂得随机应变，懂得随机应变，也就不会让外物侵害自己。得到之人，火不能烧，水不能淹，寒暑不能侵扰，禽兽不能伤害。并不是说他能够对抗这些东西，而是说他懂得观察安慰，并能在福祸之中保持安稳的心态，能够谨慎的进退，也就没有什么能够伤害他们了。所以说：天道是内在的根源，人为是外在的表象，真正的德在于遵循天道，明白一切人事，本源是天道。了解天与人的规律，要遵循自然法则，找到恰当的位置，灵活适应各种情况，回归根本，探究极致。河伯问：什么是天？什么是人？北海若说：牛和马长了四条腿，这就是天道，把辔头装在马头，把牛鼻子穿孔，这就是认为。所以说：不能让人为破坏自然法则，不能让造作毁灭性命，不以贪欲追求虚名，守住自然的天性，这就叫做返回最初的本真。 夔怜蚿，蚿怜蛇，蛇怜风，风怜目，目怜心。夔谓蚿曰：“吾以一 足趻踔而不行，予无如矣。今子之使万足，独奈何？”蚿曰：“不然。 子不见夫唾者乎？喷则大者如珠，小者如雾，杂而下者不可胜数也。 今予动吾天机，而不知其所以然。”蚿谓蛇曰：“吾以众足行，而不及子之无足，何也？”蛇曰：“夫天机之所动，何可易邪？吾安用足 哉！”蛇谓风曰：“予动吾脊胁而行，则有似也。今子蓬蓬然起于北海，蓬蓬然入于南海，而似无有，何也？”风曰：“然，予蓬蓬然起于北海而入于南海也，然而指我则胜我，鰌我亦胜我。虽然，夫折大木，蜚大屋者，唯我能也。”故以众小不胜为大胜也。为大胜者，唯圣人能之。 独脚兽羡慕多足虫，多足虫羡慕蛇，蛇羡慕风，风羡慕眼，眼羡慕心。独脚兽跟多足虫说：我用一条腿走路都困难，你是怎么用那么多条腿走路的呢？多足虫说：我也是自然行走，我也不知道为什么这样。多足虫问蛇：我用这么多条腿走路结果还不如你不用腿走路走得快，为什么呢？蛇说：这是天然的机制，改变不了的，我哪用得着脚呢？蛇对风说：我用身体走路还有形迹，你呼呼从北海吹到南海，一点形迹也没有，为什么呢？风说：是的，我能呼呼的从北海吹到南海，但是手指脚踢我做不到啊。但是，吹断大树，吹翻房子只有我能做到。所以，以做不成众多小事为代价，成就大事，只有圣人能做到。 孔子游于匡，宋人围之数币，而弦歌不惙。子路入见，曰：“何夫子之娱也？”孔子曰：“来，吾语女！我讳穷久矣，而不免，命也；求通久矣，而不得，时也。当尧、舜而天下无穷人，非知得也；当桀、纣而天下无通人，非知失也。时势适然。夫水行不避蛟龙者，渔人之勇也。陆行不避兕虎者，猎夫之勇也。白刃交于前，视死若生者，烈士之勇也。知穷之有命，知通之有时，临大难而不惧者，圣人之勇也。由，处矣！吾命有所制矣！” 无几何，将甲者进，辞曰：“以为阳虎也，故围之；今非也，请辞而退。” 孔子周游到匡地，卫国人一层又一层地包围了他，可是孔子仍在不停地弹琴诵读。子路进去见孔子说：“先生如此快乐是为什么呢？”孔子说：“来，我告诉你！我不想让自己困苦已经很久很久了，可是始终不能免除，这是命运啊。我寻求通达也已经很久很久了，可是始终未能达到，这是时运啊。当尧、舜的时代，天下没有一个困顿潦倒的人，并非因为他们都才智超人；当桀、纣的时代，天下没有一个通达的人，并非因为他们都才智低下。这都是时运所造成的。在水里活动而不躲避蛟龙的，乃是渔夫的勇敢；在陆上活动而不躲避犀牛老虎的，乃是猎人的勇敢；刀剑交错地横于眼前，看待死亡犹如生还的，乃是壮烈之士的勇敢。懂得困厄潦倒乃是命中注定，知道顺利通达乃是时运造成，面临大难而不畏惧的，这就是圣人的勇敢。仲由啊，你还是休息去吧！我这是命中注定！” 公孙龙问于魏牟曰：“龙少学先王之道，长而明仁义之行；合同异 ，离坚白；然不然，可不可；困百家之知，穷众口之辩：吾自以为至 达已。今吾闻庄子之言，茫然异之。不知论之不及与？知之弗若与？ 今吾无所开吾喙，敢问其方。”公子牟隐机大息，仰天而笑曰：“子 独不闻夫埳井之蛙乎？谓东海之鳖曰：‘吾乐与！出跳梁乎井干之上， 入休乎缺甃之崖。赴水则接腋持颐，蹶泥则没足灭跗。还虷蟹与科斗， 莫吾能若也。且夫擅一壑之水，而跨跱埳井之乐，此亦至矣。夫子奚不时来入观乎？’东海之鳖左足未入，而右膝已絷矣。于是逡巡而却， 告之海曰：‘夫千里之远，不足以举其大；千仞之高，不足以极其深。 禹之时，十年九潦，而水弗为加益；汤之时，八年七旱，而崖不为加损。夫不为顷久推移，不以多少进退者，此亦东海之大乐也。’于是 埳井之蛙闻之，适适然惊，规规然自失也。且夫知不知是非之竟，而 犹欲观于庄子之言，是犹使蚊负山，商蚷驰河也，必不胜任矣。且夫 知不知论极妙之言，而自适一时之利者，是非埳井之蛙与？且彼方跐 黄泉而登大皇，无南无北，爽然四解，沦于不测；无东无西，始于玄冥，反于大通。子乃规规然而求之以察，索之以辩，是直用管窥天， 用锥指地也，不亦小乎？子往矣！且子独不闻夫寿陵余子之学于邯郸 与？未得国能，又失其故行矣，直匍匐而归耳。今子不去，将忘子之故，失子之业。”公孙龙口呿而不合，舌举而不下，乃逸而走。 公孙龙向魏牟问道：“我年少的时候学习古代圣王的主张，长大以后懂得了仁义的行为；能够把事物的不同与相同合而为一，把一个物体的质地坚硬与颜色洁白分离开来；能够把不对的说成是对的，把不应认可的看作是合宜的；能够使百家智士困惑不解，能够使众多善辩之口理屈辞穷：我自以为是最为通达的了。如今我听了庄子的言谈，感到十分茫然。不知是我的论辩比不上他呢，还是我的知识不如他呢？现在我已经没有办法再开口了，冒昧地向你请教其中的道理。” 魏牟靠着几案深深地叹了口气，然后又仰头朝天笑着说：“你不曾听说过那浅井里的青蛙吗？井蛙对东海里的鳖说：‘我实在快乐啊！我跳跃玩耍于井口栏杆之上，进到井里便在井壁砖块破损之处休息。跳入水中井水漫入腋下并且托起我的下巴，踏入泥里泥水就盖住了我的脚背，回过头来看看水中的那些赤虫、小蟹和蝌蚪，没有谁能像我这样的快乐！再说我独占一坑之水、盘踞一口浅井的快乐，这也是极其称心如意的了。你怎么不随时来井里看看呢？’东海之鳖左脚还未能跨入浅井，右膝就已经被绊住。于是迟疑了一阵子之后又把脚退了出来，把大海的情况告诉给浅井的青蛙，说：‘千里的遥远，不足以称述它的大；千仞的高旷，不足于探究它的深。夏禹时代十年里有九年水涝，而海水不会因此增多；商汤的时代八年里有七年大旱，而岸边的水位不会因此下降。不因为时间的短暂与长久而有所改变，不因为雨量的多少而有所增减，这就是东海最大的快乐。’浅井之蛙听了这一席话，惊惶不安，茫然不知所措。再说你公孙龙的才智还不足以知晓是与非的境界，却还想去察悉庄子的言谈，这就像驱使蚊虫去背负大山，驱使马蚿虫到河水里去奔跑，必定是不能胜任的。而你的才智不足以通晓极其玄妙的言论，竟自去迎合那些一时的胜利，这不就像是浅井里的青蛙吗？况且庄子的思想主张正俯极黄泉登临苍天，不论南北，释然四散通达无阻，深幽沉寂不可探测；不论东西，起于幽深玄妙之境，返归广阔通达之域。你竟拘泥浅陋地用察视的办法去探寻它的奥妙，用论辩的言辞去索求它的真谛，这只不过是用竹管去窥视高远的苍天，用锥子去测量浑厚的大地，不是太渺小了吗！你还是走吧！而且你就不曾听说过那燕国寿陵的小子到赵国的邯郸去学习走步之事吗？未能学会赵国的本事，又丢掉了他原来的本领，最后只得爬着回去了。现在你还不尽快离开我这里，必将忘掉你原有的本领，而且也必将失去你原有的学业。” 公孙龙听了这一番话张大着口而不能合拢，舌头高高抬起而不能放下，于是快速地逃走了。 庄子钓于濮水。楚王使大夫二人往先焉，曰：“愿以境内累矣！” 庄子持竿不顾，曰：“吾闻楚有神龟，死已三千岁矣。王巾笥而藏之庙堂之上。此龟者，宁其死为留骨而贵乎？宁其生而曳尾于涂中乎？ ”二大夫曰：“宁生而曳尾涂中。”庄子曰：“往矣！吾将曳尾于涂中。” 惠子相梁，庄子往见之。或谓惠子曰：“庄子来，欲代子相。”于 是惠子恐，搜于国中三日三夜。庄子往见之，曰：“南方有鸟，其名 为鹓鹐，子知之乎？夫鹓鹐发于南海而飞于北海，非梧桐不止，非练 实不食，非醴泉不饮。于是鸱得腐鼠，鹓鹐过之，仰而视之曰：‘吓！’ 今子欲以子之梁国而吓我邪？” 庄子与惠子游于濠梁之上。庄子曰：“儵鱼出游从容，是鱼之乐也。” 惠子曰∶“子非鱼，安知鱼之乐？”庄子曰：“子非我，安知我不知 鱼之乐？”惠子曰“我非子，固不知子矣；子固非鱼也，子之不知鱼 之乐，全矣！”庄子曰：“请循其本。子曰‘汝安知鱼乐’云者，既 已知吾知之而问我。我知之濠上也。” 庄子在濮水边垂钓，楚王派遣两位大臣先行前往致意，说：“楚王愿将国内政事委托给你而劳累你了。” 庄子手把钓竿头也不回地说：“我听说楚国有一神龟，已经死了三千年了，楚王用竹箱装着它，用巾饰覆盖着它，珍藏在宗庙里。这只神龟，是宁愿死去为了留下骨骸而显示尊贵呢，还是宁愿活着在泥水里拖着尾巴呢？”两位大臣说：“宁愿拖着尾巴活在泥水里。”庄子说：“你们走吧！我仍将拖着尾巴生活在泥水里。” 惠子在梁国做宰相，庄子前往看望他。有人对惠子说：“庄子来梁国，是想取代你做宰相。”于是惠子恐慌起来，在都城内搜寻庄子，整整三天三夜。 庄子前往看望惠子，说：“南方有一种鸟，它的名字叫鹓，你知道吗？鹓从南海出发飞到北海，不是梧桐树它不会停息，不是竹子的果实它不会进食，不是甘美的泉水它不会饮用。正在这时一只鹞鹰寻觅到一只腐烂了的老鼠，鹓刚巧从空中飞过，鹞鹰抬头看着鹓，发出一声怒气：‘嚇’！如今你也想用你的梁国来怒叱我吗？” 庄子和惠子一道在濠水的桥上游玩。庄子说：“儵鱼游得多么悠闲自在，这就是鱼儿的快乐。”惠子说：“你不是鱼，怎么知道鱼的快乐？”庄子说：“你不是我，怎么知道我不知道鱼儿的快乐？”惠子说：“我不是你，固然不知道你；你也不是鱼，你不知道鱼的快乐，也是完全可以肯定的。”庄子说：“还是让我们顺着先前的话来说。你刚才所说的‘你怎么知道鱼的快乐’的话，就是已经知道了我知道鱼儿的快乐而问我，而我则是在濠水的桥上知道鱼儿快乐的。”","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://example.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"哲学","slug":"读书笔记/哲学","permalink":"http://example.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%93%B2%E5%AD%A6/"}],"tags":[{"name":"哲学","slug":"哲学","permalink":"http://example.com/tags/%E5%93%B2%E5%AD%A6/"},{"name":"庄子","slug":"庄子","permalink":"http://example.com/tags/%E5%BA%84%E5%AD%90/"},{"name":"道家","slug":"道家","permalink":"http://example.com/tags/%E9%81%93%E5%AE%B6/"}]},{"title":"Linux v5.3.1 /kernel/pid.c","slug":"Linux-v5-3-1-kernel-pid-c","date":"2023-04-12T02:34:39.000Z","updated":"2023-04-12T15:02:52.325Z","comments":true,"path":"2023/04/12/Linux-v5-3-1-kernel-pid-c/","link":"","permalink":"http://example.com/2023/04/12/Linux-v5-3-1-kernel-pid-c/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644// SPDX-License-Identifier: GPL-2.0-only/* * Generic pidhash and scalable, time-bounded PID allocator * * (C) 2002-2003 Nadia Yvette Chambers, IBM * (C) 2004 Nadia Yvette Chambers, Oracle * (C) 2002-2004 Ingo Molnar, Red Hat * * pid-structures are backing objects for tasks sharing a given ID to chain * against. There is very little to them aside from hashing them and * parking tasks using given ID&#x27;s on a list. * * The hash is always changed with the tasklist_lock write-acquired, * and the hash is only accessed with the tasklist_lock at least * read-acquired, so there&#x27;s no additional SMP locking needed here. * * We have a list of bitmap pages, which bitmaps represent the PID space. * Allocating and freeing PIDs is completely lockless. The worst-case * allocation scenario when all but one out of 1 million PIDs possible are * allocated already: the scanning of 32 list entries and at most PAGE_SIZE * bytes. The typical fastpath is a single successful setbit. Freeing is O(1). * * Pid namespaces: * (C) 2007 Pavel Emelyanov &lt;xemul@openvz.org&gt;, OpenVZ, SWsoft Inc. * (C) 2007 Sukadev Bhattiprolu &lt;sukadev@us.ibm.com&gt;, IBM * Many thanks to Oleg Nesterov for comments and help * */#include &lt;linux/mm.h&gt;#include &lt;linux/export.h&gt;#include &lt;linux/slab.h&gt;#include &lt;linux/init.h&gt;#include &lt;linux/rculist.h&gt;#include &lt;linux/memblock.h&gt;#include &lt;linux/pid_namespace.h&gt;#include &lt;linux/init_task.h&gt;#include &lt;linux/syscalls.h&gt;#include &lt;linux/proc_ns.h&gt;#include &lt;linux/refcount.h&gt;#include &lt;linux/anon_inodes.h&gt;#include &lt;linux/sched/signal.h&gt;#include &lt;linux/sched/task.h&gt;#include &lt;linux/idr.h&gt;struct pid init_struct_pid = &#123;//初始化pid .count = REFCOUNT_INIT(1),//引用计数，初始化为1，当其他地方需要引用struct pid时，可以通过增加引用计数来表示对其的引用 //引用减少时，减少引用计数。 //当引用为零时，表示该struct pid对象不再被使用，可以安全的释放其内存 //REFCOUNT_INIT(1)初始化了struct pid结构中的引用技术。 .tasks = &#123; //一个包含三个链表头的数组，分别用于存储进程的三种类型：进程、线程组、会话组。链表头初始化为NULL &#123; .first = NULL &#125;, //可执行任务TASK_RUNNING &#123; .first = NULL &#125;, //可中断的等待任务TASK_INTERRUPTIBLE &#123; .first = NULL &#125;, //不可中断的等待任务TASK_UNINTERRRUPTIBLE &#125;, .level = 0, // 表示当前进程在命名空间层次结构中的层级level .numbers = &#123; &#123; //一个数组包含pid_namespace的引用 .nr = 0, //在当前命名空间中的进程ID .ns = &amp;init_pid_ns, //指向当前层级namespace的指针 &#125;, &#125;&#125;;int pid_max = PID_MAX_DEFAULT; //pid_max定义了系统中允许的最大进程ID，PID_MAX_DEFUALT是一个预设值#define RESERVED_PIDS 300 //预留 PID 的数量。这些 PID 是为内核进程和特殊任务预留的，不分配给用户进程。通常预留 300 个 PID。int pid_max_min = RESERVED_PIDS + 1;//定义了系统中允许的最小进程ID上限。RESERVED_PIDS是一个预设值，通常是300，因此最小上限是301。int pid_max_max = PID_MAX_LIMIT; //定义了系统中允许的最大进程ID上限。PID_MAX_LIMIT是一个预设值，其值可能因系统而异。通常，其值是PID命名空间允许的最大值。/* * PID-map pages start out as NULL, they get allocated upon * first use and are never deallocated. This way a low pid_max * value does not cause lots of bitmaps to be allocated, but * the scheme scales to up to 4 million PIDs, runtime. */struct pid_namespace init_pid_ns = &#123; //定义了pid_namespace .kref = KREF_INIT(2), /*该字段是一个kref结构体，用于表示内核对象的引用计数。引用计数在内核中非常重要，因为它可以确保在对象仍被使用时不会被意外释放。引用计数使用KREF_INIT(2)宏进行初始化，将计数设为2。这意味着在引用计数减少到0之前，该命名空间对象至少需要被释放两次。*/ .idr = IDR_INIT(init_pid_ns.idr),/*这是一个IDR（ID Radix Tree）数据结构，用于分配和管理进程ID。IDR可以高效地分配、查找和释放ID，适用于动态分配的对象。使用IDR_INIT(init_pid_ns.idr)宏对其进行初始化。这个字段的主要作用是在该命名空间中分配新的唯一进程ID，以及查找和回收已分配的ID。*/ .pid_allocated = PIDNS_ADDING,/*这个字段表示命名空间中已分配的最大进程ID。初始化为PIDNS_ADDING，表示进程ID正在添加中。这个字段的主要作用是跟踪命名空间中已分配的进程ID数量，以确保系统不会超出最大允许的进程ID限制。*/ .level = 0,/*这个字段表示命名空间的层级，即嵌套的深度。level被初始化为0，表示这是一个顶级命名空间。level字段用于描述命名空间之间的父子关系，以便于管理和隔离不同层级的命名空间。*/ .child_reaper = &amp;init_task,/*这是一个指向task_struct结构体的指针，表示负责回收僵尸进程的任务。通常，这个任务是init进程（进程ID为1），它负责收养所有孤立的子进程并处理它们的终止状态。child_reaper指向init_task。这个字段的主要作用是确保在命名空间中的进程终止时能够被妥善处理。*/ .user_ns = &amp;init_user_ns,/*这是一个指向user_namespace结构体的指针，表示与此进程ID命名空间关联的用户命名空间。用户命名空间用于隔离不同命名空间中的用户和组ID。user_ns指向init_user_ns。这个字段的主要作用是将进程ID命名空间与相应的用户命名空间关联起来，以便于管理和隔离不同用户的资源。*/ .ns.inum = PROC_PID_INIT_INO,/*这个字段表示命名空间的inode编号，它用于在虚拟文件系统（如procfs）中表示该命名空间。在这个例子中，inum使用PROC_PID_INIT_INO宏进行初始化。这个字段的主要作用是为命名空间分配一个唯一的ID，以便在虚拟文件系统中区分不同的命名空间实例。*/#ifdef CONFIG_PID_NS .ns.ops = &amp;pidns_operations,#endif/*这是一个指向命名空间相关操作的结构体的指针。这个字段在编译时配置了CONFIG_PID_NS选项时才会被启用。指向pidns_operations。这个字段的主要作用是提供一组操作函数，用于处理与进程ID命名空间相关的各种操作，如创建、销毁、复制等。*/&#125;;EXPORT_SYMBOL_GPL(init_pid_ns);//EXPORT_SYMBOL_GPL(init_pid_ns)用于将init_pid_ns符号导出，使得其他内核模块可以使用此符号。/* * Note: disable interrupts while the pidmap_lock is held as an * interrupt might come in and do read_lock(&amp;tasklist_lock). * * If we don&#x27;t disable interrupts there is a nasty deadlock between * detach_pid()-&gt;free_pid() and another cpu that does * spin_lock(&amp;pidmap_lock) followed by an interrupt routine that does * read_lock(&amp;tasklist_lock); * * After we clean up the tasklist_lock and know there are no * irq handlers that take it we can leave the interrupts enabled. * For now it is easier to be safe than to prove it can&#x27;t happen.这段注释解释了在持有pidmap_lock时需要禁用中断的原因。pidmap_lock是一个自旋锁（spinlock），用于保护进程ID映射数据结构。禁用中断是为了避免一个潜在的死锁问题。死锁发生在以下情况：1、detach_pid() -&gt; free_pid()函数在释放进程ID时会持有pidmap_lock。2、同时，另一个CPU执行了spin_lock(&amp;pidmap_lock)，紧接着发生一个中断，中断处理程序试图获取read_lock(&amp;tasklist_lock)。 */static __cacheline_aligned_in_smp DEFINE_SPINLOCK(pidmap_lock);//这行代码定义了一个名为pidmap_lock的自旋锁，并确保它在SMP（对称多处理器）系统中与缓存行对齐。这有助于减少缓存行竞争，提高性能。void put_pid(struct pid *pid)//定义了一个函数put_id,用于释放进程ID struct pid的引用计数&#123; struct pid_namespace *ns;//定义一个指向pid_namespace结构体的指针ns if (!pid)//如果传入pid的是空指针 return;//直接返回 ns = pid-&gt;numbers[pid-&gt;level].ns;//根据pid-&gt;level获取pid_namespace结构体的指针 if (refcount_dec_and_test(&amp;pid-&gt;count)) &#123;//将pid的引用计数递减，并检查是否为0，如果 kmem_cache_free(ns-&gt;pid_cachep, pid);//释放pid所占的内存。ns-&gt;pid_cachep是一个内存缓存，用于加速分配和释放pid的结构体 put_pid_ns(ns);//将关联的pid_namespace结构体的引用计数递减 &#125;&#125;EXPORT_SYMBOL_GPL(put_pid);//到处put_pid给其他内核模块使用static void delayed_put_pid(struct rcu_head *rhp)//用于延迟递减进程ID的引用计数&#123; struct pid *pid = container_of(rhp, struct pid, rcu);//这行代码的作用是从指向rcu成员的指针rhp获取包含该成员的struct pid结构体的指针，并将其赋值给pid。 put_pid(pid);//递减pid的引用计数&#125;void free_pid(struct pid *pid)/*用于释放一个struct pid，这个结构体表示一个进程在不同命名空间中的进程ID当一个进程结束时，内核需要释放与之相关的资源，包括PID。这个函数的主要任务是在各个PID命名空间中删除这个PID，并在适当的时候调度相关的清理工作*/&#123; /* We can be called with write_lock_irq(&amp;tasklist_lock) held */ int i; unsigned long flags; spin_lock_irqsave(&amp;pidmap_lock, flags);/*获取pidmap_lock自旋锁保护PID映射数据结构。使用spin_lock_irqsave函数获取自旋锁的同时，禁止本地中断，以防止死锁。*/ for (i = 0; i &lt;= pid-&gt;level; i++) &#123;/*遍历struct pid结构体中的numbers数，该数组保存了进程在不同命名空间中恶PID信息数组的每个元素都是一个struct upid结构体，包含一个命名空间（ns）和一个与命名空间相关联的进程ID（nr）*/ struct upid *upid = pid-&gt;numbers + i;/*指针upid指向pid的一个numbers数组*/ struct pid_namespace *ns = upid-&gt;ns;/*ns指向upid的namespace*/ switch (--ns-&gt;pid_allocated) &#123;/*减少命名空间中分配的pid计数，根据新的ns-&gt;pid_allocated执行不同的操作*/ case 2: case 1: /* When all that is left in the pid namespace * is the reaper wake up the reaper. The reaper * may be sleeping in zap_pid_ns_processes(). *//*如果PID计数为2或1，唤醒命名空间的子收割进程（ns-&gt;child_reaper），它可能正在zap_pid_ns_processes()函数中等待。子收割进程负责在其命名空间中清理已结束的进程。*/ wake_up_process(ns-&gt;child_reaper);/*唤醒child_reaper进程*/ break; case PIDNS_ADDING: /* Handle a fork failure of the first process *//*如果PID计数为PIDNS_ADDING（一个特殊值，表示命名空间正在添加第一个进程），处理第一个进程的fork失败。在这种情况下，将PID计数重置为0，并继续执行下一步。*/ WARN_ON(ns-&gt;child_reaper); ns-&gt;pid_allocated = 0; /* fall through */ case 0: schedule_work(&amp;ns-&gt;proc_work);/*如果PID计数为0，调度命名空间的proc_work工作，以执行清理工作。*/ break; &#125; idr_remove(&amp;ns-&gt;idr, upid-&gt;nr);/*从命名空间的IDR（ns-&gt;idr）中删除当前PID（upid-&gt;nr）。*/ &#125; spin_unlock_irqrestore(&amp;pidmap_lock, flags);/*释放pidmap_lock自旋锁，并恢复本地中断*/ call_rcu(&amp;pid-&gt;rcu, delayed_put_pid);/*使用call_rcu函数安排一个RCU延迟回调，以便在适当的时候执行delayed_put_pid函数，该函数将负责释放struct pid结构体占用的内存。这里使用RCU（Read-Copy-Update）机制，因为在多核系统中，其他CPU可能仍在使用这个struct pid结构体。*/&#125;struct pid *alloc_pid(struct pid_namespace *ns)//用于在给定的pid_namespace中分配一个新的进程ID（PID）&#123; struct pid *pid;//新分配的pid结构指针 enum pid_type type;//进程ID类型枚举变量，用于遍历所有可用的进程ID类型 int i, nr;//整数变量i用于循环计数，nr用于存储新分配的进程id号 struct pid_namespace *tmp;//临时的pid_namespace指针，用于遍历命名空间的层次结构 struct upid *upid;//用于指向pid-&gt;numbers数组中的元素的指针 int retval = -ENOMEM;//整数变量，表示函数的返回值（内存不足错误）//定义了一些局部变量 pid = kmem_cache_alloc(ns-&gt;pid_cachep, GFP_KERNEL);/*从ns-&gt;pid_cachep缓存中分配一个新的pid结构。GFP_KERNEL是内存分配标志，表示允许内核进行阻塞式内存分配。*/ if (!pid)//如果pid分配失败 return ERR_PTR(retval);//返回错误指针 tmp = ns;//将tmp指针设置为当前的pid_namespace pid-&gt;level = ns-&gt;level;//pid-&gt;level设置为ns-&gt;level for (i = ns-&gt;level; i &gt;= 0; i--) &#123;//从ns-&gt;level开始到0层命名空间，遍历 int pid_min = 1;//设置一个最小进程ID号 idr_preload(GFP_KERNEL);//调用idr_preload函数预加载一组ID，以加快之后的idr_alloc_cyclic调用。 spin_lock_irq(&amp;pidmap_lock);//通过禁用本地中断并获取pidmap_lock自旋锁，进入临界区。 /* * init really needs pid 1, but after reaching the maximum * wrap back to RESERVED_PIDS */ if (idr_get_cursor(&amp;tmp-&gt;idr) &gt; RESERVED_PIDS) pid_min = RESERVED_PIDS;/*判断当前命名空间的ID分配光标是否超过了保留的进程ID范围。如果是，则将pid_min设置为RESERVED_PIDS，以便从保留ID范围开始分配新的进程ID。*/ /* * Store a null pointer so find_pid_ns does not find * a partially initialized PID (see below). */ nr = idr_alloc_cyclic(&amp;tmp-&gt;idr, NULL, pid_min, pid_max, GFP_ATOMIC);/*使用idr_alloc_cyclic函数在tmp-&gt;idr中分配一个新的ID。NULL是一个占位符指针，稍后会被替换。pid_min和pid_max定义了ID的范围。GFP_ATOMIC是内存分配标志，表示不允许阻塞式内存分配。*/ spin_unlock_irq(&amp;pidmap_lock);/*释放pidmap_lock自旋锁并重新启用本地中断，退出临界区。*/ idr_preload_end();/*结束ID预加载，释放预先分配的内存。*/ if (nr &lt; 0) &#123;/*如果nr ID分配失败，nr为负数*/ retval = (nr == -ENOSPC) ? -EAGAIN : nr;/*根据错误代码设置retval并跳转到out_free执行清理操作*/ goto out_free; &#125; pid-&gt;numbers[i].nr = nr; pid-&gt;numbers[i].ns = tmp; tmp = tmp-&gt;parent;/*将pid-&gt;numbers[i]结构的nr和ns字段设置为新分配的ID和当前的pid_namespace。将tmp指针设置为当前命名空间的父命名空间。*/ &#125; if (unlikely(is_child_reaper(pid))) &#123;/*如果新分配的进程ID（pid）是命名空间的初始子收割者（即进程ID为1），则执行以下代码。*/ if (pid_ns_prepare_proc(ns))/*如果pid_ns_prepare_proc函数返回非零值，表示在为命名空间准备/proc文件系统时发生了错误。*/ goto out_free;/* 在发生错误的情况下，跳转到out_free标签执行错误处理和清理。*/ &#125; get_pid_ns(ns);//增加命名空间ns的引用计数，表示有一个新的pid结构正在使用它。 refcount_set(&amp;pid-&gt;count, 1);/*使用refcount_set函数将pid结构的引用计数设置为1。这表示有一个引用正在使用该pid结构。*/ for (type = 0; type &lt; PIDTYPE_MAX; ++type)/*遍历所有进程ID类型*/ INIT_HLIST_HEAD(&amp;pid-&gt;tasks[type]);/*初始化pid-&gt;tasks[type]链表的头部，这一步准备了一个用于存储每种类型的进程的链表*/ init_waitqueue_head(&amp;pid-&gt;wait_pidfd);/*初始化pid-&gt;wait_pidfd等待队列头。这将用于支持pidfd的等待操作。*/ upid = pid-&gt;numbers + ns-&gt;level;/*将upid指针设置为pid-&gt;numbers数组中最顶层命名空间对应的upid结构。*/ spin_lock_irq(&amp;pidmap_lock);//通过禁用本地中断并获取pidmap_lock自旋锁，进入临界区。 if (!(ns-&gt;pid_allocated &amp; PIDNS_ADDING))/*检查命名空间（ns）的 pid_allocated 是否包含 PIDNS_ADDING 标志。如果没有，说明命名空间的创建过程未完成，需要执行错误处理。*/ goto out_unlock;/*如果命名空间的创建过程未完成，跳转到 out_unlock 标签执行错误处理和清理。*/ for ( ; upid &gt;= pid-&gt;numbers; --upid) &#123;/*从当前命名空间层级向上遍历，直到到达全局命名空间层级。upid 是指向pid-&gt;numbers数组中的一个元素的指针，代表一个命名空间层级。*/ /* Make the PID visible to find_pid_ns. */ idr_replace(&amp;upid-&gt;ns-&gt;idr, pid, upid-&gt;nr);/*使用 idr_replace 函数将新分配的 pid 结构添加到当前命名空间层级的 idr 中，使其可见并可通过 find_pid_ns 函数查找。upid-&gt;nr 是当前命名空间层级分配的进程ID。*/ upid-&gt;ns-&gt;pid_allocated++;//增加当前命名空间层级已分配的进程ID数量。 &#125; spin_unlock_irq(&amp;pidmap_lock);//解锁之前加锁的 pidmap_lock 自旋锁，允许其他线程访问进程ID映射数据结构。 return pid;//返回新创建和初始化的进程ID（pid）结构。out_unlock: spin_unlock_irq(&amp;pidmap_lock);//错误处理标签。如果在分配过程中遇到错误，将跳转到此处执行清理操作。 put_pid_ns(ns);//减少命名空间（ns）的引用计数，表示分配失败，pid 结构不再使用这个命名空间。out_free: spin_lock_irq(&amp;pidmap_lock); while (++i &lt;= ns-&gt;level) &#123; upid = pid-&gt;numbers + i; idr_remove(&amp;upid-&gt;ns-&gt;idr, upid-&gt;nr); &#125; /* On failure to allocate the first pid, reset the state */ if (ns-&gt;pid_allocated == PIDNS_ADDING) idr_set_cursor(&amp;ns-&gt;idr, 0); spin_unlock_irq(&amp;pidmap_lock); kmem_cache_free(ns-&gt;pid_cachep, pid); return ERR_PTR(retval);&#125;void disable_pid_allocation(struct pid_namespace *ns)&#123; spin_lock_irq(&amp;pidmap_lock); ns-&gt;pid_allocated &amp;= ~PIDNS_ADDING; spin_unlock_irq(&amp;pidmap_lock);&#125;struct pid *find_pid_ns(int nr, struct pid_namespace *ns)&#123; return idr_find(&amp;ns-&gt;idr, nr);&#125;EXPORT_SYMBOL_GPL(find_pid_ns);struct pid *find_vpid(int nr)&#123; return find_pid_ns(nr, task_active_pid_ns(current));&#125;EXPORT_SYMBOL_GPL(find_vpid);static struct pid **task_pid_ptr(struct task_struct *task, enum pid_type type)&#123; return (type == PIDTYPE_PID) ? &amp;task-&gt;thread_pid : &amp;task-&gt;signal-&gt;pids[type];&#125;/* * attach_pid() must be called with the tasklist_lock write-held. */void attach_pid(struct task_struct *task, enum pid_type type)&#123; struct pid *pid = *task_pid_ptr(task, type); hlist_add_head_rcu(&amp;task-&gt;pid_links[type], &amp;pid-&gt;tasks[type]);&#125;static void __change_pid(struct task_struct *task, enum pid_type type, struct pid *new)&#123; struct pid **pid_ptr = task_pid_ptr(task, type); struct pid *pid; int tmp; pid = *pid_ptr; hlist_del_rcu(&amp;task-&gt;pid_links[type]); *pid_ptr = new; for (tmp = PIDTYPE_MAX; --tmp &gt;= 0; ) if (!hlist_empty(&amp;pid-&gt;tasks[tmp])) return; free_pid(pid);&#125;void detach_pid(struct task_struct *task, enum pid_type type)&#123; __change_pid(task, type, NULL);&#125;void change_pid(struct task_struct *task, enum pid_type type, struct pid *pid)&#123; __change_pid(task, type, pid); attach_pid(task, type);&#125;/* transfer_pid is an optimization of attach_pid(new), detach_pid(old) */void transfer_pid(struct task_struct *old, struct task_struct *new, enum pid_type type)&#123; if (type == PIDTYPE_PID) new-&gt;thread_pid = old-&gt;thread_pid; hlist_replace_rcu(&amp;old-&gt;pid_links[type], &amp;new-&gt;pid_links[type]);&#125;struct task_struct *pid_task(struct pid *pid, enum pid_type type)&#123; struct task_struct *result = NULL; if (pid) &#123; struct hlist_node *first; first = rcu_dereference_check(hlist_first_rcu(&amp;pid-&gt;tasks[type]), lockdep_tasklist_lock_is_held()); if (first) result = hlist_entry(first, struct task_struct, pid_links[(type)]); &#125; return result;&#125;EXPORT_SYMBOL(pid_task);/* * Must be called under rcu_read_lock(). */struct task_struct *find_task_by_pid_ns(pid_t nr, struct pid_namespace *ns)&#123; RCU_LOCKDEP_WARN(!rcu_read_lock_held(), &quot;find_task_by_pid_ns() needs rcu_read_lock() protection&quot;); return pid_task(find_pid_ns(nr, ns), PIDTYPE_PID);&#125;struct task_struct *find_task_by_vpid(pid_t vnr)&#123; return find_task_by_pid_ns(vnr, task_active_pid_ns(current));&#125;struct task_struct *find_get_task_by_vpid(pid_t nr)&#123; struct task_struct *task; rcu_read_lock(); task = find_task_by_vpid(nr); if (task) get_task_struct(task); rcu_read_unlock(); return task;&#125;struct pid *get_task_pid(struct task_struct *task, enum pid_type type)&#123; struct pid *pid; rcu_read_lock(); pid = get_pid(rcu_dereference(*task_pid_ptr(task, type))); rcu_read_unlock(); return pid;&#125;EXPORT_SYMBOL_GPL(get_task_pid);struct task_struct *get_pid_task(struct pid *pid, enum pid_type type)&#123; struct task_struct *result; rcu_read_lock(); result = pid_task(pid, type); if (result) get_task_struct(result); rcu_read_unlock(); return result;&#125;EXPORT_SYMBOL_GPL(get_pid_task);struct pid *find_get_pid(pid_t nr)&#123; struct pid *pid; rcu_read_lock(); pid = get_pid(find_vpid(nr)); rcu_read_unlock(); return pid;&#125;EXPORT_SYMBOL_GPL(find_get_pid);pid_t pid_nr_ns(struct pid *pid, struct pid_namespace *ns)&#123; struct upid *upid; pid_t nr = 0; if (pid &amp;&amp; ns-&gt;level &lt;= pid-&gt;level) &#123; upid = &amp;pid-&gt;numbers[ns-&gt;level]; if (upid-&gt;ns == ns) nr = upid-&gt;nr; &#125; return nr;&#125;EXPORT_SYMBOL_GPL(pid_nr_ns);pid_t pid_vnr(struct pid *pid)&#123; return pid_nr_ns(pid, task_active_pid_ns(current));&#125;EXPORT_SYMBOL_GPL(pid_vnr);pid_t __task_pid_nr_ns(struct task_struct *task, enum pid_type type, struct pid_namespace *ns)&#123; pid_t nr = 0; rcu_read_lock(); if (!ns) ns = task_active_pid_ns(current); if (likely(pid_alive(task))) nr = pid_nr_ns(rcu_dereference(*task_pid_ptr(task, type)), ns); rcu_read_unlock(); return nr;&#125;EXPORT_SYMBOL(__task_pid_nr_ns);struct pid_namespace *task_active_pid_ns(struct task_struct *tsk)&#123; return ns_of_pid(task_pid(tsk));&#125;EXPORT_SYMBOL_GPL(task_active_pid_ns);/* * Used by proc to find the first pid that is greater than or equal to nr. * * If there is a pid at nr this function is exactly the same as find_pid_ns. */struct pid *find_ge_pid(int nr, struct pid_namespace *ns)&#123; return idr_get_next(&amp;ns-&gt;idr, &amp;nr);&#125;/** * pidfd_create() - Create a new pid file descriptor. * * @pid: struct pid that the pidfd will reference * * This creates a new pid file descriptor with the O_CLOEXEC flag set. * * Note, that this function can only be called after the fd table has * been unshared to avoid leaking the pidfd to the new process. * * Return: On success, a cloexec pidfd is returned. * On error, a negative errno number will be returned. */static int pidfd_create(struct pid *pid)&#123; int fd; fd = anon_inode_getfd(&quot;[pidfd]&quot;, &amp;pidfd_fops, get_pid(pid), O_RDWR | O_CLOEXEC); if (fd &lt; 0) put_pid(pid); return fd;&#125;/** * pidfd_open() - Open new pid file descriptor. * * @pid: pid for which to retrieve a pidfd * @flags: flags to pass * * This creates a new pid file descriptor with the O_CLOEXEC flag set for * the process identified by @pid. Currently, the process identified by * @pid must be a thread-group leader. This restriction currently exists * for all aspects of pidfds including pidfd creation (CLONE_PIDFD cannot * be used with CLONE_THREAD) and pidfd polling (only supports thread group * leaders). * * Return: On success, a cloexec pidfd is returned. * On error, a negative errno number will be returned. */SYSCALL_DEFINE2(pidfd_open, pid_t, pid, unsigned int, flags)&#123; int fd, ret; struct pid *p; if (flags) return -EINVAL; if (pid &lt;= 0) return -EINVAL; p = find_get_pid(pid); if (!p) return -ESRCH; ret = 0; rcu_read_lock(); if (!pid_task(p, PIDTYPE_TGID)) ret = -EINVAL; rcu_read_unlock(); fd = ret ?: pidfd_create(p); put_pid(p); return fd;&#125;void __init pid_idr_init(void)&#123; /* Verify no one has done anything silly: */ BUILD_BUG_ON(PID_MAX_LIMIT &gt;= PIDNS_ADDING); /* bump default and minimum pid_max based on number of cpus */ pid_max = min(pid_max_max, max_t(int, pid_max, PIDS_PER_CPU_DEFAULT * num_possible_cpus())); pid_max_min = max_t(int, pid_max_min, PIDS_PER_CPU_MIN * num_possible_cpus()); pr_info(&quot;pid_max: default: %u minimum: %u\\n&quot;, pid_max, pid_max_min); idr_init(&amp;init_pid_ns.idr); init_pid_ns.pid_cachep = KMEM_CACHE(pid, SLAB_HWCACHE_ALIGN | SLAB_PANIC | SLAB_ACCOUNT);&#125;","categories":[{"name":"Linux源码","slug":"Linux源码","permalink":"http://example.com/categories/Linux%E6%BA%90%E7%A0%81/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"Linux","slug":"Linux","permalink":"http://example.com/tags/Linux/"}]},{"title":"C++学习 程序的内存模型","slug":"C++-学习-程序的内存模型","date":"2023-04-11T06:42:45.000Z","updated":"2023-04-14T01:24:25.844Z","comments":true,"path":"2023/04/11/C++-学习-程序的内存模型/","link":"","permalink":"http://example.com/2023/04/11/C++-%E5%AD%A6%E4%B9%A0-%E7%A8%8B%E5%BA%8F%E7%9A%84%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/","excerpt":"","text":"内存分区模型C++程序在执行时，将内存大方向划分为四个区域 代码区：存放函数体的二进制代码，由操作系统进行管理 全局区：存放全局变量和静态变量以及常量 栈区：由编译器自动分配释放，存放函数的参数值，局部变量等 堆区：由程序员分配和释放，若程序员不释放，程序结束时由操作系统回收 内存四区的意义： 不同区域存放的数据，赋予不同的生命周期，给我们更大的灵活编程 程序运行前在程序编译后，生成了exe可执行程序，未执行该程序前分为两个区域 代码区： 存放CPU执行的机器指令 代码区是共享的，共享的目的是对于频繁执行的程序，只要在内存中有一份代码即可 代码区是只读的，使其只读的原因是防止程序意外的修改了它的指令 全局区： 全局变量和静态变量存放在此 该区域的数据在程序结束后由操作系统释放 1234567891011121314151617181920212223242526#include &lt;iostream&gt;using namespace std;int g_a = 10;int g_b = 10;const int c_g_a = 10;const int c_g_b = 10;int main()&#123; int a = 10; int b = 10; static int s_a = 10; static int s_b = 10; const int c_a = 10; const int c_b = 10; cout &lt;&lt; &quot;局部变量a的地址&quot; &lt;&lt; (long long int)&amp;a&lt;&lt;endl; cout &lt;&lt; &quot;局部变量b的地址&quot; &lt;&lt; (long long int)&amp;b&lt;&lt;endl; cout &lt;&lt; &quot;全局变量g_a的地址&quot; &lt;&lt; (long long int)&amp;g_a&lt;&lt;endl; cout &lt;&lt; &quot;全局变量g_b的地址&quot; &lt;&lt; (long long int)&amp;g_b&lt;&lt;endl; cout &lt;&lt; &quot;静态变量s_a的地址&quot; &lt;&lt; (long long int)&amp;s_a &lt;&lt; endl; cout &lt;&lt; &quot;静态变量s_b的地址&quot; &lt;&lt; (long long int)&amp;s_b &lt;&lt; endl; cout &lt;&lt; &quot;字符串常量Hello World的地址&quot; &lt;&lt; (long long int)&amp;&quot;Hello World&quot; &lt;&lt; endl; cout &lt;&lt; &quot;全局常量c_g_a的地址&quot; &lt;&lt; (long long int)&amp;c_g_a &lt;&lt; endl; cout &lt;&lt; &quot;全局常量c_g_b的地址&quot; &lt;&lt; (long long int)&amp;c_g_b &lt;&lt; endl; cout &lt;&lt; &quot;局部常量c_a的地址&quot; &lt;&lt; (long long int) &amp; c_a &lt;&lt; endl; cout &lt;&lt; &quot;局部常量c_b的地址&quot; &lt;&lt; (long long int) &amp; c_b &lt;&lt; endl;&#125; 运行结果为： 局部变量a的地址145921079908局部变量b的地址145921079940全局变量g_a的地址140702441787392全局变量g_b的地址140702441787396静态变量s_a的地址140702441787400静态变量s_b的地址140702441787404字符串常量Hello World的地址140702441778224全局常量c_g_a的地址140702441778272全局常量c_g_b的地址140702441778276局部常量c_a的地址145921079972局部常量c_b的地址145921080004 程序运行后 栈区 由编译器自动分配释放存放函数的参数值（形参），局部变量等 注意事项：不要返回局部变量的地址，栈区开辟的数据由编译器自动释放 12345678910111213#include &lt;iostream&gt;using namespace std;int* func(int a)&#123; a = 10; return &amp;a;&#125;int main()&#123; int* p = func(1); cout &lt;&lt; *p &lt;&lt; endl; cout &lt;&lt; *p &lt;&lt; endl;&#125; 运行结果为： 10-226279312 堆区 由程序员分配释放，若程序员不释放，程序结束时由操作系统回收 在C++中主要利用new在堆区开辟内存 12345678910111213#include &lt;iostream&gt;using namespace std;int* func(int a)&#123; int* p = new int(10); return p;&#125;int main()&#123; int* p = func(1); cout &lt;&lt; *p &lt;&lt; endl; cout &lt;&lt; *p &lt;&lt; endl;&#125; 运行结果为： 1010 new操作符C++中利用new操作符在堆区开辟数据 堆区开辟的数据，由程序员手动释放，释放利用操作符delete 语法：new 数据类型 利用new创建的数据，会返回该数据对应的类型的指针 12345678910111213141516171819#include &lt;iostream&gt;using namespace std;int* func()&#123; int* p = new int (10); return p;&#125;void test01()&#123; int* p = func(); cout &lt;&lt; *p &lt;&lt; endl; cout &lt;&lt; *p &lt;&lt; endl; delete(p); cout &lt;&lt; *p &lt;&lt; endl;&#125;int main()&#123; test01();&#125; 运行结果为： 1234567891011121314151617181920#include &lt;iostream&gt;using namespace std;void test02()&#123; int* arr = new int[10]; for (int i = 0; i &lt; 10; i++) &#123; arr[i] = i + 100; &#125; for (int i = 0; i &lt; 10; i++) &#123; cout &lt;&lt; arr[i] &lt;&lt; endl; &#125; delete[] arr;&#125;int main()&#123; test02();&#125; 运行结果为： 100101102103104105106107108109 delete之后，不能访问arr指针指向的内存，否则会发生跟上图一样的情况","categories":[{"name":"编程语言","slug":"编程语言","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"},{"name":"C++","slug":"编程语言/C","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/C/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://example.com/tags/C/"}]},{"title":"C++学习 结构体","slug":"C++-学习-结构体","date":"2023-04-10T07:42:49.000Z","updated":"2023-04-12T15:03:17.715Z","comments":true,"path":"2023/04/10/C++-学习-结构体/","link":"","permalink":"http://example.com/2023/04/10/C++-%E5%AD%A6%E4%B9%A0-%E7%BB%93%E6%9E%84%E4%BD%93/","excerpt":"","text":"结构体的基本概念结构体属于用户自定义的数据类型，允许用户存储不同的数据类型 结构体的定义和使用语法： struct 结构体名（结构体成员列表）； 通过结构体创建变量的方式有三种： struct 结构体名 变量名 struct 结构体名 变量名 &#x3D; {成员1值 ， 成员2值…} 定义结构体时顺便创建变量 1234567891011121314151617181920212223242526#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;struct student &#123; string name; int age; int score;&#125;s3;int main()&#123; struct student s1; s1.name = &quot;张三&quot;; s1.age = 15; s1.score = 100; cout &lt;&lt; &quot;姓名： &quot; &lt;&lt; s1.name &lt;&lt; &quot;年龄： &quot; &lt;&lt; s1.age &lt;&lt; &quot;成绩： &quot; &lt;&lt; s1.score &lt;&lt; endl; struct student s2 = &#123; &quot;李四&quot; , 16 , 90 &#125;; cout &lt;&lt; &quot;姓名： &quot; &lt;&lt; s2.name &lt;&lt; &quot;年龄： &quot; &lt;&lt; s2.age &lt;&lt; &quot;成绩： &quot; &lt;&lt; s2.score &lt;&lt; endl; s3.name = &quot;王五&quot;; s3.age = 17; s3.score = 85; cout &lt;&lt; &quot;姓名： &quot; &lt;&lt; s3.name &lt;&lt; &quot;年龄： &quot; &lt;&lt; s3.age &lt;&lt; &quot;成绩： &quot; &lt;&lt; s3.score &lt;&lt; endl;&#125; 运行结果如下： 姓名： 张三年龄： 15成绩： 100姓名： 李四年龄： 16成绩： 90姓名： 王五年龄： 17成绩： 85 结构体数组作用：将自定义的结构体放入到数组中方便维护 语法：struct 结构体 数组名[元素个数] &#x3D; { {} ， {} ，… ，{} } 1234567891011121314151617181920212223242526#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;struct student &#123; string name; int age; int score;&#125;;int main()&#123; struct student stuArray[3] = &#123; &#123;&quot;张三&quot;,18,100&#125;, &#123;&quot;李四&quot;, 19, 90&#125;, &#123;&quot;王五&quot;, 20, 85&#125; &#125;; stuArray[2].name = &quot;赵六&quot;; stuArray[2].age = 15; stuArray[2].score = 95; for (int i = 0; i &lt; 3; i++) &#123; cout &lt;&lt; &quot;姓名： &quot; &lt;&lt; stuArray[i].name &lt;&lt; &quot; 年龄： &quot; &lt;&lt; stuArray[i].age &lt;&lt; &quot; 分数： &quot; &lt;&lt; stuArray[i].score &lt;&lt; endl; &#125;&#125; 运行结果如下： 姓名： 张三 年龄： 18 分数： 100姓名： 李四 年龄： 19 分数： 90姓名： 赵六 年龄： 15 分数： 95 结构体指针作用：通过指针访问结构体中的成员 利用操作符 -&gt;可以通过结构体指针访问结构体属性 1234567891011121314#include &lt;iostream&gt;#include&lt;string&gt;using namespace std;struct student &#123; string name; int age; int score;&#125;;int main()&#123; struct student s = &#123; &quot;张三&quot; , 16 , 98 &#125;; struct student * p = &amp;s; cout &lt;&lt; &quot;姓名： &quot; &lt;&lt; p-&gt;name &lt;&lt; &quot; 年龄： &quot; &lt;&lt; p-&gt;age &lt;&lt; &quot; 分数： &quot; &lt;&lt; p-&gt;score &lt;&lt; endl;&#125; 运行结果为： 姓名： 张三 年龄： 16 分数： 98 结构体嵌套结构体作用：结构体中的成员可以是另一个结构体 例如：每个老师辅导一个学员，一个老师的结构体中，记录一个学生的结构体 1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;#include&lt;string&gt;using namespace std;struct student &#123; string name; int age; int score;&#125;;struct teacher&#123; string name; int id; int age; struct student stu;&#125;;int main()&#123; struct teacher t; t.name = &quot;张三&quot;; t.id = 100; t.age = 45; t.stu.name = &quot;李四&quot;; t.stu.age = 16; t.stu.score = 100; cout &lt;&lt; &quot;老师的姓名：&quot; &lt;&lt; t.name &lt;&lt; &quot; 老师的id：&quot; &lt;&lt; t.id &lt;&lt; &quot; 老师的年龄：&quot; &lt;&lt; t.age &lt;&lt; endl; cout &lt;&lt; &quot;老师指导的学生的姓名：&quot; &lt;&lt; t.stu.name &lt;&lt; &quot; 学生的年龄： &quot; &lt;&lt; t.stu.age &lt;&lt; &quot; 学生的成绩：&quot; &lt;&lt; t.stu.score &lt;&lt; endl;&#125; 运行结果为： 老师的姓名：张三 老师的id：100 老师的年龄：45老师指导的学生的姓名：李四 学生的年龄： 16 学生的成绩：100 结构体做函数参数作用：将结构体作为参数向函数中传递 传递方式有两种： 值传递 地址传递 1234567891011121314151617181920212223242526272829303132#include &lt;iostream&gt;#include&lt;string&gt;using namespace std;struct student &#123; string name; int age; int score;&#125;;void PrintStu1(struct student s)&#123; s.name = &quot;李四&quot;; s.age = 19; s.score = 90; cout &lt;&lt; &quot;子函数1中学生姓名：&quot; &lt;&lt; s.name &lt;&lt; &quot; 年龄：&quot; &lt;&lt; s.age &lt;&lt; &quot; 分数：&quot; &lt;&lt; s.score &lt;&lt; endl;&#125;void PrintStu2(struct student* p)&#123; p-&gt;name = &quot;李四&quot;; p-&gt;age = 19; p-&gt;score = 90; cout &lt;&lt; &quot;子函数2中学生姓名：&quot; &lt;&lt; p-&gt;name &lt;&lt; &quot; 年龄：&quot; &lt;&lt; p-&gt;age &lt;&lt; &quot; 分数：&quot; &lt;&lt; p-&gt;score &lt;&lt; endl;&#125;int main()&#123; struct student s = &#123; &quot;张三&quot; , 16 , 100 &#125;; cout &lt;&lt; &quot;main函数中学生姓名：&quot; &lt;&lt; s.name &lt;&lt; &quot; 年龄：&quot; &lt;&lt; s.age &lt;&lt; &quot; 分数：&quot; &lt;&lt; s.score &lt;&lt; endl; PrintStu1(s); cout &lt;&lt; &quot;main函数中学生姓名：&quot; &lt;&lt; s.name &lt;&lt; &quot; 年龄：&quot; &lt;&lt; s.age &lt;&lt; &quot; 分数：&quot; &lt;&lt; s.score &lt;&lt; endl; PrintStu2(&amp;s); cout &lt;&lt; &quot;main函数中学生姓名：&quot; &lt;&lt; s.name &lt;&lt; &quot; 年龄：&quot; &lt;&lt; s.age &lt;&lt; &quot; 分数：&quot; &lt;&lt; s.score &lt;&lt; endl;&#125; 运行结果为： main函数中学生姓名：张三 年龄：16 分数：100子函数1中学生姓名：李四 年龄：19 分数：90main函数中学生姓名：张三 年龄：16 分数：100子函数2中学生姓名：李四 年龄：19 分数：90main函数中学生姓名：李四 年龄：19 分数：90 结构体中const的使用场景作用：用const来防止误操作 12345678910111213141516171819#include &lt;iostream&gt;#include&lt;string&gt;using namespace std;struct student &#123; string name; int age; int score;&#125;;void PrintStu(const struct student * s)&#123; s-&gt;name = &quot;李四&quot;;&#125;int main()&#123; struct student s = &#123; &quot;张三&quot; , 16 , 100 &#125;; PrintStu(&amp;s);&#125; 结果如下： 程序报错，不能修改 结构体案例一案例描述：学校正在做毕设项目，每名老师带领五个学生，总共有三名老师，需求如下 设计学生和老师的结构体，其中在老师的结构体中，有老师姓名和一个存放五名学生的数组作为成员 学生的成员有姓名、考试分数，创建数组存放三名老师，通过函数给每个老师及所带学生的学生数赋值 最终打印出老师数据以及老师所带学生的数据 12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;iostream&gt;#include&lt;string&gt;using namespace std;struct student &#123; string sname; int score;&#125;;struct teacher&#123; string tname; struct student stuArray[5];&#125;;void inAll(struct teacher * s)&#123; printf(&quot;请输入老师的姓名：&quot;); cin &gt;&gt; s-&gt;tname; for (int i = 0; i &lt; 5; i++) &#123; printf(&quot;\\n请输入第%d位同学的姓名和成绩&quot;,i+1); cin&gt;&gt;s-&gt;stuArray[i].sname&gt;&gt;s-&gt;stuArray[i].score; &#125;&#125;void outAll(struct teacher t)&#123; cout &lt;&lt; &quot;老师的姓名&quot; &lt;&lt; t.tname &lt;&lt; endl; for (int i = 0; i &lt; 5; i++) &#123; cout &lt;&lt; &quot;学生&quot; &lt;&lt;i+1&lt;&lt;&quot;姓名为：&quot;&lt;&lt; t.stuArray[i].sname &lt;&lt; &quot; 成绩为：&quot; &lt;&lt; t.stuArray[i].score &lt;&lt; endl; &#125;&#125;int main()&#123; struct teacher tArray[3]; for (int i = 0; i &lt; 3; i++) &#123; inAll(&amp;tArray[i]); &#125; for (int i = 0; i &lt; 3; i++) &#123; outAll(tArray[i]); &#125;&#125; 运行结果如下： 请输入老师的姓名：老师1 请输入第1位同学的姓名和成绩学生11 90 请输入第2位同学的姓名和成绩学生12 90 请输入第3位同学的姓名和成绩学生13 80 请输入第4位同学的姓名和成绩学生14 79 请输入第5位同学的姓名和成绩学生15 98请输入老师的姓名：老师2 请输入第1位同学的姓名和成绩学生21 80 请输入第2位同学的姓名和成绩学生22 79 请输入第3位同学的姓名和成绩学生23 80 请输入第4位同学的姓名和成绩学生24 79 请输入第5位同学的姓名和成绩学生25 90请输入老师的姓名：老师3 请输入第1位同学的姓名和成绩学生31 90 请输入第2位同学的姓名和成绩学生32 89 请输入第3位同学的姓名和成绩学生33 79 请输入第4位同学的姓名和成绩学生34 80 请输入第5位同学的姓名和成绩学生35 98老师的姓名老师1学生1姓名为：学生11 成绩为：90学生2姓名为：学生12 成绩为：90学生3姓名为：学生13 成绩为：80学生4姓名为：学生14 成绩为：79学生5姓名为：学生15 成绩为：98老师的姓名老师2学生1姓名为：学生21 成绩为：80学生2姓名为：学生22 成绩为：79学生3姓名为：学生23 成绩为：80学生4姓名为：学生24 成绩为：79学生5姓名为：学生25 成绩为：90老师的姓名老师3学生1姓名为：学生31 成绩为：90学生2姓名为：学生32 成绩为：89学生3姓名为：学生33 成绩为：79学生4姓名为：学生34 成绩为：80学生5姓名为：学生35 成绩为：98 结构体案例二案例描述： 设计一个英雄的结构体，包括成员姓名，年龄，性别：创建结构体数组，数组中存放五名英雄。 通过冒泡排序的算法，将数组中的英雄按照年龄进行升序排序，最终打印排序后的结果。 12345678910111213141516171819202122232425262728293031323334353637#include &lt;iostream&gt;#include&lt;string&gt;using namespace std;struct Hero&#123; string name; int age; string sex;&#125;;int main()&#123; struct Hero heroArray[5] = &#123; &#123;&quot;刘备&quot;, 21, &quot;男&quot;&#125;, &#123; &quot;关羽&quot;,19,&quot;男&quot; &#125;, &#123; &quot;张飞&quot;,23,&quot;男&quot; &#125;, &#123; &quot;赵云&quot;,20,&quot;男&quot; &#125;, &#123; &quot;黄忠&quot;,18,&quot;男&quot; &#125; &#125;; int len = sizeof(heroArray) / sizeof(heroArray[0]); for (int i = 0; i &lt; len - 1; i++) &#123; for (int j = 0; j &lt; len; j++) &#123; if (heroArray[j+1].age &gt; heroArray[j].age) &#123; struct Hero temp = heroArray[j]; heroArray[j] = heroArray[j+1]; heroArray[j+1] = temp; &#125; &#125; &#125; for (int i = 0; i &lt; len; i++) &#123; cout &lt;&lt; heroArray[i].name &lt;&lt; heroArray[i].age &lt;&lt; heroArray[i].sex &lt;&lt; endl; &#125;&#125; 运行结果如下： 张飞23男刘备21男赵云20男关羽19男黄忠18男","categories":[{"name":"编程语言","slug":"编程语言","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"},{"name":"C++","slug":"编程语言/C","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/C/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://example.com/tags/C/"}]},{"title":"C++学习 指针","slug":"C++-学习-指针","date":"2023-04-09T05:57:28.000Z","updated":"2023-04-10T07:43:50.442Z","comments":true,"path":"2023/04/09/C++-学习-指针/","link":"","permalink":"http://example.com/2023/04/09/C++-%E5%AD%A6%E4%B9%A0-%E6%8C%87%E9%92%88/","excerpt":"","text":"指针基本概念指针的作用： 可以通过指针间接访问内存 内存编号是从0开始记录的，一般用十六进制数字表示 可以利用指针变量保存地址 可以通过一个指针来保存一个地址 指针的定义和使用定义指针指针定义的语法： 数据类型 \\* 指针变量名 12345678910#include &lt;iostream&gt;using namespace std;int main()&#123; int a = 10; int* p; p = &amp;a; cout &lt;&lt; &quot;a的地址为&quot; &lt;&lt; &amp;a &lt;&lt; endl; cout &lt;&lt; &quot;指针p为&quot; &lt;&lt; p &lt;&lt; endl;&#125; 运行结果为： a的地址为00000087472FFC84指针p为00000087472FFC84 我们可以得到指针就是地址 使用指针可以通过解引用的方式来找到指针指向的内存 指针前加 *代表解引用 1234567891011121314#include &lt;iostream&gt;using namespace std;int main()&#123; int a = 10; int* p; p = &amp;a; cout &lt;&lt; &quot;a的地址为&quot; &lt;&lt; &amp;a &lt;&lt; endl; cout &lt;&lt; &quot;指针p为&quot; &lt;&lt; p &lt;&lt; endl; *p = 1000; cout &lt;&lt; &quot;a = &quot; &lt;&lt; a &lt;&lt;endl; cout &lt;&lt; &quot;*p = &quot; &lt;&lt; *p &lt;&lt; endl;&#125; 运行结果为： a的地址为0000003F9953F7C4指针p为0000003F9953F7C4a &#x3D; 1000*p &#x3D; 1000 通过p找到a的内存，并且可以通过*p修改内存 指针所占内存空间指针也是一种数据类型，那么这种数据类型占用多少内存空间呢？ 在32位操作系统下：占用4个字节空间 在64位操作系统下：占用8个字节空间 123456789101112#include &lt;iostream&gt;using namespace std;int main()&#123; int a = 10; int* p = &amp;a; cout &lt;&lt; &quot;sizeof (p) = &quot; &lt;&lt; sizeof(p) &lt;&lt; endl; cout &lt;&lt; &quot;sizeof (int *) = &quot; &lt;&lt; sizeof(int *) &lt;&lt; endl; cout &lt;&lt; &quot;sizeof (char *) = &quot; &lt;&lt; sizeof(char *) &lt;&lt; endl; cout &lt;&lt; &quot;sizeof (float *) = &quot; &lt;&lt; sizeof(float *) &lt;&lt; endl; cout &lt;&lt; &quot;sizeof (double *) = &quot; &lt;&lt; sizeof(double *) &lt;&lt; endl;&#125; 运行结果为： sizeof (p) &#x3D; 8sizeof (int *) &#x3D; 8sizeof (char *) &#x3D; 8sizeof (float *) &#x3D; 8sizeof (double *) &#x3D; 8 因为指针是内存，所以不管是什么数据类型下，64位操作系统，指针都是占用8个字节空间大小 空指针和野指针空指针空指针：指针变量指向内存中为0的空间 用途：初始化指针变量 注意：空指针的内存是不可以访问的 12345678#include &lt;iostream&gt;using namespace std;int main()&#123; int* p = NULL; *p = 100;&#125; 程序运行错误 0~255之间的内存编号是系统占用的，因此不可以访问 野指针野指针：指针变量指向一段非法的内存空间 1234567#include &lt;iostream&gt;using namespace std;int main()&#123; int* p = (int *)0x1100; cout &lt;&lt; *p &lt;&lt; endl;&#125; 程序运行错误 在程序中尽量避免野指针 const修饰指针const修饰指针有三种情况 const修饰指针 - 常量指针指针的指向可以修改，指针指向的值不能修改 1const int * p; const修饰常量 - 指针常量指针的指向不可以改，指针指向的值可以改 1int * const p; const既修饰指针，又修饰常量指针的指向不可以改，指针指向的值也不可以改 1const int * const p; 12345678910111213141516171819202122#include &lt;iostream&gt;using namespace std;int main()&#123; int a = 10; int b = 10; //1、const 修饰指针 常量指针 const int * p1 = &amp;a; //*p1 = 20 错误 p1 = &amp;b;//正确 //2、const 修饰常量 指针常量 int* const p2 = &amp;a; *p2 = 100;//正确 //p2 = &amp;b; 错误 //3、const 既修饰常量又修饰指针 const int * const p3 = &amp;a; //*p3 = 100 错误 //p3 = &amp;b 错误&#125; 指针和数组利用指针访问数组中的数据元素 1234567891011121314#include &lt;iostream&gt;using namespace std;int main()&#123; int arr[] = &#123; 1, 2, 3, 4, 5, 6, 7, 8, 9 ,10 &#125;; int* p = arr; cout &lt;&lt; &quot;第一个元素为：&quot; &lt;&lt; arr[0] &lt;&lt; endl; cout &lt;&lt; &quot;指针访问第一个元素：&quot; &lt;&lt; *p &lt;&lt; endl; for (int i = 0; i &lt; 10; i++) &#123; cout &lt;&lt; *p &lt;&lt; endl; p++; &#125;&#125; 运行结果为： 第一个元素为：1指针访问第一个元素：112345678910 指针和函数利用指针作为函数参数，可以修改实参的值 12345678910111213141516171819202122232425262728#include &lt;iostream&gt;using namespace std;void swap01(int a, int b)&#123; int temp = a; a = b; b = temp; return ;&#125;void swap02(int* p1, int* p2)&#123; int temp = *p1; *p1 = *p2; *p2 = temp;&#125;int main()&#123; int a = 10; int b = 20; //1、值传递 swap01(a, b); cout &lt;&lt; &quot;swap01后a的值为&quot; &lt;&lt; a &lt;&lt; endl; cout &lt;&lt; &quot;swap01后b的值为&quot; &lt;&lt; b &lt;&lt; endl; //2、地址传递 swap02(&amp;a, &amp;b); cout &lt;&lt; &quot;swap02后a的值为&quot; &lt;&lt; a &lt;&lt; endl; cout &lt;&lt; &quot;swap02后b的值为&quot; &lt;&lt; b &lt;&lt; endl;&#125; 运行结果如下： swap01后a的值为10swap01后b的值为20swap02后a的值为20swap02后b的值为10 指针、数组、函数案例描述：封装一个函数，利用冒泡排序，实现对整型数组的升序排序 123456789101112131415161718192021222324252627282930313233343536373839#include &lt;iostream&gt;using namespace std;//冒泡排序函数void bubbleSort(int * arr, int len)&#123; for (int i = 0; i &lt; len - 1; i++) &#123; for (int j = 0; j &lt; len - i - 1; j++) &#123; //如果j&gt;j+1,交换数字 if (arr[j] &gt; arr[j + 1]) &#123; int temp = arr[j]; arr[j] = arr[j + 1]; arr[j + 1] = temp; &#125; &#125; &#125;&#125;//打印数组void printArray(int* arr, int len)&#123; for (int i = 0; i &lt; len; i++) &#123; cout &lt;&lt; arr[i] &lt;&lt; endl; &#125;&#125;int main()&#123; //1、创建数组 int arr[10] = &#123;4 , 3 , 6 , 9 , 1 , 2 , 10 , 8 , 7 , 5&#125;; //数组长度 int len = sizeof(arr) / sizeof(arr[0]); //2、创建函数，实现冒泡排序 bubbleSort(arr, len); //3、打印排序后的数组 printArray(arr, len);&#125; 运行结果如下： 12345678910","categories":[{"name":"编程语言","slug":"编程语言","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"},{"name":"C++","slug":"编程语言/C","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/C/"}],"tags":[{"name":"C++","slug":"C","permalink":"http://example.com/tags/C/"},{"name":"指针","slug":"指针","permalink":"http://example.com/tags/%E6%8C%87%E9%92%88/"}]},{"title":"学习路径","slug":"学习路径","date":"2023-04-08T12:15:26.000Z","updated":"2023-04-10T12:14:08.370Z","comments":true,"path":"2023/04/08/学习路径/","link":"","permalink":"http://example.com/2023/04/08/%E5%AD%A6%E4%B9%A0%E8%B7%AF%E5%BE%84/","excerpt":"","text":"Rust学习Rust的过程涉及多个阶段。这里提供了一个详细的Rust学习计划，帮助您逐步掌握这门语言： 1. 基础阶段 阅读《Rust编程语言》（The Rust Programming Language，又称”The Book”）：这是学习Rust的官方教材，为初学者提供了全面的入门知识。在线版本可免费访问：The Rust Programming Language - The Rust Programming Language 学习Rust的基本语法、数据类型、控制结构、错误处理等概念。 完成《The Book》中的示例和练习，以巩固所学知识。 参加Rust社区活动，如阅读论坛帖子、加入聊天室和邮件列表，以了解最新动态和获得帮助。 2. 实践阶段 尝试解决一些简单的编程问题，例如LeetCode上的题目，以熟悉Rust的编程范式。 阅读Rust编写的开源项目代码，学习他人如何使用Rust解决实际问题。 参与开源项目，为Rust生态做贡献。这可以帮助您熟悉实际项目中的编程实践、代码审查和协作流程。 开始实现自己的项目，将学到的知识应用于实践。可以从一个简单的命令行工具或Web服务开始。 3. 进阶阶段 深入了解Rust的所有权（Ownership）、借用（Borrowing）和生命周期（Lifetime）系统。这是理解Rust内存安全的关键。 学习Rust的并发和异步编程。掌握如何使用线程、通道、异步I&#x2F;O和async/await编写高性能、可扩展的Rust代码。 阅读Rust的官方文档，例如《Rust异步编程》（Asynchronous Programming in Rust）和《Rust标准库文档》（The Rust Standard Library Documentation），以深入了解各种概念和API。 学习Rust的宏（Macros）系统，了解如何编写DRY（Don’t Repeat Yourself）代码和元编程。 4. 专业阶段 探索Rust在不同领域的应用，例如Web开发、嵌入式系统、游戏开发、区块链等。 阅读有关Rust性能优化、安全性和最佳实践的文章和教程。 参加Rust会议和研讨会，与其他Rust开发者交流经验和技巧。 考虑投入到Rust生态系统的开发中，例如编写库、工具和框架，为社区提供贡献。学习Rust的过程涉及多个阶段。这里提供了一个详细的Rust学习计划，帮助您逐步掌握这门语言： 1. 基础阶段 阅读《Rust编程语言》（The Rust Programming Language，又称”The Book”）：这是学习Rust的官方教材，为初学者提供了全面的入门知识。在线版本可免费访问：The Rust Programming Language - The Rust Programming Language 学习Rust的基本语法、数据类型、控制结构、错误处理等概念。 完成《The Book》中的示例和练习，以巩固所学知识。 参加Rust社区活动，如阅读论坛帖子、加入聊天室和邮件列表，以了解最新动态和获得帮助。 2. 实践阶段 尝试解决一些简单的编程问题，例如LeetCode上的题目，以熟悉Rust的编程范式。 阅读Rust编写的开源项目代码，学习他人如何使用Rust解决实际问题。 参与开源项目，为Rust生态做贡献。这可以帮助您熟悉实际项目中的编程实践、代码审查和协作流程。 开始实现自己的项目，将学到的知识应用于实践。可以从一个简单的命令行工具或Web服务开始。 3. 进阶阶段 深入了解Rust的所有权（Ownership）、借用（Borrowing）和生命周期（Lifetime）系统。这是理解Rust内存安全的关键。 学习Rust的并发和异步编程。掌握如何使用线程、通道、异步I&#x2F;O和async/await编写高性能、可扩展的Rust代码。 阅读Rust的官方文档，例如《Rust异步编程》（Asynchronous Programming in Rust）和《Rust标准库文档》（The Rust Standard Library Documentation），以深入了解各种概念和API。 学习Rust的宏（Macros）系统，了解如何编写DRY（Don’t Repeat Yourself）代码和元编程。 4. 专业阶段 探索Rust在不同领域的应用，例如Web开发、嵌入式系统、游戏开发、区块链等。 阅读有关Rust性能优化、安全性和最佳实践的文章和教程。 参加Rust会议和研讨会，与其他Rust开发者交流经验和技巧。 考虑投入到Rust生态系统的开发中，例如编写库、工具和框架，为社区提供贡献。 C++C++是一门功能强大的编程语言，学习过程可以分为多个阶段。以下是一份详细的C++学习计划，帮助您逐步掌握C++： 1. 基础阶段 阅读C++的经典教材，如《C++ Primer》(by Stanley B. Lippman, Josée Lajoie, and Barbara E. Moo) 或《C++程序设计原理与实践》（Programming: Principles and Practice Using C++, by Bjarne Stroustrup）。 学习C++的基本语法、数据类型、控制结构、函数、类和对象等概念。 练习编写简单的C++程序，巩固所学知识。 参加在线C++社区活动，如Stack Overflow和C++ subreddit，了解最新动态和获得帮助。 2. 实践阶段 学习使用C++标准库（STL），掌握容器、算法和迭代器等重要概念。 尝试解决一些实际编程问题，例如LeetCode上的题目，以熟悉C++编程范式。 阅读开源C++项目的代码，学习他人如何使用C++解决实际问题。 参与开源项目，为C++生态做贡献。这可以帮助您熟悉实际项目中的编程实践、代码审查和协作流程。 开始实现自己的项目，将学到的知识应用于实践。可以从一个简单的命令行工具或图形界面应用开始。 3. 进阶阶段 深入学习C++的高级特性，如模板、异常处理、智能指针、多态等。 学习C++的并发和多线程编程，掌握线程、互斥量、条件变量等概念。 阅读有关C++性能优化、内存管理和最佳实践的文章和教程。 学习C++11、C++14、C++17、C++20等新标准中的新特性，以便编写现代、高效的C++代码。 4. 专业阶段 探索C++在不同领域的应用，例如游戏开发、高性能计算、嵌入式系统等。 学习使用C++编写跨平台应用程序，使用诸如Qt等框架。 参加C++会议和研讨会，与其他C++开发者交流经验和技巧。 考虑投入到C++生态系统的开发中，例如编写库、工具和框架，为社区提供贡献。 云系统内核安全云系统内核安全是一个高度专业化的领域，涉及操作系统、虚拟化技术、硬件安全等多方面知识。以下是一份详细的云系统内核安全学习计划，帮助您逐步掌握相关知识： 1. 基础阶段 学习计算机组成原理和计算机体系结构，了解CPU、内存、IO设备等基本概念。 学习操作系统基础知识，如进程、线程、内存管理、文件系统、设备驱动等。 学习网络基础知识，掌握TCP&#x2F;IP协议栈、网络设备、网络安全等概念。 2. 虚拟化技术阶段 学习虚拟化技术的基本原理，了解全虚拟化和半虚拟化的区别。 学习常见的虚拟化平台，如VMware、KVM、Xen、Hyper-V等，了解它们的架构和特点。 学习容器技术，如Docker和Kubernetes，了解与虚拟机相比的优势和局限。 3. 云安全阶段 学习云计算的基本概念，了解IaaS、PaaS、SaaS等服务模型。 学习主流云服务提供商（如AWS、Azure、Google Cloud、阿里云等）的安全服务和最佳实践。 了解云安全的共享责任模型，学会在云环境中保护数据、网络、应用和用户的安全。 4. 内核安全阶段 深入学习操作系统内核，了解内核态和用户态的区别，学习内核编程。 学习内核漏洞的类型和原理，例如缓冲区溢出、竞争条件、提权漏洞等。 学习内核漏洞的利用技术，如ROP、堆喷射、内核地址泄露等。 学习内核安全防护技术，如内核地址随机化（KASLR）、内核代码只读（RO）、内存保护扩展（MPX）等。 5. 云系统内核安全阶段 学习虚拟化环境下的内核安全挑战，如虚拟机逃逸、共享资源攻击等。 学习容器环境下的内核安全挑战，如容器逃逸、资源隔离不足等。 学习硬件安全技术，如安全引导（Secure Boot）、可信计算（TPM）、英特尔SGX等。 学习云环境下的内核安全加固措施，如安全基线、监控、自动化补丁等。 6. 实践阶段 参与开源内核安全项目，为社区提供贡献。 阅读内核安全相关的研究论文和技术报告，了解最新的研究动态。 参加内核安全和云安全的会议和研讨会，与同行交流经验和技巧。 pwn学习网络安全和 “pwn” 技能需要时间和努力，但通过制定一个合理的计划，你可以逐步掌握所需的知识和技能。以下是一个建议的学习计划： 学习基础知识： 计算机科学基础：了解计算机系统的基本原理，学习编程语言（如 Python, C, Java 或 JavaScript）。 计算机网络：学习网络基本原理，如 OSI 模型、TCP&#x2F;IP 协议、路由和交换等。 操作系统：熟悉 Windows、Linux 和 macOS 等操作系统的原理和使用。 学习网络安全基础： 加密与解密：学习基本的密码学原理，如对称加密、非对称加密、哈希函数等。 系统安全：了解常见的系统漏洞，如缓冲区溢出、SQL 注入、跨站脚本等。 安全工具：熟悉常用的安全工具，如 Wireshark、Nmap、Metasploit 等。 掌握 Pwn 技能： 静态分析：学习使用反汇编和调试工具（如 IDA Pro、Ghidra、OllyDbg 等）分析程序。 动态分析：学习使用调试器（如 GDB、x64dbg 等）调试程序，了解程序运行时的状态。 漏洞挖掘：学习如何发现潜在漏洞，如内存泄漏、整数溢出、格式化字符串等。 漏洞利用：学习编写利用代码，如利用 ROP 技术绕过 DEP、使用堆喷射绕过 ASLR 等。 实践与进阶： 参加 CTF 比赛：参加 Capture The Flag（CTF）比赛，提高实战能力。 研究漏洞案例：分析已知的漏洞案例，了解漏洞发现和利用的具体过程。 学习安全研究论文：阅读网络安全领域的学术论文，跟踪最新技术和研究成果。 参与开源项目：参与网络安全相关的开源项目，如漏洞扫描器、安全框架等。 持续学习： 关注安全领域的新闻和动态：关注网络安全领域的新闻、博客、漏洞报告等。 参加安全会议：参加网络安全会议（如 DEFCON、Black Hat 等），了解最新的安全趋势和技术。 建立个人网络：加入网络安全社区，与同行交流，分享经验和技巧。","categories":[{"name":"学习路径","slug":"学习路径","permalink":"http://example.com/categories/%E5%AD%A6%E4%B9%A0%E8%B7%AF%E5%BE%84/"}],"tags":[]},{"title":"Ubuntu源码 /proc/meminfo","slug":"Ubuntu源码-proc-meminfo","date":"2023-04-06T06:56:58.000Z","updated":"2023-04-06T07:26:56.266Z","comments":true,"path":"2023/04/06/Ubuntu源码-proc-meminfo/","link":"","permalink":"http://example.com/2023/04/06/Ubuntu%E6%BA%90%E7%A0%81-proc-meminfo/","excerpt":"","text":"1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253MemTotal: 3982192 kB 系统总内存大小MemFree: 333280 kB 系统中未使用的内存大小MemAvailable: 2062852 kB 系统中可供分配的内存大小，包括缓存和缓冲区Buffers: 149848 kB 用于文件I/O的临时存储区域的大小Cached: 1762576 kB 被操作系统缓存的文件大小SwapCached: 356 kB 已被交换且在内存中的数据大小Active: 1183472 kB 正在使用或最近被使用过的内存大小Inactive: 1406216 kB 最近没有被使用的内存大小Active(anon): 2988 kB 活动匿名内存大小，不包括文件Inactive(anon): 723692 kB 非活动匿名内存大小，不包括文件Active(file): 1180484 kB 活动文件内存大小Inactive(file): 682524 kB 非活动文件内存大小Unevictable: 0 kB 无法驱逐的内存大小Mlocked: 0 kB 锁定在内存中的内存大小SwapTotal: 3991548 kB 系统总交换空间大小SwapFree: 3987928 kB 系统交换空间空闲内存Zswap: 0 kB 使用 zswap 的压缩交换缓存大小Zswapped: 0 kB 使用 zswap 的压缩交换缓存大小Dirty: 180 kB 等待写回磁盘的内存大小Writeback: 0 kB 正在写回磁盘的内存大小AnonPages: 676928 kB 未映射到文件的匿名内存大小Mapped: 339472 kB 映射到文件的内存大小Shmem: 55032 kB 共享内存大小KReclaimable: 142032 kB 可回收的内核内存大小Slab: 417952 kB 内核数据结构缓存的大小SReclaimable: 142032 kB 可回收的 Slab 内存大小SUnreclaim: 275920 kB 不可回收的 Slab 内存大小KernelStack: 11180 kB 内核栈使用的内存大小PageTables: 16944 kB 页表使用的内存大小NFS_Unstable: 0 kB NFS 不稳定页缓存的大小Bounce: 0 kB 用于块设备 I/O 的跳跃缓冲区大小WritebackTmp: 0 kB 临时写回内存大小CommitLimit: 5982644 kB 基于内存和交换空间的提交限制Committed_AS: 4906744 kB 已提交的内存大小，包括内存和交换空间VmallocTotal: 34359738367kB 虚拟内存分配的总量，这是系统可以使用的虚拟内存总量VmallocUsed: 251220 kB 已使用的虚拟内存量VmallocChunk: 0 kB 最大连续虚拟内存空闲区域的大小Percpu: 134656 kB 每个 CPU 的内存使用量，这个值是每个 CPU 的 per-CPU 区域的大小之和HardwareCorrupted: 0 kB 由硬件错误导致的损坏内存量AnonHugePages: 4096 kB 用于匿名映射的大内存页的总量，这些映射不会关联到任何文件ShmemHugePages: 0 kB 用于共享内存（shmem）的大内存页的总量ShmemPmdMapped: 0 kB 已映射到共享内存的PMD大小，PMD 是页中间目录的缩写FileHugePages: 0 kB 用于文件映射的大内存页的总量FilePmdMapped: 0 kB 已映射到文件的 PMD 大小HugePages_Total: 0 系统配置的大内存页的总数HugePages_Free: 0 当前可用的大内存页的数量HugePages_Rsvd: 0 已预留（保留）但尚未使用的大内存页的数量HugePages_Surp: 0 超出系统需求的大内存页的数量，这些页可以在需要时立即分配给应用程序Hugepagesize: 2048 kB 系统配置的大内存页的大小Hugetlb: 0 kB 当前使用的 hugetlb 内存池的总大小，hugetlb 是大内存页的缩写DirectMap4k: 202624 kB 使用 4KB 大小的页映射的物理内存大小DirectMap2M: 3991552 kB 使用 2MB 大小的页映射的物理内存大小DirectMap1G: 2097152 kB 使用 1GB 大小的页映射的物理内存大小","categories":[{"name":"Ubuntu源码","slug":"Ubuntu源码","permalink":"http://example.com/categories/Ubuntu%E6%BA%90%E7%A0%81/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://example.com/tags/Ubuntu/"}]},{"title":"MIT6 S081 Operating System Engineering Lecture04 Page Tables","slug":"MIT6-S081-Operating-System-Engineering-Lecture04-Page-Tables","date":"2023-04-05T09:03:11.000Z","updated":"2023-04-14T11:30:30.108Z","comments":true,"path":"2023/04/05/MIT6-S081-Operating-System-Engineering-Lecture04-Page-Tables/","link":"","permalink":"http://example.com/2023/04/05/MIT6-S081-Operating-System-Engineering-Lecture04-Page-Tables/","excerpt":"","text":"Topic Address Spaces 支持虚拟内存的硬件 XV中的虚拟内存代码 Address Spaces为什么需要隔离性创造虚拟内存的一个出发点是你可以通过它实现隔离性。如果你正确的设置了page table，并且通过代码对它进行正确的管理，那么原则上你可以实现强隔离。 我们期望的是，每个用户程序都被装进一个盒子里，这样它们就不会彼此影响了。类似的，我们也想让它们与内核操作系统相互独立，这样如果某个应用程序无意或者故意做了一些坏事，也不会影响到操作系统。 如果我们不做任何工作，默认情况下我们是没有内存隔离性的。 RISC-V主板上，内存是由一些DRAM芯片组成。在这些DRAM芯片中保存了程序的数据和代码。例如内存中的某一个部分是内核，包括了文本，数据，栈等等；如果运行了Shell，内存中的某个部分就是Shell；如果运行了cat程序，内存中的某个部分是cat程序。这里说的都是物理内存，它的地址从0开始到某个大的地址结束。结束地址取决于我们的机器现在究竟有多少物理内存。所有程序都必须存在于物理内存中，否则处理器甚至都不能处理程序的指令。 这里的风险很明显。我们简单化一下场景，假设Shell存在于内存地址1000-2000之间。 如果cat出现了程序错误，将内存地址1000，也就是Shell的起始地址加载到寄存器a0中。之后执行sd $7, (a0)，这里等效于将7写入内存地址1000。 现在cat程序弄乱了Shell程序的内存镜像，所以隔离性被破坏了，这是我们不想看到的现象。所以，我们想要某种机制，能够将不同程序之间的内存隔离开来，这样类似的事情就不会发生。一种实现方式是地址空间（Address Spaces）。 基本概念这里的基本概念也很简单直观，我们给包括内核在内的所有程序专属的地址空间。所以，当我们运行cat时，它的地址空间从0到某个地址结束。当我们运行Shell时，它的地址也从0开始到某个地址结束。内核的地址空间也从0开始到某个地址结束。 如果cat程序想要向地址1000写入数据，那么cat只会向它自己的地址1000，而不是Shell的地址1000写入数据。所以，基本上来说，每个程序都运行在自己的地址空间，并且这些地址空间彼此之间相互独立。在这种不同地址空间的概念中，cat程序甚至都不具备引用属于Shell的内存地址的能力。这是我们想要达成的终极目标，因为这种方式为我们提供了强隔离性，cat现在不能引用任何不属于自己的内存。 所以现在我们的问题是如何在一个物理内存上，创建不同的地址空间，因为归根到底，我们使用的还是一堆存放了内存信息的DRAM芯片。 虚拟内存可以比物理内存更大，物理内存也可以比虚拟内存更大 如果太多的进程使用了虚拟内存，有可能使物理内存耗尽 kalloc保存了空余的page的列表，如果这个列表为空或者耗尽了，那么kalloc会返回一个空指针，内核会妥善处理并将结果返回给用户应用程序。并告诉用户应用程序，要么是对这个应用程序没有额外的内存了，要么整个机器都没有内存了。 Page页表流程页表是在硬件中通过处理器和内存管理单元（Memory Management Unit）实现。 CPU正在执行指令，例如sd $7, (a0)。 对于任何一条带有地址的指令，其中的地址应该认为是虚拟内存地址而不是物理地址。假设寄存器a0中是地址0x1000，那么这是一个虚拟内存地址。虚拟内存地址会被转到内存管理单元（MMU，Memory Management Unit） 内存管理单元会将虚拟地址翻译成物理地址。之后这个物理地址会被用来索引物理内存，并从物理内存加载，或者向物理内存存储数据。 从CPU的角度来说，一旦MMU打开了，它执行的每条指令中的地址都是虚拟内存地址。 为了能够完成虚拟内存地址到物理内存地址的翻译，MMU会有一个表单，表单中，一边是虚拟内存地址，另一边是物理内存地址。举个例子，虚拟内存地址0x1000对应了一个我随口说的物理内存地址0xFFF0。这样的表单可以非常灵活。 通常来说，内存地址对应关系的表单也保存在内存中。所以CPU中需要有一些寄存器用来存放表单在物理内存中的地址。现在，在内存的某个位置保存了地址关系表单，我们假设这个位置的物理内存地址是0x10。那么在RISC-V上一个叫做SATP的寄存器会保存地址0x10。 这样，CPU就可以告诉MMU，可以从哪找到将虚拟内存地址翻译成物理内存地址的表单。 page table存储在内存中，MMU只是会去查看page table。 每个应用程序都有自己独立的表单，并且这个表单定义了应用程序的地址空间。所以当操作系统将CPU从一个应用程序切换到另一个应用程序时，同时也需要切换SATP寄存器中的内容，从而指向新的进程保存在物理内存中的地址对应表单。这样的话，cat程序和Shell程序中相同的虚拟内存地址，就可以翻译到不同的物理内存地址，因为每个应用程序都有属于自己的不同的地址对应表单。 内核会写SATP寄存器，写SATP寄存器是一条特殊权限指令。所以，用户应用程序不能通过更新这个寄存器来更换一个地址对应表单，否则的话就会破坏隔离性。所以，只有运行在kernel mode的代码可以更新这个寄存器。 虚拟地址到物理地址 虚拟内存地址分为两个部分 index：用来查找page offset：对应一个page中的字节 当MMU在做地址翻译的时候，通过读取虚拟内存地址中的index可以知道物理内存中的page号，这个page号对应了物理内存中的4096个字节。之后虚拟内存地址中的offset指向了page中的4096个字节中的某一个，假设offset是12，那么page中的第12个字节被使用了。将offset加上page的起始地址，就可以得到物理内存地址。 RSIC-V处理器RISC-V的寄存器是64bit，但是并不是所有的64bit都被使用了，高25bit未被使用。 这样的结果是限制了虚拟内存地址的数量，虚拟内存地址的数量现在只有2^39个，大概是512GB。 当然如果有必要的话，最新的处理器或许可以支持更大的地址空间，只需要将未使用的25bit拿出来作为虚拟内存地址的一部分即可。 在剩下的39bit中，有27bit被用来当作index，12bit被用来当作offset。offset必须是12bit，因为对应了一个page的4096个字节。 在RISC-V中，物理内存地址是56bit。所以物理内存地址可以大于单个内存地址空间，但是也最多到2^56。大多数主板还不支持2^56这么大的物理内存，但是原则上，如果你能造出这样的主板，那么最多可以支持2^56字节的物理内存。 物理内存地址是56bit，其中44bit是物理page号（PPN,Physical Page Number)，剩下的12bit是offset完全继承自虚拟内存地址（也就是地址转换时，只需要将虚拟内存中的27bit翻译成物理内存中的44bit的page号，剩下的12bitoffset直接拷贝过来即可。 多级page table 我们之前提到的虚拟内存地址中的27bit的index，实际上是由3个9bit的数字组成（L2，L1，L0）。前9个bit被用来索引最高级的page directory（注：通常page directory是用来索引page table或者其他page directory物理地址的表单) 一个directory是4096Bytes，就跟page的大小是一样的。Directory中的一个条目被称为PTE（Page Table Entry）是64bits，就像寄存器的大小一样，也就是8Bytes。所以一个Directory page有512个条目。 所以实际上，SATP寄存器会指向最高一级的page directory的物理内存地址，之后我们用虚拟内存中index的高9bit用来索引最高一级的page directory，这样我们就能得到一个PPN，也就是物理page号。这个PPN指向了中间级的page directory。 当我们在使用中间级的page directory时，我们通过虚拟内存地址中的L1部分完成索引。接下来会走到最低级的page directory，我们通过虚拟内存地址中的L0部分完成索引。在最低级的page directory中，我们可以得到对应于虚拟内存地址的物理内存地址。 优点如果地址空间中大部分地址都没有使用，你不必为每一个index准备一个条目。举个例子，如果你的地址空间只使用了一个page，4096Bytes。除此之外，你没有使用任何其他的地址。现在，你需要多少个page table entry，或者page table directory来映射这一个page？ 在最高级，你需要一个page directory。在这个page directory中，你需要一个数字是0的PTE，指向中间级page directory。所以在中间级，你也需要一个page directory，里面也是一个数字0的PTE，指向最低级page directory。所以这里总共需要3个page directory（也就是3 * 512个条目）。 而在单级page table中，虽然我们只使用了一个page，还是需要2^27个PTE。这个方案中，我们只需要3 * 512个PTE。所需的空间大大减少了。这是实际上硬件采用这种层次化的3级page directory结构的主要原因。 PTE 物理页号（Physical Page Number，PPN）: 与物理地址字段类似，PPN存储与虚拟地址关联的物理内存地址。在RISC-V中，PTE的高位部分存储PPN。 有效位（Valid，V）: 有效位表示此PTE中存储的映射是否有效。如果有效位设置为1，表示此PTE的虚拟地址已映射到物理内存中。如果设置为0，则表示该虚拟地址尚未映射。 读（Read，R）: 读权限位表示允许对该页面进行读访问。 写（Write，W）: 写权限位表示允许对该页面进行写访问。 执行（Execute，X）: 执行权限位表示允许对该页面进行执行访问。 用户（User，U）: 用户权限位表示该页面是否允许在用户模式下访问。如果设置为1，则允许用户模式访问；如果设置为0，则仅允许特权模式访问。 全局（Global，G）: 全局位表示该页面是否对所有地址空间可见。如果设置为1，则表示该页面在地址空间切换时不会从转换查找缓冲器（Translation Lookaside Buffer，TLB）中清除。这对于操作系统内核和共享库等全局数据结构特别有用。 访问（Accessed，A）: 访问位表示自上次清零以来该页面是否被访问过。当发生内存访问时，硬件会自动设置访问位。 脏（Dirty，D）: 脏位表示自上次清零以来该页面是否被修改过。当某个页面的内容被修改时，硬件会自动设置脏位。 软件可用位（Software Use，SW）: 这些位是为操作系统软件保留的，可以在页表遍历过程中用于自定义用途。 页表缓存（Translation Lookaside Buffer）观察page table的结构，可以发现，当处理器从内存加载或者存储数据时，基本上都要做3次内存查找，第一次在最高级的page directory，第二次在中间级的page directory，最后一次在最低级的page directory。所以对于一个虚拟内存地址的寻址，需要读三次内存，这里代价有点高。所以实际中，几乎所有的处理器都会对于最近使用过的虚拟地址的翻译结果有缓存。这个缓存被称为：Translation Lookside Buffer（通常翻译成页表缓存）。你会经常看到它的缩写TLB。基本上来说，这就是Page Table Entry的缓存，也就是PTE的缓存。 当处理器第一次查找一个虚拟地址时，硬件通过3级page table得到最终的PPN，TLB会保存虚拟地址到物理地址的映射关系。这样下一次当你访问同一个虚拟地址时，处理器可以查看TLB，TLB会直接返回物理地址，而不需要通过page table得到结果。 TLB实现的具体细节不是我们要深入讨论的内容。这是处理器中的一些逻辑，对于操作系统来说是不可见的，操作系统也不需要知道TLB是如何工作的。你们需要知道TLB存在的唯一原因是，如果你切换了page table，操作系统需要告诉处理器当前正在切换page table，处理器会清空TLB。因为本质上来说，如果你切换了page table，TLB中的缓存将不再有用，它们需要被清空，否则地址翻译可能会出错。所以操作系统知道TLB是存在的，但只会时不时的告诉操作系统，现在的TLB不能用了，因为要切换page table了。在RISC-V中，清空TLB的指令是sfence_vma。 整个CPU和MMU都在处理器芯片中，所以在一个RISC-V芯片中，有多个CPU核，MMU和TLB存在于每一个CPU核里面。RISC-V处理器有L1 cache，L2 Cache，有些cache是根据物理地址索引的，有些cache是根据虚拟地址索引的，由虚拟地址索引的cache位于MMU之前，由物理地址索引的cache位于MMU之后。 Kernel Page Table 在XV6中，page table是如何工作的? 当操作系统启动时，会从地址0x80000000开始运行，这个地址其实也是由硬件设计者决定的。 主板的设计人员决定了，在完成了虚拟到物理地址的翻译之后，如果得到的物理地址大于0x80000000会走向DRAM芯片，如果得到的物理地址低于0x80000000会走向不同的I&#x2F;O设备。这是由这个主板的设计人员决定的物理结构。 首先，地址0是保留的，地址0x10090000对应以太网，地址0x80000000对应DDR内存，处理器外的易失存储（Off-Chip Volatile Memory），也就是主板上的DRAM芯片。 所有的事情都是由硬件，即主板决定的，CPU只是主板的一小部分，DRAM芯片位于处理器之外。是主板设计者将处理器，DRAM和许多I&#x2F;O设备汇总在一起。对于一个操作系统来说，CPU只是一个部分，I&#x2F;O设备同样也很重要。所以当你在写一个操作系统时，你需要同时处理CPU和I&#x2F;O设备，比如你需要向互联网发送一个报文，操作系统需要调用网卡驱动和网卡来实际完成这个工作。 地址0x1000是boot ROM的物理地址，当你对主板上电，主板做的第一件事情就是运行存储在boot ROM中的代码，当boot完成之后，会跳转到地址0x80000000，操作系统需要确保那个地址有一些数据能够接着启动操作系统。 物理地址还有一些其他的I&#x2F;O设备 PLIC是中断控制器（Platform-Level Interrupt Controller） CLINT（Core Local Interruptor）也是中断的一部分。所以多个设备都能产生中断，需要中断控制器来将这些中断路由到合适的处理函数。 UART0（Universal Asynchronous Receiver&#x2F;Transmitter）负责与Console和显示器交互。 VIRTIO disk，与磁盘进行交互。 高于0x80000000的物理地址对应DRAM芯片，但是对于例如以太网接口，也有一个特定的低于0x80000000的物理地址，我们可以对这个叫做内存映射I&#x2F;O（Memory-mapped I&#x2F;O）的地址执行读写指令，来完成设备的操作。 地址0x02000000对应CLINT，当你向这个地址执行读写指令，你是向实现了CLINT的芯片执行读写。这里你可以认为你直接在与设备交互，而不是读写物理内存。 物理地址总共有2^56那么多，但是你不用在主板上接入那么多的内存。所以不论主板上有多少DRAM芯片，总是会有一部分物理地址没有被用到。实际上在XV6中，我们限制了内存的大小是128MB。 在RISC-V中有一个多路输出选择器（demultiplexer）可以帮助CPU将指令送到正确的I&#x2F;O设备。 两件重要的事情： 有一些page在虚拟内存中的地址很靠后，比如kernel stack在虚拟内存中的地址就很靠后。这是因为在它之下有一个未被映射的Guard page，这个Guard page对应的PTE的Valid 标志位没有设置，这样，如果kernel stack耗尽了，它会溢出到Guard page，但是因为Guard page的PTE中Valid标志位未设置，会导致立即触发page fault，这样的结果好过内存越界之后造成的数据混乱。立即触发一个panic（也就是page fault），你就知道kernel stack出错了。同时我们也又不想浪费物理内存给Guard page，所以Guard page不会映射到任何物理内存，它只是占据了虚拟地址空间的一段靠后的地址。&#96; 同时，kernel stack被映射了两次，在靠后的虚拟地址映射了一次，在PHYSTOP下的Kernel data中又映射了一次，但是实际使用的时候用的是上面的部分，因为有Guard page会更加安全。 权限：例如Kernel text page被标位R-X，意味着你可以读它，也可以在这个地址段执行指令，但是你不能向Kernel text写数据。通过设置权限我们可以尽早的发现Bug从而避免Bug。对于Kernel data需要能被写入，所以它的标志位是RW-，但是你不能在这个地址段运行指令，所以它的X标志位未被设置。（注，所以，kernel text用来存代码，代码可以读，可以运行，但是不能篡改，kernel data用来存数据，数据可以读写，但是不能通过数据伪装代码在kernel中运行） 每一个用户进程都有一个对应的kernel stack。 在kernel page table中，有一段Free Memory，它对应了物理内存中的一段地址。XV6使用这段free memory来存放用户进程的page table，text和data。如果我们运行了非常多的用户进程，某个时间点我们会耗尽这段内存，这个时候fork或者exec会返回错误。 当kernel创建了一个进程，针对这个进程的page table也会从Free memory中分配出来。内核会为用户进程的page table分配几个page，并填入PTE。在某个时间点，当内核运行了这个进程，内核会将进程的根page table的地址加载到SATP中。从那个时间点开始，处理器会使用内核为那个进程构建的虚拟地址空间。 Code:Creating an address space大部分用于操作地址空间和页表的xv6代码位于vm.c（kernel&#x2F;vm.c）中。主要数据结构是pagetable_t，它实际上是指向RISC-V 35根页表页面的指针；pagetable_t可以是内核页表，也可以是每个进程的页表之一。主要函数为walk，该函数查找虚拟地址的PTE，并且mappages安装新映射的PTE。以kvm开头的函数操作内核页表；以uvm开头的函数操作用户页表；其他功能同时用于两者。copyout和copyin将数据复制和从作为系统调用参数提供的用户虚拟地址复制出来；它们在vm.c中因为需要明确翻译这些地址才能找到相应物理存储器。 在引导序列早期，main调用kvminit（kernel&#x2F;vm.c:54）使用kvmmake（kernel&#x2F;vm.c:20）创建内核页面表格。 12345voidkvminit(void)&#123; kernel_pagetable = kvmmake();&#125; 1234567891011121314151617181920212223242526272829303132pagetable_tkvmmake(void)&#123; pagetable_t kpgtbl; kpgtbl = (pagetable_t) kalloc(); memset(kpgtbl, 0, PGSIZE); // uart registers kvmmap(kpgtbl, UART0, UART0, PGSIZE, PTE_R | PTE_W); // virtio mmio disk interface kvmmap(kpgtbl, VIRTIO0, VIRTIO0, PGSIZE, PTE_R | PTE_W); // PLIC kvmmap(kpgtbl, PLIC, PLIC, 0x400000, PTE_R | PTE_W); // map kernel text executable and read-only. kvmmap(kpgtbl, KERNBASE, KERNBASE, (uint64)etext-KERNBASE, PTE_R | PTE_X); // map kernel data and the physical RAM we&#x27;ll make use of. kvmmap(kpgtbl, (uint64)etext, (uint64)etext, PHYSTOP-(uint64)etext, PTE_R | PTE_W); // map the trampoline for trap entry/exit to // the highest virtual address in the kernel. kvmmap(kpgtbl, TRAMPOLINE, (uint64)trampoline, PGSIZE, PTE_R | PTE_X); // allocate and map a kernel stack for each process. proc_mapstacks(kpgtbl); return kpgtbl;&#125; 此调用发生在xv6启动RISC-V分页之前，因此地址直接引用物理存储器。kvmmake首先分配一个物理存储器页面来保存根页面- 表示页面; 然后它调用kvmmap来安装内核所需的转换。这些转换包括内核指令和数据、PHYSTOP以下 的物理存储器以及实际上是设备的内存范围。 proc_mapstacks（kernel&#x2F;proc.c:33）为每个进程分配一个内核堆栈。它调用kvmmap将每个堆栈映射到由KSTACK生成的虚拟地址，这样可以留出无效的堆栈保护页。 12345678910111213141516// Allocate a page for each process&#x27;s kernel stack.// Map it high in memory, followed by an invalid// guard page.voidproc_mapstacks(pagetable_t kpgtbl)&#123; struct proc *p; for(p = proc; p &lt; &amp;proc[NPROC]; p++) &#123; char *pa = kalloc(); if(pa == 0) panic(&quot;kalloc&quot;); uint64 va = KSTACK((int) (p - proc)); kvmmap(kpgtbl, va, (uint64)pa, PGSIZE, PTE_R | PTE_W); &#125;&#125; kvmmap（kernel&#x2F;vm.c:127）调用mappages（kernel&#x2F;vm.c:138），该函数为一系列虚拟地址范围安装映射到相应物理地址的页面表格中。 123456789// add a mapping to the kernel page table.// only used when booting.// does not flush TLB or enable paging.voidkvmmap(pagetable_t kpgtbl, uint64 va, uint64 pa, uint64 sz, int perm)&#123; if(mappages(kpgtbl, va, sz, pa, perm) != 0) panic(&quot;kvmmap&quot;);&#125; 12345678910111213141516171819202122232425262728// Create PTEs for virtual addresses starting at va that refer to// physical addresses starting at pa. va and size might not// be page-aligned. Returns 0 on success, -1 if walk() couldn&#x27;t// allocate a needed page-table page.intmappages(pagetable_t pagetable, uint64 va, uint64 size, uint64 pa, int perm)&#123; uint64 a, last; pte_t *pte; if(size == 0) panic(&quot;mappages: size&quot;); a = PGROUNDDOWN(va); last = PGROUNDDOWN(va + size - 1); for(;;)&#123; if((pte = walk(pagetable, a, 1)) == 0) return -1; if(*pte &amp; PTE_V) panic(&quot;mappages: remap&quot;); *pte = PA2PTE(pa) | perm | PTE_V; if(a == last) break; a += PGSIZE; pa += PGSIZE; &#125; return 0;&#125; 它对于范围中的每个虚拟地址单独执行此操作，在页面间隔处执行此操作。对于要映射的每个虚拟地址，mappages都会调用walk来查找该地址PTE的位置。然后，它初始化PTE以保存相关物理页号、所需权限（PTE_W、PTE_X和&#x2F;或 PTE_R）和标记PTE_V作为有效(kernel&#x2F;vm.c:153)。 12345678910111213141516171819202122232425262728// Create PTEs for virtual addresses starting at va that refer to// physical addresses starting at pa. va and size might not// be page-aligned. Returns 0 on success, -1 if walk() couldn&#x27;t// allocate a needed page-table page.intmappages(pagetable_t pagetable, uint64 va, uint64 size, uint64 pa, int perm)&#123; uint64 a, last; pte_t *pte; if(size == 0) panic(&quot;mappages: size&quot;); a = PGROUNDDOWN(va); last = PGROUNDDOWN(va + size - 1); for(;;)&#123; if((pte = walk(pagetable, a, 1)) == 0) return -1; if(*pte &amp; PTE_V) panic(&quot;mappages: remap&quot;); *pte = PA2PTE(pa) | perm | PTE_V; if(a == last) break; a += PGSIZE; pa += PGSIZE; &#125; return 0;&#125; walk（kernel&#x2F;vm.c:81）模仿RISC-V分页硬件，查找虚拟地址的PTE。walk每次下降3级页面表9位。它使用每个级别的9位虚拟地址来查找下一级页面表或最终页面的PTE（kernel&#x2F;vm.c:87）。如果PTE无效，则尚未分配所需页面；如果设置了alloc参数，则walk将分配新的页表页并将其物理地址放入PTE中。 12345678910111213141516171819202122232425262728293031// Return the address of the PTE in page table pagetable// that corresponds to virtual address va. If alloc!=0,// create any required page-table pages.//// The risc-v Sv39 scheme has three levels of page-table// pages. A page-table page contains 512 64-bit PTEs.// A 64-bit virtual address is split into five fields:// 39..63 -- must be zero.// 30..38 -- 9 bits of level-2 index.// 21..29 -- 9 bits of level-1 index.// 12..20 -- 9 bits of level-0 index.// 0..11 -- 12 bits of byte offset within the page.pte_t *walk(pagetable_t pagetable, uint64 va, int alloc)&#123; if(va &gt;= MAXVA) panic(&quot;walk&quot;); for(int level = 2; level &gt; 0; level--) &#123; pte_t *pte = &amp;pagetable[PX(level, va)]; if(*pte &amp; PTE_V) &#123; pagetable = (pagetable_t)PTE2PA(*pte); &#125; else &#123; if(!alloc || (pagetable = (pde_t*)kalloc()) == 0) return 0; memset(pagetable, 0, PGSIZE); *pte = PA2PTE(pagetable) | PTE_V; &#125; &#125; return &amp;pagetable[PX(0, va)];&#125; 它返回树中最低层的PTE地址。以上代码依赖于物理内存被直接映射到内核虚拟地址空间中。例如，当walk下降页面表级别时，它从PTE获取下一个向下级别页面表(物理)地址，并使用该地址作为虚拟地址获取下一个向下级别的 PTE 。 12345678910111213/ Switch h/w page table register to the kernel&#x27;s page table,// and enable paging.voidkvminithart()&#123; // wait for any previous writes to the page table memory to finish. sfence_vma(); w_satp(MAKE_SATP(kernel_pagetable)); // flush stale entries from the TLB. sfence_vma();&#125; 主函数调用kvminithart(kernel &#x2F; vm.c：62)安装内核页表。 它将根页表页的物理地址写入satp寄存器。之后CPU将使用内核页表翻译地址。由于内核使用身份映射，现在指令集合上一条指令对应正确的物理内存位置。 每个RISC-V CPU都会在转换前缓存TLB中相应信息，在xv6更改某一页时必须告诉CPU使相应的缓存TLB条目失效。如果没有这样做，那么在以后的某个时候，TLB可能会使用旧的缓存映射，指向此时已分配给另一个进程的物理页面，并且结果是进程可能能够涂写其他进程的内存。RISC-V有一种指令sfence.vma可以刷新当前CPU的TLB。Xv6在重新加载satp寄存器之后，在kvminithart中执行sfence.vma，并在跳板代码(kernel&#x2F;trampoline.S:79)中切换到36用户页表并返回用户空间前执行。 为了避免刷新完整的TLB，RISC-V CPU可以支持地址空间标识符（ASIDs）。然后内核只需清除特定地址空间的TLB条目即可","categories":[{"name":"课程学习","slug":"课程学习","permalink":"http://example.com/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"MIT6.S081 Operating System Engineering","slug":"课程学习/MIT6-S081-Operating-System-Engineering","permalink":"http://example.com/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/MIT6-S081-Operating-System-Engineering/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"MIT6 S081 Operating System Engineering Lecture03 OS Organization and System Call","slug":"MIT6-S081-Operating-System-Engineering-Lecture03-OS-Organization-and-System-Call","date":"2023-04-02T06:44:05.000Z","updated":"2023-04-06T08:24:13.187Z","comments":true,"path":"2023/04/02/MIT6-S081-Operating-System-Engineering-Lecture03-OS-Organization-and-System-Call/","link":"","permalink":"http://example.com/2023/04/02/MIT6-S081-Operating-System-Engineering-Lecture03-OS-Organization-and-System-Call/","excerpt":"","text":"Topic Isolation:Isolation是设计操作系统组织结构的驱动力 System Call:System call是你的应用程序能够转换到内核执行的基本方法 Kernel mode&#x2F;user mode Isolation应用程序之间有隔离性我们在用户空间有多个应用程序，例如Shell、echo、find等等。但是，如果你通过Shell运行你们的Prime代码（lab1中的一个部分）时，假设你们的代码出现了问题，Shell不应该会影响到其他的应用程序。举个反例，如果Shell出现问题时，杀掉了其他的进程，这将会非常糟糕。所以你需要在不同的应用程序之间有强隔离性。 应用程序与操作系统之间有隔离性操作系统某种程度上为所有的应用程序服务。当你的应用程序出现问题时，你会希望操作系统不会因此而崩溃。比如说你向操作系统传递了一些奇怪的参数，你会希望操作系统仍然能够很好的处理它们（能较好的处理异常情况）。所以，你也需要在应用程序和操作系统之间有强隔离性。 如果没有操作系统如果没有操作系统，或者操作系统只是一些库文件，比如说你在使用Python，通过import os你就可以将整个操作系统加载到你的应用程序中。那么现在，我们有一个Shell，并且我们引用了代表操作系统的库。同时，我们有一些其他的应用程序，例如echo。 通常来说，如果没有操作系统，应用程序会直接与硬件交互。比如，应用程序可以直接看到CPU的多个核，看到磁盘，内存。所以现在应用程序和硬件资源之间没有一个额外的抽象层。 调度及复用隔离问题使用操作系统的一个目的是为了同时运行多个应用程序，所以时不时的，CPU会从一个应用程序切换到另一个应用程序。我们假设硬件资源里只有一个CPU核，并且我们现在在这个CPU核上运行Shell。但是时不时的，也需要让其他的应用程序也可以运行。现在我们没有操作系统来帮我们完成切换，所以Shell就需要时不时的释放CPU资源。 为了不变成一个恶意程序，Shell在发现自己运行了一段时间之后，需要让别的程序也有机会能运行。这种机制有时候称为协同调度（Cooperative Scheduling）。但是这里的场景并没有很好的隔离性，比如说Shell中的某个函数有一个死循环，那么Shell永远也不会释放CPU，进而其他的应用程序也不能够运行，甚至都不能运行一个第三方的程序来停止或者杀死Shell程序。所以这种场景下，我们基本上得不到真正的multiplexing（CPU在多进程同分时复用）。而这个特性是非常有用的，不论应用程序在执行什么操作，multiplexing都会迫使应用程序时不时的释放CPU，这样其他的应用程序才能运行。 内存隔离问题假设现在物理内存中的一部分被Shell使用，另一部分被echo使用。因为两个应用程序的内存之间没有边界，如果echo程序将数据存储在属于Shell的一个内存地址中，那么就echo就会覆盖Shell程序内存中的内容。 使用操作系统的一个原因，甚至可以说是主要原因就是为了实现multiplexing和内存隔离。如果你不使用操作系统，并且应用程序直接与硬件交互，就很难实现这两点。所以，将操作系统设计成一个库，并不是一种常见的设计。你或许可以在一些实时操作系统中看到这样的设计，因为在这些实时操作系统中，应用程序之间彼此相互信任。但是在大部分的其他操作系统中，都会强制实现硬件资源的隔离。 从隔离的角度来看Unix接口如果我们从隔离的角度来稍微看看Unix接口，那么我们可以发现，接口被精心设计以实现资源的强隔离，也就是multiplexing和物理内存的隔离。接口通过抽象硬件资源，从而使得提供强隔离性成为可能。 Example 1之前通过fork创建了进程。进程本身不是CPU，但是它们对应了CPU，它们使得你可以在CPU上运行计算任务。所以你懂的，应用程序不能直接与CPU交互，只能与进程交互。操作系统内核会完成不同进程在CPU上的切换。所以，操作系统不是直接将CPU提供给应用程序，而是向应用程序提供“进程”，进程抽象了CPU，这样操作系统才能在多个应用程序之间复用一个或者多个CPU。 我们在实验中使用的RISC-V处理器实际上是有4个核。所以你可以同时运行4个进程，一个进程占用一个核。但是假设你有8个应用程序，操作系统会分时复用这些CPU核，比如说对于一个进程运行100毫秒，之后内核会停止运行并将那个进程从CPU中卸载，再加载另一个应用程序并再运行100毫秒。通过这种方式使得每一个应用程序都不会连续运行超过100毫秒。这里只是一些基本概念，我们在接下来的几节课中会具体的看这里是如何实现的。 我们可以认为exec抽象了内存。当我们在执行exec系统调用的时候，我们会传入一个文件名，而这个文件名对应了一个应用程序的内存镜像。内存镜像里面包括了程序对应的指令，全局的数据。应用程序可以逐渐扩展自己的内存，但是应用程序并没有直接访问物理内存的权限，例如应用程序不能直接访问物理内存的1000-2000这段地址。不能直接访问的原因是，操作系统会提供内存隔离并控制内存，操作系统会在应用程序和硬件资源之间提供一个中间层。exec是这样一种系统调用，它表明了应用程序不能直接访问物理内存。 Example 2files基本上来说抽象了磁盘。应用程序不会直接读写挂在计算机上的磁盘本身，并且在Unix中这也是不被允许的。在Unix中，与存储系统交互的唯一方式就是通过files。Files提供了非常方便的磁盘抽象，你可以对文件命名，读写文件等等。之后，操作系统会决定如何将文件与磁盘中的块对应，确保一个磁盘块只出现在一个文件中，并且确保用户A不能操作用户B的文件。通过files的抽象，可以实现不同用户之间和同一个用户的不同进程之间的文件强隔离。 Defensive 防御性：当你在做内核开发时，这是一种你需要熟悉的重要思想。操作系统需要确保所有的组件都能工作，所以它需要做好准备抵御来自应用程序的攻击。如果说应用程序无意或者恶意的向系统调用传入一些错误的参数就会导致操作系统崩溃，那就太糟糕了。在这种场景下，操作系统因为崩溃了会拒绝为其他所有的应用程序提供服务。所以操作系统需要以这样一种方式来完成：操作系统需要能够应对恶意的应用程序。 隔离性：另一个需要考虑的是，应用程序不能够打破对它的隔离。应用程序非常有可能是恶意的，它或许是由攻击者写出来的，攻击者或许想要打破对应用程序的隔离，进而控制内核。一旦有了对于内核的控制能力，你可以做任何事情，因为内核控制了所有的硬件资源。 所以操作系统或者说内核需要具备防御性来避免类似的事情发生。实际中，要满足这些要求还有点棘手。在Linux中，时不时的有一些内核的bug使得应用程序可以打破它的隔离域并控制内核。这里需要持续的关注，并尽可能的提供最好的防御性。当你在开发内核时，防御性是你必须掌握的一个思想。实际中的应用程序或许就是恶意的，这意味着我们需要在应用程序和操作系统之间提供强隔离性。如果操作系统需要具备防御性，那么在应用程序和操作系统之间需要有一堵厚墙，并且操作系统可以在这堵墙上执行任何它想执行的策略。 通常来说，需要通过硬件来实现强隔离性。这里的硬件主要包括两部分，一个是user&#x2F;kernel mode，kernel mode在RISC-V中被称为Supervisor mode但是其实是同一种东西；第二部分是page table或者虚拟内存（Virtual Memory） 所以，所有的处理器，如果需要运行能够支持多个应用程序的操作系统，需要同时支持user&#x2F;kernle mode和虚拟内存。具体的实现或许会有细微的差别，但是基本上来说所有的处理器需要能支持这些。 硬件对于强隔离的支持user&#x2F;kernel mode为了支持user&#x2F;kernel mode，处理器会有两种操作模式，第一种是user mode，第二种是kernel mode。当运行在kernel mode时，CPU可以运行特定权限的指令（privileged instructions）；当运行在user mode时，CPU只能运行普通权限的指令（unprivileged instructions）。 普通权限的指令都是一些你们熟悉的指令，例如将两个寄存器相加的指令ADD、将两个寄存器相减的指令SUB、跳转指令JRC、BRANCH指令等等。这些都是普通权限指令，所有的应用程序都允许执行这些指令。 特殊权限指令主要是一些直接操纵硬件的指令和设置保护的指令，例如设置page table寄存器、关闭时钟中断。在处理器上有各种各样的状态，操作系统会使用这些状态，但是只能通过特殊权限指令来变更这些状态。 举个例子，当一个应用程序尝试执行一条特殊权限指令，因为不允许在user mode执行特殊权限指令，处理器会拒绝执行这条指令。通常来说，这时会将控制权限从user mode切换到kernel mode，当操作系统拿到控制权之后，或许会杀掉进程，因为应用程序执行了不该执行的指令。 在处理器里面有一个flag。在处理器的一个bit，当它为1的时候是user mode，当它为0时是kernel mode。当处理器在解析指令时，如果指令是特殊权限指令，并且该bit被设置为1，处理器会拒绝执行这条指令，就像在运算时不能除以0一样。设置那个bit位的指令必须是特殊权限指令，因为应用程序不应该能够设置那个bit到kernel mode，否则的话应用程序就可以运行各种特殊权限指令了。所以那个bit是被保护的。 RISC-V还有第三种模式称为machine mode。在大多数场景下，我们会忽略这种模式，所以我们实际上有三级权限user&#x2F;kernel&#x2F;machine。 page table每一个进程都会有自己独立的page table，这样的话，每一个进程只能访问出现在自己page table中的物理内存。操作系统会设置page table，使得每一个进程都有不重合的物理内存，这样一个进程就不能访问其他进程的物理内存，因为其他进程的物理内存都不在它的page table中。一个进程甚至都不能随意编造一个内存地址，然后通过这个内存地址来访问其他进程的物理内存。这样就给了我们内存的强隔离性。 基本上来说，page table定义了对于内存的视图，而每一个用户进程都有自己对于内存的独立视图。这给了我们非常强的内存隔离性。 User&#x2F;Kernel mode切换我们可以认为user&#x2F;kernel mode是分隔用户空间和内核空间的边界，用户空间运行的程序运行在user mode，内核空间的程序运行在kernel mode。操作系统位于内核空间。 当ls程序运行的时候，会调用read&#x2F;write系统调用；Shell程序会调用fork或者exec系统调用，所以必须要有一种方式可以使得用户的应用程序能够将控制权以一种协同工作的方式转移到内核，这样内核才能提供相应的服务。 Ecall在RISC-V中，有一个专门的指令用来实现控制权的转换功能，叫做ECALL。ECALL接收一个数字参数，当一个用户程序想要将程序执行的控制权转移到内核，它只需要执行ECALL指令，并传入一个数字。这里的数字参数代表了应用程序想要调用的System Call。 ECALL会跳转到内核中一个特定，由内核控制的位置。在XV6中存在一个唯一的系统调用接入点，每一次应用程序执行ECALL指令，应用程序都会通过这个接入点进入到内核中。举个例子，不论是Shell还是其他的应用程序，当它在用户空间执行fork时，它并不是直接调用操作系统中对应的函数，而是调用ECALL指令，并将fork对应的数字作为参数传给ECALL。之后再通过ECALL跳转到内核。 在内核侧，有一个位于syscall.c的函数syscall，每一个从应用程序发起的系统调用都会调用到这个syscall函数，syscall函数会检查ECALL的参数，通过这个参数内核可以知道需要调用的是fork。 用户空间和内核空间的界限是一个硬性的界限，用户不能直接调用fork，用户的应用程序执行系统调用的唯一方法就是通过这里的ECALL指令。 假设我现在要执行另一个系统调用write，相应的流程是类似的，write系统调用不能直接调用内核中的write代码，而是由封装好的系统调用函数执行ECALL指令。所以write函数实际上调用的是ECALL指令，指令的参数是代表了write系统调用的数字。之后控制权到了syscall函数，syscall会实际调用write系统调用。 宏内核和微内核（Monolithic Kernel and Micro Kernel）现在，我们有了一种方法，可以通过系统调用或者说ECALL指令，将控制权从应用程序转到操作系统中。之后内核负责实现具体的功能并检查参数以确保不会被一些坏的参数所欺骗。所以内核有时候也被称为可被信任的计算空间（Trusted Computing Base），在一些安全的术语中也被称为TCB。 基本上来说，要被称为TCB，内核首先要是正确且没有Bug的。假设内核中有Bug，攻击者可能会利用那个Bug，并将这个Bug转变成漏洞，这个漏洞使得攻击者可以打破操作系统的隔离性并接管内核。所以内核真的是需要越少的Bug越好。 另一方面，内核必须要将用户应用程序或者进程当做是恶意的。内核的设计人员在编写和实现内核代码时，必须要有安全的思想。这个目标很难实现，因为当你的操作系统变得足够大的时候，很多事情就不是那么直观了。几乎每一个你用过的或者被广泛使用的操作系统，时不时的都有一个安全漏洞。就算被修复了，但是过了一段时间，又会出现一个新的漏洞。我们之后会介绍为什么很难让所有部分都正确工作，但是你要知道是内核需要做一些tricky的工作，需要操纵硬件，需要非常小心做检查，所以很容易就出现一些小的疏漏，进而触发一个Bug。这也是可以理解的。 宏内核（Monolithic Kernel）让整个操作系统代码都运行在kernel mode。大多数的Unix操作系统实现都运行在kernel mode。比如，XV6中，所有的操作系统服务都在kernel mode中，这种形式被称为Monolithic Kernel Design。 在一个宏内核中，任何一个操作系统的Bug都有可能成为漏洞。因为我们现在在内核中运行了一个巨大的操作系统，出现Bug的可能性更大了。你们可以去查一些统计信息，平均每3000行代码都会有几个Bug，所以如果有许多行代码运行在内核中，那么出现严重Bug的可能性也变得更大。所以从安全的角度来说，在内核中有大量的代码是宏内核的缺点。 如果你去看一个操作系统，它包含了各种各样的组成部分，比如说文件系统，虚拟内存，进程管理，这些都是操作系统内实现了特定功能的子模块。宏内核的优势在于，因为这些子模块现在都位于同一个程序中，它们可以紧密的集成在一起，这样的集成提供很好的性能。例如Linux，它就有很不错的性能。 微内核（Micro Kernel）在这种模式下，希望在kernel mode中运行尽可能少的代码。所以这种设计下还是有内核，但是内核只有非常少的几个模块，例如，内核通常会有一些IPC的实现或者是Message passing；非常少的虚拟内存的支持，可能只支持了page table；以及分时复用CPU的一些支持。 微内核的目的在于将大部分的操作系统运行在内核之外。所以，我们还是会有user mode以及user&#x2F;kernel mode的边界。但是我们现在会将原来在内核中的其他部分，作为普通的用户程序来运行。比如文件系统可能就是个常规的用户空间程序。 某种程度上来说，这是一种好的设计。因为在内核中的代码的数量较小，更少的代码意味着更少的Bug。 但是这种设计也有相应的问题。假设我们需要让Shell能与文件系统交互，比如Shell调用了exec，必须有种方式可以接入到文件系统中。通常来说，这里工作的方式是，Shell会通过内核中的IPC系统发送一条消息，内核会查看这条消息并发现这是给文件系统的消息，之后内核会把消息发送给文件系统。 文件系统会完成它的工作之后会向IPC系统发送回一条消息说，这是你的exec系统调用的结果，之后IPC系统再将这条消息发送给Shell。 所以，这里是典型的通过消息来实现传统的系统调用。现在，对于任何文件系统的交互，都需要分别完成2次用户空间&lt;-&gt;内核空间的跳转。与宏内核对比，在宏内核中如果一个应用程序需要与文件系统交互，只需要完成1次用户空间&lt;-&gt;内核空间的跳转，所以微内核的的跳转是宏内核的两倍。通常微内核的挑战在于性能更差，这里有两个方面需要考虑： 在user&#x2F;kernel mode反复跳转带来的性能损耗。 在一个类似宏内核的紧耦合系统，各个组成部分，例如文件系统和虚拟内存系统，可以很容易的共享page cache。而在微内核中，每个部分之间都很好的隔离开了，这种共享更难实现。进而导致更难在微内核中得到更高的性能。 在实际中，两种内核设计都会出现，出于历史原因大部分的桌面操作系统是宏内核，如果你运行需要大量内核计算的应用程序，例如在数据中心服务器上的操作系统，通常也是使用的宏内核，主要的原因是Linux提供了很好的性能。但是很多嵌入式系统，例如Minix，Cell，这些都是微内核设计。这两种设计都很流行，如果你从头开始写一个操作系统，你可能会从一个微内核设计开始。但是一旦你有了类似于Linux这样的宏内核设计，将它重写到一个微内核设计将会是巨大的工作。并且这样重构的动机也不足，因为人们总是想把时间花在实现新功能上，而不是重构他们的内核。 编译运行Kernel代码结构 kernel：里面包含了基本上所有的内核文件。因为XV6是一个宏内核结构，这里所有的文件会被编译成一个叫做kernel的二进制文件，然后这个二进制文件会被运行在kernle mode中。 user：这基本上是运行在user mode的程序。这也是为什么一个目录称为kernel，另一个目录称为user的原因。 mkfs：它会创建一个空的文件镜像，我们会将这个镜像存在磁盘上，这样我们就可以直接使用一个空的文件系统。 编译过程 Makefile（XV6目录下的文件）会读取一个C文件，例如proc.c；之后调用gcc编译器，生成一个文件叫做proc.s，这是RISC-V 汇编语言文件；之后再走到汇编解释器，生成proc.o，这是汇编语言的二进制格式。 Makefile会为所有内核文件做相同的操作，比如说pipe.c，会按照同样的套路，先经过gcc编译成pipe.s，再通过汇编解释器生成pipe.o。 之后，系统加载器（Loader）会收集所有的.o文件，将它们链接在一起，并生成内核文件。 这里生成的内核文件就是我们将会在QEMU中运行的文件。同时，为了你们的方便，Makefile还会创建kernel.asm，这里包含了内核的完整汇编语言，你们可以通过查看它来定位究竟是哪个指令导致了Bug。 传给QEMU的几个参数 kernel ：这里传递的是内核文件（kernel目录下的kernel文件），这是将在QEMU中运行的程序文件。 -m ：这里传递的是RISC-V虚拟机将会使用的内存数量。 smp：这里传递的是虚拟机可以使用的CPU核数 -drive：传递的是虚拟机使用的磁盘驱动，这里传入的是fs.img文件 QEMU直观来看，QEMU是一个大型的开源C程序，你可以下载或者git clone它。但是在内部，在QEMU的主循环中，只在做一件事情： 读取4字节或者8字节的RISC-V指令。 解析RISC-V指令，并找出对应的操作码（op code）。我们之前在看kernel.asm的时候，看过一些操作码的二进制版本。通过解析，或许可以知道这是一个ADD指令，或者是一个SUB指令。 之后，在软件中执行相应的指令。 这基本上就是QEMU的全部工作了，对于每个CPU核，QEMU都会运行这么一个循环。 XV6的启动过程QEMU 是一个通用的开源处理器模拟器和虚拟化程序，可以用于在物理计算机上模拟设备，并运行各种操作系统，如 xv6。以下是结合 QEMU 源代码和 xv6 源代码说明启动过程的概述： 启动 QEMU：从命令行启动 QEMU，并指定要加载的操作系统映像（在这种情况下为 xv6 操作系统）。命令可能如下所示： 1qemu-system-i386 -nographic -serial mon:stdio -hdb fs.img xv6.img -s -S 在这里，qemu-system-i386 是针对 x86（32 位）系统的 QEMU 模拟器，-nographic 参数表示不使用图形界面，-serial mon:stdio 表示将监视器（QEMU 控制台）连接到标准输入&#x2F;输出，-hdb fs.img 指定要加载的 xv6 文件系统映像，xv6.img 是 xv6 操作系统映像，-s 和 -S 参数用于调试。 QEMU 初始化虚拟硬件：QEMU 将根据所指定的参数和配置，初始化虚拟处理器、内存、硬盘和其他硬件设备。 加载引导程序：QEMU 模拟 BIOS 行为，将 xv6.img 映像中的启动扇区加载到内存中，并将控制权交给这段代码。在 xv6 的情况下，引导程序位于 bootasm.S（汇编代码）和 bootmain.c（C 代码）中。 引导程序运行：接下来的步骤与实际硬件上的启动过程相同。引导程序首先切换到保护模式，然后加载 ELF 格式的 xv6 内核映像到内存中。 进入 xv6 内核：引导程序找到 xv6 内核的入口点（在 kernel/entry.S 中），并将控制权交给内核。内核现在开始运行并执行初始化任务。 内核初始化：在 main.c 中的 main() 函数中，xv6 内核执行诸如设置分页、初始化中断控制器、初始化进程调度器等初始化任务。 创建初始进程：xv6 创建第一个内核进程（initcode.S），它是一个用户程序，负责启动其他用户进程。内核通过 fork() 系统调用创建新进程，并通过 exec() 系统调用加载并执行 initcode.S。 运行 init 进程：initcode.S 调用 init 程序（在 init.c 中），init 是一个用户空间程序，负责启动系统的第一个正常用户进程，通常是一个 shell 程序。在 xv6 中，这个程序是 sh.c。 运行 shell 程序：init 进程通过 fork() 和 exec() 创建并运行 shell 程序。这时，用户可以在 shell 中输入命令并与操作系统进行交互。","categories":[{"name":"课程学习","slug":"课程学习","permalink":"http://example.com/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"MIT6.S081 Operating System Engineering","slug":"课程学习/MIT6-S081-Operating-System-Engineering","permalink":"http://example.com/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/MIT6-S081-Operating-System-Engineering/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"MIT6.S081 Operating System Engineering Lecture01 Intrduction and Examples","slug":"MIT6-S081-Operating-System-Engineering-Lecture01-Intrduction-and-Examples","date":"2023-03-31T06:19:09.000Z","updated":"2023-04-06T07:00:08.730Z","comments":true,"path":"2023/03/31/MIT6-S081-Operating-System-Engineering-Lecture01-Intrduction-and-Examples/","link":"","permalink":"http://example.com/2023/03/31/MIT6-S081-Operating-System-Engineering-Lecture01-Intrduction-and-Examples/","excerpt":"","text":"简介课程目标 理解操作系统的设计和实现。理解整体结构和具体代码。 通过XV6操作系统获得实际动手经验。扩展操作系统，修改并提升操作系统的相关经验，并且能够通过操作系统接口，编写系统软件 OS的目标 Abstract Hardware Multiplex Isolation Sharing Preformance Access Control&#x2F;Security Range Of Users OS的结构分层思想 Userspace在架构的最上层，运行各种各样的应用程序例如文本编辑器（VI），C编辑器（CC），作为CLI存在的shell。 Kernel区别于userspace，有一个特殊的程序总是会在运行。Kernel是计算机资源的守护者，当打开计算机时，Kernel总是第一个被启动。Kernel程序只有一个，维护数据来管理每一个用户空间进程。Kernel同时还维护了大量数据结构来帮助它管理各种各样的硬件资源，以供用户空间的程序使用。Kernel同时还会有大量内置的服务。例如，Kernel通常会有文件系统实现类似文件名，文件内容，目录的东西，并理解如何将文件存储在磁盘中。所以用户空间的程序会与Kernel中的文件系统交互，文件系统再与磁盘交互。 我们主要关注在Kernel、连接Kernal和用户空间程序的接口、Kernel内软件的架构 。所以我们会关心Kernel内的服务。其中一个是文件系统，另一个就是进程管理系统。 Manage Process：每一个用户空间程序都被称为一个进程，它们有自己的内存和共享的CPU时间。 Allocate Memory：Kernel会管理内存的分配，不同的进程需要不同数量的内存，Kernel会复用内存、划分内存，并为所有的进程分配内存。 File System：文件系统通常有一些逻辑分区。目前而言，我们可以认为文件系统的作用是管理文件内容并找出文件具体在磁盘中的哪个位置。文件系统还维护了一个独立的命名空间，其中每个文件都有文件名，并且命名空间中有一个层级的目录，每个目录包含了一些文件。所有这些都被文件系统所管理。 Security&#x2F;Access Control: 当一个进程想要使用某些资源时，比如读取磁盘中的数据，使用某些内存，Kernel中的Access Control机制会决定是否允许这样的操作。对于一个分时共享的计算机，例如Athena系统，这里可能会变得很复杂。因为在Athena系统中，每一个进程可能属于不同的用户，因此会有不同Access规则来约定哪些资源可以被访问。 在一个真实的完备的操作系统中，会有很多很多其他的服务，比如在不同进程之间通信的进程间通信服务，比如一大票与网络关联的软件（TCP&#x2F;IP协议栈），比如支持声卡的软件，比如支持数百种不同磁盘，不同网卡的驱动。所以在一个完备的系统中，Kernel会包含大量的内容，数百万行代码。 Kernel APIKernel API决定了应用程序如何访问Kernel。通常来说，这里通过系统调用System Call来完成。系统调用与程序中的函数调用看起来是一样的，但区别是系统调用会实际运行到系统内核中，并执行内核中对于系统调用的实现。 Kernel的代码总是有特殊的权限。当机器启动Kernel时，Kernel会有特殊的权限能直接访问各种各样的硬件，例如磁盘。而普通的用户程序是没有办法直接访问这些硬件的。所以，当你执行一个普通的函数调用时，你所调用的函数并没有对于硬件的特殊权限。然而，如果你触发系统调用到内核中，内核中的具体实现会具有这些特殊的权限，这样就能修改敏感的和被保护的硬件资源，比如访问硬件磁盘。 Example 112fd = open(&quot;out&quot;,1);write(fd,&quot;hello\\n&quot;,6); 第一个系统调用open，它会跳到Kernel，Kernel会获取到open的参数，执行一些实现了open的Kernel代码，或许会与磁盘有一些交互，最后返回一个文件描述符对象。上图中的fd全称就是file descriptor。之后应用程序可以使用这个文件描述符作为handle，来表示相应打开的文件。 第二个系统调用write，你需要向write传递一个由open返回的文件描述符作为参数。你还需要向write传递一个指向要写入数据的指针（数据通常是char型序列），在C语言中，可以简单传递一个双引号表示的字符串。第三个参数是你想要写入字符的数量。第二个参数的指针，实际上是内存中的地址。所以这里实际上告诉内核，将内存中这个地址起始的6个字节数据写入到fd对应的文件中。 Example 21pid = fork(); fork是一个系统调用，它创建了一个与调用进程一模一样的新的进程，并返回新进程的Process ID/PID。 这些系统调用看起来跟普通的函数调用一样，但是它最终会跳到系统内核中。 操作系统的难点 内核的编程环境比较困难。当你在编写、修改，扩展内核，或者写一个新的操作系统内核时，你实际上在提供一个基础设施让别人来运行他们的程序。当程序员在写普通的应用程序时，应用程序下面都是操作系统。而当我们在构建操作系统时，在操作系统下面就是硬件了，这些硬件通常会更难处理。 当你在设计一个操作系统时，你需要满足一些列矛盾的需求。 你想要你的操作系统既高效又易用。高效通常意味着操作系统需要在离硬件近的low-level进行操作，而易用则要求操作系统为应用程序提供抽象的high-level可移植接口。所以，提供一个简单可移植，同时又高效的抽象接口需要一定的技巧。 我们想要提供一个非常强大的操作系统服务，这样操作系统才能分担运行应用程序的负担。同时，我们也想要有简单的接口。我们不想程序员看到数量巨多，复杂且难以理解的的内核接口。因为，如果他们不理解这些接口，他们就会很难使用这些接口。 你希望给与应用程序尽可能多的灵活性，你不会想要限制应用程序，所以你需要内核具备灵活的接口。但是另一方面，你的确需要在某种程度上限制应用程序，因为你会想要安全性。我们希望给程序员完全的自由，但是实际上又不能是真正的完全自由，因为我们不想要程序员能直接访问到硬件，干扰到其他的应用程序，或者干扰操作系统的行为。 read，write，exit系统调用12345678910111213#inclued &quot;kernel/types.h&quot;#include &quot;user/user.h&quot;int main()&#123; char buf[64]; while(1)&#123; int n = read(0,buf,sizeof(buf)); if(n &lt;= 0) break; write(1,buf,n); &#125; exit(0);&#125; read系统调用 第一个参数是文件描述符，实际上是对以前打开文件的引用。Shell会确保默认情况下，当一个程序启动时，文件描述符0为连接到console的输入，文件描述符1为连接到了console的输出。所以我们可以通过这个程序看到console打印我的输入。当然，这里的程序会预期文件描述符已经被Shell打开并设置好。 第二个参数是只想某段内存的指针，程序可以通过指针对应的地址读取内存中的数据，这里的指针就是代码中的buf参数。char buf[64]在栈中申请了64字节的内存，并将指针保存在buf中，这样read可以将数据保存在这64字节中。 第三个参数是代码想读取的最大长度。sizeof(buf)表示，最多读取64字节的数据，所以这里的read最多只能从连接到文件描述符0的设备，也就是console中，读取64字节的数据。 如果第三个参数是65字节，操作系统会拷贝65个字节到你提供的内存中（第二个参数）。但是如果栈中的第65个字节有一些其他数据，那么这些数据会被覆盖，这里是个bug，或许会导致你的代码崩溃，或者一些异常的行为。 read的返回值 可能是读到的字节数 如果从一个文件读数据，如果到达了文件的结尾没有更多的内容了，read会返回0。 如果出现了一些错误，比如文件描述符不存在，read或许会返回-1 。 write系统调用第一个参数为文件描述符，第二个参数是数据的指针，第三个参数是要写入的字节数 数据被写入到了文件描述符对应的文件中 open系统调用12345678#include &quot;kernel/types.h&quot;#include &quot;user/user.h&quot;#include &quot;kernel/fcntl.h&quot;int main()&#123; int fd = open(&quot;output.txt&quot;,O_WRONLY | O_CREATE); write(fd, &quot;ooo\\n&quot;,4); exit(0);&#125; 这个程序会创建一个叫做output.txt的新文件，并向它写入一些数据，最后退出。我们看不到任何输出，因为它只是向打开的文件中写入数据，但是我们可以查看output.txt的内容，并看到open程序写入的“ooo”。 所以执行open系统调用，将out.txt作为参数传入，第二个参数是一些标志位，用来告诉open系统调用在内核中的实现，用来告诉open系统调用在内核中的实现：我们将要创建并写入一个文件。open系统调用会返回一个新分配的文件描述符，这里的文件描述符是一个小的数字，可能是2，3，4或者其他的数字。然后将文件描述符传入write中。 文件描述符本质上对应了内核中的一个表单数据。内核维护了每个运行进程的状态，内核会为每一个运行进程保存一个表单，表单的key是文件描述符。这个表单让内核知道，每个文件描述符对应的实际内容是什么。这里比较关键的点是，每个进程都有自己独立的文件描述符空间，所以如果运行了两个不同的程序，对应两个不同的进程，如果它们都打开一个文件，它们或许可以得到相同数字的文件描述符，但是因为内核为每个进程都维护了一个独立的文件描述符空间，这里相同数字的文件描述符可能会对应到不同的文件。 C语言与Python在文件描述符中的区别：Python提供了对与open调用的较好的封装，通常来说，Python提供的是更高级的函数，比如说Python不会使用指向内存的指针，并且Python会为你做更多的错误检查。当我们在Python中打开文件或者写入文件时，你在Python中的调用最终会走到跟我们例子中一样的系统调用。 ShellShell通常也是人们说的命令行接口。如果你还没有用过Shell，Shell是一种对于Unix系统管理来说非常有用的接口，它提供了很多工具来管理文件，编写程序，编写脚本。当你输入内容时，你是在告诉Shell运行相应的程序。 1ls ls的实际工作就是输出当前目录的文件列表 1ls &gt; out Shell允许重定向IO，这里的实际意义是要求Shell允许ls命令，但是将输出重定向到一个叫做out的文件中。这里执行完成之后我们看不到任何的输出，因为输出都送到了out文件。 1cat out 我们可以通过cat指令来读取一个文件，并显示文件的内容，之后我们可以看到ls指令相同的输出。 1grep x 你也可以运行一个名为grep的指令，并将x作为参数传给grep。 1grep x &lt; out grep x会搜索输入中包含x的行，我可以告诉shell将输入重定向到文件out，这样我们就可以查看out中的x。因为out文件包含了ls的输出，所以我们可以看出有3个文件名包含了x。 编译器如何处理系统调用？生成的汇编语言是不是会调用一些由操作系统定义的代码段？ 有一个特殊的RISC-V指令，程序可以调用这个指令，并将控制权交给内核。所以，实际上当你运行C语言并执行例如open或者write的系统调用时，从技术上来说，open是一个C函数，但是这个函数内的指令实际上是机器指令，也就是说我们调用的open函数并不是一个C语言函数，它是由汇编语言实现，组成这个系统调用的汇编语言实际上在RISC-V中被称为ecall。这个特殊的指令将控制权转给内核。之后内核检查进程的内存和寄存器，并确定相应的参数。 fork系统调用123456789101112#include &quot;kernel/types.h&quot;#include &quot;user/user.h&quot;int main()&#123; int pid; pid = fork(); printf(&quot;fork() returned %d\\n&quot;,pid); if(pid == 0)&#123; printf(&quot;child\\n&quot;); &#125; else &#123; printf(&quot;parent\\n&quot;); &#125;&#125; fork会拷贝当前进程的内存，并创建一个新的进程，这里的内存包含了进程的指令和数据。之后我们就有了两个完全一样的内存的进程。fork系统调用在两个进程中都会返回，在原始的进程中，fork会返回大于0的整数，这个是新创建进程的ID。而在新创建的进程中，fork系统调用会返回0。所以即使两个进程的内存是完全一样的，我们还是可以通过fork的返回值区分旧进程和新进程。 返回 ffoorrkk(()) rreettuuttnende d 0 lc9h ilpda rent if（pid == 0），你可以看到代码检查pid。如果pid &#x3D; 0，这必然是子进程。在我们的例子中，调用进程通常称为父进程，父进程看到的pid必然大于0.所以父进程会打印“parent”,子进程会打印”child”。之后两个进程都会退出。 输出结果，实际发生二点是，fork系统调用之后，两个进程都在同时运行。它们会同时一个字节一个字节的输出，两个进程的输出交织在一起，所以你可以看到两个f，两个o等等。在第一行最后，你可以看到0，这是子进程的输出。 我猜父进程返回了19，作为子进程的进程ID。通常来说，这意味着这是操作系统启动之后的第19个进程。之后一个进程输出了child，一个进程输出了parent，这两个输出交织在一起。虽然这只是对于fork的一个简单应用，但是我们可以清晰的从输出看到这里创建了两个运行的进程，其中一个进程打印了child，另一个打印了parent。所以，fork（在子父进程中）返回不同的值是比较重要的。 父进程与子进程除了fork的返回值，两个进程是一样的。两个进程的指令是一样的，数据是一样的，栈是一样的，同时，两个进程又有各自独立的地址空间，它们都认为自己的内存从0开始增长，但这里是不同的内存。 在一个更加复杂的操作系统，有一些细节，我们现在并不关心，这些细节偶尔会导致父子进程不一致，但是在XV6中，父子进程除了fork的返回值，其他都是一样的。 除了内存是一样的以外，文件描述符的表单也从父进程拷贝到子进程。所以如果父进程打开了一个文件，子进程可以看到同一个文件描述符，尽管子进程看到的是一个文件描述符的表单的拷贝。除了拷贝内存以外，fork还会拷贝文件描述符表单。 exec，wait系统调用fork创建了一个新的进程。当我们在shell中运行东西的时候，shell实际上会创建一个新的进程来运行你输入的每一个指令。所以，当我输入ls时，我们需要shell通过fork创建一个进程来运行ls，这里需要某种方式来让这个新的进程来运行ls程序中的指令，加载名为ls的文件中的指令，也就是exec系统调用。 12345678910// exec.c:replace a process with an executable file#include &quot;kernel.types.h&quot;#include &quot;user/user.h&quot;int main()&#123; char *argv[] = &#123; &quot;echo&quot;, &quot;this&quot;, &quot;is&quot;, &quot;echo&quot;, 0 &#125;; exec(&quot;echo&quot;, argv); printf(&quot;exec failed!\\n&quot;); exit(0);&#125; 代码会执行exec系统调用，这个系统调用会从指定的文件中读取并加载指令，并替代当前调用进程的指令。从某种程度上来说，这样相当于丢弃了调用进程的内存，并开始执行新加载的指令。所以系统调用exec会有这样的效果：操作系统从名为echo的文件中加载指令到当前的进程中，并替换了当前进程的内存，之后开始执行这些新加载的指令。同时，你可以传入命令行参数，exec允许你传入一个命令行参数的数组，这里就是一个C语言中的指针数组，在上面代码设置好了一个字符指针的数组，这里的字符指针本质就是一个字符串（string） echo 程序是一个常见的命令行实用程序，用于在 Unix、Linux 和类 Unix 系统（如 macOS）上显示文本。它将传递给它的命令行参数（字符串）输出到标准输出（通常是终端或控制台）。echo 命令通常用于编写脚本或在控制台显示消息。 通过 exec(&quot;echo&quot;, argv); 系统调用执行。在这个例子中，argv 数组包含以下参数： 12345argv[0] = &quot;echo&quot;argv[1] = &quot;this&quot;argv[2] = &quot;is&quot;argv[3] = &quot;echo&quot;argv[4] = NULL (空指针) 通常，argv[0] 是程序名称（在这里是 “echo”），后面是实际要传递的命令行参数（在这里是 “this”, “is”, “echo”）。argv 数组以空指针（NULL）结尾，表示参数列表的结束。 当 echo 程序执行时，它会输出 &quot;this is echo&quot;。 exec系统调用会保留当前的文件描述符表单。所以任何在exec系统调用之前的文件描述符，例如0，1，2等。它们在新的程序中表示相同的东西。 通常来说exec系统调用不会返回，因为exec会完全替换当前进程的内存，相当于当前进程不复存在了，所以exec系统调用已经没有地方能返回了,在实例代码中，执行错误才会返回。 这就是一个程序如何用文件中的另一个程序来替代自己。实际上，当我们在Shell中运行类似于“echo a b c”的指令，或者ls，或者任何命令，我们不会想要代替Shell进程，所以我们不会希望Shell执行exec系统调用。如果我们这么做了，这里会用echo指令来替代Shell进程，当echo退出了，一切就结束了。所以我们不想要echo替代Shell。实际上，Shell会执行fork，之后fork出的子进程再调用exec系统调用，这是一个非常常见的Unix程序调用风格。对于那些想要运行程序，但是还希望能拿回控制权的场景，可以先执行fork系统调用，然后在子进程中调用exec。 1234567891011121314151617181920// forkexec.c: fork then exec#include &quot;user/user.h&quot;int main()&#123; int pid, status; pid = fork(); if(pid == 0) &#123; char *argv[] = &#123;&quot;echo&quot; ,&quot;THIS&quot; ,&quot;IS&quot; ,&quot;ECHO&quot;, 0 &#125;; exec(&quot;echo&quot;, argv); printf(&quot;exec failed!\\n&quot;); exit(1); &#125;else &#123; printf(&quot;parent waiting\\n&quot;); wait(&amp;status); printf(&quot;the child exited with status %d\\n&quot;,status); &#125; exit(0);&#125; fork系统调用会创建一个新的子进程，是当前进程的一个副本。 如果pid == 0，即进程是子进程，则会调用echo程序，输出&quot;THIS IS ECHO&quot;，如果错误则返回1。并且子进程在echo程序执行结束之后就会退出。，之后继续进行父进程。 父进程会先输出“parent waiting\\n”，之后使用wait系统调用，等待子进程返回，将子进程返回的状态传入status，&amp;status，是将status对应的地址传递给内核，内核会向这个地址写入子进程向exit传入的参数。 如果一个子进程退出成功了，那么exit的参数会是0，如果出现了错误，会向exit传入1。所以父进程读取的wait的参数取决于子进程是否成功的完成了。 I&#x2F;O Redirect1echo hello &gt; out Shell会将echo的输出送到文件out 1cat &lt; out 之后可以运行cat指令，并将out指令作为输入，之后保存在out文件中的内容就是echo指令的输出 Shell首先会先fork然后在子进程中，Shell改变了文件描述符。文件描述符1用来console输出，Shell会将文件描述符1改为output文件，之后再运行你的指令。同时，父进程的文件描述符1并没有改变。所以这里先fork再改变子进程的文件描述符。 123456789101112131415161718//redirect.c: run a command with output redirectedint main()&#123; int pid; pid = fork(); if(pid == 0) &#123; close(1); open(&quot;output.txt, O_WRONLY|O_CREATE&quot;); char *argv[] = &#123;&quot;echo&quot;, &quot;this&quot; ,&quot;is&quot; ,&quot;redirect&quot;, &quot;echo&quot;, 0 &#125;; exec(&quot;echo&quot;,argv); printf(&quot;exec failed!\\n&quot;) &#125; else &#123; wait((int *) 0); &#125;&#125; 在if(pid == 0)中，先检查pid的值，如果pid为0（在子进程中），则首先close(1),close(1)的意义是，我们希望文件描述符1指向一个其他的位置。也就是说，在子进程中我们不想使用原本指向console输出的文件描述符1，即关闭标准输出。 使用 open(&quot;output.txt&quot;, O_WRONLY | O_CREAT, 0666); 打开或创建名为 “output.txt” 的文件，以只写模式（O_WRONLY）打开，并设置创建模式（0666，表示所有用户都可以读写此文件）。这将使得新打开的文件描述符成为子进程的标准输出。 使用 exec(&quot;echo&quot;, argv); 系统调用，替换子进程的映像为 echo 程序，并传递 argv 参数列表。 如果 exec 调用失败，输出 “exec failed!”。 在父进程中，调用 wait((int *)0); 函数，等待子进程结束。 当运行此程序时，它将执行 echo 命令，并将输出 “this is redirect echo” 重定向到 “output.txt” 文件。如果文件已存在，它将覆盖现有内容；如果文件不存在，它将创建一个新文件。","categories":[{"name":"课程学习","slug":"课程学习","permalink":"http://example.com/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"MIT6.S081 Operating System Engineering","slug":"课程学习/MIT6-S081-Operating-System-Engineering","permalink":"http://example.com/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/MIT6-S081-Operating-System-Engineering/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"}]},{"title":"论文阅读 A Study on the Security Implications of Information Leakages in Container Clouds","slug":"论文阅读 A-Study-on-the-Security-Implications-of-Information-Leakages-in-Container-Clouds","date":"2023-03-30T14:40:21.000Z","updated":"2023-04-15T05:07:00.036Z","comments":true,"path":"2023/03/30/论文阅读 A-Study-on-the-Security-Implications-of-Information-Leakages-in-Container-Clouds/","link":"","permalink":"http://example.com/2023/03/30/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%20A-Study-on-the-Security-Implications-of-Information-Leakages-in-Container-Clouds/","excerpt":"","text":"摘要Container technology提供了一个轻量级的操作系统虚拟主机环境。Container technology的出现深刻的改变了多层分布式应用的开发和部署范式（paradigms of multi-tier distributed applications）。然而，由于Linux系统内核中的系统资源隔离机制没有完全实现（system resource isolation mechanisms），在一个基于container的多租户云服务（multi-tenancy container-based cloud service）中，一些安全问题仍然存在。在本文，我们首先介绍了可以在containers内访问的信息泄露渠道。这些渠道暴露了一系列的系统范围的主机信息给没有适当资源分区的containers。通过利用泄露的主机信息，作为租户在container cloud中的恶意的攻击者就会更容易的发起可能影响云服务的可靠性的安全攻击。我们证明了信息泄露渠道将会被利用于推断隐私数据，检测和验证co-residence，建立隐蔽通道，发动更高级的基于云的攻击。我们讨论了container中的信息泄露的根本原因，并提出了一个两阶段的防御方法。正如评估中所证明的，我们的防御是有效的，并且性能开销非常小。 Introduction云计算已经广泛的运用于整合计算机资源。多租户是云计算的有利特征，允许来自不同租户的计算实例在同一物理服务器上运行。在不同类型的云服务中，多租户容器云最近作为传统的以云基础设施为基础的虚拟机VM的轻量级替代品出现。容器是一种OS级的虚拟化技术，在Linux内核中有多个building blocks，包括资源隔离&#x2F;控制技术（如namespace和cgroup）和安全机制（如Capabilities，SELinux，AppArmor和seccomp）。通过避免additional abstraction layers的开销，容器能够实现接近原生的性能，并且在几乎所有方面都超过了基于虚拟机的系统。除此之外，容器管理和orchestration系统的出现，如Docker和Kubernetes，深刻的改变了在云上构建、运输和部署多层分布式应用的生态系统。 尽管容器服务很成功，但是在同一个操作系统内核上运行多个可能属于不同租户的容器，始终存在安全和隐私问题。为了支持容器云上的多租户，Linux内核正在进行跨容器隔离和取消特权用户级别容器的努力。现有的容器启用内核功能大大缩小了暴露给容器租户的攻击面，并且可以限制大多数现有的恶意攻击。然而，并不是所有的Linux内核的子系统都能够区分容器和主机之间的执行上下文，因此它们可能会向容器化应用程序公开系统范围的信息。一些子系统被认为对容器适应性的优先级较低。其余的子系统面临着将代码库转换成容器形式的实现困难，并且它们的维护者不愿意接受激烈的变化。为了关闭这些漏洞，当前容器运行时软件和容器云提供商通常利用访问控制策略来隐藏这些与容器无关的子系统用户内核接口。然而，这种手动和临时修复只能覆盖一小部分暴露出来的攻击面。 在本文中，我们系统地探索和识别可能意外暴露主机操作系统和co-residence容器信息的容器内泄漏通道。这些信息泄漏包括主机系统状态信息（例如功耗、性能数据、全局内核数据和异步内核事件）以及单个进程执行信息（例如进程调度、cgroups 和进程运行状态）。在特定时间点暴露的区分特征信息可以帮助唯一地识别物理机器。此外，恶意租户可以通过提前获取系统范围的知识来优化攻击策略并最大化攻击效果。我们在 Docker 和 LinuX 容器 (LXC) 上的本地测试平台上发现了这些泄漏通道，并验证了它们在五个公共商业多租户容器云服务上（部分）存在。 我们证明了那些信息泄露渠道存在多个安全隐患。总的来说，尽管被挂载为只读，这些通道仍然会被恶意的容器租户利用来推断同一物理机上其他容器的私有数据，检测和验证共存关系，并建立隐蔽通道以偷偷地传输信息。我们提出了几种技术，攻击者可以通过利用那些信息泄露渠道来推断co-residence。与基于缓存的隐蔽信道等传统方法相比，我们的方法对云环境中的噪声更具韧性。我们根据它们的风险等级对这些通道进行排名。我们发现在容器实例中的活动会影响多个通道的系统范围的内的values。通过对运行在容器中的工作负载进行专门操作，攻击者可以实现可靠和高速的隐蔽通道，以突破云部署中采用的隔离机制。例如，通过故意获取和释放锁而不产生网络活动，从而攻击者可以在容器之间隐蔽的传输比特。这些泄露的信息可以被同一物理机上的所有容器观察到。为了揭示这些泄漏通道的安全风险，我们采用不同技术构建了两个隐蔽通道，并在真实的多租户云环境中测试它们的带宽。 我们进一步设计出了一种先进的攻击，称为synergistic power attack，来利用通过这些通道的看似无害的信息。我们证明这样的信息暴露可以极大地放大攻击效果，降低攻击成本，简化攻击编排。power attacks已被证明对现有的数据中心有事实的威胁。如果没有基础云架构运行状态的信息，现有的power attack只能盲目的启动power-intensive workloads，希望高峰能够触发branch circuit breakers来导致power outages。这样的攻击可能costly并且ineffective。 然而，通过学习系统范围内的状态信息，攻击者可以选择 选择最佳时机发动攻击，也就是，在现有的power峰值下，由benign workloads触发，通过增加power-intensive workload来进行攻击。 通过检测被控制的容器的proximity-residence，同步对同一物理机&#x2F;机架的多次power attacks。我们在一个真实的容器云服务上进行了proof-of-concept实验 ，并定量证明了我们的攻击能够以更低的成本产生更高的power峰值。 我们进一步深入分析了这些泄漏渠道的根本原因，并发现是Linux内核中容器implementation的incomplete coverage所致。我们提出了一个两阶段的防卫机制来解决这个在容器云上的问题。特别是，为了防卫synergistic power attacks，我们设计并实现了一个power-based namespace，在Linux内核中对power进行更细粒度（容器）级别的划分。我们和准确性，安全性和性能开销的角度评估了我们的power-based namespace。我们的实验结果表明，我们的系统可以在很小的系统开销下抵御container-based power attack。 BackgroundLinux Kernel Support for Container Technology容器依赖于多个独立的Linux内核组件来实现用户空间实例之间的隔离。与基于虚拟机的虚拟化方法相比，多个容器共享同一个操作系统内核，从而消除了启动和维护虚拟机所需的额外性能开销。容器在业界受到了广泛关注，并在近年来迅速发展，以提高应用程序性能、增强开发人员效率和促进服务部署。在这里，我们介绍两种关键技术namespace和cgroup，它们使得Linux上的容器化成为可能。 Namespace第一个namespace在Linux内核2.4.19中被引入。namespace的关键思想是为一组进程隔离和虚拟化系统资源，这些形成一个容器。每个进程可以与多个不同类型的namespace联系。内核为每个进程提供了一个基于namespace类型的定制化系统资源视图。对任何namespace系统资源的修改都会被限制在相关联的namespace里面，因此不会造成整个系统范围内的修改。 现有的内核有七种不同的namespace：mount（MNT）namespace，UNIX timesharing system （UTS）namespace，PIDnamespace， network（NET） namespace，interprocess communications（IPC）namespace，USER namespace，and CGOUP namespace MNT namespace：隔离一组文件系统mount point。在不同的MNT namespace中，进程对文件系统层次结构有不同的视图。 UTS namespace：每个容器都有自己的主机名和域名，因此一个容器可以被视为独立节点。 PID namespace：虚拟化进程标识符（pids），每个进程有两个pid：在其namespace中有一个pid，在主机上有一个（全局唯一）pid。 NET namespace：包含独立的虚拟网络设备、IP地址、端口和IP路由表。IPC命名空间隔离了进程间通信资源，包括信号、管道和共享内存。 IPC namespace：隔离进程间通信资源，包括信号、管道和共享内存。 USER namespace：引入了用户和组ID号空间的隔离。它在容器内创建一个根用户到主机上非特权用户之间的映射关系。因此，进程可以在用户命名空间内拥有完全权限，但在主机上则被削弱了权限。 CGROUP namespace：虚拟化cgroup资源，每个进程只能通过cgroupfs挂载和/proc/self/cgroup文件获得容器化的cgroup视图。 Cgroup在Linux内核中，cgroup（control group）提供了一种机制，将进程和所有它们的子进程的group分层为具有可控行为的分层group。容器利用cgroup功能，对每个容器实例应用每个cgroup资源限制，从而防止单个容器耗尽主机资源。这些受控资源包括CPU、内存、块IO、网络等。在云计算的计费模型中，cgroup也可以用于为每个容器分配相应的资源并记录它们的使用情况。每个cgroup子系统提供了一个统一的sysfs接口，以简化用户空间中的cgroup操作。 Container Cloud有了这些可用于资源隔离和管理的内核功能，Linux 内核可以在操作系统级别提供轻量级虚拟化功能。未来预计会将更多的namespace和 cgroup 子系统合并到upstream Linux 内核中，以增强容器安全性。近年来，随着容器运行时软件的成熟，容器化已成为虚拟托管的流行选择。LXC 是第一个完整实现于 2008 年构建的 Linux 容器管理器。Docker 建立在 LXC（现在使用 libcontainer）之上，在最近几年已成为最受欢迎的容器管理工具。Docker 可以将应用程序及其依赖项（例如代码、运行时、系统工具和系统库）打包到镜像中，从而保证应用程序在不同平台上表现一致。许多云服务提供商已经提供了容器云服务，其中包括 Amazon ECS、IBM Bluemix、Microsoft Azure 和 Google Compute Engine 等等。对于多租户容器云服务来说，容器可以运行在裸机物理机或虚拟机上。无论是哪种情况下，不同租户的容器都与主机操作系统共享相同的 Linux 内核。 Covert Channels隐蔽通道利用共享资源来打破隔离机制，从而使孤立的实体之间能够进行通信。具有隐秘性的隐蔽通道可用于检索敏感信息并绕过标准通道上的访问控制。广泛认为，即使在虚拟机和容器强制执行隔离技术的情况下，今天的云环境也容易受到隐蔽通道攻击。已经提出了各种技术来建立多租户云环境中的隐蔽通道。Ristenpart等人报告了在公共云中利用共享L2数据缓存达到0.2bps 的比特率。Xu等人使用VM之间的最后一级缓存，在Amazon EC2 环境中构建带宽为3.2bps 的隐藏信道。Wu等人通过利用内存总线上发生竞争实现110 bps 和误码率为0.75% 的隐藏信道。Masti等人成功地通过获取芯片传感器读数来构建隐藏信道，并以12.5bps 的比特率进行传输；Bartolini等人将基于温度的隐藏信道改进至相邻核心50bps 。在云环境中，除了泄露敏感数据的威胁外，隐蔽通道还可以进一步被滥用来检测和验证共存性，这是大多数基于云的攻击的前提条件。通过成功地通过隐蔽通道传输信息，攻击者可以确认两个实例是否在同一主机服务器上co-residence。因此，为了通过构建强大的防御机制来保护云端安全，发现新技术以构建隐蔽通道是一个重要步骤，并已经得到先前研究的密切关注。 Power Attacks on Data Centerspower attacks已经被证明对现有的云基础设施有事实的威胁。考虑到升级power设施的成本，当前数据中心普遍采用power oversubscription来在现有电力供应能力范围内托管尽可能多的服务器。安全保障是基于这样一个假设：相邻的多个服务器同时达到峰值功耗的概率很低。虽然功率超额订阅允许部署更多服务器而不增加电源容量，但降低了电源冗余性，增加了停电可能性，这可能导致同一机架或同一配电单元（PDU）上的服务器被迫关闭。即使正常工作负载也可能产生引起停电的功率峰值。Facebook最近报告称，在2016年的六个月内预防了18次潜在停电事件。如果恶意对手故意投放“能量病毒”发动攻击，则情况将更为严重。停电带来的后果可能是灾难性的，例如Delta Airlines在2016年8月遭遇数据中心断电事件，导致大规模航班延误和取消。最近研究表明，无论是传统还是备用式数据中心都可以进行 power 攻击。 发起一个成功的power attack 需要三个关键因素： 通过合法订阅服务得到目标数据中心的服务器访问权限 稳定的运行适度的工作负载，以增加服务器功耗至其上限。 突然切换到耗电量大的工作负载以触发功率峰值。通过在短时间窗口内引起功率峰值，断路器可以被跳闸以保护服务器免受过流或过载造成的物理损害。 断路器的跳闸条件取决于power峰值的强度和持续时间。为了最大化攻击效果，攻击者需要在同一机架或者PDU所属的一组服务器上运行恶意工作负载。此外，发动攻击的时机也至关重要。如果数据中心的特定的一组服务器（例如，位于同一机架上）已经运行在其峰值功率状态下，则发动成功的power attack的可能性更高。 power 限制技术旨在防御power attack。在机架和PDU级别上，通过监控power消耗，数据中心可以通过基于功率的反馈环路限制服务器的功耗。在主机级别上，Running Average Power Limit(RAPL)是一种用于监视和限制单个服务器功耗的技术。自Sandy Bridge微体系结构以来，Intel引入了RAPL。它提供微秒级细粒度CPU级能源计量，并可用于限制一个包的功耗。 power限制机制显著缩小了功率攻击面，但它无法解决power oversubscription的问题，这是数据中心停电的根本原因。虽然单个服务器的主机级功率限制可以立即响应power surface，但机架或PDU级别的功率限制机制仍会遭受分钟级延迟。假设攻击者可以将电源病毒部署到物理相邻的服务器中，即使每个服务器消耗的电力低于其功率上限，所控制服务器总体聚合后的能量消耗仍可能超过供电容量并触发断路器。我们在以下章节中证明恶意容器租户可以通过控制其高能耗工作负载的部署和利用背景下良性工作负载来放大他们的power attack。 Information Leakages In Container CloudsLinux内核为容器抽象提供了大量支持以实现资源隔离和控制。这些内核机制是在多租户云上运行容器的启用技术。由于优先级和困难程度，Linux内核的某些组件尚未转化为支持容器化。我们打算系统地探索哪些部分的内核没有覆盖，根本原因是什么以及潜在对手如何利用它们。 Container Information Leakages我们首先在本地安装了Docker和LXC容器，并在Linux机器上进行实验。系统设置为默认配置，所有容器都以用户特权启动，与商业容器云类似。Linux提供了两种从用户空间进程到内核的受控接口：系统调用和基于内存的伪文件系统。系统调用主要设计用于用户进程请求内核服务。这些系统调用具有严格的公共接口定义，并通常向后兼容。然而，基于内存的伪文件系统更灵活，可扩展内核功能（例如ioctl），访问内核数据（例如procfs）并调整内核参数（例如sysctl）。此外，这样的伪文件系统使得通过正常文件I&#x2F;O操作操纵内核数据成为可能。Linux有许多基于内存的伪文件系统（例如，procfs、sysfs、devfs、securityfs、debugfs等），这些文件系统服务于不同的内核操作目的。我们更感兴趣的是procfs和sysfs，默认情况下由容器运行时软件挂载。 如图所示，我们设计了一个交叉验证工具，自动发现这些将主机信息暴露给容器的基于内存的伪文件。关键思想是在两个执行上下文中递归探索procfs和sysfs下所有伪文件，在一个未经特权处理的容器中运行，并在主机上运行另一个。我们根据它们的路径对齐并重新排序这些文件，然后对相同内容之间进行成对差分分析。如果从特定虚拟文件访问到的系统资源没有被Linux内核namespace化，则主机和容器会达到相同片段（如图中❷的情况）。否则，如果正确namespace化，则容器可以检索到自己的私有和定制内核数据（如图中❶的情况）。使用这个交叉验证工具，我们可以快速识别可能将系统范围主机信息暴露给容器的伪文件（及其内部内核数据结构）。 Leakage Channel Analysis我们在表中列出了可能泄露主机信息的所有伪文件。这些泄漏渠道包含主机信息的不同方面。容器用户可以检索内核数据结构（例如，/proc/modules显示加载模块列表），内核事件（例如，/proc/interrupts显示每个IRQ的中断数）和硬件信息（例如，/proc/cpuinfo和/proc/meminfo分别显示CPU和内存规格）。此外，容器用户还可以通过某些通道获取性能统计数据。例如，容器可以通过RAPL sysfs接口获得硬件传感器数据（如果这些传感器在物理机上可用），如每个package、核心和DRAM的功耗，并通过数字温度传感器(DTS)sysfs接口获得每个核心的温度。此外，处理器、内存和磁盘I&#x2F;O的使用情况也暴露给容器。虽然乍一看泄露这样的信息似乎无害，但恶意对手可能利用它来发动攻击。 我们通过检查内核代码（在Linux内核版本4.7中）进一步调查了这些信息泄漏的根本原因。通常，泄漏问题是由于内核中namespace实现不完整引起的。更具体地说，我们总结了两个主要原因如下：（1）对于现有namespace缺少context check，以及（2）某些Linux子系统没有（完全）进行namespace隔离。我们提供了两个案例研究，分别是容器中的net prio.ifpriomap和RAPL，以揭示泄漏源头。 Case study 1 - net_prio.ifpriomap伪文件net prio.ifpriomap（位于/sys/fs/cgroup/net prio下）包含了一个映射，该映射将从cgroup中的进程开始并离开系统的流量分配给不同接口。数据格式为[ifname priority]。我们发现，在net prio.ifpriomap上挂钩的内核处理程序函数不知道NET命名空间，因此它向容器化应用程序披露物理机器上所有网络接口。更具体地说，net prio.ifpriomap的读操作由read_priomap函数处理。从这个函数跟踪，我们发现它调用for_each_netdev_rcu，并将第一个参数设置为init_net地址。它迭代主机的所有网络设备，而不考虑NET命名空间。因此，在容器视图中，可以读取主机所有网络设备名称。 Case study 2 - RAPL in containersRAPL是英特尔最近推出的用于设置单个服务器处理器包和DRAM功率限制的技术，可以在毫秒级别响应。在容器云中，RAPL sysfs接口位于/sys/class/powercap/intel-rapl，容器可以访问该接口。因此，容器租户可以通过这个sysfs接口获取主机的系统范围内电源状态，包括核心、DRAM和package等。例如，容器用户可以从伪文件energy uj中读取当前微焦耳能量计数器值。Intel RAPL Linux驱动程序中energy uj的函数处理程序是get_energy_counter。该函数从RAPL MSR检索原始能量数据。由于尚未实现功率数据名称空间，则energy_raw指针引用主机的能量消耗数据。 我们进一步调查了采用Docker&#x2F;LXC容器引擎的容器云服务中存在的信息泄漏问题。我们选择了五个商业公共多租户容器云服务进行泄漏检测，并在表中呈现结果。在云提供商修补通道之前，我们对这些容器云服务的名称（CCi代表第i个Container Cloud）进行匿名化处理。如果结果与我们的容器实例配置不一致，则确认泄露存在。黑点表示通道不存在于该云中，而白点表示通道存在于该云中。我们发现大多数本地机器上的泄露渠道也可以在容器云服务上使用。其中一些由于缺乏特定硬件支持而无法使用（例如Sandy Bridge之前的英特尔处理器或不支持RAPL技术的AMD处理器）。对于CC5，我们发现某些通道信息与本地测试平台不同，这意味着云供应商已经定制了一些额外限制条件。例如，只有属于租户核心和内存相关信息是可用的。然而，这些渠道部分泄露主机信息仍可能被高级攻击者利用, 我们将它们标记为黑白点。 Inference of Co-resident Container我们进一步深入研究特定案例，以查看它们是否可以被利用来检测共存容器 Co-residence problems in cloud settingsCo-residence是云安全中一个众所周知的研究问题。为了提取受害者的信息，攻击者倾向于将恶意实例移动到与受害者相同的物理主机上。Zhang等人已经证明，攻击者可以使用共存实例劫持用户帐户并提取私钥。 此外，实现Co-residence的成本相当低。由于意图整合服务器资源和降低成本，Co-residence仍然是现有云中存在的问题。验证Co-residence的传统方法基于缓存或基于内存泄漏通道。这些方法的准确性可能会因云环境中高噪声而下降。 Approaches and results of checking co-resident containers由于容器可以通过我们发现的泄漏通道读取主机信息，因此我们倾向于测量某些通道是否可用于检查容器共存。我们定义了三个指标，即唯一性（U）、变化性（V）和操作性（M），以定量评估每个通道推断共存的能力。指标 U 表示该通道是否赋予特征数据，可以唯一地识别主机。这是确定两个容器是否位于同一主机最重要和准确的因素。我们已经发现了 17 个泄漏通道，满足这种度量标准。一般来说，我们可以将这些渠道分类为三组： 包含唯一静态标识符的渠道。例如，在/proc/sys/kernel/random 下的引导 ID 是在启动时生成的随机字符串，并且对于每个运行内核都是唯一的。如果两个容器可以读取相同的引导 ID，则明显表示它们正在运行在同一个主机内核上。此组中渠道数据既是静态又是独特的。 容器租户可以动态植入独特签名到其中的渠道 。例如，在/proc/sched debug中 ，容器用户可以通过此接口检索所有活动进程信息的主机 。租户可以在容器内部启动一个带有独特制作的任务名称的进程。从其他容器中，他们可以通过在自己的 sched debug 中搜索此任务名称来验证共存。类似情况适用于计时器列表和锁。 包含唯一动态标识符的渠道。例如，在/proc/uptime中有两个数据字段：系统运行时间和自引导以来的系统空闲时间（以秒为单位）。它们是累积值，并且对于每台主机都是唯一的。同样，RAPL sysfs 接口中的能量 uj 是微焦耳中累积能量计数器 。从该组通道读取到 的 数据 在实时更改 ，但仍然是独特的代表主机 。我们根据其增长率对该组通道进行排名。较快的增长速度表示重复几率较低。 度量V可以展示数据是否随时间变化。有了这个特性，两个容器可以同时定期地对该伪文件进行快照。然后，它们可以通过检查两个数据快照跟踪是否相互匹配来确定co-residence关系。例如，从同一时刻开始，在一分钟内每秒钟记录/proc/meminfo中的MemFree在两个容器中。如果这两个60点数据跟踪彼此匹配，则我们有信心认为这两个容器运行在同一个主机上。每个通道包含不同的信息推断共存的能力，可以通过联合香农熵自然地测量。我们用公式（1）定义熵H。 每个多重独立数据字段Xi，n表示独立数据字段的数量。每个Xi都有可能的值{xi1，· · · ，xim}。我们根据表中的熵结果对能够揭示co-residence能力的九个通道（其中U&#x3D;False且V&#x3D;True）进行排名。 指标M表示容器租户是否可以操作数据。如果租户可以直接将特制的数据嵌入通道中，我们会对其进行标记为黑色。例如，我们可以在容器内创建一个带有特殊任务名称的计时器程序。该任务名称及其关联的计时器将出现在/proc/timer列表中。另一个容器可以搜索计时器列表中的此特殊任务名称以验证共存性。如果租户只能间接影响此通道中的数据，则我们会标记为黑白色。例如，攻击者可以使用taskset命令将计算密集型工作负载绑定到特定核心，并从另一个容器检查CPU利用率、功耗或温度等信息。这些条目可能被高级攻击者利用作为隐蔽信道来传输信号。 对于那些没有这些 U V M 属性的通道，我们认为它们很难被利用。例如，在云数据中心中，大多数服务器可能安装了相同的操作系统分发版和相同的模块列表。虽然 /proc/modules泄漏了主机上加载模块的信息，但是使用此通道推断co-resident容器是困难的。 Constructing Covert Channels包含manipulation（M）的通道可以进一步利用，以在两个容器之间建立隐蔽通道。我们证明了这些信息泄漏通道中的动态标识符和性能数据都可以被滥用来传输信息。特别地，我们实现了两个通道并测试它们的吞吐量和错误率。 Covert channel based on unique dynamic identifiers我们以/proc/locks为例来演示隐蔽通道可以构建在唯一动态标识符之上。通道/proc/locks显示了操作系统中所有锁信息的概述，包括锁类型、相应的进程以及inode号。 这种泄漏也破坏了 pid命名空间，因为所有锁的全局pid都被泄露了。Linux内核的维护者在4.9版本中部分修复了/proc/locks。内核4.9版本中部分修复了/proc/locks，将当前pid命名空间中的所有pid屏蔽为零。然而，其他信息，如锁的数量和节点信息仍然在容器。 我们构建了一个基于/proc/locks的隐蔽通道。具体来说，发送方可以lock一个文件来表示1，并释放lock来表示0。虽然lock和文件不在容器之间共享，但接收器可以在/proc/locks中检查lock的存在。通过不断检查特定lock的状态，可以传输信息。此外，可以同时设置多个lock以传输多个比特。为了建立可靠的高带宽隐蔽信道，攻击者需要考虑几个因素。我们在算法1中详细介绍了构建基于锁的隐蔽信道的过程。 通道/proc/locks包含内部内核数据，因此它一直在更改。尤其是在存在噪声的云环境中，内容可能会发生巨大的波动。 可靠传输数据块的第一步是握手：接收方需要找出发送方使用的所有lock。特别地，握手过程负责： 设置数据传输的起点. 锚定锁，用于同时传送一个block of bits. 同步发送器和接收器。 我们通过为每个数据锁创建一个特定的模式来实现握手。对于一个简化的情况，发送方在短时间内不断获取和释放锁。然后，接收器检查每个数据锁的切换次数（锁定或解锁文件）。如果切换次数超过特定阈值，则接收器通过跟踪索引节点编号来记录该lock，该索引节点编号对于特定文件上的相同锁定是不变的。同时，我们使用一个额外的锁来表示传输信号，用于通知接收器每一轮传输的开始。 在创建特定模式之后，理论上发送方可以立即开始传输。然而，接收方的处理过程的时间是未知的和不确定的，特别是在多租户云环境中存在大量锁的情况下。如果发送方传输数据过快，则可能会丢失一个比特块。虽然发送方可以在发送下一个数据块之前等待一段时间，但这种方法将极大地影响传输速度。 我们进一步添加了一个ACK锁，用于同步发送方和接收方。在获得所有数据锁定之后，接收器通过设置ACK锁定来进行确认。发送器侧的ACK锁的检测类似于接收器侧的其他数据锁的检测方法。接收器在用ACK锁定进行应答之后进入准备状态，并等待数据传输。 对于数据传输，发送方通过获取或释放数据锁，在每一轮中发送一个数据块。例如，八个锁可以表示一个字节。接收器通过检查数据锁的状态来解码数据。一旦接收到ACK锁定，发送器就开始下一轮数据传输。 Covert channel based on performance data variation通过这些信息的泄露，容器用户可以检索到主机服务器的全系统性能统计数据。例如，容器可以通过/proc/stat获取每个核心的CPU使用率，通过/proc/meminfo或/proc/vmstat获取内存使用率。性能数据的取值受容器运行状态的影响。尽管在云环境中，一个容器只能容纳有限的计算资源，但容器中的恶意用户可以仔细选择在容器中运行的工作负载。通过在性能通道中生成独特的模式，容器可以构建隐蔽通道来传输信息。我们建立了一个隐蔽通道，通过滥用/proc/meminfo中的内存使用信息。 /proc/meminfo报告大量关于系统内存使用情况的有价值的信息，包括可用内存总量、系统未使用的物理RAM总量和脏内存总量。 这里我们利用了系统中未使用的内存量。 在云环境中，这个值可能有很大差异，因为每个容器用户都可能影响它。对于建立可靠的隐蔽数据传输来说，这种显著的变化是不可取的。但是，如果不运行内存密集型工作负载，使用情况可能在可接受的范围内波动。我们首先在服务器上记录一段时间的未使用内存，以获得基线值。如果该值变化不迅速且不显著，则表示可以建立隐蔽通道。然后，发送方容器可以分配不同数量的内存来表示位1和位0(例如，位1为100MB，位0为50MB)，这将导致/proc/meminfo中的MemFree字段dorp immediately。接收端可以通过监视空闲内存的变化来简单地转换数据。MemFree分为三个级别:基线情况、位1和位0。发送方在发送1或0后释放所有分配的内存，以便接收方可以知道上次传输的结束并为下一个比特做准备。 为了确保可靠的传输，握手是发送方和接收方之间的第一个必要步骤。 发送方可以选择发送一个固定的模式，比如8位直比特1，来发起一次传输。接收端获得握手模式后，将进入数据接收模式。具体算法见算法2。为了减少其他容器内存消耗所产生的噪声的影响，一旦MemFree落在预定义的范围内，接收端将标记数据传输。同时，增加内存分配量可以减少噪声的影响。但是，由于分配和释放内存需要消耗时间，因此会影响传输带宽。为了减少来自环境的干扰，用户可以进一步设计更高级别的可靠协议，例如使用校验和，以确保传输数据的完整性。 Experiments on a Multi-tenancy Container Cloud为了测量在有真实噪声的环境下的性能，我们选择了一个商业多租户容器云来测试我们的隐蔽通道。我们反复启动容器，并通过检查惟一的静态标识符来验证共存。我们在同一物理机器上创建两个容器。 Lock-based covert channel: 我们在三种不同大小的数据(5,000字节、10,000字节和20,000字节)下测试了基于锁的隐蔽通道的带宽和错误率。我们还选择了四种不同数量的锁(即8、16、24、32)来衡量性能。我们根据经验为切换次数选择一个阈值，以确保所有锁都能被正确识别。握手过程的花费以秒为单位。然后，所有传输数据都是随机生成的。我们恢复接收端的所有数据，并与原始数据进行比较。 具有8个锁的基于锁的隐蔽通道的带宽约为5150 bps。显然，使用的锁越多，带宽就越高。在通道中使用32个数据锁(每轮传输4个字节)，带宽达到22186 bps。 此外，所有案例的错误率都在2%以下。结果表明，基于锁的隐蔽信道具有较高的可靠性。 Memory-based covert channel: 对于构建在/proc/meminfo上的隐蔽通道，我们首先将位1和位0的内存分配分别设置为100,000KB和50,000KB。我们发送1000位来测试性能。然后我们逐渐减少内存分配，直到构建握手失败。带宽和错误率的结果如表3所示。带宽与内存分配大小成反比。但是，如果分配的内存太小，握手过程就会失败，从而导致传输中出现大量错误。最后，通过将65,000KB分配给bit 1, 35,000KB分配给bit 0，我们能够在真实的云环境中实现13.6 bps的带宽。 基于锁的隐蔽通道提供了非常高的数据传输速率，同时仍然保持低错误率。虽然基于内存的隐蔽信道速度有限，但仍能可靠地传输数据。在基于内存的隐蔽信道中可以添加更多的优化方法。例如，我们可以使用更多的级别来每次传输多个比特。我们把它作为我们今后的工作。 值得注意的是，一旦两个容器共存于同一物理服务器上，无论使用相同的CPU包或核心，构建在信息泄漏通道上的隐蔽通道就可以工作。相反，只有当两个实例共享相同的CPU包时，基于最后一级缓存的通道才有效。另据报道，在真实的云环境中，基于内存总线的方法只能适用于近20%的co-residence情况。热隐蔽通道只能在两个核彼此靠近时起作用。 Synergistic Power Attack由于procfs和sysfs在容器中都是只读挂载的，因此恶意租户只能读取这些信息，但不允许修改。我们认为，通过利用泄漏通道，攻击者可以通过学习主机的运行时状态来做出更好的决策。 我们将介绍潜在的Synergistic Power Attack，可能影响数据中心的可靠性，在power outage threats的范围内。我们证明，对手可以利用我们发现的这些信息泄漏来放大攻击效果，降低攻击成本，并促进攻击编排。所有实验都是在真实的容器云中进行的。 Attack Amplification发动成功的power attack的关键是产生短时间的高power峰值，可以超过电力设施的供应能力。正如我们在2.4节中提到的，电源攻击的根本原因是广泛采用电源oversubscription，这使得电源峰值超过安全阈值成为可能。此外，机架级功率封顶机制只能在分钟级时间粒度内反应，为短时间高功率峰值的发生留下了空间。在最严重的情况下，过度充电可能会跳闸分支断路器，导致停电，最终导致服务器瘫痪。能量峰值的高度主要由攻击者控制的资源决定。现有的电源攻击通过自定义电源密集型工作负载 customizing powerintensive workloads(称为电源病毒)来最大限度地提高功耗。Ganesan等人，利用遗传算法自动生成比正常stress基准消耗更多的power的power viruses。 根据Barroso等的报告，在真实的数据中心中，平均利用率约为20%至30%。在如此低的利用率下，不加区分地发起power attack而跳闸断路器的几率极低。 然而，虽然平均利用率较低，但在峰值需求下，数据中心仍然面临断电威胁。这说明物理服务器的功耗随着工作负载的变化会有很大的波动。 为了确认这一假设，我们进行了一个实验，监测容器云中8个物理服务器的整个系统功耗(通过第3节案例研究II中的RAPL泄漏通道)，持续一周。我们将结果显示在图中。我们首先以30秒为间隔对功率数据进行平均，并在第2天和第5天观察功率的剧烈变化。此外，我们在第2天选择一个高功耗区域，并以一秒(这是产生功率峰值的典型时间窗口)为间隔对数据进行平均。峰值功耗达到1199瓦(W)，在一周的时间内，总功耗相差34.72% (899W ~ 1199w)。 我们预计，如果我们能对其进行更长时间的监控，比如在黑色星期五这样的假日，当托管在云上的在线购物网站可能会产生巨大的电力激增时，功耗差异将会更大。 对于容器云中的synergistic power attack，攻击者可以通过RAPL通道监控整个系统的功耗，实时了解功耗模式的波峰和波谷，而不是不加区分地启动功耗密集型工作负载。因此，他们可以利用后台功耗(由同一主机上其他租户的良性工作负载产生)，并在服务器处于峰值运行时间时叠加他们的电源攻击。 这与金融市场的内幕交易现象类似——掌握更多内幕信息的人总是能在合适的时间交易。对手可以通过通过RAPL通道泄露的“内部”功耗信息，在已经很高的功耗基础上再增加一个更高的功耗峰值。 Reduction of Attack Costs从攻击者的角度来看，他们总是希望以最低的代价获得最大的攻击结果。持续运行功耗高的工作负载绝对可以捕获所有良性功耗的峰值。但是，由于几个原因，它对于真实世界的攻击可能并不实用。首先，它不是隐形的。要发起电源攻击，攻击者需要运行电源密集型工作负载。这种行为具有明显的模式，很容易被云提供商检测到。 其次，基于利用率的计费模式现在变得越来越流行。更多的云服务根据CPU&#x2F;内存利用率和网络流量提供更细粒度的价格。例如，Elastic Container为客户提供了基于CPU计量计费的容器。 IBM Cloud为云中的计算资源提供计费指标。Amazon EC2提供了Burstable性能实例，该实例偶尔会崩溃，但大多数时间不会完全运行。VMware按需定价计算器甚至给出了不同利用率水平的估计值。例如，对于一个拥有16个vcpu且平均利用率为1%的实例，它每月收费2.87美元，对于相同的服务器且利用率为100%的实例，每月收费167.25美元。在这些云计费模式下，持续的power attack可能最终导致昂贵的账单。 对于synergistic power attack，通过RAPL监视功耗几乎没有CPU占用。 为了达到相同的效果(功率峰值的高度)，与连续和周期性攻击相比，协同功率攻击可以显著降低攻击成本。我们比较了synergistic power attack和周期性攻击(每300秒发起一次synergistic power attack)的攻击效果。协同攻击在3000秒内只进行两次试验，就可以达到1359瓦的功率峰值，而周期性攻击则进行了9次试验，最多只能达到1280瓦。 Attack Orchestration与传统的power attack不同，synergistic power attack的另一个独特特征是它的攻击编排。假设攻击者已经控制了一些容器实例。如果这些容器分散在数据中心的不同位置，那么它们在多个物理服务器上增加的power不会对电力设施造成压力。现有的功率封顶机制可以毫无困难地容忍来自不同位置的多个小power surges。发动实际电力攻击的唯一方法是将所有“弹药”聚集到相邻位置，同时攻击单个电源。在这里，我们将深入讨论攻击容器实例的编排。 正如我们在第3节中提到的，通过利用多个泄漏通道，攻击者可以将多个容器实例聚合到一个物理服务器中。具体来说，在CC1上的实验中，我们选择使用计时器列表来验证多个容器的共存。具体验证方法请参见3.3节。我们反复创建不在同一物理服务器上的容器实例和终止实例。通过这样做，我们可以轻松地在同一台服务器上部署三个容器。我们在每个容器中运行四个Prime基准测试副本，以充分利用四个分配的核心。每个容器可以贡献大约40W的功率。使用三个容器，攻击者可以轻松地将功耗提高到近230W，这比单个服务器的平均功耗高出约100W。 我们还发现/proc/uptime是另一个有趣的泄漏通道。正常运行时间包括两个数据项，物理服务器的启动时间和所有核心的空闲时间。 在我们的实验中，我们发现一些服务器的启动时间相似，但空闲时间不同。通常情况下，数据中心的服务器在安装和打开后不会重新启动。不同的空闲时间表明它们不是相同的物理服务器，而相似的引导时间表明它们很可能在同一时间段被安装和打开。这是强有力的证据，表明它们可能离得很近，共用同一个断路器。攻击者可以利用此通道将其攻击容器实例聚合到相邻的物理服务器中。这大大增加了他们跳闸导致停电的机会。 Defense AproachA Two-Stage Defense Mechanism直观地说，解决方案应该消除所有泄漏，这样就不会通过这些渠道检索泄漏的信息。我们将防御机制划分为两个阶段:(1)屏蔽通道和(2)增强容器的资源隔离模型。 在第一阶段，系统管理员可以显式地拒绝对容器内通道的读访问，例如，通过AppArmor中的安全策略或挂载伪文件“不可读”。这不需要对内核代码进行任何更改(合并到上游Linux内核可能需要一些时间)，并且可以立即消除信息泄漏。此解决方案取决于容器中运行的合法应用程序是否使用这些通道。如果这些信息与容器化的应用程序正交，则屏蔽它不会对容器租户产生负面影响。我们已经向Docker和表中列出的所有云供应商报告了我们的结果，并收到了积极的回应。 我们与容器云供应商合作解决此信息泄漏问题，并将对容器中托管的应用程序的影响降至最低。这种屏蔽方法可以快速修复基于内存的伪文件系统中的所有泄漏，但它可能会对容器化应用程序的功能增加限制，这与容器提供通用计算平台的概念相矛盾。 在第二阶段，防御方法涉及修复丢失的namespace上下文检查和虚拟化更多的系统资源(即，实现新的namespace)以增强容器的隔离模型。 我们首先向Linux内核维护者报告了与现有namespace相关的信息披露错误，他们很快发布了针对其中一个问题的新补丁([CVE2017-5967])。对于没有namespace隔离保护的其他通道，我们需要更改内核代码，以强制使用更细粒度的系统资源分区。由于每个通道都需要单独修复，因此这种方法可能涉及大量工作。虚拟化一个特定的内核组件可能会影响多个内核子系统。另外，有些系统资源不容易精确地划分到每个容器中。但是，我们认为这是解决问题的根本办法。特别是，为了防御synergistic power attack，我们在Linux内核中设计并实现了一个proof-of-concept power-based namespace，以向每个容器显示分区的电源使用情况。 Power-based Namespace我们提出了一个power-based namespace，通过未更改的RAPL接口向每个容器显示每个容器的power使用情况。在不泄漏整个系统功耗信息的情况下，攻击者无法推断主机的电源状态，从而消除了在良性电源峰值上叠加功耗密集型工作负载的机会。此外，有了每个容器的功率使用统计数据，我们可以动态地限制超过预定义功率阈值的容器的计算能力(或增加使用费用)。容器云管理员可以基于此基于功能的namespace设计粒度更细的计费模型。 我们的设计有三个目标。 准确性:由于没有硬件支持每个容器的功率分区，我们基于软件的功率建模需要准确反映每个容器的功率使用情况。 透明性:容器内的应用程序不知道该命名空间外的功率变化，功率子系统的接口保持不变。 效率:功率分区不应在容器内或容器外引起重要的性能开销。 我们在图中说明了系统的工作流程。我们基于功率的命名空间由三个主要组件组成:数据收集、功率建模和动态校准。我们在容器中保持相同的Intel RAPL接口，但是改变了处理能源使用的读取操作的实现。一旦检测到能源使用的读取操作，修改后的RAPL驱动程序检索每个容器的性能数据(数据收集)，使用检索到的数据来建模能源使用(功率建模)，最后校准建模的能源使用(动态校准)。 我们将在下面详细讨论每个组件。 Data collection为了对每个容器的功耗进行建模，我们需要获得每个容器的 fine-grained performance data。每个容器都与一个cpuacct cgroup相关联。cpuacct cgroup表示容器的处理器核心上的CPU周期。CPU周期累计。我们只使用CPU周期来计算后面的缓存丢失率和分支丢失率。Linux内核还有一个perf_event子系统，它支持计算不同类型的性能事件。The granularity ofperformance accounting 可以是单个进程或一组进程(视为一个per_event cgroup)。到目前为止，我们只为每个perf_event cgroup检索退役指令、缓存缺失和分支缺失(在下一个电源建模组件中需要)的数据。我们当前的实现是可扩展的，可以收集与未来电源建模的变化相对应的更多性能事件类型。 我们从power-based namespace的初始化监视性能事件，并创建多个perf_events，每个事件都与特定的性能事件类型和特定的CPU核心相关联。然后，我们将该容器的perf_cgroup与这些perf_event连接起来，开始计算。此外，我们需要将所有创建的perf_event的所有者设置为TASK TOMBSTONE，这表明这样的性能核算与任何用户进程都是分离的。 Power modeling要实现power-based namespace，我们需要将功率消耗归因于每个容器。RAPL不是提供瞬态功耗，而是分别为package、核心和DRAM提供累计能耗。power消耗可以通过测量时间单位窗口内的能源消耗来计算。 我们power-based namespace还以与原始RAPL接口相同的格式提供了每个容器的累计能量数据。 我们首先将核心的功耗归为属性。 传统的电源建模利用CPU利用率来确定核心的功耗。然而，Xu等证明，在相同的CPU利用率下，power消耗可能会有很大差异。底层管道和数据依赖可能导致CPU失速和功能单元空转。在相同的CPU利用率下，实际退出指令的数量是不同的。 图显示了退役指令和能量之间的关系。我们在四个不同的基准上进行测试:用C编写的空闲循环，prime, 462.SPECCPU2006中的libquantum，以及不同内存配置的strss。我们在主机上运行基准测试，并使用Perf来收集性能统计数据。我们可以看到，对于每个基准测试，能量消耗几乎严格地与退役指令的数量成线性。但是，随着应用类型的不同，拟合线的梯度也相应变化。为了使我们的模型更加准确，我们进一步加入cache miss rate和branch miss rate，建立一个多次多项式模型来拟合斜率。 对于DRAM，我们使用package失败的数量来分析power。图显示了核心实验中相同基准测试和相同配置的能耗。它清楚地表明cache miss的数量与DRAM能量近似线性。 在此基础上，我们利用的线性回归对DRAM能量进行建模。 对于package的功耗，我们将核心、DRAM和一个额外常数的值相加。具体模型如式所示，其中M为建模能量;CM、BM、C分别表示cache miss次数、branch miss次数和CPU周期;F为通过多次线性回归拟合斜率得到的函数。I是退役指令的数量。α， β， γ， λ是由图实验数据得出的常数。 这里我们讨论浮点指令对功率建模的影响。独立的浮点指令可能比整数操作消耗更多的能量。具有高浮点指令比例的工作负载实际上可能导致整体功耗较低，因为功能单元可能被迫在管道的不同阶段处于空闲状态。为了建立一个更精细的模型，有必要考虑微架构。我们计划在今后的工作中朝着这个方向努力。此外，α、β、γ参数的选择也受结构的影响。这样的问题可以在接下来的校准步骤中得到缓解。 On-the-fly calibration我们的系统还为主机的能量数据建模，并与通过RAPL获得的实际能量数据进行交叉验证。为了尽量减小建模数据的误差，我们使用下式对每个容器的建模能量数据进行校准。Econtainer表示返回给每个容器的能量值。这种实时校准是对RAPL接口的每个读取操作进行的，可以有效地减少前一步的错误数量。 Defense Ecaluation我们从三个方面评估本地机器上基于功能的名称空间:准确性、安全性和性能。我们的测试平台配备了Intel i7-6700 3.40GHz 8核CPU, 16GB RAM，运行Ubuntu Linux 16.04，内核版本为4.7.0。 Accuracy我们使用SPECCPU2006基准来测量power建模的准确性。我们将建模的power使用情况与通过RAPL获得的ground truth进行比较。 功耗等于每秒的能量消耗。由于Docker容器的安全策略的限制，我们选择了SPECCPU2006基准测试的一个子集，这些基准测试可以在容器内运行，并且与用于功率建模的基准测试没有重叠。误差ξ定义如下: 其中ERAPL是从主机上的RAPL读取的功耗，而Mcontainer是在容器中读取的相同工作负载的建模功耗。注意，主机和容器都在空闲状态下消耗电力，差别很小。我们使用常数∆diff作为修饰符，反映主机和容器在空闲状态下的功耗差异。结果如图所示，我们的power模型是准确的，因为所有测试基准的误差值都低于0.05。 Security我们也从安全的角度来评估我们的系统。 启用了power-based namespace后，容器应该只检索容器内消耗的功率，而不知道主机的电源状态。我们在测试平台中启动两个容器进行比较。我们在一个容器中运行SPECCPU2006基准测试，并将另一个容器闲置。我们记录容器和主机的每秒用电量。如图所示401.bzip2的结果。所有其他基准测试都表现出类似的模式。 当两个容器都没有工作负载时，它们的功耗与主机的功耗基本相同，从0到10s。一旦容器1在10s启动工作负载，我们可以发现容器1和主机的功耗同时激增。从10s到60s，容器1和主机的功耗基本一致，而容器2仍然处于较低的功耗水平。容器2不知道整个系统的功率波动，因为基于power-based namespace强制隔离。这表明我们的系统能够有效地隔离和划分多个容器的功耗。如果没有电源相关的信息，攻击者将无法发起synergistic power attack。 Performance我们使用UnixBench来比较启用系统前后的性能开销。表列出了所有结果。 正如结果所示，诸如Dhrystone(测试整数和字符串操作)和Whetstone(测试浮点算术性能)这样的CPU基准测试所产生的开销可以忽略不计。 其他基准测试，如shell脚本、管道吞吐量和系统调用，也会触发很少的开销。 在一个并行副本的情况下，基于管道的上下文切换(pip-based context swtiching)确实会产生61.53%的开销，但在8个并行副本时，它会减少到1.63%。我们预计inter-cgroup context switching涉及启用&#x2F;禁用性能事件监视器，而intra-cgroup context switching不涉及任何此类开销。 这解释为什么在禁用power-based namespace情况下，8个并行副本可以保持相似的性能水平。此外，上下文切换只占整个系统性能开销的很小一部分，因此对正常使用的影响很小。 在我们的系统中，对于每个新创建的容器，内核将在每个内核上创建多个perf_events，以收集与性能相关的数据。此测量过程仅对容器过程进行。因此，测量开销将随着容器数量的增加而线性增加。但是，容器数量的增加对系统的影响很小。使用这种机制，在创建所有进程时，内核会检查该进程是否是容器进程。这个检查进程是Unix基准测试中进程创建开销的主要原因。 如表的最后一行所示，UnixBench的总体性能开销对于一个并行副本是9.66%，对于8个并行副本是7.03%。 我们的系统性能在很大程度上依赖于perf_event cgroup的实现，并且可以随着性能监视子系统的改进而提高。 DiscussionSynnergistic Power Attack without the RAPL Channel我们还注意到，一些容器云中的服务器没有配备RAPL或其他类似的嵌入式power meters。这些服务器仍可能面临power attack。如果没有像RAPL这样的power-capping工具，这些服务器在一台机器上可能容易受到host-level power attacks。 此外，如果power data不能直接获得，高级攻击者会尝试根据资源利用信息(如CPU和内存利用率)来近似电源状态，这些信息在已识别的信息泄漏中仍然可用。最好让容器租户无法使用系统范围的性能统计数据。 Complete Container Implementation造成信息泄漏和synergistic power attack的根本原因是Linux内核中隔离机制的不完整实现。最好引入更多的安全特性，比如实现更多的namespace和cgroup。但是，一些系统资源仍然难以分区，如中断、调度信息、温度等。人们还认为，完整的容器实现与虚拟机没有什么不同，并且失去了容器的所有优点。这是容器之间的权衡。如何在容器云中平衡安全性、性能和可用性的问题需要进一步研究。 Related Work由于容器最近变得流行，研究人员对容器和硬件虚拟化之间的性能比较感到好奇。Felter等人通过使用一套涵盖CPU、内存、存储和网络资源的基准测试来比较Docker和KVM的性能。他们的结果显示，Docker在所有情况下都能达到与KVM相同或更好的性能。Spoiala等人使用Kurento媒体服务器来比较Docker和KVM上的WebRTC服务器的性能。他们还证明了Docker的性能优于KVM，可以支持实时应用。Morabito等人比较了传统管理程序和操作系统级虚拟化在计算、存储、内存和网络方面的性能。他们对Docker、LXC和KVM进行了实验，观察到磁盘I&#x2F;O仍然是KVM管理程序的瓶颈。所有这些工作都表明，基于容器的操作系统级虚拟化可以实现比硬件虚拟化更高的性能。除了性能，容器云的安全性始终是一个重要的研究领域。Gupta简要介绍了Docker的安全性。Bui也对Docker容器进行了分析，包括隔离问题和相应的内核安全机制。他们声称，Docker容器在默认配置下是相当安全的。Grattafiori等人总结了容器的各种潜在漏洞。他们还提到了基于内存的伪文件系统中的几个通道。Luo等人证明了错误配置的能力可以被利用来在Docker中建立隐蔽的通道。之前关于容器的性能和安全性的研究工作鼓励我们更多地研究容器如何能够实现与硬件虚拟化相同的安全保证，但在性能方面的折衷却微不足道。我们是第一批系统地识别容器中的信息泄露问题，并研究建立在这些泄漏渠道的基于容器的潜在的power attcak。 Cloud Security and Side&#x2F;Covert Channel Attacks云安全已经受到学术界和业界的广泛关注。云环境下的co-residence检测是与我们工作最密切相关的研究课题。co-residence检测最早由Ristenpart等人提出。他们证明，攻击者可以将恶意VM与目标VM co-residence 在同一服务器上，然后发起侧通道和隐蔽通道攻击。在现有主流云服务中实现co-residence仍然是可行的。为了验证在同一物理服务器上的co-residence，攻击者通常利用侧通道或隐蔽通道，例如，一种广泛采用的方法是使用cahe-based channel。位于同一个包上的多个实例共享最后一级缓存。通过使用一些专用的操作(如cflush)，攻击者可以通过测量缓存访问时间来检测共驻留。Liu等证明了l3缓存侧通道攻击对于跨核和跨vm攻击是可行的。Zhang等人对云进行了真实的侧通道攻击，并提出了几种防御机制来缓解这些攻击。特别是，他们证明了跨租户侧通道攻击可以成功地在PaaS中使用共存服务器进行。除了基于缓存的通道外，内存总线和内存重复数据删除也已被证明是构造隐蔽通道的有效方法。与现有的侧&#x2F;隐蔽通道研究工作不同，我们在容器云设置中发现了系统范围的信息泄漏，并设计了一种新的方法来定量评估泄漏通道的容量，以用于共居检测。另外，与最小化虚拟机的内核攻击面研究相比，我们提出了一种两级防御机制，以最小化容器云上的信息泄漏和电源攻击空间。 系统状态信息，如核心温度和系统功耗，也被用于构建侧&#x2F;隐蔽通道。Thiele等提出了一种基于每个核心温度的热隐蔽通道，并在局部试验台测试了容量。功耗也可能被滥用来破坏AES。在工作中，我们不使用功耗数据作为传递信息的隐蔽通道。相反，我们证明了对手可以利用主机功耗泄漏来发起更高级的power attack。 Power Modeling在没有hardware-based power meter的情况下，power modeling是逼近功耗的一种方法。 Russell等和Chakrabarti等提出了指令级功率建模。他们的工作表明，分支的数量影响功耗。对虚拟机功耗的近似研究有几种。有工作证明了VM级的功耗可以通过CPU利用率和最后一级缓存失误率来估计。Mobius等将VM的功耗分为CPU、缓存、内存和磁盘。BITWATTS在细粒度流程级别上对功耗进行了建模。Shen等提出了一种power容器来计算多核系统中请求的能量消耗。我们对synergistic的防御主要是受到power modeling approach for VMs的启发。我们提出了一种新的power分区技术来近似每个容器的功耗并重用RAPL接口，从而解决了容器设置中的RAPL数据泄漏问题。 Conlusion容器云服务因提供轻量级操作系统级虚拟主机环境而变得流行起来。容器技术的出现深刻地改变了在云中开发和部署分布式应用程序的生态系统。但是，由于Linux内核中系统资源分区机制的不完全实现，对于共享同一个内核的多个容器租户仍然存在一些安全问题。在本文中，我们首先提出了一种系统的方法来发现可能将主机信息暴露给容器的信息泄漏通道。通过利用这些泄露的主机信息，恶意容器租户可以发起一种新型的power attack，这可能会危及数据中心电源系统的可靠性。此外，我们讨论了这些信息泄漏的根本原因，并提出了一个两阶段的防御机制。我们的评估表明，所提出的解决方案是有效的，并引起微不足道的性能开销。 MyLinux的incomplete coverageLinux内核提供了对各种容器化技术的支持，使用户能够在单个主机上运行多个隔离环境。Linux内核中的容器实现主要利用一组特性，如namespace、cgroup和seccomp。然而，在Linux内核中，容器实现的某些方面可能是不完整或有限制的。以下是一些潜在的incomplete coverage范围： namespace：通过创建系统资源的分离视图来为容器提供隔离。虽然Linux内核支持几种命名空间（mout、PID、NET、IPC、UTS和user），但某些资源类型可能没有相应的命名空间或具有有限的支持，这可能导致不完全隔离。 control groups（cgroups）：Cgroups用于限制、记录和隔离进程组使用资源（CPU、内存、I&#x2F;O等）。虽然存在cgroups v1和v2，但某些功能可能无法在两个版本之间得到充分支持或具有局限性。这会导致容器资源管理不完整或不一致。 安全性：Linux内核提供了诸如seccomp、AppArmor和SELinux之类的安全机制来强制访问控件并限制容器可以进行哪些系统调用。但是，这些机制可能存在漏洞或限制，可能会暴露潜在的安全风险。 兼容性：容器实现的某些功能（如文件系统快照或检查点&#x2F;恢复）可能取决于特定的内核版本、存储驱动程序或文件系统。这可能导致在某些配置上出现兼容性问题和限制。 性能：虽然Linux内核为容器工作负载提供了各种优化，但仍有一些领域可以改进，例如存储I&#x2F;O或网络吞吐量。 内核更新：随着新功能和改进被添加到Linux内核中，容器实现可能需要更新以利用这些增强功能。在某些情况下，这可能会导致容器支持方面存在差距，直到它们与新的内核特性完全集成并进行测试。 值得注意的是，Linux内核正在积极开发中，并且对于容器支持的改进不断被提出和实施。此外，像Docker、Kubernetes和LXC之类的容器化解决方案建立在这些内核特性之上，并提供更完整、无缝的用户体验。 数据中心的oversubscription电力超额订阅是数据中心使用的一种策略，其中分配给服务器、存储系统和网络设备的总电源供应超过实际可用电源供应。这种方法基于一个观察结果：并非所有设备同时消耗其最大额定功率。通过利用这一点，数据中心可以托管比其电力基础设施允许更多的服务器和设备。 Linux子系统Linux子系统是Linux内核中的一部分，负责处理特定功能或设备。例如，文件系统、网络协议栈、进程调度等都可以被认为是Linux子系统。它们通常以模块的形式实现，并在运行时加载到内核中。这些子系统允许Linux内核与硬件和外部资源进行交互，以便为上层应用程序提供所需的功能。 执行上下文执行上下文是操作系统在运行某个任务时的环境，它包括一个任务所需的所有状态信息。这包括程序计数器、堆栈指针、寄存器值、内存分配信息等。执行上下文使得操作系统能够在多个任务之间进行切换，以实现多任务并发执行。 Linux子系统不能区分容器和主机之间的执行上下文，可能泄露系统信息容器是一种轻量级的虚拟化技术，允许在同一主机上运行多个隔离的应用程序。容器与主机共享相同的内核，但每个容器都有其独立的文件系统、进程空间、网络接口等。容器技术的一个关键优势是资源隔离，这意味着每个容器只能访问分配给它的资源，而不能访问其他容器或主机的资源。 然而，某些Linux子系统可能无法区分容器和主机之间的执行上下文。这意味着当容器化应用程序访问这些子系统时，它们可能能够访问不应暴露给它们的系统范围信息。这可能导致安全和隐私问题，因为容器之间和容器与主机之间的隔离可能被破坏。 例如，如果某个Linux子系统负责处理系统范围的统计信息（如CPU使用率、内存使用情况等），那么容器内的应用程序可能能够访问这些信息，从而获取其他容器或主机的资源使用情况。这可能导致容器之间的信息泄露，破坏了它们之间的隔离。 为了解决这个问题，容器运行时和内核开发人员需要确保所有Linux子系统都能够正确地区分容器和主机之间的执行上下文，以实现更强大的隔离和安全性。这可能包括修改子系统的实现，以便它们能够识别和处理来自容器的请求，以及限制容器访问系统范围信息的能力。 Namespace和cgroup以及具体实现Linux中的Namespace和Cgroup是两种操作系统级别的资源管理和隔离技术。它们在容器技术（如Docker）中被广泛应用，用于实现轻量级虚拟化。 Namespace（命名空间） 是Linux内核提供的一种隔离技术，允许创建多个独立的空间，每个空间内可以有自己的进程、文件系统、网络等资源。Namespace有以下几种类型： Mount Namespace：隔离不同命名空间的文件系统挂载点。 PID Namespace：隔离进程ID空间，使每个命名空间有独立的PID。 Network Namespace：隔离网络接口和路由表，使每个命名空间有独立的网络环境。 IPC Namespace：隔离System V IPC对象和POSIX消息队列。 UTS Namespace：隔离主机名和域名。 User Namespace：隔离用户和组ID。 Cgroup（控制组） 是Linux内核提供的一种资源管理技术，允许对一组进程进行资源限制、优先级调整等操作。Cgroup通过将进程组织到层次结构的控制组中来实现资源管理。主要有以下几类资源控制： CPU：限制进程的CPU使用率。 Memory：限制进程的内存使用。 Block I&#x2F;O：限制进程的磁盘I&#x2F;O。 Network：限制进程的网络带宽。 以下是一个简单的Namespace和Cgroup的使用示例： 安装相关工具： 1sudo apt-get install cgroup-tools 创建一个新的Namespace（使用unshare命令）： 1sudo unshare --uts --pid --mount-proc --fork /bin/bash 这个命令创建了一个新的Namespace，并在其中启动了一个新的bash进程。这个新的Namespace具有独立的UTS、PID和挂载的&#x2F;proc文件系统。 创建一个新的Cgroup（使用cgcreate命令）： 1sudo cgcreate -g cpu,memory:/my_cgroup 这个命令创建了一个名为my_cgroup的新Cgroup，用于管理CPU和内存资源。 为Cgroup分配资源限制（使用cgset命令）： 12sudo cgset -r cpu.shares=512 my_cgroupsudo cgset -r memory.limit_in_bytes=100M my_cgroup 这个命令为my_cgroup设置了CPU份额为512（相对权重）和内存限制为100MB。 将进程添加到Cgroup（使用cgclassify命令）： 1sudo cgclassify -g cpu,memory:my_cgroup &lt;PID&gt; 将指定的进程PID添加到my_cgroup中，使其受到Cgroup资源限制的约束。 以上示例展示了如何使用Namespace和Cgroup进行资源隔离和管理。在实际应用中，这些技术通常与容器运行时（如Docker）结合使用，以提供更高级别的抽象和管理工具。 Namespace和Cgroup的具体使用Namespace 和 cgroup 是 Linux 内核提供的两个关键特性，它们在容器技术（如 Docker）中发挥着重要作用。Namespace 负责为容器提供独立的视图，使得容器在网络、进程、文件系统等方面与主机和其他容器隔离。而 cgroup（控制组）则负责限制和管理容器的资源使用（如 CPU、内存、磁盘 I&#x2F;O 等）。 Namespace 例子： 假设我们想要创建一个新的网络 Namespace，使容器具有独立的网络栈。我们可以使用 ip 命令来实现这一目标： 123456789101112131415# 创建一个新的网络 Namespacesudo ip netns add my_namespace# 将网络设备 veth0（容器端）和 veth1（主机端）添加到新的 Namespacesudo ip link add veth0 type veth peer name veth1sudo ip link set veth0 netns my_namespace# 配置容器端网络设备sudo ip netns exec my_namespace ip addr add 192.168.1.2/24 dev veth0sudo ip netns exec my_namespace ip link set veth0 upsudo ip netns exec my_namespace ip route add default via 192.168.1.1# 配置主机端网络设备sudo ip addr add 192.168.1.1/24 dev veth1sudo ip link set veth1 up 在这个例子中，我们创建了一个新的网络 Namespace，并配置了一对虚拟以太网设备（veth0 和 veth1），将容器的网络与主机网络连接起来。这使得容器可以拥有独立的网络栈，与主机和其他容器隔离。 cgroup 例子： 假设我们想要限制容器的 CPU 和内存资源。我们可以使用 cgroup 来实现这一目标： 123456789101112131415# 创建一个新的 cgroupsudo mkdir -p /sys/fs/cgroup/cpu/my_cgroupsudo mkdir -p /sys/fs/cgroup/memory/my_cgroup# 限制容器的 CPU 使用率为 50%echo 50000 &gt; /sys/fs/cgroup/cpu/my_cgroup/cpu.cfs_quota_usecho 100000 &gt; /sys/fs/cgroup/cpu/my_cgroup/cpu.cfs_period_us# 限制容器的内存使用为 100MBecho 100000000 &gt; /sys/fs/cgroup/memory/my_cgroup/memory.limit_in_bytes# 启动一个新的容器，并将其添加到我们之前创建的 cgroupdocker run -itd --name=my_container ubuntu:18.04echo $(docker inspect -f &#x27;&#123;&#123;.State.Pid&#125;&#125;&#x27; my_container) &gt; /sys/fs/cgroup/cpu/my_cgroup/cgroup.procsecho $(docker inspect -f &#x27;&#123;&#123;.State.Pid&#125;&#125;&#x27; my_container) &gt; /sys/fs/cgroup/memory/my_cgroup/cgroup.procs 在这个例子中，我们创建了一个新的 CPU 和内存 cgroup，并限制了容器的 CPU 使用率和内存使用。然后我们启动了一个新的容器，并将其添加到我们之前创建的 cgroup 中，这样容器的资源使用就受到了限制。 综上所述，Namespace 和 cgroup 在容器技术中发挥着重要作用，使得容器可以在资源使用和隔离方面实现更精细的控制。 Linux中的pseudo file在 Linux 系统中，伪文件（pseudo file）是一种特殊类型的文件，它们提供了与系统内核和设备驱动程序交互的途径。伪文件并不包含实际的文件数据，而是在用户和内核空间之间提供了一个通信接口。这些文件通常位于 /proc 和 /sys 文件系统中。 /proc 文件系统是一个虚拟文件系统，包含了许多伪文件，这些伪文件可以用来监控和调整系统内核的运行状态。例如，/proc/cpuinfo 提供了有关处理器的详细信息，/proc/meminfo 提供了关于系统内存使用情况的数据。这些伪文件可以像普通文件一样使用命令行工具（如 cat、grep 等）进行查看和操作。 /sys 文件系统是另一个虚拟文件系统，用于 Linux 内核的设备管理。它包含了许多伪文件，这些伪文件提供了对系统设备的配置和状态信息的访问。/sys 文件系统的结构更加规范化，按照设备、总线和驱动程序的层次关系进行组织。 总之，伪文件在 Linux 系统中提供了一种简单、统一的方法，使用户能够方便地访问和修改系统内核和设备驱动程序的状态信息。 pseudo file和真实文件的区别伪文件（pseudo file）和真实文件在 Linux 系统中具有不同的特点和用途。以下是它们之间的主要区别： 数据存储：真实文件存储在磁盘上，包含实际的文件数据。而伪文件并不包含实际的文件数据，它们通常不存在于磁盘上，而是由内核动态生成，用于在用户空间和内核空间之间提供通信接口。 用途：真实文件用于存储和读取数据，例如文档、图像或程序。伪文件主要用于提供系统信息、监控和调整内核参数或设备驱动程序的状态。它们可以让用户通过文件系统接口与内核交互，而无需使用特殊的系统调用。 位置：真实文件通常分布在整个文件系统中，根据目录结构进行组织。伪文件主要位于特定的虚拟文件系统中，例如 /proc（用于内核参数和进程信息）和 /sys（用于设备管理）。 访问方式：伪文件和真实文件都可以使用类似的命令行工具（如 cat、grep 等）进行查看和操作。然而，伪文件通常是只读的或仅支持特定操作，它们的内容可能会随着系统状态的变化而动态改变。 总之，伪文件和真实文件在数据存储、用途、位置和访问方式上存在显著差异。伪文件主要用于提供与内核和设备驱动程序的交互途径，而真实文件用于存储和读取实际数据。 伪文件例子/proc/loadavg 伪文件是由内核动态生成的，不在磁盘上存在。它允许用户和程序通过熟悉的文件系统接口访问负载平均值信息，而无需使用特殊的系统调用。 要使用 /proc/loadavg，您可以像读取常规文件一样简单地读取其内容。例如，您可以使用 cat 命令在终端中显示其内容： 1cat /proc/loadavg 输出可能类似于以下内容： 10.51 0.38 0.35 1/1234 5678 这些数字分别表示 1 分钟、5 分钟和 15 分钟的负载平均值，后面的数字表示当前正在运行的进程数&#x2F;系统总进程数，以及最近分配的进程 ID。 总之，/proc/loadavg 是一个伪文件的示例，它为访问 Linux 系统中的负载平均值信息提供了一个接口，无需使用特殊的系统调用。","categories":[{"name":"论文精读","slug":"论文精读","permalink":"http://example.com/categories/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/"},{"name":"内核安全","slug":"论文精读/内核安全","permalink":"http://example.com/categories/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/%E5%86%85%E6%A0%B8%E5%AE%89%E5%85%A8/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"云安全","slug":"云安全","permalink":"http://example.com/tags/%E4%BA%91%E5%AE%89%E5%85%A8/"}]},{"title":"论文阅读 Demons in the Shared Kernel: Abstract Resource Attacks Against","slug":"论文阅读 Demons-in-the-Shared-Kernel-Abstract-Resource-Attacks-Against","date":"2023-03-30T14:06:58.000Z","updated":"2023-04-15T05:52:39.814Z","comments":true,"path":"2023/03/30/论文阅读 Demons-in-the-Shared-Kernel-Abstract-Resource-Attacks-Against/","link":"","permalink":"http://example.com/2023/03/30/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%20Demons-in-the-Shared-Kernel-Abstract-Resource-Attacks-Against/","excerpt":"","text":"摘要 由于其更快的启动速度和更好的资源利用效率，OS-level的虚拟化（virtualization）已被广泛采用，并成为云计算的一项基本技术。与硬件虚拟化相比，OS-level的虚拟化利用共享内核（shared-kernel）设计来实现高效率，并在共享内核上运行多个用户空间实例（又称容器） 然而，在本文中，我们揭示了一种新的攻击面，它是操作系统级虚拟化所固有的，会影响Linux、FreeBSD和Fuchsia。根本原因是操作系统级虚拟化中的共享内核设计导致容器直接或间接地共享成千上万的内核变量和数据结构。在不利用任何内核漏洞的情况下，非特权容器可以轻松耗尽共享的内核变量和数据结构实例，从而对其他容器发起DoS攻击。与物理资源相比，这些内核变量或数据结构实例(称为抽象资源)更普遍，但保护不足。 为了说明限制抽象资源的重要性，我们针对操作系统内核的不同方面进行了抽象资源攻击。结果表明，攻击抽象的资源是非常实用和关键的。我们进一步进行了系统分析，识别出Linux内核中脆弱的抽象资源，成功检测到1010个抽象资源，其中501个可以动态重复使用。我们还在前四家云供应商的自部署共享内核容器环境中进行了攻击实验。结果表明，所有环境都容易受到抽象资源攻击。我们得出结论，containing抽象资源是困难的，并给出了多种策略来降低风险 CCS CONCEPTS Security and privacy -&gt; Virtualization and security KEYWORDS OS-level Virtualization；Shared Kernel；Abstract Resource Attack IntroductionOS-level虚拟化允许多个包含且隔离的用户空间环境在同一个内核上运行。与硬件虚拟化相比（虚拟机），OS-level虚拟化消除了为每个用户空间实例维护操作系统内核的负担，因此具有更快的启动速度和更好的资源利用效率。因此，OS-level虚拟化在近年来得到了广泛的应用，并成为云计算的基础技术。OS-level虚拟化中的空间实例在FreeBSD中命名为jails，在Solaris命名为Zones，在Linux中命名为containers。 尽管OS-level的虚拟化效率很高，但它也带来了多种安全问题。首先，由于共享内核，操作系统级虚拟化容易受到内核漏洞的攻击。因此，它不能隔离内核错误。一旦共享内核受到威胁，所有用户空间实例(称为容器)都将失去隔离和保护。此外，研究人员最近对容器技术的隔离提出了质疑，例如信息泄漏、隐蔽通道和out-of-band workloads 打破了cgroup。 然而，在本文中，我们揭示了OS-level虚拟化所固有的一种新的攻击面（attack surface）。与硬件虚拟化相比，OS-level虚拟化利用共享内核设计来实现高效率。在典型的OS-level虚拟化环境中，容器运行在相同的操作系统内核上，并通过300多个系统调用请求各种服务。请注意，底层OS内核包含数十万个变量和数据结构实例，用于为容器提供服务。因此，这些容器直接或间接地共享这些内核变量和数据结构实例。 不幸的是，这些共享的内核变量和数据结构实例是OS-level中的新攻击面。在不利用任何漏洞的情况下，非特权容器可以轻松耗尽某些内核变量和数据结构实例，从而在OS-level虚拟化环境中引起DoS攻击。因此，即使其他容器拥有足够的物理资源，但随着内核关键变量或数据结构实例的耗尽，它们仍然不能执行任何有意义的任务。与真实硬件所支持的物理资源相比，我们将这些内核变量或数据结构实例视为抽象资源，将对这些资源的用尽攻击视为抽象资源攻击（abstract resource attack）。 尽管抽象资源可以被用于DoS攻击，但它们往往得不到充分保护。内核和容器开发人员更关注保护物理资源，而不是抽象资源。例如，Linux内核提供了cgroup来限制每个容器实例的资源使用。但在13个cgroup中，有12个是物理资源cgroup，限制CPU、内存、存储、IO等资源的使用。只有pid cgroup是为限制抽象资源pid而设计的。因此，数百种容器共享的抽象资源没有任何限制，例如global dirty ratio、open-file structs和pseudo-terminal structs，这使它们容易受到DoS攻击。 为了展示在OS-level上限制抽象资源的重要性，我们在Linux内核上使用Docker容器进行攻击，针对操作系统服务的不同方面的抽象资源，包括进程管理、内存管理、存储管理和IO管理。 我们的实验证明攻击抽象资源是非常实用和关键的-它很容易地禁用新程序的执行，降低内存写入速度97.3%，使所有文件打开相关地操作崩溃，并拒绝所有新的SSH连接。更糟糕地是，它会影响操作系统服务的所有方面。此外，实验还表明，除了Linux FreeBSD和Fuchsia也容易受到抽象资源攻击。 遗憾的是，尽管抽象资源很重要，但由于几个基本原因，它们本身就很难contain。首先，在操作系统内核中列举所有可能的抽象资源是不切实际的。与很少的物理资源类型不同，内核中的抽象资源类型是多种多样的。第二，很容易形成导致抽象资源枯竭的条件。在内核中实现新特性时，开发人员经常关注物理资源的消耗，而很少关注抽象资源的消耗。此外，OS内核具有复杂的数据和路径依赖关系，导致内核中的抽象资源以各种方式耗尽。 因此，我们设计了一个基于LLVM的工具，系统地识别Linux内核中脆弱的抽象资源。我们提出了识别可共享抽象资源并分析其容器可控性的新技术。我们将我们的工具应用于新的Linux内核，并检测1010个抽象资源。其中501个可以动态地重复使用，从检测到的抽象资源中，我们根据我们的熟悉度挑选了7个影响操作系统各个方面的资源（即，我们知道耗尽该资源的影响）。我们进一步对部署在四大云供应商（包括AWS、MS Azure、谷歌cloud和阿里云）上的共享内核容器环境中的这些选定资源进行攻击实验。试验结果表明，所有环境都容易受到我们的攻击。最后给出了多种降低抽象资源攻击风险的策略。 本文的贡献如下： New Attack Surface：我们揭示了操作系统级虚拟化所固有的新的攻击面。我们提出了一种新的攻击方法，称为抽象资源攻击。我们证明了抽象资源攻击是非常实用的，并且是影响Linux、FreeBSD和Fuchsia的广泛攻击类别。 Systematic Analysis：我们设计并实现了一个基于LLVM的静态分析工具来识别Linux内核中脆弱的抽象资源，包括基于配置的分析和容器可控性分析。我们的工具检测501个可以在Linux内核中动态重复触发的抽象资源。 Practical Evaluation：我们评估了AWS、MS Azure、谷歌Cloud和阿里云上self-deployed共享内核容器环境中的7种抽象资源攻击。（目前的公共云供应商没有直接向不同的用户提供共享内核容器。公共云中的容器通常由虚拟机隔离。）所有环境都容易收到抽象资源攻击。其中有两个环境易受6 attacks，一个环境易受 5 attacks，另一个环境易受 4 attacks。我们负责地向所有云供应商披露了我们的调查结果。所有这些都证实了所确定的问题。 Community Impact：我们计划在GitHub - ZJU-SEC&#x2F;AbstractResourceAttack: This repository is used to analysis the shared resources of different containers中开源我们的工具和识别出的抽象资源，这样它们就可以帮助Linux内核community和容器community识别出OS-level虚拟化中资源隔离的弱点。 BackgroundOS-level虚拟化依赖于底层操作系统内核进行资源隔离和containment。更具体地说，Linux内核为资源隔离提供了namespace，为资源containment提供了cgroup。 Linux NamespacesLinux namespace提供进程级资源隔离。目前，Linux namespace分为8种类型。根据它们的发布时间，如下： Mount：用于文件系统隔离 UTS：用于主机名和域名隔离 IPC：用于消息队列隔离 PID：用于进程ID隔离 Network：用于网络资源隔离 User：用于UID&#x2F;GID隔离 Cgroup：用于cgroup隔离 Time：用于时钟时间隔离 一个进程可以被分配给不同类型的不同namespace。但是对于每种类型，它只能属于一个namespace。默认情况下，进程与其父进程在相同的namespace中。它可以在进程创建期间通过pass specific flags添加到新的namespace，或者在进程运行期间通过调用setns系统调用添加到新的namespace。理想情况下，只有同一namespace中的进程可以共享namespace隔离的资源。因此，资源是跨namespace隔离的。因此，一个namespace中的隔离资源耗尽不会影响其他namespace中的进程。这样的设计本质上要求namespace机制正确且彻底地contain资源。 然而，仍然有数百种抽象资源类型没有包含在namespace中。即使有namespace的保护，大型攻击面仍然存在。有人可能会主张使用namespace隔离所有抽象资源。然而，这是不切实际的:抽象资源的巨大数量和灵活性使得解决方案由于巨大的代码更改和高性能开销而无法接受。 Linux Control Groups另一方面，Linux cgroup用于限制限制资源的实用。cgroup负责控制组内所有进程使用的资源。cgroup被组织成树状结构，其中children的资源也包括parent的资源。对资源使用的限制也在树上递归地强制执行，以便cgroup中的资源使用不应超过其所有祖先的限制。 cgroup主要管理硬件资源，如CPU、内存、存储、IO等。有两个版本的cgroup，v1和v2，主要的区别是，cgroup v1对于每种类型的资源可以有一个树状层次结构，而控制组v2只有一个层次结构。resource account和resource usage limit的实现在v1和v2之间差别不大。目前默认使用cgroup v1，因为它更稳定，并提供更多对资源的控制。它管理13种资源类型，而v2目前只支持9种资源类型。更具体地说，在这13种资源中，有5种用于CPU accouting，包括cpu、cpuacct、cpuset、freeze、pref_event；其中3个是用于内存，包括memory、hugetlb、rdma；blkio用于storage；还有3个用于IO，包括devices、net_cls、net_prio。只有PIDs cgroup为PID的抽象资源。 虽然限制容器进程中共享抽象资源的使用可以减轻DoS攻击，但将cgroup扩展到包括所有抽象资源也是不切实际的。计算资源并对如此多类型的资源实施限制将引入不可接受的开销。 Abstract Resource Attacks Threat model and assumptions：在本文中，由于我们的目标是OS-level虚拟化，所以我们假设容器运行在相同的共享内核上。容器执行最先进的保护，并在部署中遵循最安全的实践。更具体地说，容器以不同的非根用户运行，删除了所有功能。而内核则为容器强制使用尽可能多的namespace和cgroup。此外，内核还使用seccomp来阻止敏感的系统调用。我们进一步假设内核没有bug，所有安全机制都正常工作。 另一方面，攻击者控制一个容器，并试图破坏在同一内核上运行的其他容器。攻击者可以在容器内运行任何代码并调用seccomp允许的系统调用。但是，他&#x2F;她不允许利用内核漏洞。此外，攻击者作为非根用户处于非特权容器中，根本没有任何功能。最后，攻击者不允许升级特权或重新获得任何功能。在下面的文章中，我们展示了由于内核中的共享抽象资源，即使这样的攻击者仍然可以对其他容器发起DoS攻击。 Weaknesses in OS-level Virtualization在OS-level虚拟化中，容器直接或间接地共享成千上万的内核抽象资源，这使它们容易受到资源耗尽攻击。我们利用Linux内核中的一个示例来说明细节。 12345678910111213141516171819202122232425static struct percpu_counter nr_files __cacheline_aligner_in_smp;static long get_nr_files(void)&#123; return percpu_counter_read_positive(&amp;nr_files);&#125;struct file *alloc_empty_file(int flags, const struct cred *cred)&#123; static long old_max; struct file *f; if(get_nr_files() &gt;= files_stat.max_files&amp;&amp;!capable(CAP_SYS_ADMIN) &#123; ... goto over; &#125; f = __alloc_file(flags, cred); if (!IS_ERR(f)) percpu_counter_inc(&amp;nr_files); ...over: ... return ERR_PTR(-ENFILE);&#125; 它定义了一个每个CPU计数器nr_files，一个函数get_nr_files()和一个函数alloc_empty_file()。 nr_files：这是一个每个CPU计数器，用于跟踪每个CPU上分配的文件结构的数量。 get_nr_files()：此函数通过读取nr_files计数器的正值，返回所有CPU上分配的文件结构的总数。 alloc_empty_file()：此函数接受两个参数，flags和cred，并尝试分配一个空的文件结构。 如果分配的文件结构的数量（get_nr_files()）大于或等于允许的最大值（files_stat.max_files），并且当前进程没有CAP_SYS_ADMIN能力，它将跳过文件分配并跳转到over标签。 如果满足条件，它将调用__alloc_file()函数来分配一个新的文件结构。 如果分配成功（即返回的指针不是错误），它会增加nr_files计数器。 如果分配失败或达到最大文件数且没有所需的权限，该函数将返回一个带有-ENFILE错误代码的错误指针。 代码显示了Linux内核中的全局变量nr_files和函数alloc_empty_file。alloc_empty_file分配struct文件(f = __alloc_file(flags, cred);)。对于每个分配的结构文件，nr_files通过增加计数器来计算(ercpu_counter_inc(&amp;nr_files);)。在主机Linux内核中，struct文件的总数受files_stat的限制。Max_files(if(get_nr_files() &gt;= files_stat.max_files&amp;&amp;!capable(CAP_SYS_ADMIN))。如果达到限制，alloc_empty_file返回一个错误(return ERR_PTR(-ENFILE);)。 然而，Linux内核并没有提供任何namespace或cgroup来隔离或限制nr_files。因此，nr_files是可以直接控制所有容器的–任何容器对结构文件的分配都会增加相同的共享全局变量nr_files。 这样的nr_files共享会导致新的攻击。在Linux中，所有东西都是一个文件。如此多的操作，如文件打开、进程创建、管道创建、新的网络连接创建，甚至计时器创建(timerfd_create)和事件生成(eventfd)，都增加了nr_files。恶意容器可以很容易地将nr_files弹出到其上限。实际上，在我们的实验中，nr_files的配额可以在几秒钟内快速耗尽。因此，所有使用struct文件的操作都将失败。 影响是严重的:受害者容器甚至不能运行命令(因为它需要打开命令文件)或执行新的二进制文件，导致程序崩溃。从上面的例子中，我们发现即使容器有足够的物理资源，比如CPU或内存，如果没有nr_files中的配额，它仍然不能运行任何新的程序。 为了证明抽象资源攻击会影响所有内核功能，我们针对Linux内核功能的每个方面(包括进程、内存、存储和IO管理)提出了一个抽象资源攻击。在本节中，我们将展示本地测试环境上的攻击结果.。 对于本地测试环境设置，测试机器具有Intel Core i5 CPU, 8 GB内存和500 GB HDD，运行Ubuntu 18.04和Linux内核v5.3.1。我们将其称为主机。在主机上，我们使用docker 18.06.0-ce建立了两个docker容器，分别作为攻击者容器和受害者容器使用。我们按照docker安全最佳实践设置了这两个容器，即在不同的非根用户中运行它们，删除所有功能，启用namespace和cgroup，并应用seccomp系统调用阻塞，如threat model中所讨论的那样。 Attacks on Process Management为了实现进程管理，Linux内核引入了一系列的抽象资源，如进程控制块struct task_struct、pid、state和各种数据结构来支持派生实体,如用于线程的struct thread_info、struct rq runqueues用于调度,struct shm_info和struct semaphore用于进程间通信（IPC），struct spinlock和struct semaphores来实现同步。事实上，Linux中的进程管理引入了成千上万的抽象资源。在下面，我们介绍针对结构idr的攻击，作为一个的例子。 Attacking idr of PIDLinux内核引入了用于整数ID管理的struct idr。进程管理也使用idr进行pid分配。代码显示了alloc_pid函数，该函数调用idr_alloc_cyclic来获得一个新的pid。Idr_alloc_cyclic在idr分配期间检查pid_max，如果idr增长超过pid_max，则返回一个负错误代码。稍后我们将展示，即使启用了PID namespace和PID cgroup，idr仍然可以被视为所有进程的全局共享资源。类似于fork炸弹，恶意容器进程可以重复fork耗尽所有idr。因此，共享内核上的所有容器都不能创建任何新的进程或线程。 在我们的实验中，攻击者-容器通过调用fork系统调用反复生成进程。结果，在受害容器中，所有与创建新进程相关的操作都失败，并报错“资源临时不可用”。即使是主机上的根用户也会遇到同样的故障。 12345678910111213struct pid *alloc_pid(struct pid_namespace *ns,pid_t *set_tid, size_t set_tid_size)&#123; ... nr = idr_alloc_cyclic(&amp;tmp-&gt;idr, NULL, pid_min, pid_max, GFP_ATOMIC); ... if(nr &lt; 0) &#123; retval = (nr == ENOSPC) ? -EAGAIN : nr; goto out_free; &#125; pid-&gt;numbers[i].nr = nr; ...&#125; 这段C代码片段是Linux内核中的一部分，涉及到进程ID（PID）的分配。它定义了一个名为alloc_pid的函数，用于在给定的namespace ns中分配一个新的PID。 alloc_pid函数接受以下参数： struct pid_namespace *ns：进程ID的命名空间，用于将PID限制在特定的namespace范围内。 pid_t *set_tid：指向一个包含线程ID的数组，这些线程ID与新分配的PID关联。通常用于clone系统调用。 size_t set_tid_size：set_tid数组的大小。 在函数的主体中： idr_alloc_cyclic()函数被调用以在tmp-&gt;idr中分配一个新的ID，范围在pid_min和pid_max之间。GFP_ATOMIC标志表示内存分配应该是原子性的，即在不释放内核锁的情况下进行分配。 如果nr小于0，说明分配失败。根据失败的原因，retval被设置为-EAGAIN（当nr等于ENOSPC）或nr。然后跳转到out_free标签。 如果分配成功，pid-&gt;numbers[i].nr被设置为新分配的ID。 这段代码负责在给定namespace中分配和管理进程ID。 The effectiveness of the PID namespaceLinux v2.6.24引入了PID namespace，它为进程提供了一组独立的PID，这些PID来自其他PID namespace。但是，在PID namespace实现中，Linux内核会在根PID namespace中为其他PID namespace中分配的任何PID分配一个额外的PID，这样其他PID namespace中的所有PID都可以映射到根PID namespace。换句话说，根PID namespace仍然是全局共享的。因此，即使攻击者-容器处于分离的PID namespace中，其PID分配仍然会耗尽根PID namespace中的PID，从而导致victim-container和主机上的new-process-create失败。因此，即使启用了PID namespace，容器仍然容易受到上述idr耗尽攻击的攻击。 The effectiveness of the PIDs control group最近在Linux v4.3中也引入了PIDs cgroup。它的作用是用来限制分配在一个控制组中的PIDs的总数。更具体地说，PIDs控制组在进程分叉过程中检查进程的限制，如果PIDs控制组中的总进程数（pids_cgroup-&gt;counter）达到上限（pids_cgroup -&gt;limit），则返回错误并中止分叉。PIDs控制组在防御直接分叉方面是有效的。然而，它只向当前进程收取pid号。attacker-container可以欺骗内核来分叉大量的内核线程，比如频繁中止导致内核产生中断处理线程。通过这种方式，idr被内核线程耗尽，这就绕过了由 PIDs cgroup。 Attacks on Memory ManagementLinux内核引入了各种内核数据结构，例如mm_struct用于保存进程的所有内存相关信息，vm_area_struct用于表示虚拟内存区域。此外，为了提高读写效率，Linux内核还使用内存作为缓冲区来缓存某些数据。此外，还介绍了回写方案，即只对内存进行写操作。脏内存页稍后将由内核线程写入磁盘。使用write-back方案，调用方只需要写入内存，而不需要等待耗时的磁盘io操作完成(即wirtr-through)，这大大提高了写性能。然而，我们发现内核并没有隔离或限制脏内存区域的使用，这给了攻击者耗尽所有脏内存的机会，这大大减慢了其他容器的速度。接下来，我们讨论对脏内存的攻击。 Attacking dirty_throttle_control memory dirty ratioLinux内核为脏区控制引入了dirty_throttle_control结构体，它使用dirty字段表示整个内核空间的dirty ratio。只要dirty值太高，内核就会唤醒后台线程，将脏内存同步到磁盘。但同时由于dirty比过高，内核会阻塞write_back，将所有写都转换为write_through，写性能大大降低。 不幸的是，内核没有为内存dirty ratio提供任何隔离。任何进程都可能影响全局内存dirty ratio。在我们的攻击中，攻击者-容器使用dd命令生成文件，快速占用所有脏内存，达到内存dirty ratio限制。结果，来自主机或受害者容器的所有写操作都被转换为write_through，这极大地降低了性能。在我们的实验中，由于攻击，受害者容器上的命令dd if&#x3D;&#x2F;dev&#x2F;zero of&#x3D;&#x2F;mnt&#x2F;test bs&#x3D;1M count&#x3D;1024的性能从1.2 GB&#x2F;s下降到32.6 MB&#x2F;s，导致97.3%的减速。 此外，即使是主机上的特权根用户也有96.1%的性能下降。 请注意，当前Linux内核没有与内存管理相关的namespace，内存cgroup用于限制内存使用，而不是限制内存dirty ratio。因此，无法防御针对内存dirty ratio的攻击。 Attacks on Storage Management操作系统内核将磁盘或其他辅助存储抽象为文件，并引入各种与文件相关的抽象资源。实际上，Linux内核中的存储管理是复杂的，它涉及数千个函数和数据结构。在我们的实验中，我们发现有133个与存储相关的抽象资源可以从容器进程中访问。不幸的是，内核没有提供任何namespace或cgroup来隔离或限制这些抽象资源的使用。因此，攻击者容器可以耗尽这些抽象资源，对共享内核上的其他容器发起DoS攻击。 接下来，我们将说明恶意容器如何利用文件限制变量nr_files进行DoS攻击。 Attacking nr_filesnr_files是Linux内核中的一个全局变量，它计算内核中打开的文件总数。更具体地说，对于每个分配的结构文件，内核将nr_files加1。不幸的是，nr_files是所有进程共享的。它既不受namespace的隔离，也不受任何cgroup的限制。因此，攻击容器可以很容易地耗尽nr_files来实现DoS攻击。 为了验证这种攻击的可行性，我们的攻击容器生成了数百个进程，每个进程打开1024个文件。因此，nr_files达到其极限。结果，在主机和受害者容器上，所有文件打开操作都失败，内核发出“系统中打开的文件太多”的警告。我们的攻击证实，即使只有几百个进程，攻击者也能够耗尽nr_files。而为了可用性，pid cgroup通常允许数千个进程。因此，即使启用了pid cgroup，攻击者-容器仍然可以成功地对nr_files进行dos攻击。更糟糕的是，nr_files在所有进程(包括根进程和非根进程)之间共享。 因此，不仅非特权容器进程受到影响，主机上的根进程也不能执行任何文件打开操作。 12345678910111213141516171819202122232425static struct percpu_counter nr_files __cacheline_aligner_in_smp;static long get_nr_files(void)&#123; return percpu_counter_read_positive(&amp;nr_files);&#125;struct file *alloc_empty_file(int flags, const struct cred *cred)&#123; static long old_max; struct file *f; if(get_nr_files() &gt;= files_stat.max_files&amp;&amp;!capable(CAP_SYS_ADMIN)) &#123; ... goto over; &#125; f = __alloc_file(flags, cred); if (!IS_ERR(f)) percpu_counter_inc(&amp;nr_files); ...over: ... return ERR_PTR(-ENFILE);&#125; Attacks on IO ManagementIO管理是操作系统的重要组成部分。为了便于管理，Linux内核将IO设备抽象到/dev文件中，并引入抽象资源(如tty_struct)来实现IO设备管理。与前面的情况类似，这些抽象资源不受任何namespace或控cgroup的隔离或限制，因此会导致新的攻击。下面，我们将介绍针对pty_count的攻击，它会导致SSH连接出现DoS。 Attacking pty_countLinux内核将伪终端pseudo-terminal(缩写为pty)抽象为/dev/ptmx和/dev/pts。与此同时，内核还使用一个名为pty_count的全局变量来计算打开的pseudo-terminal的总数，每打开一次/dev/ptmx，pseudo-terminal的总数就增加1，如代码。但是，内核没有提供任何namespace或cgroup来隔离或限制pty_count的使用。因此，攻击者可以很容易地耗尽pty_count。 123456789101112131415161718static atomic_t pty_count = ATOMIC_INIT(0);int devpts_new_index(struct pts_fs_info *fsi)&#123; int index = -ENOSPC; if (atomic_inc_return(&amp;pty_count) &gt;= (pty_limit - (fsi-&gt;mount_ops.reserve ? 0 : pty_reserve))) goto out; return index;&#125;static int ptmx_open(struct inode *inode, struct file *flip)&#123; ... index = devpts_new_index(fsi); ...&#125; 这段C代码片段是Linux内核中的一部分，涉及到伪终端（PTY）的分配和管理。它定义了一个名为devpts_new_index的函数，用于在给定的文件系统信息fsi中分配一个新的伪终端索引。此外，还展示了一个名为ptmx_open的函数，它在打开伪终端主设备（PTMX）时调用devpts_new_index。 一个名为pty_count的原子变量被初始化为0。它表示当前分配的伪终端的数量。 devpts_new_index函数接受一个参数： struct pts_fs_info *fsi：一个指向伪终端文件系统信息的指针。 在devpts_new_index函数中： 初始化index为-ENOSPC，表示没有足够的空间分配新的索引。 增加pty_count的值。如果增加后的值大于等于pty_limit - (fsi-&gt;mount_ops.reserve ? 0 : pty_reserve)，则跳转到out标签。 返回index。 ptmx_open函数是在打开伪终端主设备（PTMX）时调用的。它接受两个参数： struct inode *inode：表示伪终端主设备（PTMX）的inode结构。 struct file *flip：表示伪终端主设备（PTMX）的file结构。 在ptmx_open函数中，调用devpts_new_index(fsi)以获取一个新的伪终端索引。 这段代码负责在给定的伪终端文件系统信息中分配和管理伪终端索引。当打开伪终端主设备（PTMX）时，会调用devpts_new_index函数以获取新的伪终端索引。 在我们的实验中，攻击者不断打开/dev/ptmx在触发ptmx_open，它调用devpts_new_index并增加pty_count。在几秒钟内，pty_count达到极限，所有接下来的ptmx_open操作都会失败。其后果很严重，因为pty设备被各种应用广泛使用，如SSH连接。结果是，由于伪终端打开失败，所有对任何其他容器的SSH连接尝试都会失败。更糟糕的是，主机无法启动任何新的容器，因为新容器的连接由于同样的错误而被拒绝。 Attacking FreeBSD and Fuchsia Kernels抽象资源攻击的根本原因是共享的内核数据(即抽象资源)。接下来，我们将演示共享内核数据还使FreeBSD和Fuchsia容易受到抽象资源攻击。 Attacking FreeBSD 在FreeBSD内核中，在Linux内核中类似的资源之后，我们手动识别了5个共享的全局抽象资源，分别是dp_dirty_total、numvnodes、openfiles、pid和pty。我们的实验进一步证实了前两个可以被DoS攻击，而后三个则受到rctl per-jail的限制。 实验是在FreeBSD 13.0-RELEASE和Ezjail-admin v3.4.2上进行的，运行在具有Intel酷睿i5处理器、8GB内存和40GB硬盘的虚拟机上。Ezjail是一个jail管理框架。ezjail命令提供了一种使用FreeBSD的jail系统创建多个jail的简单方法。这里的jail类似于Linux上的容器。我们根据FreeBSD手册建立了两个jail，并使用rctl来限制每个jail的资源。我们使用这两个jails作为attacker-jail和victim-jail，这类似于§3.1中的容器设置。 对于脏计数器dp_dirty_total, FreeBSD中的ZFS引入了dsl_pool结构体来记录每个ZFS池的数据。dsl_pool结构体使用dp_dirty_total字段表示整个ZFS池脏数据。当dp_dirty_total达到zfs_dirty_data_max的限制时，ZFS将延迟即将进行的写操作，并等待脏数据同步到磁盘。不幸的是，FreeBSD没有为dp_dirty_total提供任何隔离。在attacker-jail中，我们运行命令dd if=/dev/zero of=/mnt/test bs=1M count=1024(与§3.3中的相同)来耗尽dp_dirty_total。因此，victim-jail的IO性能下降了46%。 对于numvnodes, FreeBSD使用vnode结构体来表示文件系统实体，例如文件或目录。FreeBSD还保留了一个全局变量numvnodes来记录整个内核中vnode的总数。极限在maxvnodes。在实验中，通过在attacker-victim中重复创建目录，我们可以很容易地耗尽主机的numvnodes并达到maxvnodes的限制。 Attacking Fushsia Fuchsia使用Zircon内核，他引入了handle的概念，允许用户空间程序引用内核对象。Zircon维护了一个名为gHandleTableArena的全局数据结构，用于分配所有句柄。内核中handle的限制是kMaxHandleCount。handle在Zircon中使用非常频繁。令人惊讶的是，我们发现handle的创建不受限制。我们在Fuchsia模拟器上进一步确认了这个问题。具有基本权限(类似于Linux中的功能)的用户可以重复创建handle，耗尽所有handle，从而导致整个系统崩溃。我们向Fuchsia开发人员报告了这个问题。他们已经确认了这个问题，并计划在确定更多的攻击载体到本地DoS后修复这个问题。 Summary从上面的讨论中，很容易看出抽象的资源攻击是非常实用的，后果是严重的。更糟糕的是，抽象资源在Linux内核中非常常见，影响Linux功能的各个方面。此外，抽象资源攻击是操作系统级虚拟化所固有的。它也适用于FreeBSD和Fuchsia内核。 Static Analysis Of Container-Exhaustible Abstract Resources如前所述，抽象资源对容器至关重要。 另一方面，有成千上万的抽象资源，这使得几乎不可能列举所有这些资源。在本文中，我们迈出了识别容器共享的可耗尽抽象资源的第一步。 Challenges 首先，很难识别有意义的抽象资源，尤其是那些在内核中共享的资源。Linux内核中的抽象资源可以是变量或数据结构实例。然而，并非所有变量或数据结构实例都是有意义的抽象资源。我们需要找到对操作系统功能至关重要的抽象资源。此外，所识别的抽象资源需要在容器之间共享，以便一个容器可以耗尽这些资源来攻击其他容器。不幸的是，没有关于可共享抽象资源的文档。 为了解决这个问题，我们建议使用基于配置的分析configuration-based analysis和基于访问的分析access-based analysis来识别Linux内核中的各种共享抽象资源。 其次，决定容器是否可以用尽特定的抽象资源是一个挑战。与普通的用户空间程序不同，从容器中访问资源面临更多的限制，如namespace、cgroup和seccomp。此外，由于每个容器在一个单独的用户中运行，其资源消耗也受到每个用户的限制。因此，对资源消耗点的简单可达性分析不能说明容器对抽象资源的可控性。例如、对于被namespace隔离的抽象资源，即使容器可以消费这些抽象资源，由于namespace的隔离，它仍然可能不会影响其他容器。因此，为了克服这一挑战，我们提出了容器可控性分析，包括seccomp限制分析、per-user限制分析和namespace隔离分析，以进一步过滤容器可耗费的资源。 图显示了我们的工具的体系结构，它自动识别出容器可耗尽的抽象资源。分析工具以内核源IR作为输入。它首先使用§4.1中基于配置的分析和基于访问的分析来识别所有内核可共享的抽象资源。然后进行§4.2中的系统调用可达性分析和容器限制分析，包括seccomp、per-user和namespace限制分析，分析这些抽象资源上的容器可控性。 此外，我们在§4.3给出了分析结果。 Identification of Kernel Shareable Abstract Resources如前所述，从成千上万的内核变量和数据结构实例中识别有意义的抽象资源具有挑战性。更困难的是，为了确保这些抽象资源在容器之间直接或间接地共享，我们需要将它们缩小到可共享的内核抽象资源。 为了克服这一挑战，我们利用内核编程范例并提出基于配置的分析和基于访问的分析来识别内核可共享资源。 Configuration-based AnalysisLinux内核在/proc/sys下提供sysctl接口，允许用户空间程序配置内核参数。我们的主要观察结果是，这些sysctl配置中的大多数用于抽象的资源限制，例如限制文件数fs.file-nr或内存大页vm.nr_hugepages。因此，所有容器都共享由sysctl配置指定的相同全局限制。这样的sysctl配置提供了关于容器之间可共享的抽象资源的重要线索。 基于上述观察，我们建议使用sysctl配置来识别可共享的内核抽象资源，称为基于配置的分析，它包括三个基本步骤。 首先，它使用特定的sysctl数据类型来识别所有的sysctl相关数据结构。这些数据结构包含可配置的sysctl内核参数。 其次，sysctl数据结构通常包含在/proc/sys/文件夹中显示sysctl值的函数。因此，通过分析该函数，我们能够准确地找出该内核参数的变量。 最后，如果一个内核参数被用于限制资源消耗，它的相应变量应该出现在比较指令中。因此，我们按照使用-定义链来检查所确定的变量的使用情况，如果它在比较指令中被使用，就把它标记为抽象资源。 我们在LLVM中设计并实现了一个过程间分析通道。我们在代码中使用一个示例来说明细节。具体来说，Linux内核使用类型struct ctl_table来配置sysctl内核参数，例如代码中的第1行所示的fs_table中的文件系统配置。 因此，该通道首先遍历所有的内核全局变量，收集所有的结构ctl_table变量，如代码中的fs_table。其次，fs_table使用proc_handler中的函数指针来显示/proc/sys/文件系统中的参数。因此，从遍历所有的内核全局变量来收集所有的结构ctl_table变量，如代码中的fs_table。 第二，fs_table使用proc_handler中的函数指针来显示/proc/sys/文件系统中的参数。因此，从proc_handler字段中，通证遵循其指向，启动程序间分析以获得确切的变量，其值显示在sysctl配置界面中。如代码第19行所示，我们的传递将nr_files标记为关键变量。 第三，我们的传递检查所有已识别的关键变量的使用情况。如果一个关键变量在比较指令中被使用（即LLVM IR中的icmp），我们的传递就会记录这些位置并将这个变量标记为抽象资源。例如，在代码的第25行，nr_files被用于比较。我们的传递进一步检测到，如果比较失败，在第25行和第27行会返回一个错误。因此，我们的传递将nr_files标记为一个抽象资源。通过分析所有的struct ctl_table，我们的传递得到一个抽象资源的集合。 12345678910111213141516171819202122232425262728293031static struct ctl_table fs_table[] = &#123; ... &#123; .procname = &quot;file-nr&quot;, .data = &amp;files_stat, .proc_handler =proc_nr_files, &#125;, ...&#125;int proc_nr_files(...)&#123; files_stat.nr_files = get_nr_files(); ...&#125;static long get_nr_files(void)&#123; return percpu_counter_read_positive(&amp;nr_files);&#125;struct file *alloc_empty_file(int flags, ...)&#123; ... if(get_nr_files() &gt;= files_stat.max_files &amp;&amp; !capable(CAP_SYS_ADMIN)) &#123; ... goto over; &#125; ...&#125; 这个代码片段是一个C代码，用于管理Linux内核模块中的文件资源。它定义了一个名为fs_table的ctl_table结构数组、一个用于设置当前打开文件数量的proc_nr_files函数、一个返回打开文件数量的get_nr_files函数，以及一个在打开文件数量未超过允许的最大值时分配新文件结构的alloc_empty_file函数。 以下是各个组件的详细解释： fs_table是一个ctl_table结构数组，用于定义/proc/sys/fs/目录中的sysctl条目。具有procname为”file-nr”的条目与当前打开文件的数量相关联。 proc_nr_files是一个设置当前打开文件数量的函数。当调用该函数时，它会使用get_nr_files()函数返回的值更新files_stat.nr_files。 get_nr_files是一个返回当前打开文件数量的函数。它通过从名为nr_files的percpu_counter结构中读取一个值来实现这一点。该结构用于以适用于多核系统的高效方式存储文件数量。 alloc_empty_file是一个尝试分配空文件结构的函数。它检查当前打开文件的数量（由get_nr_files()返回）是否大于或等于最大允许的文件数量（存储在files_stat.max_files中）。如果满足此条件且调用者没有CAP_SYS_ADMIN能力，则跳转到标签over，这个标签可能处理文件数量超过最大值的情况。 这个代码片段是Linux内核如何管理文件资源并对同时打开的文件数量施加限制的一个例子。 Access_based Analysis除了sysctl配置外，Linux内核还使用锁或原子机制来保护并发访问的资源。因此，我们建议使用并发访问作为标识来标识一组可共享的抽象资源。 由于（race condition）竞态条件和并发性分析是一个老话题，我们采用现有的lockset检测方法。如果锁在数据结构的某个字段上，我们将该数据结构标记为抽象资源，并将该函数添加到敏感函数集中。具体来说，如果在某个数据结构的字段上使用了锁，那么可以将此数据结构标记为抽象资源，并将涉及该字段的函数添加到敏感函数集合中。这意味着这些函数可能需要特别关注，因为它们可能会受到并发访问的影响。此外，如果一个变量在lock和unlock函数之间被定量地修改，我们也将其标记为抽象资源。例如，多个线程在没有锁保护的情况下访问同一数据结构，那么可以将这组资源标记为抽象资源。如果某个变量在 lock 和 unlock 函数之间被定量地修改（即，在锁保护下发生了修改），那么也可以将其标记为抽象资源。这有助于进一步确定可能受到并发影响的资源。 除了锁定&#x2F;解锁，我们还观察到原子计数器和percpu计数器还用于保护并发访问的数据，例如percpu_counter_inc和atomic_inc_return。因此，我们实现了一个pass来分析所有原子计数器和percpu计数器的使用情况。我们的传递首先分析函数参数，并将所有具有struct atomic_t、struct atomic64_t和struct percpu_counter参数的函数添加到原子/percpu函数集中。其次，遍历所有内核函数中的所有语句，以检查原子/percpu函数的所有使用情况。如果一个变量被传递给一个原子/percpu函数，我们将它标记为一个抽象资源。 识别具有原子/percpu计数器参数的函数. 遍历内核函数中的语句，检查原子/percpu函数的使用情况。 在实现过程中，我们发现LLVM链接器合并了具有相同内存布局的结构类型，例如typedef struct &#123;int counter;&#125; atomic_t和typedef struct &#123;uid_t val;&#125; kuid_t。原因是uid_t的类型是unsigned int，它的大小与int相同。因此，LLVM链接器将它们合并，并错误地使用kuid_t代替atomic_t。为了解决这个问题，我们跟踪LLVM链接器，并发现lib/ linker / irmove .cpp中的get方法将新类型与现有类型进行比较，如果内存布局相同，则合并它们。因此，我们通过注释掉比较和合并代码来禁用合并。 Container-Contorllability Analysis通过识别抽象资源，我们提出了容器可控性分析，以确保容器实际上可以消耗这些抽象资源。我们对容器可控性分析的想法是（two-fold）双重的。 首先，我们需要确保容器进程可以到达§4.1中的抽象资源消耗点。为此，我们基于内核控制流图执行传统的反向控制流分析，其中基于结构类型解析间接调用。如果没有从系统调用项到抽象资源消耗点的路径，我们将该抽象资源标记为容器不可访问的。 其次，注意，单靠可达性分析是不够的，我们需要进一步确保路径上没有额外的特定于容器的限制。换句话说，我们需要检查路径上是否存在任何限制检查，以确保容器可以耗尽这些抽象资源。如前所述，与用户空间程序不同，容器面临更多限制，如seccomp、namespace、cgroup以及每个用户的资源限制。由于我们的可达性分析是标准的，在接下来的文章中，我们将重点关注限制分析。 Seccomp Restriction AnalysisSeccomp是一种用于系统调用过滤的机制。我们对seccomp的限制分析如下。在我们的实现中，我们使用Docker默认的seccomp配置文件，它可以阻止超过50个系统调用。在从系统调用条目到资源消耗站点的所有路径中，我们过滤掉来自任何阻塞的系统调用的路径。 Per-User Restriction Analysis在实际部署中，容器通常以不同的用户运行。因此，每个容器的资源消耗也受到peruser资源配额的限制。例如，Linux提供了user-limits命令ulimit，用于限制用户的资源消耗。而ulimit的底层实现是使用rlimit来设置多个每个用户的资源配额。 除了ulimit, Linux还提供了允许用户利用PAM (Pluggable Authentication Module)部署每个用户配额的接口。PAM使用setup_limits函数来设置每个用户的资源配额，该函数调用setrlimit来配置多个rlimit约束。对于ulimit、rlimit和PAM所限制的资源，攻击者容器不能消耗超过每个用户配额的资源。因此，它无法完全控制这些抽象资源来发起DoS攻击。由于ulimit和PAM都使用rlimit来设置每个用户的资源配额，因此我们需要分析rlimit并过滤出受其限制的抽象资源。 对于rlimit分析，我们的关键观察是rlimit值通常在struct rlimit或struct rlimit64中指定。因此，我们首先遍历内核IR，以识别从struct rlimit或struct rlimit64加载的所有变量。然后，我们执行数据流分析，以跟踪这些变量的所有传播和使用，并在任何比较指令中使用这些函数时标记它们。在这些函数中，检查rlimit以限制某些资源。我们认为这些资源是攻击容器不可耗尽的，因此我们根据这些函数来过滤路径。我们的工具确定了40个检查rlimit的函数。 Namespace Isolation Analysis如前所述，Linux内核为资源隔离引入了namespace。对于namespace隔离的资源，Linux内核在每个namespace下为其创建一个“copy”，以便一个namespace中的修改不会影响其他namespace。因此，为了确认容器的可控性，我们需要确保那些抽象资源不受namespace的保护。这里的挑战是，尽管Linux有关于namespace的文档，但没有关于哪些抽象资源由namespace隔离的规范。 因此，我们提出了namespace隔离分析来系统地识别受namespace保护的抽象资源。 我们的主要观察结果是，对于namespace隔离的资源，对应的数据结构有一个指针字段，指向它所属的namespace。因此，我们的工具首先遍历内核中每种数据结构类型的所有字段。如果该类型具有名称空间指针，则将其标记为隔离资源。其次，对于已识别的隔离资源，我们的工具使用它来过滤§4.1中识别的共享抽象资源。 请注意，由于不同namesapce之间的映射，一些namespace隔离的资源仍然容易受到抽象资源攻击。如§3.2.2所述，idr由pid_namespace-&gt;idr隔离。但是，在非根PID namespace中分配的每个idr都映射到根PID namespace中的一个新的idr，以便根namespace可以管理它。因此，根PID namespace被所有PID namespace中的所有容器全局共享。因此，它仍然容易受到idr耗尽攻击。 在我们的分析中，我们手动过滤掉这些资源。 Analysis Results我们在LLVM 12.0中使用大约2500行c++代码实现了我们的分析工具。Linux内核IR是基于最新的Linux稳定版本v5.10和defconfig生成的。特别是，通过应用基于配置的分析和基于访问的分析，以及来自系统调用的可达性分析和seccomp限制分析，我们的工具确定了1844个容器可达的共享抽象资源。 Resource Filtering 通过每个用户配额限制和namespace隔离分析，我们的工具可以找到342个受rlimit限制或具有指向namespace结构的指针的资源。这些资源要么对路径进行限制检查，要么对其进行namespace。 我们进一步进行手工分析。具体来说，对于已识别的抽象资源中的每个资源𝑅，我们将遍历所有检测到的𝑅或𝑅字段的修改。如果修改不是定量的，比如被赋值为布尔类型、枚举类型或字符串类型，则将此修改标记为非定量的。如果对𝑅和𝑅字段的所有修改都是非定量的，我们将𝑅标记为不可耗尽的。我们的手工分析确定了492种不可耗尽的抽象资源，经过人工分析，仍然有1010个抽象资源。 Dynamic Validation 为了进一步验证这1010个资源的动态耗尽，我们开发了一个资源消耗的动态验证方法。对于每个资源，我们首先从可控性分析中获得其消耗点和触发的系统调用。在此之后，我们对这些消耗站点进行测量，以监控实际的资源消耗。接下来，我们执行相应触发系统调用的测试用例，以重复触发消费并记录结果。我们利用来自Linux测试项目的1156个测试用例，并开发177个新的用例来覆盖更多的用例。我们还开发脚本来自动化上述步骤。 我们应用动态验证方法来测试所有1010个资源的消耗。 对于1010个检测到的资源，其中700个不在驱动程序文件夹中，而其他310个资源在驱动程序文件夹中，在700个非驱动资源中，有389个资源可以动态重复触发，真阳性率为55.6%。驱动程序文件夹中的资源需要特别处理，原因有两个。首先，驱动程序是特定于硬件的。如果没有相应的硬件，就无法动态触发驱动程序代码。我们的主要观察结果是，大多数硬件支持的驱动程序在/dev或/sys/class文件夹下公开特定的接口。基于这种观察，我们删除了硬件不支持的驱动程序中的92个资源。第二，LTP提供的测试用例可能不覆盖特定的驱动程序。 为了解决这个问题，我们修改LTP测试用例并为驱动程序开发新的测试用例。218个驱动资源中，有112个驱动资源可以重复触发，真阳性率为51.4%。 识别容器可耗尽抽象资源是一项非常具有挑战性的任务，因为它需要领域知识来触发抽象资源的耗尽，并且需要评估这些资源耗尽时的影响。在本文中，我们进行了初步分析。请注意，彻底的分析和风险评估需要来自Linux内核和容器社区的帮助。因此，我们计划开源我们的工具和检测到的抽象资源。我们认为这将有助于Linux内核和容器社区识别资源隔离的弱点，并开发健壮的资源遏制方案。 Abstract Resource Attacks On Cloud Platforms在本节中，我们将进一步评估针对公共云供应商容器环境的抽象资源攻击。我们首先介绍环境设置，然后给出结果。 Environment Setup and Ethical Considerations为了评估抽象资源攻击的有效性，我们在本地和云平台上建立了容器环境。 本地测试环境已在§3.1中给出。 Ethical Considerations 对于云平台，我们打算尽可能减少我们的攻击对其他云用户的影响。因此，我们使用专用的虚拟服务器，如AWS EC2、Azure VM、谷歌GCE、阿里巴巴ECS来进行实验。此外，我们确保我们是该服务器的唯一用户。 此外，大多数容器用户利用容器编排系统来部署和管理容器。因此，我们选择了最流行的Kubernetes，并利用云供应商的Kubernetes服务在虚拟服务器上部署两个docker容器(即攻击者容器和受害者容器)。为了实现强隔离，我们为attacker-container和victim-container应用了不同的Kubernetes namespace。如§4.2所述，容器也受到每个用户配额的限制。为了在我们的实验中强制执行每个用户的配额，我们在不同的用户中运行攻attacker-container和victim-container，并强制执行每个用户的配额。我们还在§6中讨论了PAM可以部署的限制。 Amazon AWS 对于容器服务，我们使用Elastic Kubernetes Service (EKS)在EC2实例上部署两个容器实例。EC2实例包含4个cpu、8gb内存和20gb SSD磁盘。在容器部署期间，我们惊奇地发现“Amazon EKS默认pod安全策略”使用了EKS。特权为默认pod安全策略。请注意，此策略允许容器作为特权用户运行，还允许特权升级以及主机网络访问。 为了更好地演示我们提出的攻击的有效性，我们从本地测试环境采用了更强的安全策略，从EKS容器运行在非根用户中，删除所有特权，启用所有namespace和cgroup，并使用docker seccomp配置文件来阻止50多个敏感系统调用，包括ptrace、pivot_root等。我们对attacker-container和victim-container应用相同的安全策略。 MS Azure我们使用Azure Kubernetes服务（AKS），在Azure虚拟机上部署了两个容器实例。Azure虚拟机包含2个CPU、8GB内存和120GB磁盘。为了提高部署的容器的安全性，Azure在AKS中提供了pod安全策略的最佳实践，通过在yaml文件中设置runAsUser:1000，以非root用户的身份运行容器，并通过设置allowPrivilegeEscalation: false，拒绝特权升级。然而，它仍然增加了两种能力，即CAP_NET_ADMIN和CAP_SYS_TIME，并且没有强制执行seccomp。与AWS的设置一样，我们对AKS上的容器采取了更严格的安全策略。除了最佳实践建议（即非root用户和不允许特权升级），我们以非root用户运行AKS容器，放弃所有功能，启用所有的namespace和cgroup，并使用docker seccomp配置文件。来阻止50多个敏感的系统调用。我们对attacker-container和victim-container应用相同的安全策略。 Google Cloud 对于容器服务，我们选择Kubernetes并使用谷歌Kubernetes Engine (GKE)在谷歌计算引擎实例上部署两个容器实例。我们使用的谷歌计算引擎(GCE)实例包含4个cpu、16gb内存和100gb SSD。更具体地说，我们应用一个GCE实例，并基于该GCE实例上的常规运行时部署两个容器(即attacker-container和victim-container)。 对于容器部署，我们遵循GKS容器设置向导。谷歌Cloud提供了操作容器的最佳实践，建议避免使用特权容器。因此，在yaml配置文件的securityContext中，我们不允许特权升级，以非特权用户运行容器，并删除所有功能。GKS设置向导默认启用6个namespace和13个cgroup。此外，我们应用docker默认的seccomp配置文件来过滤敏感的系统调用。 此外，GKE还提供了谷歌的安全容器运行时- gvisor，它利用名为Sentry的用户空间内核为来自应用程序的系统调用提供服务。哨兵调用大约50个主机系统调用，根据需要提供服务。gVisor被认为是容器的安全沙盒运行时。对于基于gVisor的容器部署，其所有安全设置(包括非特权用户、删除功能)都与GKE docker运行时设置相同。 Alibaba Cloud 在容器服务方面，阿里云提供了弹性容器实例、Kubernetes容器服务、容器注册和阿里云服务Mesh。我们使用Kubernetes的容器服务在一个弹性计算服务(ECS)实例上部署两个容器实例。ECS实例包含4个cpu、16gb内存和120gb SSD盘。对于容器安全性，我们遵循容器服务部署的官方指南，该指南通过将runAsUser设置为1000来使用非根用户运行容器。但是，它并不禁止特权升级，也不强制执行seccomp和SELinux。 我们采取了与以往相同的更强有力的安全政策。我们在非根用户中运行容器，删除所有功能，启用所有namespace和cgroup，并使用docker seccomp配置文件来阻止敏感的系统调用。我们对attacker-container和victim-container应用相同的安全策略。 Selection of Abstract Resources为了进行攻击，我们需要选择有意义的抽象资源。为了演示抽象资源攻击的有效性，我们希望选择影响操作系统服务各个方面的抽象资源，包括进程管理、内存管理、存储管理和IO管理。 因此，我们首先根据它们的声明位置将所有标识的资源分为这四类，即用于进程、内存、存储和IO管理的资源。然后，我们根据我们的领域知识从每个类别中选择至少一个资源，即我们知道资源耗尽的影响。 最终，我们选择了涵盖所有四个方面的7个抽象资源，。资源名称列在表的第二列中。在所选的抽象资源中，基于访问分析识别出PID idr、dirty ratio、inode、netns_ct-&gt;count、random entropy个，基于配置分析识别出nr_files、pty_count 2个，如表第三列所示。我们还在表的第四列中列出了资源消耗函数，在表的最后一列中列出了用于触发攻击的系统调用。 Attacking Results on Cloud Platforms如前一节所述，我们为我们提出的攻击设置了5个测试环境，包括本地、AWS、Azure、谷歌云和阿里云。对于每个测试环境，我们设置了两个具有严格安全策略的容器，作为attacker-container和victim-container。attacker-container针对某些抽象资源发起攻击。我们使用上述7个选定的抽象资源来发起攻击。在victim-container和主机上都运行一个基准测试，以测量它们在抽象资源攻击下的性能下降。结果如表所示。 PID idr攻击。PID idr攻击及其根源已在§3.2.1中详细介绍。针对厂商的PID攻击，所有受害容器，甚至在Local、AWS、Azure和谷歌测试环境中的主机都不能fork新的进程。victim-container甚至会被驱逐。阿里云不容易受到PID攻击。 dirty ratio攻击。dirty ratio攻击已经在§3.3.1中讨论过。如果没有攻击，则认为IO性能为100%。在dirty ratio攻击下，受害容器在AWS、Azure和阿里云上的IO性能分别下降到6.3%、1.2%和6.7%。更糟糕的是，主机也容易受到这种攻击，其IO性能在AWS上下降到8.3%，在阿里云上下降到8.6%。这里MS Azure不提供对主机的任何访问，因此我们无法获得Azure主机IO性能。谷歌云不容易受到dirty ratio攻击。 inode攻击。在inode攻击中，受害者容器不断分配inode结构。不幸的是，mount namespace没有隔离inode。Linux内核都不提供任何与inode相关的cgroup。结果，该分区上的所有inode都被耗尽。所有消耗inode的操作都会失败，包括来自victim-container或主机的操作。在我们的实验中，阿里云很容易受到inode攻击。victim-container甚至会被驱逐。此外，主机也不能创建任何新文件。 nr_files攻击。nr_files攻击已经在§3.4.1中讨论过。nr_files由所有容器全局共享。没有namespace或cgroup来限制它的使用。当nr_files配额耗尽时，各种操作都会失败，包括打开文件、执行新程序、创建管道、创建套接字和创建计时器，因为Linux中的所有东西都是文件。我们的实验表明，所有排名前4的供应商都容易受到nr_files攻击。 pty_count攻击。pty_count攻击已经在§3.5.1中讨论过，它会耗尽所有开放的伪终端配额。这将导致所有需要打开新的伪终端的操作失败，如SSH连接等。不幸的是，所有前4个供应商都容易受到pty_count攻击。 netns_ct-&gt;count攻击。Linux内核中的Netfilter提供了连接跟踪功能，可以跟踪所有的逻辑网络连接。而总连接数是有限制的，由struct netns_ct-&gt;count来计数。主机和容器都需要维护连接。尽管容器位于不同的net namespace中，但它们的所有连接都需要使用init_net.ct。主机的init net namespace的计数。因此，如果在短时间内产生大量的TCP连接，就会消耗掉init_net.ct的所有配额。计数，导致Netfilter故障。在我们的实验中，attacker-container可以耗尽init_net.ct。数秒内计数，导致随机丢包。同样，前4个供应商的所有环境都容易受到结构体netns_ct-&gt;count攻击。 random entropy攻击。在Linux内核中，每次读取/dev/random都会消耗random entropy。每当random entropy下降到阈值以下时，Linux内核就会阻塞对/dev/random的读取操作，并等待entropy增加。 由于没有namespace或cgroup来隔离random entropy，attacker-container很容易通过反复读取/dev/random来消耗所有的random entropy，从而导致良性的读取阻塞。最新的Linux内核v5.10通过将/dev/random读重定向到/dev/urandom修复了这个问题。然而，Azure和阿里云都容易受到这种攻击。 Attacking gVisor我们还对gVisor进行了7种资源攻击。为了建立gVisor环境，我们在谷歌Kubernetes Engine (GKE)中选择runsc而不是runc作为容器运行时，如§5.1所述。其中nr_files攻击和netns_ct-&gt;count攻击两种攻击在gVisor环境下仍然有效。在接下来的文章中，我们将分析为什么这两种攻击可以在gVisor上工作。 对于nr_files, gVisor使用Sentry为系统调用服务，而Gofer为Sentry处理不同类型的IO。Sentry拦截来自容器的open syscall并将请求发送给Gofer。在另一边，Gofer通过调用主机操作系统的openat系统调用来处理该请求。最终，主机操作系统上的openat系统调用触发了alloc_empty_file函数，它消耗了nr_files。通过这种方式，gVisor的攻击者能够耗尽主机的nr_files。对于netns_ct-&gt;count，Sentry拦截连接系统调用，并使用自己的网络堆栈将数据包转发到主机中创建的veth-peer网卡。vth -peer连接到主机中的虚拟网桥。当网络帧通过虚拟网桥转发时，主机上的netfilter被触发调用nf_conntrack_alloc函数，该函数消耗netns_ct-&gt;count。因此，gVisor中的攻击者仍然可以耗尽主机的netns_ct-&gt;count。 Summary对于自部署的共享内核容器环境，其中两个易受6次攻击，一个易受5攻击，另一个易受4攻击。令人惊讶的是，gVisor运行时也容易受到两种攻击——nr_files攻击和netns_ct-&gt;count攻击。我们已经向所有四个供应商报告了这些攻击。他们都确认了问题存在于他们的共享内核容器环境中。 尽管顶级供应商使用虚拟机来隔离不同租户的容器，但由于几个原因，抽象资源攻击仍然是可行的。首先，正如在Linux、FreeBSD和Fuchsia上所演示的，抽象资源攻击是操作系统级虚拟化所固有的，因此是一种广泛的攻击类型。其次，没有经验的用户可能不了解共享内核的风险，可能会使用容器进行sand-boxing。我们的论文将有助于提高对风险的认识。第三，即使在同一个租户中，竞争的团队也可能通过利用抽象资源来攻击对方。因此，监控和减轻此类攻击仍然是必要的。 Mitigation Discussions在本文中，我们揭示了除了物理资源，容器还共享底层运行内核的抽象资源。这些抽象资源很容易被攻击，后果很严重。在下面，我们给出了多种策略来降低抽象资源带来的风险。 Using PAM for per-user quota restrictions 正如正如第4.2节中提到的，Linux内核提供了允许用户加载用户定制的PAM的接口。PAM能够限制18种资源，其中5种为抽象资源，包括maxlogin/maxsyslogins、nofile、nproc和sigpending。从我们与云计算供应商的沟通中，我们不知道有任何云计算供应商采用PAM。因此，我们建议对某些抽象资源的限制使用PAM。§4.2节提到的，Linux内核提供了允许用户加载用户定制的PAM的接口。PAM能够限制18种资源，其中5种为抽象资源，包括maxlogin/maxsyslogins、nofile、nproc和sigpending。从我们与云计算供应商的沟通中，我们不知道有任何云计算供应商采用PAM。因此，我们建议对某些抽象资源的限制使用PAM。 Using VM for strong isolation 对于安全关键型应用程序，我们建议不要使用多租户容器环境。更强的隔离方案，例如基于虚拟机的虚拟化，是更可取的。 Using Monitoring Tools 我们建议使用Kubernetes集群的监控工具，如Falco，来监控容器的资源消耗。对于敏感的抽象资源(如nr_files和inode)，用户应该自定义自己的规则来监视系统中特定的资源消耗。 Improving current isolation design 对于现有的namespace，如qPID namespaceq，由于映射到根qnamespaceq的设计，无法防御资源耗尽攻击。如§3.2.2所述，Linux内核在根PID namespace中为在其他PID namespace中分配的任何idr分配一个额外的idr。因此，根PID namespace仍然是全局共享的。攻击者仍然可以很容易地耗尽根PID namespace中的PID，从而导致DoS攻击。出于类似的原因，即使被NET namespace隔离，nf-conntrack 数 netns_ct-&gt;count也可能被攻击。因此，Linux社区需要重新审视namespace的设计，消除namespace依赖关系以提高隔离性。 New kernel containment mechanisms Linux内核社区和容器社区需要投入更多精力来保护抽象资源。实际上，我们已经向Docker安全团队报告了这个问题。反馈是“Linux容器只能使用可用的内核隔离机制。如果没有内核机制来控制限制，容器就不能做任何事情来限制它”。因此，我们首先需要对所有容器共享的抽象资源进行彻底的分析，以便我们能够理解，更重要的是，清除它们的数据依赖关系。这需要全面的内核领域知识和大量的内核代码更改。而且，Linux内核最初并不是为支持操作系统级虚拟化而设计的。它的资源隔离和遏制是不完整的。因此，需要新的namespace和cgroup。 More restrictive system call blocking 从容器方面来看，目前，即使执行了seccomp，容器中的应用程序仍然可以访问大约250个系统调用。在我们了解这些系统调用的数据依赖性之前，建议执行更严格的seccomp配置文件来阻止更多不必要的系统调用。容器用户可以使用技术来获得更严格的seccomp配置文件，以减少潜在的抽象资源攻击的可能性 Related WorkVirtualization Techniques在云环境中有两种主流的虚拟化技术，基于vm的虚拟化和OS-level虚拟化。与基于vm的虚拟化相比，OS-level虚拟化越来越流行，因为它可以通过轻量级虚拟化实现完整的应用程序功能。为了充分了解性能优势，研究人员进行了一系列研究。Felter等人表明，通过使用一组涵盖多个资源的基准测试，Docker在所有情况下都可以获得比KVM更好的性能。Joy等人在性能和可伸缩性方面对Linux容器和虚拟机进行了比较。Zhang等人的研究表明，容器在大数据环境中具有比虚拟机更好的性能。 所有这些工作都表明，操作系统级虚拟化比传统的基于虚拟机的虚拟化具有更好的性能。然而，他们都没有注意到底层内核抽象资源的潜在影响。本文揭示了抽象资源引入的新的攻击面。 Resource IsolationLinux使用功能来禁止没有特定功能的进程访问相应类型的资源实例。 研究人员提出了基于Linux功能的方法，如Wedge ， Capsicum和ACES。这些工作执行更细粒度的能力控制，以减轻内存损坏攻击。然而，他们不能防御我们的DoS攻击，耗尽可访问的共享资源。 内存地址空间隔离是一种典型的资源空间隔离方案，避免内存地址资源耗尽。Linux命名空间隔离了§2.1中列出的8种资源。这些方案只能隔离有限类型的资源。资源容器建议扩展单片内核，隔离系统资源，在线程级对资源进行划分，类似于控制组。由于性能开销很大，使用资源容器来保护所有抽象资源是不切实际的。EdgeOS为边缘云部署了强隔离的操作系统。然而，采用没有硬件支持的微内核会比单片内核引入更多的开销。Faasm使用软件故障隔离(SFI)进行内存隔离，而在无服务器计算中使用名称空间隔离网络资源空间。然而，大多数共享资源仍然暴露在DoS攻击的威胁之下。 Container Security除了资源隔离之外，还有对容器安全性的研究。Gao等人发现，可以利用&#x2F;proc或&#x2F;sys的信息泄露，发动电源攻击。而同一研究小组还进行了5次攻击，产生带外工作负载，以打破Linux控制组的资源约束。但它们主要针对信息泄露问题或攻击CPU、IO等物理资源，而不是抽象资源。 Lin等人表明容器不能隔离内核漏洞。另一项工作使用静态分析来分析Docker的代码，以找到漏洞和修补代码之间的差异。然而，这些工作主要针对现有的漏洞和利用。相反，我们的工作引入了针对共享抽象资源的新攻击。 此外，还有加固集装箱的工作。Lei等人提出了一种名为SPEAKER的容器安全机制，以减少应用程序在容器中可用的系统调用。Sun等人开发了为每个容器提供安全策略隔离的安全namespace。另一项工作使用Intel SGX保护容器，它提供了一个低性能开销的小型可信计算基础。Brady等人实现了容器图像的安全评估系统。然而，所有这些作品中的容器仍然依赖于内核提供各种服务，因此仍然容易受到抽象资源攻击。 Conclusion在本文中，我们揭示了共享内核在操作系统级虚拟化中引入的一种新的攻击面。这些容器直接或间接地共享成千上万的抽象资源，这些资源很容易被耗尽，从而导致对其他容器的DoS攻击。 为了显示限制抽象资源的重要性，我们进行了抽象资源攻击，针对操作系统内核的不同方面的抽象资源。结果表明，攻击抽象资源具有很强的实用性和关键性。 抽象资源本身就难以包含。为了了解这些攻击面，我们首先进行了一次系统分析，以识别Linux内核中易受攻击的抽象资源。我们的工具成功检测了501个动态触发的抽象资源，从中选取了7个，并在排名前4的云供应商的自部署共享内核容器环境中进行了攻击实验。结果表明，所有环境都容易受到我们的攻击。为了降低风险，我们为容器用户和开发人员提供了一些建议。 My硬件虚拟化和OS-level虚拟化虚拟化技术通常可以分为两大类：操作系统级虚拟化（OS-level virtualization）和硬件虚拟化（hardware virtualization）。这两者的主要区别在于虚拟化层的位置以及资源分配方式。 操作系统级虚拟化（OS-level virtualization)操作系统级虚拟化是一种轻量级虚拟化技术，它允许在单个操作系统内运行多个独立的、隔离的应用程序或服务。在这种方式下，所有虚拟实例共享相同的操作系统内核，但每个实例拥有自己的文件系统、进程、网络等资源。 详细说明： 资源分配：操作系统级虚拟化使用容器（Container）技术将系统资源（如CPU、内存、磁盘、网络等）划分给各个虚拟实例。容器之间相互隔离，互不干扰。 性能：操作系统级虚拟化具有较低的性能开销，因为所有虚拟实例共享相同的操作系统内核，避免了多个操作系统之间的资源竞争。 灵活性：操作系统级虚拟化支持的操作系统类型受限于宿主机操作系统，因此在跨平台方面的灵活性较差。 实现方式： Linux：LXC（Linux Containers）、Docker FreeBSD：Jails Solaris：Zones&#x2F;Containers 硬件虚拟化（Hardware virtualization）硬件虚拟化是一种全面的虚拟化技术，它允许在单个物理机器上运行多个独立的、完全隔离的操作系统实例。在这种方式下，虚拟化层位于操作系统和硬件之间，为每个虚拟机提供一个虚拟硬件环境。 详细说明： 资源分配：硬件虚拟化使用虚拟机（Virtual Machine）技术将系统资源（如CPU、内存、磁盘、网络等）划分给各个虚拟实例。虚拟机之间相互隔离，互不干扰。 性能：硬件虚拟化具有较高的性能开销，因为每个虚拟机需要运行独立的操作系统内核，导致资源竞争和虚拟化开销。 灵活性：硬件虚拟化支持运行不同类型的操作系统，具有较强的跨平台灵活性。 实现方式： 基于软件的虚拟化：VMware Workstation、VirtualBox 基于硬件的虚拟化：Intel VT-x、AMD-V 虚拟化管理器（Hypervisor）：VMware ESXi、KVM（Kernel-based Virtual Machine）、Microsoft Hyper-V、Xen 总结起来，操作系统级虚拟化和硬件虚拟化的主要区别在于虚拟化层的位置以及资源分配方式。操作系统级虚拟化通过共享相同的操作系统内核实现较低的性能开销，但跨平台灵活性较差；硬件虚拟化允许运行多个独立的操作系统实例，具有较强的跨平台灵活性，但性能开销较高。 LLVMLLVM（Low Level Virtual Machine）是一个编译器基础设施项目，它提供了一系列模块化和可重用的编译器组件和工具链。LLVM的设计目标是为各种编程语言提供一个通用的中间表示（Intermediate Representation，IR），以及一套用于优化、分析和生成机器代码的编译器后端。LLVM项目包括一些子项目，如Clang（C、C++和Objective-C的编译器前端）和LLDB（一个调试器）。 LLVM的核心组件包括： LLVM IR：LLVM中间表示是一种低级别、类型化、平台无关的编程语言，用于表示程序的结构和行为。LLVM IR既可以表示为人类可读的文本，也可以表示为二进制格式。 编译器前端：编译器前端将源代码（如C、C++、Rust等）解析成LLVM IR。Clang是LLVM最著名的编译器前端，用于处理C、C++和Objective-C语言。其他语言也有针对LLVM的编译器前端。 优化器：LLVM提供了一系列通用的代码优化和转换通道，这些通道可以在LLVM IR上进行操作，例如：常量折叠、死代码消除、循环不变式代码移动等。优化器可以根据需要配置和组合，以生成高度优化的代码。 编译器后端：编译器后端将优化后的LLVM IR转换为特定架构的机器代码。LLVM支持多种目标平台，包括x86、ARM、MIPS、WebAssembly等。编译器后端还负责处理调用约定、寄存器分配和指令调度等底层细节。 LLVM的优势在于其模块化、可扩展和可重用的设计。这使得LLVM可以很容易地支持新的编程语言和硬件架构，而不需要重新实现整个编译器。这也使得LLVM成为了许多编程语言（如Rust、Swift和Julia）和平台（如WebAssembly、GPUs和FPGAs）的编译器基础设施的首选。 Linux cgroup的组织和结构cgroup 是一种用于限制和控制进程资源使用的实用工具： 限制资源：Linux cgroup 的主要目的是限制进程使用的资源，如 CPU 使用率、内存、磁盘 I&#x2F;O 等。这有助于确保系统上的各个进程不会过度消耗资源，从而影响其他进程或整个系统的性能。 控制组内进程：cgroup 负责管理和控制组内所有进程的资源使用。这意味着你可以将一组进程组织在一个 cgroup 中，并对整个组施加资源限制，而不是单独设置每个进程的限制。 树状结构：cgroup 的组织方式是树状结构，其中每个节点（cgroup）可以包含若干子节点（子 cgroup）。这种结构允许你对资源使用进行分层管理，通过在不同层次施加不同的限制，可以更灵活地控制进程资源使用。 子节点和父节点的资源关系：在 cgroup 树状结构中，子 cgroup 的资源限制包括其父 cgroup 的资源限制。这意味着子 cgroup 不能单独设置超出其父 cgroup 限制的资源使用。这有助于维护整体资源限制的一致性，并确保子 cgroup 不会因过度消耗资源而影响其父 cgroup 或整个系统。 递归强制执行：cgroup 树结构中的资源限制是递归强制执行的。这意味着一个 cgroup 的资源使用限制将受到其所有祖先（父、祖父等）cgroup 限制的约束。这可以确保在整个 cgroup 树结构中，资源限制得到恰当的执行和遵守。 总之，Linux cgroup 是一种用于限制和管理进程资源使用的实用工具。它采用树状结构来组织进程，允许分层管理资源，并通过递归强制执行来确保资源限制得到遵守。 fork炸弹和idrfork炸弹Fork 炸弹是一种拒绝服务攻击（DoS攻击），其目的是通过创建大量子进程耗尽系统资源，从而导致系统崩溃或无法响应。攻击者可以编写一个简单的程序，使其反复调用 fork() 系统调用，每次调用都会创建一个新的子进程。这些子进程可能会继续创建更多子进程，从而导致进程数量迅速增加。这种攻击方法也被称为“逻辑炸弹”或“蠕虫炸弹”。 在 Linux 系统中，fork() 系统调用用于创建一个新进程，它是当前进程的一个副本。新进程（子进程）继承了父进程的资源（如打开的文件描述符、内存映射等），并从父进程的当前执行点开始执行。子进程拥有自己的独立地址空间和资源，并分配一个唯一的进程 ID。 idr在 Linux 内核中，IDR（ID Radix Tree）是一种用于管理和查找整数类型对象标识符（如进程 ID、文件描述符等）的数据结构。IDR 是一种基于基数树（radix tree）的高效数据结构，可以快速查找、添加和删除 ID。IDR 用于分配唯一的 ID 给内核对象，如进程、线程、文件等，以便在内核中进行跟踪和管理。 fork 炸弹会通过创建大量子进程来耗尽所有可用的进程 ID，从而导致系统无法创建新的进程。这可能会导致系统性能下降、响应缓慢甚至崩溃。为了防止这类攻击，系统管理员可以通过设置进程数资源限制（如使用 ulimit 命令）或在容器中使用cgroup 限制进程数来保护系统。 clone系统调用clone() 系统调用是 Linux 中用于创建进程和线程的一个底层函数。与 fork() 相比，clone() 提供了更多的选项和灵活性，因为它允许程序员指定哪些资源应该在父进程和新创建的子进程之间共享。这使得 clone() 适用于创建轻量级的线程以及新的独立进程。 clone() 系统调用的原型如下： 1int clone(int (*fn)(void *), void *child_stack, int flags, void *arg, ...); 参数说明： fn：一个函数指针，指向子进程或线程开始执行的函数。子进程或线程运行结束后，这个函数应该返回一个整数值，用于表示退出状态。 child_stack：指向子进程或线程的栈空间的指针。子进程或线程在执行过程中将使用这个栈空间。 flags：用于指定子进程或线程的行为和资源共享的位掩码。这些标志包括 CLONE_VM（共享内存空间）、CLONE_FS（共享文件系统信息）、CLONE_FILES（共享文件描述符表）等。通过组合这些标志，程序员可以精细控制子进程或线程的行为。 arg：传递给 fn 函数的参数。通常，它是一个指向某种结构或数据的指针。 clone() 系统调用的返回值在父进程和子进程中有所不同。在父进程中，clone() 返回新创建的子进程或线程的进程 ID（PID）。在子进程中，clone() 返回 0。如果创建失败，clone() 返回 -1，并设置相应的错误码。 clone() 系统调用的使用相对复杂，通常不直接在应用程序中使用。在实践中，程序员更倾向于使用更高级别的库函数，如 pthread_create()（用于创建线程）或 fork()（用于创建进程）。这些库函数在内部使用 clone() 系统调用来完成进程和线程的创建。 脏内存脏内存（Dirty Memory）是计算机内存管理中的一个概念，指的是已经被修改过但尚未写回到持久存储（如硬盘）的内存数据。在操作系统和应用程序中，内存（RAM）被用作缓存，以加速对数据的访问。与磁盘相比，内存访问速度要快得多，因此将数据缓存在内存中可以提高系统性能。 当一个程序或操作系统修改了内存中的数据，与磁盘上的原始数据不再一致时，这部分内存就被称为 “脏内存”。脏内存中的数据最终需要写回到磁盘，以确保数据的一致性和持久性。以下是脏内存产生的一些常见场景： 文件系统缓存：操作系统通常会将磁盘上的文件数据缓存在内存中，以提高文件访问速度。当一个程序修改了文件内容时，内存中的缓存数据变为脏内存。这些脏内存数据最终需要同步回磁盘，以确保文件在磁盘上的内容与内存中的内容一致。 数据库缓存：数据库系统经常使用内存来缓存数据库表和索引中的数据。当数据库事务修改了表中的数据时，相应的内存缓存数据也会变为脏内存。这些脏内存数据需要在适当的时机写回到磁盘，以确保数据的一致性和持久性。 虚拟内存管理：在虚拟内存管理中，操作系统通过将内存中的数据与磁盘上的交换空间（或页面文件）进行交换，来模拟更大的内存空间。当操作系统需要将内存中的数据交换出去时，如果这部分数据是脏内存，操作系统需要先将其写回到磁盘，然后才能将其交换出去。 操作系统通常会使用一些策略来平衡脏内存的处理和系统性能。例如，Linux 内核通过监控脏内存占比（dirty ratio），在必要时触发后台线程将脏内存同步到磁盘。这样可以在提高系统性能的同时，确保数据的一致性和持久性。 Linux处理脏内存 Linux 内核如何处理脏内存（即已修改但尚未同步到磁盘的内存）的过程。在 Linux 内核中，dirty_throttle_control 结构体用于管理和控制脏内存。结构体中的 dirty 字段表示整个内核空间的脏内存占比（dirty ratio）。 当 dirty 值过高时，内核会唤醒后台线程（例如 pdflush、flusher 或 kswapd），将脏内存同步到磁盘。这有助于确保数据的一致性和持久性，防止意外丢失。 然而，如果 dirty 值太高，内核会阻塞 write_back 操作。这意味着内核将所有写操作都转换为 write_through 操作，从而降低写性能。接下来，我们解释 write_back 和 write_through 之间的区别： write_back：在 write_back 操作中，数据首先写入缓存（例如 CPU 缓存或文件系统缓存）。一旦数据被写入缓存，操作就被认为是完成的，即使数据尚未同步到磁盘。在后台，脏数据会在适当的时机被刷新到磁盘。write_back 的优势在于它可以提供较高的写性能，因为写操作可以立即返回，而不需要等待磁盘同步。 write_through：在 write_through 操作中，数据同时写入缓存和磁盘。写操作在数据被写入磁盘之前不会被认为已完成。虽然这可以确保数据的一致性和持久性，但 write_through 的性能通常低于 write_back，因为它需要等待磁盘同步。 总之，这段话描述了 Linux 内核如何在处理脏内存时在性能和数据一致性之间寻求平衡。当脏内存占比过高时，内核会采取措施降低写性能，以确保数据的一致性和持久性。 Linux伪终端Linux 内核使用 /dev/ptmx（主设备）和 /dev/pts（从设备）来实现伪终端（pseudo-terminal，简称 pty）。伪终端是一种特殊的终端设备，它不直接连接到物理设备，而是通过软件来模拟终端的输入和输出。伪终端广泛应用于远程登录（如 SSH）、终端模拟器（如 xterm）和其他需要模拟终端行为的场景。 以下是关于伪终端和 /dev/ptmx 以及 /dev/pts 的一些详细信息： 主设备（&#x2F;dev&#x2F;ptmx）：/dev/ptmx 是一个字符设备文件，用于创建伪终端的主设备。当一个进程（如 SSH 服务器或终端模拟器）需要创建一个新的伪终端时，它会打开 /dev/ptmx 设备文件。内核会为这个进程分配一个未使用的伪终端，并返回一个指向伪终端主设备的文件描述符。主设备用于管理伪终端，如接收从设备的输入数据、向从设备发送输出数据等。 从设备（&#x2F;dev&#x2F;pts）：/dev/pts 是一个虚拟文件系统（通常挂载在 /dev/pts 目录下），用于存储伪终端的从设备。当一个伪终端被创建时，内核会在 /dev/pts 目录下为其从设备分配一个唯一的编号（如 /dev/pts/0、/dev/pts/1 等）。从设备用于模拟终端的输入和输出操作，如读取用户输入、显示文本输出等。通常情况下，从设备会被分配给另一个进程（如 shell），以便它可以与主设备进行通信。 通过主设备和从设备的交互，伪终端实现了终端模拟器和其他类似程序与 shell、远程会话等之间的通信。这种抽象使得伪终端可以在不依赖于特定硬件的情况下，提供与物理终端类似的功能。 FreeBSD和FuchsiaFreeBSD和Fuchsia是两种不同的操作系统。下面我们分别详细解释这两个操作系统。 FreeBSDFreeBSD是一个类Unix的开源操作系统，它基于创建Unix的Berkeley Software Distribution（BSD）的源代码。FreeBSD成立于1993年，是BSD家族的一个成员，与NetBSD和OpenBSD等其他BSD操作系统并行发展。 FreeBSD的特点： 开源：FreeBSD的源代码可以免费获取和修改，遵循BSD许可证。这使得许多公司和开发者可以根据自己的需求定制操作系统。 稳定性：FreeBSD以其稳定性和可靠性而闻名，使其成为服务器和关键基础设施的理想选择。 性能：FreeBSD的性能优异，被广泛应用于高性能计算、网络服务和存储解决方案。 安全性：FreeBSD提供了多种安全功能，如强制访问控制、安全级别和防火墙集成。 可移植性：FreeBSD支持多种硬件平台，包括x86、x86-64、ARM、MIPS和PowerPC等。 FuchsiaFuchsia是由谷歌（Google）开发的一个开源操作系统。与FreeBSD不同，Fuchsia不是基于Unix的，而是基于名为Zircon的新内核构建的。Fuchsia的开发始于2016年，目标是创建一个高度模块化、可扩展且可用于各种设备的操作系统。 Fuchsia的特点： 开源：Fuchsia是一个开源项目，遵循BSD、MIT、Apache等许可证。这意味着开发者和公司可以免费访问和修改它的源代码。 Zircon内核：Fuchsia基于Zircon内核，这是一个微内核设计，使得操作系统更加轻量化和高度模块化。 跨平台：Fuchsia旨在成为一个统一的操作系统，适用于各种设备，包括智能手机、平板电脑、个人电脑以及物联网（IoT）设备。 模块化和可扩展性：Fuchsia的设计允许开发者轻松地添加和移除组件，使得操作系统能够根据需求进行定制化。 Flutter框架：Fuchsia使用谷歌的Flutter框架构建用户界面，Flutter支持跨平台应用开发，可以使Fuchsia应用在其他操作系统上运行。 总结，FreeBSD是一个基于Unix的稳定、高性能的开源操作系统，主要用于服务器和高性能计算。而Fuchsia是谷歌开发的一个全新的、基于Zircon内核的操作系统，旨在提供统一的、跨设备的体验。 sysctl接口Linux内核通过/proc/sys下的sysctl接口为用户空间程序提供了一种方式来查询和修改内核参数。sysctl可以通过文件系统访问，同时也可以通过命令行工具sysctl进行操作。这些参数涉及到许多内核子系统和组件，包括内存管理、网络设置、安全设置等。 在sysctl配置中，有很多参数涉及到抽象资源限制。这些限制通常用于约束系统资源的分配，以防止资源耗尽或者保证系统的稳定运行。以下是一些常见的资源限制相关的sysctl参数： vm.max_map_count：这个参数用于限制一个进程可以拥有的最大内存映射区域数量。这个限制有助于防止资源耗尽，尤其是在内存分配密集型的应用场景中。 kernel.pid_max：这个参数用于设置系统中分配的最大进程ID。通过限制进程ID的数量，可以防止恶意软件或编程错误导致的大量僵尸进程占用系统资源。 kernel.threads-max：这个参数用于限制系统中可以创建的最大线程数量。线程数量的限制可以防止过多的线程导致系统资源耗尽。 net.core.somaxconn：这个参数用于设置系统中最大的已完成连接队列长度。这个限制可以保障在高并发网络服务场景下，系统能够在资源有限的情况下处理连接请求。 fs.file-max：这个参数用于限制系统中可以打开的最大文件描述符数量。这个限制可以防止过多的文件描述符导致内核资源耗尽。 这些sysctl参数通常可以在系统启动时通过配置文件设置，也可以在运行时通过命令行工具sysctl进行动态调整。这为管理员和开发者提供了一种灵活的方式来优化系统性能和资源分配。 seccompseccomp（secure computing mode，安全计算模式）是一种Linux内核安全特性，允许在用户空间的进程将其可用的系统调用（syscalls）限制为一个最小的集合。这样做可以降低进程被攻击者利用的风险，因为攻击者可以使用的系统调用减少了。seccomp在容器、沙箱和其他高度安全的环境中非常有用，因为它可以限制潜在的攻击面。 seccomp的工作原理是允许进程定义一个系统调用白名单，只有在这个白名单上的系统调用才能被进程执行。当进程试图执行不在白名单上的系统调用时，内核会阻止进程，并根据seccomp的配置执行相应的操作。这些操作可能包括：终止进程、向进程发送信号或者返回一个错误码。 为了使用seccomp，进程需要使用prctl系统调用启用seccomp模式。接着，进程可以通过seccomp系统调用定义一个过滤器（通常是一个BPF（Berkeley Packet Filter）程序），用于检查系统调用的编号，并根据白名单执行相应的操作。 以下是一个简单的seccomp示例，演示了如何使用seccomp限制一个进程只能调用read、write、exit和rt_sigreturn系统调用： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/prctl.h&gt;#include &lt;linux/seccomp.h&gt;#include &lt;linux/filter.h&gt;#include &lt;linux/audit.h&gt;#include &lt;sys/syscall.h&gt;#define ALLOW_SYSCALL(syscall_nr) \\ BPF_JUMP(BPF_JMP + BPF_JEQ + BPF_K, syscall_nr, 0, 1), \\ BPF_STMT(BPF_RET + BPF_K, SECCOMP_RET_ALLOW)int main() &#123; // 定义seccomp过滤器 struct sock_filter filter[] = &#123; // 检查架构是否正确 BPF_STMT(BPF_LD + BPF_W + BPF_ABS, offsetof(struct seccomp_data, arch)), BPF_JUMP(BPF_JMP + BPF_JEQ + BPF_K, AUDIT_ARCH_X86_64, 1, 0), BPF_STMT(BPF_RET + BPF_K, SECCOMP_RET_KILL), // 加载系统调用编号 BPF_STMT(BPF_LD + BPF_W + BPF_ABS, offsetof(struct seccomp_data, nr)), // 允许白名单上的系统调用 ALLOW_SYSCALL(__NR_read), ALLOW_SYSCALL(__NR_write), ALLOW_SYSCALL(__NR_exit), ALLOW_SYSCALL(__NR_rt_sigreturn), // 不允许的系统调用将导致进程被终止 BPF_STMT(BPF_RET + BPF_K, SECCOMP_RET_KILL), &#125;; // 定义seccomp过滤器的元数据 struct sock_fprog prog = &#123; .len = (unsigned short)(sizeof(filter) / sizeof(filter[0])), .filter = filter, &#125;; // 启用seccomp模式 if (prctl(PR_SET_SECCOMP, SECCOMP_MODE_FILTER, &amp;prog) &lt; 0) &#123; perror(&quot;prctl&quot;); return 1; &#125; // 在此处执行您的程序逻辑 // 如果尝试执行不在白名单上的系统调用，进程将被终止 return 0;&#125; 请注意，这个示例使用的是seccomp的BPF过滤器，该过滤器提供了一种灵活的方式来控制系统调用。这种方法在容器和沙箱环境中非常有用，因为它可以针对特定应用程序的需求定制系统调用的限制。然而，编写BPF过滤器可能相对复杂，因此在实践中，许多开发者选择使用像libseccomp这样的库来简 化seccomp过滤器的创建和管理。 以下是使用libseccomp库的示例，实现与前面相同的功能： 1234567891011121314151617181920212223242526272829303132333435363738#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;seccomp.h&gt;int main() &#123; // 初始化一个新的seccomp上下文 scmp_filter_ctx ctx = seccomp_init(SCMP_ACT_KILL); if (!ctx) &#123; perror(&quot;seccomp_init&quot;); return 1; &#125; // 向过滤器中添加允许的系统调用 if (seccomp_rule_add(ctx, SCMP_ACT_ALLOW, SCMP_SYS(read), 0) &lt; 0 || seccomp_rule_add(ctx, SCMP_ACT_ALLOW, SCMP_SYS(write), 0) &lt; 0 || seccomp_rule_add(ctx, SCMP_ACT_ALLOW, SCMP_SYS(exit), 0) &lt; 0 || seccomp_rule_add(ctx, SCMP_ACT_ALLOW, SCMP_SYS(rt_sigreturn), 0) &lt; 0) &#123; perror(&quot;seccomp_rule_add&quot;); seccomp_release(ctx); return 1; &#125; // 将过滤器加载到内核中 if (seccomp_load(ctx) &lt; 0) &#123; perror(&quot;seccomp_load&quot;); seccomp_release(ctx); return 1; &#125; // 释放资源 seccomp_release(ctx); // 在此处执行您的程序逻辑 // 如果尝试执行不在白名单上的系统调用，进程将被终止 return 0;&#125; 这个示例使用了libseccomp库提供的API，使得创建和管理seccomp过滤器更加简单。只需通过seccomp_init初始化一个新的上下文，使用seccomp_rule_add添加允许的系统调用，然后使用seccomp_load将过滤器加载到内核中。最后，使用seccomp_release释放资源。 总之，seccomp是一种在Linux内核中实现安全计算模式的机制，它允许进程限制其可用的系统调用集，从而降低潜在的攻击面。在容器、沙盒和其他高度安全的环境中，seccomp非常有用。使用BPF过滤器或第三方库（如libseccomp）可以帮助开发者更轻松地创建和管理seccomp过滤器。 inodeinode是什么在文件系统中，inode（索引节点）是一种数据结构，用于存储有关文件和目录的元数据（如权限、大小、创建时间等），但不包括文件名和实际文件数据。每个文件或目录在文件系统中都有一个唯一的inode，它们通过inode号进行识别。不同的文件系统类型（如ext4、XFS、Btrfs等）可能会有不同的inode实现，但其基本概念是相同的。 以下是inode可能包含的一些元数据信息： 文件类型（普通文件、目录、符号链接等） 文件大小 文件的权限（读、写、执行） 文件的所有者和所属组 创建、修改和访问时间戳 文件数据所在的磁盘块的位置 现在让我们通过一个简单的Python脚本示例来展示如何获取文件的inode信息： 1234567891011121314151617import osfile_path = &quot;example.txt&quot;# 获取文件的 inode 信息file_stat = os.stat(file_path)# 打印详细的 inode 信息print(f&quot;File path: &#123;file_path&#125;&quot;)print(f&quot;Inode number: &#123;file_stat.st_ino&#125;&quot;)print(f&quot;File size: &#123;file_stat.st_size&#125; bytes&quot;)print(f&quot;File owner: &#123;file_stat.st_uid&#125;&quot;)print(f&quot;File group: &#123;file_stat.st_gid&#125;&quot;)print(f&quot;File permissions: &#123;oct(file_stat.st_mode)[-4:]&#125;&quot;)print(f&quot;File creation time: &#123;file_stat.st_ctime&#125;&quot;)print(f&quot;File modification time: &#123;file_stat.st_mtime&#125;&quot;)print(f&quot;File access time: &#123;file_stat.st_atime&#125;&quot;) 在这个例子中，我们首先通过os.stat()函数获取了指定文件路径的inode信息。然后，我们可以从返回的os.stat_result对象中获取各种inode元数据，如文件大小、所有者、权限等。 需要注意的是，此示例仅适用于类Unix系统（如Linux和macOS）。在Windows系统上，文件元数据的管理方式与inode有所不同。可以使用Python的os模块的其他函数，如os.path.getsize()和os.path.getctime()等，来获取Windows系统上的文件元数据。 inode攻击inode攻击是一种资源耗尽攻击，其目标是耗尽文件系统中可用的inode。在这种攻击中，攻击者会在受害者容器中不断创建新文件或目录，从而分配大量的inode结构。由于Linux内核没有针对inode的cgroup隔离，这种攻击会影响整个分区，导致分区上的所有inode都被耗尽。 当inode耗尽时，任何试图创建新文件或目录的操作都会失败，无论这些操作来自受害者容器还是主机。在这种情况下，受害者容器可能会被驱逐，而主机也不能创建任何新文件。阿里云容器服务容易受到inode攻击的影响。 为了防御inode攻击，可以考虑以下方法： 限制容器的存储使用：为容器设置存储配额，以限制每个容器可以使用的存储空间。这可以防止攻击者耗尽整个文件系统的inode。 监控inode使用情况：定期检查文件系统的inode使用情况，以便在inode快速耗尽时发现潜在的攻击。 设置警报和自动响应：在inode使用达到临界值时设置警报，并实施自动响应措施，例如限制或隔离可疑容器。 运行时隔离：使用更高级别的运行时隔离技术，如gVisor或Kata Containers，以提供更强大的安全隔离。 需要注意的是，防御inode攻击的方法可能会对性能产生影响，因此在实施这些措施时需要权衡安全性和性能。 netns_ct-&gt;count攻击一种针对 Linux 内核中的连接跟踪功能（Netfilter）的攻击，该攻击涉及到利用 netns_ct-&gt;count 计数来消耗主机和容器的网络资源。这种攻击通常被称为连接消耗攻击（Connection Exhaustion Attack）或资源耗尽攻击（Resource Exhaustion Attack）。 攻击原理概述如下： 攻击者在容器内产生大量的 TCP 连接，这些连接会被跟踪。 尽管这些容器位于不同的网络命名空间（net namespace）中，但它们的所有连接都需要使用主机的 init_net.ct 计数。 当攻击者在短时间内产生大量连接时，会消耗掉主机的 init_net.ct 计数配额。 一旦配额耗尽，Netfilter 功能将受到影响，可能导致随机丢包等问题。 要防范这种攻击，可以采取以下措施： 限制容器的连接数：为每个容器设置连接数限制，以防止单个容器耗尽主机的连接资源。 限制连接速率：使用 Netfilter 的 iptables 工具限制容器的连接速率。例如，可以设置每秒最多允许的新连接数，从而防止攻击者在短时间内产生大量连接。 隔离网络命名空间：在某些情况下，可以为每个容器提供独立的网络命名空间，以降低资源争用的可能性。然而，这种方法可能会增加资源消耗和管理复杂性。 监控和报警：实施实时网络连接监控，以便在攻击发生时迅速检测并采取相应措施。 通过实施这些防范措施，可以降低容器和主机受到 netns_ct-&gt;count 攻击的风险。 gVisorgVisor 是一个开源的沙箱运行时，由谷歌开发，用于为容器提供隔离和安全性。gVisor 主要目标是为容器提供更高级别的安全性，同时保持接近原生容器的性能。它在容器与宿主机之间增加了一个用户空间内核，从而限制容器对宿主机内核的访问。这种方法降低了潜在安全漏洞对整个系统的影响。 gVisor 的核心组件是名为 “Sentry” 的用户空间内核，它拦截和处理来自容器的系统调用。Sentry 为每个容器提供了一个独立的内核实例，从而限制容器之间的相互影响。此外，gVisor 还包括一个名为 “Gofer” 的文件系统代理，用于将容器的文件系统操作转发到宿主机。 gVisor 与 Docker 和 Kubernetes 等容器运行时环境兼容，可以轻松集成到现有的容器部署中。为了在 Docker 中使用 gVisor，您需要安装 gVisor 并将其配置为 Docker 的运行时。以下是在 Docker 中使用 gVisor 的示例： 首先，安装 gVisor： 12345wget https://storage.googleapis.com/gvisor/releases/nightly/latest/runscwget https://storage.googleapis.com/gvisor/releases/nightly/latest/runsc.sha512sha512sum -c runsc.sha512chmod a+x runscsudo mv runsc /usr/local/bin 配置 Docker 使用 gVisor： 12345678910sudo mkdir -p /etc/dockerecho &#x27;&#123; &quot;runtimes&quot;: &#123; &quot;runsc&quot;: &#123; &quot;path&quot;: &quot;/usr/local/bin/runsc&quot;, &quot;runtimeArgs&quot;: [&quot;--platform=ptrace&quot;] &#125; &#125;&#125;&#x27; | sudo tee /etc/docker/daemon.jsonsudo systemctl restart docker 运行一个使用 gVisor 的 Docker 容器： 1docker run --runtime=runsc -it alpine sh 这将启动一个使用 gVisor 作为沙箱运行时的新容器。通过使用 gVisor，您可以提高容器的安全性，降低潜在安全漏洞对整个系统的影响。然而，需要注意的是，gVisor 可能会带来一定的性能损失，因此在实际应用中需要权衡安全性和性能。 Per-user quota restrictionsPer-user quota restrictions 是一种在文件系统层面设置的资源限制方法，用于控制每个用户所能使用的磁盘空间和文件数量。这种限制方法通常用于多用户共享同一系统资源的环境，如共享主机或服务器，以防止单个用户占用过多的磁盘空间或文件数量，从而导致其他用户无法正常使用系统资源。 Per-user quota restrictions 主要包括以下两种类型： 磁盘空间限制（Block Quotas）：该限制用于限制每个用户所能使用的磁盘空间。系统管理员可以为每个用户分配一定量的磁盘空间，当用户达到分配的磁盘空间上限时，将无法继续写入或创建新文件。 文件数量限制（Inode Quotas）：该限制用于限制每个用户所能创建的文件数量。系统管理员可以为每个用户分配一定数量的文件（或目录）创建权限，当用户达到分配的文件数量上限时，将无法继续创建新文件或目录。 在 Linux 系统中，可以通过以下步骤设置 per-user quota restrictions： 安装 quota 工具： 1sudo apt-get install quota quotatool 在 /etc/fstab 文件中启用用户配额。例如，为 /home 分区启用用户配额，可以将以下内容添加到 /etc/fstab 文件： 1/dev/sda1 /home ext4 defaults,usrquota,grpquota 0 0 重新挂载分区以应用更改： 1sudo mount -o remount /home 初始化配额文件： 1sudo quotacheck -cug /home 为特定用户设置配额限制。例如，为用户 exampleuser 设置 100MB 的磁盘空间限制和 1000 个文件数量限制： 1sudo setquota -u exampleuser 100000 110000 1000 1100 /home 使用 quota 命令查看用户配额情况： 1quota -u exampleuser 通过实施 per-user quota restrictions，系统管理员可以确保系统资源在用户之间公平地分配，防止单个用户过度使用资源。","categories":[{"name":"论文精读","slug":"论文精读","permalink":"http://example.com/categories/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/"},{"name":"内核安全","slug":"论文精读/内核安全","permalink":"http://example.com/categories/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/%E5%86%85%E6%A0%B8%E5%AE%89%E5%85%A8/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"云安全","slug":"云安全","permalink":"http://example.com/tags/%E4%BA%91%E5%AE%89%E5%85%A8/"}]},{"title":"《理想国》柏拉图 阅读","slug":"《理想国》柏拉图 阅读","date":"2023-03-29T03:09:42.000Z","updated":"2023-04-09T13:41:12.250Z","comments":true,"path":"2023/03/29/《理想国》柏拉图 阅读/","link":"","permalink":"http://example.com/2023/03/29/%E3%80%8A%E7%90%86%E6%83%B3%E5%9B%BD%E3%80%8B%E6%9F%8F%E6%8B%89%E5%9B%BE%20%E9%98%85%E8%AF%BB/","excerpt":"","text":"前言 《理想国》作为一本必读的哲学经典，是柏拉图在思想成熟时期所著，包含了古希腊当时个个方面的问题，包括哲学、教育、军事、政治、伦理、文艺、诗歌等等。柏拉图一步步构建出理念世界，并借苏格拉底之口讨论了哲学中的一些重要问题，苏格拉底运用“辩证法”一步步让对方发现自身观点的矛盾之处，可以说是压迫感极强，甚至说是阴阳怪气。再读《理想国》，意在让自己浅薄的思想能得到升华。本人希望通过阅读总结书中的思想，可能由于时代的局限性，某些思想在现在看来可能已经过时并且不够完善，但是我们也依然可以从中汲取智慧为自己的思想所用。 财产 正义 节制开篇以苏格拉底和赛弗拉的对话开始，苏格拉底从年长者的问题入手，逐步引出财产，正义的讨论，并一步步进行了论证，反驳了当时流行的观点。 当一个人对肉体上的享受越来越少时，那他对精神上的畅谈也就要求越多。 我向来认为年长的人就像已经翻越千山万水的老旅客，你们曾经遇到的坎坷也可能是我之后要经历的，所以我对于过来人十分愿意与他们探讨一下旅途中的艰难险阻。 人在老年阶段是否会更艰难？大部分人在年老时对年老的抱怨，在于不能像以前一样吃喝玩乐、或是体验爱情的快乐、或是美好的事物已成过往，有人埋怨至亲好友的忽视，有人埋怨年老是痛苦的根源。赛弗拉讲脱离所谓的情爱比喻成从一个暴君处脱离苦海，到了老年时代，对于情爱一事早已没了兴趣，人已经清心寡欲，有了另一种自由快乐的感受。 赛弗拉从此入手，论证年老时之所以会抱怨连连，不是因为年纪，而是性情。如果一个人性情是恬静的、心平气和的，那么年龄大并不是痛苦，如果不是，那么不管什么年龄都会是痛苦的。 苏格拉底故意激赛弗拉继续回答，苏格拉底评价赛弗拉是因为家财万贯而不是因为性情恬静，所以老年时才会快乐，之后引出财富的问题。 你从财富上得到了什么？ 自己赚钱的人不仅因为钱有用才喜欢它，而更是因为这是他们辛苦得来的，内心生出了一种强烈的占有欲，就像诗人爱自己的诗篇，父母疼爱自己的儿女一样。我看到这种人，就觉得他们很讨厌，他们说的内容不外乎是赞美金钱之类的。 人从财富中获得的最大的好处就是，在赚取财富时的问心无愧，没有恐慌和忧虑。在人快死亡的时候，会有一种恐慌和忧虑，担心来世受到惩罚。如果一个人知道自己造孽颇深，就会过度悲观，惊恐万分，而问心无愧的人，便会心中坦然。 正义是什么？有话实说、欠债还债是否正义？不是正义，这个观点是日常生活中某个情形下的正义行为，并不是正义的定义。如果如此定义正义，便会造成有时是正义的，有时不是正义的情形。 柏拉图借苏格拉底之口举例： 你有个朋友在头脑清楚的时候，曾经把武器交给你，假如他后来疯了，再要回去，任何人都会说不能还给他，如果你还给他，这是不正义的行为。 把整个真实情况告诉疯子不是正义。 如果债主是敌人，还债是对他的帮助，则还债不是正义。 即当有话实说或者欠债还债的对象不同时，根据不同情况，这种行为也有可能是不正义的。苏格拉底希望找到一种普遍的正义，我们想要看一种行为是否是正义的，不能光从自身的立场出发，还要从我们的对象能否收益来检验我们的行为是否是有利于对方的，还要判断收益的对象。 把善给予友人，把恶给予敌人是否正义？把善给予友人：医生把医术给予病人，舵手在航海遇到风急浪险时维护船舶的安全。 把恶给予敌人：在战争中与盟友攻敌。 苏格拉底论证，在不生病的时候，医生是没有用处的，在人们不航海的时候，舵手是没有用处的，在不打仗的时候，正义者是没有用处的。而正义在不论任何时候都是有用处的。农名在种田时有用处，鞋匠在造鞋时有用处，但是鞋匠和农民不是正义者。 那么在平时什么事情上必须有正义？多人合作关系，例如订合同、立契约等等。下棋能手和正义者在下棋时，下棋能手更有用处，瓦匠和正义者在砌砖盖瓦建屋时，瓦匠更有用处，琴师和正义者在奏乐时，琴师更有用处，因此有用者并不等于正义者。这说明这样的正义定义太过狭窄。 事实上恰恰相反，一个正义的人和政府都是在平时就能做得很好才能保持自己和国家的久安。在涉及到金钱时，花钱与保管钱，同样都有比正义者更有用处的角色存在。 以此类推，如果一件事物有用，那么正义就没用，正义有用，那么这件事物就没用。是在平时就能做得很好才能保持自己和国家的久安。如果说正义平时也有用比如在替朋友保管钱财方面做到以善待友，那么就会得出钱财不用时正义有用，一旦钱财被使用了正义反而无用了。最后正义还要求“以恶对敌”这是不是意谓着还要替朋友去掠取敌人的东西呢？这样正义之举不就成了小偷行为了吗？这样的驳难看似荒唐，其实正好揭露出了这个定义本身所包含的内在矛盾。 而根据命题的定义，我们有时也会混淆朋友和敌人，所谓的朋友是那些看上去好的人还是实际上真正好的人呢？你所谓的敌人是看上去坏的人还是那些看上去不坏但是真的坏人呢。如果弄错了，便会导致帮助坏人，对抗好人。这个也引出善恶的问题，柏拉图在之后也借苏格拉底之口对此进行了论证。 根据讨论进一步完善定义，真正善良的朋友，报之以善，真正邪恶的敌人，报之以恶，才是正义。这个定义似乎更接近真理一些了。但是考虑如下例子：正义的人是否可以伤害他人呢？伤害他人是一件恶事，正义之人一定是善人，基于此，并考虑如下例子：善于骑马的人能够凭借其起码的技能让人不会骑马吗？音乐家能够凭借其音乐上的技能使人不懂音乐吗？正义者能以他的正义使人做不正义的事情吗？我们可以认为正义者作为一个善人不应该做伤害他人的恶事。 所以根据上述的讨论，正义并非是把善给予友人，把恶给予敌人。 正义就是强者的利益正义就是强者的利益，区别于上述判断收益的对象以及对于友人的利益，这个命题认为正义是强者的利益，所以首先要明确的是何为”强者“。如果只是因为吃的比别人好而比别人强壮，这并不是强者，我们通常提到强者，首先想到的就是统治者，制定法律的人，违反法律的人就是不正义之人，而对于政府有利的百姓就是正义。因此，有人认为，所谓正义就是当时政府的利益，正义就是强者的利益。 苏格拉底对此进行了反驳。 政府不是绝对不会出错的，如果治理得当，那么他们所立的法就是基于政府的利益的，而治理出现问题，就会与政府的利益违背，此时还是正义的吗？如果是正义的便会得到，即使与政府的利益违背，人民依旧需要服从，这仍然是正义。但是如果弱者服从了，实际上是损害了强者的利益，因此与命题相违背。 如果强者的利益指的是强者实际上的利益而不是强者心中认为的利益，并且是基于严格意义上的强者，即不会犯错误的强者。 苏格拉底做出了一个比喻，如果说技艺是完美的，如果技艺是不完美的，例如人的身体不完备的时候，需要医术来弥补，医术不完备的时候，需要其他的技艺来弥补。假设技艺在严格意义上是完美的不需要其他任何方式弥补的话，那么医生就不会考虑自身医术的利益，而会考虑病人的利益，骑马者不会考虑骑术的利益，而会考虑马的利益。以此类推，技艺本身是没有错误的，因此他担心的便是对象的利益，因为任何技艺都是为其对象服务的。那么不会犯错的强者可以比喻成完美的技艺，百姓可以比喻成技艺所服务的对象。那么一个统治者更多顾及的便是受统治者的利益而不是自身的利益，就像完美的技艺是为它的对象服务的。即名实相符的统治者会始终以人民的利益为前提，而不是以自己的利益为前提。 不正义比正义更有益有人认为正义和正义者会白白给出利益，换言之，正义意味着强者和统治者得到利益，而弱者和被统治者失去利益。不正义与之相反。例如专制君主的暴政。 根据苏格拉底在上文的证明，一个名实相符的统治者，无论什么事都是以被统治者的利益为目的。 每种技艺除了普通的利益之外，应该要给人以特殊的利益，比如医术给人以健康的利益，航海之术给人以安渡大海的利益。除此之外，技艺应当还有特殊的功用，而这种功用不能与其他技艺的功用相混合。每种技艺的利益都不能与其他的技艺混为一谈，除了它自身的特殊功用外，具有同一功用的技艺之间必定有同一利益在其中，那么技艺者所得到得报酬，应该是技艺所附带的利益，而不是技艺本身的利益。报酬与各种技艺有连带关系，而掌握技艺饿人只要各尽所能，便可以施利于人，报酬自然在其中。凡是真正的技艺家，当他工作的时候或指挥他人的时候，是以他人的利益为中心的，而不应该掺杂自己的私欲。工作没有相当的报酬是没有人愿意尽力而为的。所以，统治者或治理者的工作也必须有报酬，他们才会尽心为人民服务。他们的报酬有三种：金钱、荣誉与不愿承担责任的惩罚。 金钱和荣誉可以理解，而惩罚是什么意思呢？惩罚如何能作为报酬？ 对于高尚的人，名与利都不能使之动心。他们不愿意为拿报酬去做事，被人当佣人看待，更不愿意以阴谋的手段，假公济私，被人当强盗看待。因此，只能用损毁他们高洁的名节来惩罚他们，迫使他们不得不出来做事。也正因为这个缘故，那些急于做官的人受到轻视，而那些被逼出来做官的人则感受到莫大的尊荣。这种惩罚之所以最有效，是因为如果他们不出来，就用不如他们的人来管理他们的生活和行为。因此，这些人出来做官并不是因为他们有这个志向，也不是这里面有什么可贪图的，而是因为一时没有比他们更好的人或能力相同的人。所以，对他们来说，做官实在是刀架在脖子上，迫不得已的事。假如一个国家都是高尚的人，那么不想做官的肯定不会比今日想要做官的少。因此，真正的统治是要给他人以利益，而不是给自己以利益。如此，那么有谁会不愿意被统治，接受他人的利益呢？有谁会愿意做统治者，专门给他人以利益呢？所以，不得不以惩罚的手段迫使高尚者出来做官。 这进一步证明了正义不是强者的利益，初步证明了不正义不一定更有益，下面进一步证明。 如果能够治理国家和人民的纯粹的不正义者，会比正义者有能力得多，那么不正义者就会是明智的且有美德的，而正义便是其对立面。基于此，一个正义者不能够胜过其他的正义者即没有竞争，因为正义者是不明智的且无能的，并且所作所为不能有超过正义事业之外的事情，并且正义者获得的利益不能多于不正义者。而不正义者愿意获得比正义者更多的利益，并且愿意做正义之外的事情，所以不正义者在利益的竞争上要比正义者激烈，然后才能获取更多的利益。总结如下：正义者不愿意获得比同类更多的利益，而愿意获得比异类更多的利益；不正义者即愿意获得比同类更多的利益，也愿意获得比异类更多的利益。不正义者属于善而有智慧者的同类，正义者属于其异类。 我们再来看技艺家，人所拥有的技艺是不同的，例如一人为音乐家，一人为非音乐家，那么就音乐上的智慧来说，音乐家是聪明的。以此类推，医生也是这样的。音乐家在调整琴弦时不会有意想胜过别的音乐家，而会有意胜过非音乐家。医生在治病时不会做超出医生范围之外的事。再以知识与愚笨来说，有知识者的言行和其他有知识者的言行差不多，而愚笨的人会想要自己的言行超过有知识和无知识的人。有知识的人是聪明的而聪明的人是善良的（这段我无法推出，可能是由于当时的局限性对于善良，聪明等的定义并不明确，上文也出现了类似的情况），聪明又善良的人仅仅希望胜过异类，而不希望胜过同类，我们基于上文的假设得到这些结论。 而上文说不正义者常常想要胜过同类和异类，正义者只想胜过异类，而不想胜过同类，那么正义者则与聪明又有善德的相似，不正义者与无知而又没有善的的相似。那么现在正义者变成了聪明又有善德的人，不正义者变成了无知又没有善德的人，与上一段的结论矛盾。 正义与不正义的性质基于我们已经证明正义是美德和智慧，不正义是没有善德和愚蠢的。那么正义者比不正义者强是不言而喻的。现在我们假设，有一个国家或一支军队或一伙强盗或任何一些作恶的团伙，如果他们成员之间整天自相残杀，那么这个团伙一定是不能成功运作的，而如果不自相残杀，那么这些团伙的运作才能进行的更好。所以不正义会引发争端和仇恨，而正义能调和彼此之间的矛盾以达到和谐。（看到这里，我们应该也明白了，柏拉图对于正义和不正义的定义也是比较模糊的，一些证明看似有道理，但是细细思考一下，就会发现其中的纰漏）不正义既然有引发争论和仇恨的性质，那么凡是在不正义的地方，不论是努力还是自由人，他们会因此相互争斗，意见分歧，而不能有共同的行动。那么不正义在二人之间，则彼此会发生争论和激战，势必会称为仇敌，并且还会称为正义的敌人。而不正义在一个人身上，不正义会是其自相矛盾，言行前后不一，所以不正义不仅仅是正义的敌人，也是自我的敌人。所以不正义即使对个人也是有害的，一是会使人的言行不一致，二是会是人三心二意，使自己称为自己的敌人，并且也成为正义的敌人。 哪些共同作恶的人，之所以能够进行作恶行为，还不能算是真正的不正义者，假如他们是真正的不正义者，那么他们必定会自相残害，如果他们能够联合在一起为恶，那么还有一部分正义存在于其间，所以才能进行集体的行动。 凡物都有其专门独特的功能和事业，也一定会有它的一个特长，就像人的眼睛有它自身独特的功能。假如眼睛的特长不完备而有缺陷，那么眼睛就不能成就它的事业。那么有正义之心的人，自然就会生活得坦然自若，终身愉快，而不正义的人刚好相反。根据以上推论，只有正义者才能生活得安乐而幸福，不正义者则不能。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"http://example.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"哲学","slug":"读书笔记/哲学","permalink":"http://example.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%93%B2%E5%AD%A6/"}],"tags":[{"name":"柏拉图","slug":"柏拉图","permalink":"http://example.com/tags/%E6%9F%8F%E6%8B%89%E5%9B%BE/"},{"name":"理想国","slug":"理想国","permalink":"http://example.com/tags/%E7%90%86%E6%83%B3%E5%9B%BD/"}]},{"title":"Hello ,my blog","slug":"Hello-my-blog","date":"2022-06-23T06:44:47.000Z","updated":"2023-03-31T04:52:42.333Z","comments":true,"path":"2022/06/23/Hello-my-blog/","link":"","permalink":"http://example.com/2022/06/23/Hello-my-blog/","excerpt":"","text":"Zwei Dinge erfüllen das Gemuet mit immer neuer und zunehmender Bewunderung und Ehrfurcht, je öfter und anhaltender sich das Nachdenken damit beschäftigt:: der bestirnte Himmel über mir und das moralische Gesetz in mir.","categories":[{"name":"Dairy","slug":"Dairy","permalink":"http://example.com/categories/Dairy/"}],"tags":[{"name":"new","slug":"new","permalink":"http://example.com/tags/new/"}]}],"categories":[{"name":"论文精读","slug":"论文精读","permalink":"http://example.com/categories/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/"},{"name":"内核安全","slug":"论文精读/内核安全","permalink":"http://example.com/categories/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/%E5%86%85%E6%A0%B8%E5%AE%89%E5%85%A8/"},{"name":"编程语言","slug":"编程语言","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"},{"name":"C++","slug":"编程语言/C","permalink":"http://example.com/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/C/"},{"name":"课程学习","slug":"课程学习","permalink":"http://example.com/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/"},{"name":"MIT6.S081 Operating System Engineering","slug":"课程学习/MIT6-S081-Operating-System-Engineering","permalink":"http://example.com/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/MIT6-S081-Operating-System-Engineering/"},{"name":"Linux源码","slug":"Linux源码","permalink":"http://example.com/categories/Linux%E6%BA%90%E7%A0%81/"},{"name":"读书笔记","slug":"读书笔记","permalink":"http://example.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"哲学","slug":"读书笔记/哲学","permalink":"http://example.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%93%B2%E5%AD%A6/"},{"name":"学习路径","slug":"学习路径","permalink":"http://example.com/categories/%E5%AD%A6%E4%B9%A0%E8%B7%AF%E5%BE%84/"},{"name":"Ubuntu源码","slug":"Ubuntu源码","permalink":"http://example.com/categories/Ubuntu%E6%BA%90%E7%A0%81/"},{"name":"Dairy","slug":"Dairy","permalink":"http://example.com/categories/Dairy/"}],"tags":[{"name":"操作系统","slug":"操作系统","permalink":"http://example.com/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"内核安全","slug":"内核安全","permalink":"http://example.com/tags/%E5%86%85%E6%A0%B8%E5%AE%89%E5%85%A8/"},{"name":"C++","slug":"C","permalink":"http://example.com/tags/C/"},{"name":"Linux","slug":"Linux","permalink":"http://example.com/tags/Linux/"},{"name":"哲学","slug":"哲学","permalink":"http://example.com/tags/%E5%93%B2%E5%AD%A6/"},{"name":"庄子","slug":"庄子","permalink":"http://example.com/tags/%E5%BA%84%E5%AD%90/"},{"name":"道家","slug":"道家","permalink":"http://example.com/tags/%E9%81%93%E5%AE%B6/"},{"name":"指针","slug":"指针","permalink":"http://example.com/tags/%E6%8C%87%E9%92%88/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://example.com/tags/Ubuntu/"},{"name":"云安全","slug":"云安全","permalink":"http://example.com/tags/%E4%BA%91%E5%AE%89%E5%85%A8/"},{"name":"柏拉图","slug":"柏拉图","permalink":"http://example.com/tags/%E6%9F%8F%E6%8B%89%E5%9B%BE/"},{"name":"理想国","slug":"理想国","permalink":"http://example.com/tags/%E7%90%86%E6%83%B3%E5%9B%BD/"},{"name":"new","slug":"new","permalink":"http://example.com/tags/new/"}]}