<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-mac-osx.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"hide","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"mac"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":true,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="随便记录">
<meta property="og:type" content="website">
<meta property="og:title" content="Plucky">
<meta property="og:url" content="http://example.com/page/4/index.html">
<meta property="og:site_name" content="Plucky">
<meta property="og:description" content="随便记录">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Plucky">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/page/4/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Plucky</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Plucky</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Comfortably Numb</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-links">

    <a href="/links/" rel="section"><i class="fa fa-link fa-fw"></i>links</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/04/05/MIT6-S081-Operating-System-Engineering-Lecture04-Page-Tables/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Plucky">
      <meta itemprop="description" content="随便记录">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Plucky">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/04/05/MIT6-S081-Operating-System-Engineering-Lecture04-Page-Tables/" class="post-title-link" itemprop="url">MIT6 S081 Operating System Engineering Lecture04 Page Tables</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-04-05 17:03:11" itemprop="dateCreated datePublished" datetime="2023-04-05T17:03:11+08:00">2023-04-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-04-14 19:30:30" itemprop="dateModified" datetime="2023-04-14T19:30:30+08:00">2023-04-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">课程学习</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/MIT6-S081-Operating-System-Engineering/" itemprop="url" rel="index"><span itemprop="name">MIT6.S081 Operating System Engineering</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>13k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>24 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Topic"><a href="#Topic" class="headerlink" title="Topic"></a>Topic</h1><ul>
<li><p><strong>Address Spaces</strong></p>
</li>
<li><p><strong>支持虚拟内存的硬件</strong></p>
</li>
<li><p><strong>XV中的虚拟内存代码</strong></p>
</li>
</ul>
<h1 id="Address-Spaces"><a href="#Address-Spaces" class="headerlink" title="Address Spaces"></a>Address Spaces</h1><h2 id="为什么需要隔离性"><a href="#为什么需要隔离性" class="headerlink" title="为什么需要隔离性"></a>为什么需要隔离性</h2><p>创造虚拟内存的一个出发点是你可以通过它实现隔离性。如果你正确的设置了<code>page table</code>，并且通过代码对它进行正确的管理，那么原则上你可以实现强隔离。</p>
<p>我们期望的是，每个用户程序都被装进一个盒子里，这样它们就不会彼此影响了。类似的，我们也想让它们与内核操作系统相互独立，这样如果某个应用程序无意或者故意做了一些坏事，也不会影响到操作系统。</p>
<p>如果我们不做任何工作，默认情况下我们是没有内存隔离性的。</p>
<p>RISC-V主板上，内存是由一些DRAM芯片组成。在这些DRAM芯片中保存了程序的数据和代码。例如内存中的某一个部分是内核，包括了文本，数据，栈等等；如果运行了<code>Shell</code>，内存中的某个部分就是<code>Shell</code>；如果运行了<code>cat</code>程序，内存中的某个部分是<code>cat</code>程序。这里说的都是物理内存，它的地址从0开始到某个大的地址结束。结束地址取决于我们的机器现在究竟有多少物理内存。所有程序都必须存在于物理内存中，否则处理器甚至都不能处理程序的指令。</p>
<p>这里的风险很明显。我们简单化一下场景，假设Shell存在于内存地址1000-2000之间。</p>
<p>如果<code>cat</code>出现了程序错误，将内存地址<code>1000</code>，也就是<code>Shell</code>的起始地址加载到寄存器a0中。之后执行<code>sd $7, (a0)</code>，这里等效于将7写入内存地址<code>1000</code>。</p>
<p>现在<code>cat</code>程序弄乱了<code>Shell</code>程序的内存镜像，所以隔离性被破坏了，这是我们不想看到的现象。所以，我们想要某种机制，能够将不同程序之间的内存隔离开来，这样类似的事情就不会发生。一种实现方式是地址空间（Address Spaces）。</p>
<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><p>这里的基本概念也很简单直观，我们给包括内核在内的所有程序专属的地址空间。所以，当我们运行<code>cat</code>时，它的地址空间从0到某个地址结束。当我们运行<code>Shell</code>时，它的地址也从0开始到某个地址结束。内核的地址空间也从0开始到某个地址结束。</p>
<p>如果<code>cat</code>程序想要向地址<code>1000</code>写入数据，那么<code>cat</code>只会向它自己的地址<code>1000</code>，而不是<code>Shell</code>的地址<code>1000</code>写入数据。所以，基本上来说，每个程序都运行在自己的地址空间，并且这些地址空间彼此之间相互独立。在这种不同地址空间的概念中，<code>cat</code>程序甚至都不具备引用属于<code>Shell</code>的内存地址的能力。这是我们想要达成的终极目标，因为这种方式为我们提供了强隔离性，<code>cat</code>现在不能引用任何不属于自己的内存。</p>
<p>所以现在我们的问题是如何在一个物理内存上，创建不同的地址空间，因为归根到底，我们使用的还是一堆存放了内存信息的DRAM芯片。</p>
<ul>
<li><p>虚拟内存可以比物理内存更大，物理内存也可以比虚拟内存更大</p>
</li>
<li><p>如果太多的进程使用了虚拟内存，有可能使物理内存耗尽</p>
</li>
<li><p><code>kalloc</code>保存了空余的<code>page</code>的列表，如果这个列表为空或者耗尽了，那么<code>kalloc</code>会返回一个空指针，内核会妥善处理并将结果返回给用户应用程序。并告诉用户应用程序，要么是对这个应用程序没有额外的内存了，要么整个机器都没有内存了。</p>
</li>
</ul>
<h1 id="Page页表"><a href="#Page页表" class="headerlink" title="Page页表"></a>Page页表</h1><h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><p>页表是在硬件中通过处理器和内存管理单元（Memory Management Unit）实现。</p>
<p>CPU正在执行指令，例如<code>sd $7, (a0)</code>。</p>
<p>对于任何一条带有地址的指令，其中的地址应该认为是虚拟内存地址而不是物理地址。假设<code>寄存器a0</code>中是地址<code>0x1000</code>，那么这是一个虚拟内存地址。虚拟内存地址会被转到内存管理单元（MMU，Memory Management Unit）</p>
<p>内存管理单元会将虚拟地址翻译成物理地址。之后这个物理地址会被用来索引物理内存，并从物理内存加载，或者向物理内存存储数据。</p>
<p>从CPU的角度来说，一旦<code>MMU</code>打开了，它执行的每条指令中的地址都是虚拟内存地址。</p>
<p>为了能够完成虚拟内存地址到物理内存地址的翻译，<code>MMU</code>会有一个表单，表单中，一边是虚拟内存地址，另一边是物理内存地址。举个例子，虚拟内存地址<code>0x1000</code>对应了一个我随口说的物理内存地址<code>0xFFF0</code>。这样的表单可以非常灵活。</p>
<p>通常来说，内存地址对应关系的表单也保存在内存中。所以CPU中需要有一些寄存器用来存放表单在物理内存中的地址。现在，在内存的某个位置保存了地址关系表单，我们假设这个位置的物理内存地址是<code>0x10</code>。那么在RISC-V上一个叫做<code>SATP</code>的寄存器会保存地址<code>0x10</code>。</p>
<p>这样，CPU就可以告诉<code>MMU</code>，可以从哪找到将虚拟内存地址翻译成物理内存地址的表单。</p>
<p><code>page table</code>存储在内存中，<code>MMU</code>只是会去查看<code>page table</code>。</p>
<p>每个应用程序都有自己独立的表单，并且这个表单定义了应用程序的地址空间。所以当操作系统将CPU从一个应用程序切换到另一个应用程序时，同时也需要切换<code>SATP</code>寄存器中的内容，从而指向新的进程保存在物理内存中的地址对应表单。这样的话，<code>cat</code>程序和<code>Shell</code>程序中相同的虚拟内存地址，就可以翻译到不同的物理内存地址，因为每个应用程序都有属于自己的不同的地址对应表单。</p>
<p>内核会写<code>SATP</code>寄存器，写<code>SATP</code>寄存器是一条特殊权限指令。所以，用户应用程序不能通过更新这个寄存器来更换一个地址对应表单，否则的话就会破坏隔离性。所以，只有运行在kernel mode的代码可以更新这个寄存器。</p>
<h2 id="虚拟地址到物理地址"><a href="#虚拟地址到物理地址" class="headerlink" title="虚拟地址到物理地址"></a>虚拟地址到物理地址</h2><p><img src="/2023/04/05/MIT6-S081-Operating-System-Engineering-Lecture04-Page-Tables/P18.png"></p>
<p>虚拟内存地址分为两个部分</p>
<ul>
<li><p><code>index</code>：用来查找<code>page</code></p>
</li>
<li><p><code>offset</code>：对应一个<code>page</code>中的字节</p>
</li>
</ul>
<p>当<code>MMU</code>在做地址翻译的时候，通过读取虚拟内存地址中的<code>index</code>可以知道物理内存中的<code>page</code>号，这个<code>page</code>号对应了物理内存中的4096个字节。之后虚拟内存地址中的<code>offset</code>指向了<code>page</code>中的4096个字节中的某一个，假设<code>offset</code>是12，那么<code>page</code>中的第12个字节被使用了。将<code>offset</code>加上<code>page</code>的起始地址，就可以得到物理内存地址。</p>
<h3 id="RSIC-V处理器"><a href="#RSIC-V处理器" class="headerlink" title="RSIC-V处理器"></a>RSIC-V处理器</h3><p>RISC-V的寄存器是64bit，但是并不是所有的64bit都被使用了，高25bit未被使用。</p>
<p>这样的结果是限制了虚拟内存地址的数量，虚拟内存地址的数量现在只有2^39个，大概是512GB。</p>
<p>当然如果有必要的话，最新的处理器或许可以支持更大的地址空间，只需要将未使用的25bit拿出来作为虚拟内存地址的一部分即可。</p>
<p>在剩下的39bit中，有27bit被用来当作<code>index</code>，12bit被用来当作<code>offset</code>。<code>offset</code>必须是12bit，因为对应了一个<code>page</code>的4096个字节。</p>
<p>在RISC-V中，物理内存地址是56bit。所以物理内存地址可以大于单个内存地址空间，但是也最多到2^56。大多数主板还不支持2^56这么大的物理内存，但是原则上，如果你能造出这样的主板，那么最多可以支持2^56字节的物理内存。</p>
<p>物理内存地址是56bit，其中44bit是物理<code>page</code>号（<code>PPN,Physical Page Number</code>)，剩下的12bit是<code>offset</code>完全继承自虚拟内存地址（也就是地址转换时，只需要将虚拟内存中的27bit翻译成物理内存中的44bit的<code>page</code>号，剩下的12bit<code>offset</code>直接拷贝过来即可。</p>
<h2 id="多级page-table"><a href="#多级page-table" class="headerlink" title="多级page table"></a>多级page table</h2><p><img src="/2023/04/05/MIT6-S081-Operating-System-Engineering-Lecture04-Page-Tables/Addresstransition.png"></p>
<p>我们之前提到的虚拟内存地址中的27bit的<code>index</code>，实际上是由3个9bit的数字组成（<code>L2</code>，<code>L1</code>，<code>L0</code>）。前9个bit被用来索引最高级的<code>page directory</code>（注：通常<code>page directory</code>是用来索引<code>page table</code>或者其他<code>page directory</code>物理地址的表单)</p>
<p>一个<code>directory</code>是4096Bytes，就跟<code>page</code>的大小是一样的。<code>Directory</code>中的一个条目被称为<code>PTE（Page Table Entry）</code>是64bits，就像寄存器的大小一样，也就是8Bytes。所以一个<code>Directory page</code>有512个条目。</p>
<p>所以实际上，<code>SATP</code>寄存器会指向最高一级的<code>page directory</code>的物理内存地址，之后我们用虚拟内存中<code>index</code>的高9bit用来索引最高一级的<code>page directory</code>，这样我们就能得到一个<code>PPN</code>，也就是物理<code>page</code>号。这个<code>PPN</code>指向了中间级的<code>page directory</code>。</p>
<p>当我们在使用中间级的<code>page directory</code>时，我们通过虚拟内存地址中的<code>L1</code>部分完成索引。接下来会走到最低级的<code>page directory</code>，我们通过虚拟内存地址中的<code>L0</code>部分完成索引。在最低级的<code>page directory</code>中，我们可以得到对应于虚拟内存地址的物理内存地址。</p>
<h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>如果地址空间中大部分地址都没有使用，你不必为每一个<code>index</code>准备一个条目。举个例子，如果你的地址空间只使用了一个<code>page</code>，4096Bytes。除此之外，你没有使用任何其他的地址。现在，你需要多少个<code>page table entry</code>，或者<code>page table directory</code>来映射这一个<code>page</code>？</p>
<p>在最高级，你需要一个<code>page directory</code>。在这个<code>page directory</code>中，你需要一个数字是0的<code>PTE</code>，指向中间级<code>page directory</code>。所以在中间级，你也需要一个<code>page directory</code>，里面也是一个数字0的<code>PTE</code>，指向最低级<code>page directory</code>。所以这里总共需要3个<code>page directory</code>（也就是3 * 512个条目）。</p>
<p>而在单级<code>page table</code>中，虽然我们只使用了一个<code>page</code>，还是需要2^27个<code>PTE</code>。这个方案中，我们只需要3 * 512个<code>PTE</code>。所需的空间大大减少了。这是实际上硬件采用这种层次化的3级<code>page directory</code>结构的主要原因。</p>
<h3 id="PTE"><a href="#PTE" class="headerlink" title="PTE"></a>PTE</h3><ol>
<li><p><strong>物理页号（Physical Page Number，PPN）</strong>: 与物理地址字段类似，PPN存储与虚拟地址关联的物理内存地址。在RISC-V中，PTE的高位部分存储PPN。</p>
</li>
<li><p><strong>有效位（Valid，V）</strong>: 有效位表示此PTE中存储的映射是否有效。如果有效位设置为1，表示此PTE的虚拟地址已映射到物理内存中。如果设置为0，则表示该虚拟地址尚未映射。</p>
</li>
<li><p><strong>读（Read，R）</strong>: 读权限位表示允许对该页面进行读访问。</p>
</li>
<li><p><strong>写（Write，W）</strong>: 写权限位表示允许对该页面进行写访问。</p>
</li>
<li><p><strong>执行（Execute，X）</strong>: 执行权限位表示允许对该页面进行执行访问。</p>
</li>
<li><p><strong>用户（User，U）</strong>: 用户权限位表示该页面是否允许在用户模式下访问。如果设置为1，则允许用户模式访问；如果设置为0，则仅允许特权模式访问。</p>
</li>
<li><p><strong>全局（Global，G）</strong>: 全局位表示该页面是否对所有地址空间可见。如果设置为1，则表示该页面在地址空间切换时不会从转换查找缓冲器（Translation Lookaside Buffer，TLB）中清除。这对于操作系统内核和共享库等全局数据结构特别有用。</p>
</li>
<li><p><strong>访问（Accessed，A）</strong>: 访问位表示自上次清零以来该页面是否被访问过。当发生内存访问时，硬件会自动设置访问位。</p>
</li>
<li><p><strong>脏（Dirty，D）</strong>: 脏位表示自上次清零以来该页面是否被修改过。当某个页面的内容被修改时，硬件会自动设置脏位。</p>
</li>
<li><p><strong>软件可用位（Software Use，SW）</strong>: 这些位是为操作系统软件保留的，可以在页表遍历过程中用于自定义用途。</p>
</li>
</ol>
<h1 id="页表缓存（Translation-Lookaside-Buffer）"><a href="#页表缓存（Translation-Lookaside-Buffer）" class="headerlink" title="页表缓存（Translation Lookaside Buffer）"></a>页表缓存（Translation Lookaside Buffer）</h1><p>观察<code>page table</code>的结构，可以发现，当处理器从内存加载或者存储数据时，基本上都要做3次内存查找，第一次在最高级的<code>page directory</code>，第二次在中间级的<code>page directory</code>，最后一次在最低级的<code>page directory</code>。所以对于一个虚拟内存地址的寻址，需要读三次内存，这里代价有点高。所以实际中，几乎所有的处理器都会对于最近使用过的虚拟地址的翻译结果有缓存。这个缓存被称为：<code>Translation Lookside Buffer</code>（通常翻译成页表缓存）。你会经常看到它的缩写<code>TLB</code>。基本上来说，这就是<code>Page Table Entry</code>的缓存，也就是<code>PTE</code>的缓存。</p>
<p>当处理器第一次查找一个虚拟地址时，硬件通过3级<code>page table</code>得到最终的<code>PPN</code>，<code>TLB</code>会保存虚拟地址到物理地址的映射关系。这样下一次当你访问同一个虚拟地址时，处理器可以查看<code>TLB</code>，<code>TLB</code>会直接返回物理地址，而不需要通过<code>page table</code>得到结果。</p>
<p><code>TLB</code>实现的具体细节不是我们要深入讨论的内容。这是处理器中的一些逻辑，对于操作系统来说是不可见的，操作系统也不需要知道<code>TLB</code>是如何工作的。你们需要知道TLB存在的唯一原因是，如果你切换了<code>page table</code>，操作系统需要告诉处理器当前正在切换<code>page table</code>，处理器会清空<code>TLB</code>。因为本质上来说，如果你切换了<code>page table</code>，<code>TLB</code>中的缓存将不再有用，它们需要被清空，否则地址翻译可能会出错。所以操作系统知道<code>TLB</code>是存在的，但只会时不时的告诉操作系统，现在的TLB不能用了，因为要切换<code>page table</code>了。在RISC-V中，清空<code>TLB</code>的指令是<code>sfence_vma</code>。</p>
<p>整个CPU和<code>MMU</code>都在处理器芯片中，所以在一个RISC-V芯片中，有多个CPU核，<code>MMU</code>和<code>TLB</code>存在于每一个CPU核里面。RISC-V处理器有<code>L1 cache</code>，<code>L2 Cache</code>，有些<code>cache</code>是根据物理地址索引的，有些cache是根据虚拟地址索引的，由虚拟地址索引的<code>cache</code>位于<code>MMU</code>之前，由物理地址索引的<code>cache</code>位于<code>MMU</code>之后。</p>
<h1 id="Kernel-Page-Table"><a href="#Kernel-Page-Table" class="headerlink" title="Kernel Page Table"></a>Kernel Page Table</h1><p><img src="/2023/04/05/MIT6-S081-Operating-System-Engineering-Lecture04-Page-Tables/KernelPage.png"></p>
<p>在XV6中，<code>page table</code>是如何工作的?</p>
<p>当操作系统启动时，会从地址<code>0x80000000</code>开始运行，这个地址其实也是由硬件设计者决定的。</p>
<p>主板的设计人员决定了，在完成了虚拟到物理地址的翻译之后，如果得到的物理地址大于<code>0x80000000</code>会走向DRAM芯片，如果得到的物理地址低于<code>0x80000000</code>会走向不同的I&#x2F;O设备。这是由这个主板的设计人员决定的物理结构。</p>
<p>首先，地址<code>0</code>是保留的，地址<code>0x10090000</code>对应以太网，地址<code>0x80000000</code>对应DDR内存，处理器外的易失存储（Off-Chip Volatile Memory），也就是主板上的DRAM芯片。</p>
<p>所有的事情都是由硬件，即主板决定的，CPU只是主板的一小部分，DRAM芯片位于处理器之外。是主板设计者将处理器，DRAM和许多I&#x2F;O设备汇总在一起。对于一个操作系统来说，CPU只是一个部分，I&#x2F;O设备同样也很重要。所以当你在写一个操作系统时，你需要同时处理CPU和I&#x2F;O设备，比如你需要向互联网发送一个报文，操作系统需要调用网卡驱动和网卡来实际完成这个工作。</p>
<p>地址<code>0x1000</code>是<code>boot ROM</code>的物理地址，当你对主板上电，主板做的第一件事情就是运行存储在<code>boot ROM</code>中的代码，当<code>boot</code>完成之后，会跳转到地址<code>0x80000000</code>，操作系统需要确保那个地址有一些数据能够接着启动操作系统。</p>
<p>物理地址还有一些其他的I&#x2F;O设备</p>
<ul>
<li><p>PLIC是中断控制器（Platform-Level Interrupt Controller）</p>
</li>
<li><p>CLINT（Core Local Interruptor）也是中断的一部分。所以多个设备都能产生中断，需要中断控制器来将这些中断路由到合适的处理函数。</p>
</li>
<li><p>UART0（Universal Asynchronous Receiver&#x2F;Transmitter）负责与Console和显示器交互。</p>
</li>
<li><p>VIRTIO disk，与磁盘进行交互。</p>
</li>
</ul>
<p>高于<code>0x80000000</code>的物理地址对应DRAM芯片，但是对于例如以太网接口，也有一个特定的低于<code>0x80000000</code>的物理地址，我们可以对这个叫做内存映射I&#x2F;O（Memory-mapped I&#x2F;O）的地址执行读写指令，来完成设备的操作。</p>
<p>地址<code>0x02000000</code>对应CLINT，当你向这个地址执行读写指令，你是向实现了CLINT的芯片执行读写。这里你可以认为你直接在与设备交互，而不是读写物理内存。</p>
<p>物理地址总共有2^56那么多，但是你不用在主板上接入那么多的内存。所以不论主板上有多少DRAM芯片，总是会有一部分物理地址没有被用到。实际上在XV6中，我们限制了内存的大小是128MB。</p>
<p>在RISC-V中有一个多路输出选择器（demultiplexer）可以帮助CPU将指令送到正确的I&#x2F;O设备。</p>
<p>两件重要的事情：</p>
<ul>
<li><p>有一些<code>page</code>在虚拟内存中的地址很靠后，比如<code>kernel stack</code>在虚拟内存中的地址就很靠后。这是因为在它之下有一个未被映射的<code>Guard page</code>，这个<code>Guard page</code>对应的<code>PTE</code>的<code>Valid</code> 标志位没有设置，这样，如果<code>kernel stack</code>耗尽了，它会溢出到<code>Guard page</code>，但是因为<code>Guard page</code>的<code>PTE</code>中<code>Valid</code>标志位未设置，会导致立即触发<code>page fault</code>，这样的结果好过内存越界之后造成的数据混乱。立即触发一个<code>panic</code>（也就是<code>page fault</code>），你就知道<code>kernel stack</code>出错了。同时我们也又不想浪费物理内存给<code>Guard page</code>，所以<code>Guard page</code>不会映射到任何物理内存，它只是占据了虚拟地址空间的一段靠后的地址。&#96;</p>
<p>同时，<code>kernel stack</code>被映射了两次，在靠后的虚拟地址映射了一次，在<code>PHYSTOP</code>下的<code>Kernel data</code>中又映射了一次，但是实际使用的时候用的是上面的部分，因为有<code>Guard page</code>会更加安全。</p>
</li>
<li><p>权限：例如<code>Kernel text page</code>被标位<code>R-X</code>，意味着你可以读它，也可以在这个地址段执行指令，但是你不能向<code>Kernel text</code>写数据。通过设置权限我们可以尽早的发现Bug从而避免Bug。对于<code>Kernel data</code>需要能被写入，所以它的标志位是<code>RW-</code>，但是你不能在这个地址段运行指令，所以它的<code>X</code>标志位未被设置。（注，所以，<code>kernel text</code>用来存代码，代码可以读，可以运行，但是不能篡改，<code>kernel data</code>用来存数据，数据可以读写，但是不能通过数据伪装代码在kernel中运行）</p>
</li>
</ul>
<p>每一个用户进程都有一个对应的<code>kernel stack</code>。</p>
<p>在<code>kernel page table</code>中，有一段<code>Free Memory</code>，它对应了物理内存中的一段地址。XV6使用这段<code>free memory</code>来存放用户进程的<code>page table</code>，<code>text</code>和<code>data</code>。如果我们运行了非常多的用户进程，某个时间点我们会耗尽这段内存，这个时候<code>fork</code>或者<code>exec</code>会返回错误。</p>
<p>当kernel创建了一个进程，针对这个进程的<code>page table</code>也会从<code>Free memory</code>中分配出来。内核会为用户进程的<code>page table</code>分配几个<code>page</code>，并填入<code>PTE</code>。在某个时间点，当内核运行了这个进程，内核会将进程的根<code>page table</code>的地址加载到<code>SATP</code>中。从那个时间点开始，处理器会使用内核为那个进程构建的虚拟地址空间。</p>
<h1 id="Code-Creating-an-address-space"><a href="#Code-Creating-an-address-space" class="headerlink" title="Code:Creating an address space"></a>Code:Creating an address space</h1><p>大部分用于操作地址空间和页表的xv6代码位于vm.c（kernel&#x2F;vm.c）中。主要数据结构是<code>pagetable_t</code>，它实际上是指向RISC-V 35根页表页面的指针；<code>pagetable_t</code>可以是内核页表，也可以是每个进程的页表之一。主要函数为<code>walk</code>，该函数查找虚拟地址的<code>PTE</code>，并且<code>mappages</code>安装新映射的PTE。以<code>kvm</code>开头的函数操作内核页表；以<code>uvm</code>开头的函数操作用户页表；其他功能同时用于两者。<code>copyout</code>和<code>copyin</code>将数据复制和从作为系统调用参数提供的用户虚拟地址复制出来；它们在vm.c中因为需要明确翻译这些地址才能找到相应物理存储器。</p>
<p>在引导序列早期，<code>main</code>调用<code>kvminit</code>（kernel&#x2F;vm.c:54）使用<code>kvmmake</code>（kernel&#x2F;vm.c:20）创建内核页面表格。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span></span><br><span class="line"><span class="title function_">kvminit</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">  kernel_pagetable = kvmmake();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">pagetable_t</span></span><br><span class="line"><span class="title function_">kvmmake</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="type">pagetable_t</span> kpgtbl;</span><br><span class="line"></span><br><span class="line">  kpgtbl = (<span class="type">pagetable_t</span>) kalloc();</span><br><span class="line">  <span class="built_in">memset</span>(kpgtbl, <span class="number">0</span>, PGSIZE);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// uart registers</span></span><br><span class="line">  kvmmap(kpgtbl, UART0, UART0, PGSIZE, PTE_R | PTE_W);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// virtio mmio disk interface</span></span><br><span class="line">  kvmmap(kpgtbl, VIRTIO0, VIRTIO0, PGSIZE, PTE_R | PTE_W);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// PLIC</span></span><br><span class="line">  kvmmap(kpgtbl, PLIC, PLIC, <span class="number">0x400000</span>, PTE_R | PTE_W);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// map kernel text executable and read-only.</span></span><br><span class="line">  kvmmap(kpgtbl, KERNBASE, KERNBASE, (uint64)etext-KERNBASE, PTE_R | PTE_X);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// map kernel data and the physical RAM we&#x27;ll make use of.</span></span><br><span class="line">  kvmmap(kpgtbl, (uint64)etext, (uint64)etext, PHYSTOP-(uint64)etext, PTE_R | PTE_W);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// map the trampoline for trap entry/exit to</span></span><br><span class="line">  <span class="comment">// the highest virtual address in the kernel.</span></span><br><span class="line">  kvmmap(kpgtbl, TRAMPOLINE, (uint64)trampoline, PGSIZE, PTE_R | PTE_X);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// allocate and map a kernel stack for each process.</span></span><br><span class="line">  proc_mapstacks(kpgtbl);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> kpgtbl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>此调用发生在xv6启动RISC-V分页之前，因此地址直接引用物理存储器。<code>kvmmake</code>首先分配一个物理存储器页面来保存根页面- 表示页面; 然后它调用<code>kvmmap</code>来安装内核所需的转换。这些转换包括内核指令和数据、<code>PHYSTOP</code>以下 的物理存储器以及实际上是设备的内存范围。</p>
<p><code>proc_mapstacks</code>（kernel&#x2F;proc.c:33）为每个进程分配一个内核堆栈。它调用<code>kvmmap</code>将每个堆栈映射到由<code>KSTACK</code>生成的虚拟地址，这样可以留出无效的堆栈保护页。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Allocate a page for each process&#x27;s kernel stack.</span></span><br><span class="line"><span class="comment">// Map it high in memory, followed by an invalid</span></span><br><span class="line"><span class="comment">// guard page.</span></span><br><span class="line"><span class="type">void</span></span><br><span class="line"><span class="title function_">proc_mapstacks</span><span class="params">(<span class="type">pagetable_t</span> kpgtbl)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">proc</span> *<span class="title">p</span>;</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span>(p = proc; p &lt; &amp;proc[NPROC]; p++) &#123;</span><br><span class="line">    <span class="type">char</span> *pa = kalloc();</span><br><span class="line">    <span class="keyword">if</span>(pa == <span class="number">0</span>)</span><br><span class="line">      panic(<span class="string">&quot;kalloc&quot;</span>);</span><br><span class="line">    uint64 va = KSTACK((<span class="type">int</span>) (p - proc));</span><br><span class="line">    kvmmap(kpgtbl, va, (uint64)pa, PGSIZE, PTE_R | PTE_W);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>kvmmap</code>（kernel&#x2F;vm.c:127）调用<code>mappages</code>（kernel&#x2F;vm.c:138），该函数为一系列虚拟地址范围安装映射到相应物理地址的页面表格中。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// add a mapping to the kernel page table.</span></span><br><span class="line"><span class="comment">// only used when booting.</span></span><br><span class="line"><span class="comment">// does not flush TLB or enable paging.</span></span><br><span class="line"><span class="type">void</span></span><br><span class="line"><span class="title function_">kvmmap</span><span class="params">(<span class="type">pagetable_t</span> kpgtbl, uint64 va, uint64 pa, uint64 sz, <span class="type">int</span> perm)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">if</span>(mappages(kpgtbl, va, sz, pa, perm) != <span class="number">0</span>)</span><br><span class="line">    panic(<span class="string">&quot;kvmmap&quot;</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Create PTEs for virtual addresses starting at va that refer to</span></span><br><span class="line"><span class="comment">// physical addresses starting at pa. va and size might not</span></span><br><span class="line"><span class="comment">// be page-aligned. Returns 0 on success, -1 if walk() couldn&#x27;t</span></span><br><span class="line"><span class="comment">// allocate a needed page-table page.</span></span><br><span class="line"><span class="type">int</span></span><br><span class="line"><span class="title function_">mappages</span><span class="params">(<span class="type">pagetable_t</span> pagetable, uint64 va, uint64 size, uint64 pa, <span class="type">int</span> perm)</span></span><br><span class="line">&#123;</span><br><span class="line">  uint64 a, last;</span><br><span class="line">  <span class="type">pte_t</span> *pte;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span>(size == <span class="number">0</span>)</span><br><span class="line">    panic(<span class="string">&quot;mappages: size&quot;</span>);</span><br><span class="line"></span><br><span class="line">  a = PGROUNDDOWN(va);</span><br><span class="line">  last = PGROUNDDOWN(va + size - <span class="number">1</span>);</span><br><span class="line">  <span class="keyword">for</span>(;;)&#123;</span><br><span class="line">    <span class="keyword">if</span>((pte = walk(pagetable, a, <span class="number">1</span>)) == <span class="number">0</span>)</span><br><span class="line">      <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">if</span>(*pte &amp; PTE_V)</span><br><span class="line">      panic(<span class="string">&quot;mappages: remap&quot;</span>);</span><br><span class="line">    *pte = PA2PTE(pa) | perm | PTE_V;</span><br><span class="line">    <span class="keyword">if</span>(a == last)</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    a += PGSIZE;</span><br><span class="line">    pa += PGSIZE;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>它对于范围中的每个虚拟地址单独执行此操作，在页面间隔处执行此操作。对于要映射的每个虚拟地址，<code>mappages</code>都会调用<code>walk</code>来查找该地址<code>PTE</code>的位置。然后，它初始化<code>PTE</code>以保存相关物理页号、所需权限（<code>PTE_W</code>、<code>PTE_X</code>和&#x2F;或 <code>PTE_R</code>）和标记<code>PTE_V</code>作为有效(kernel&#x2F;vm.c:153)。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Create PTEs for virtual addresses starting at va that refer to</span></span><br><span class="line"><span class="comment">// physical addresses starting at pa. va and size might not</span></span><br><span class="line"><span class="comment">// be page-aligned. Returns 0 on success, -1 if walk() couldn&#x27;t</span></span><br><span class="line"><span class="comment">// allocate a needed page-table page.</span></span><br><span class="line"><span class="type">int</span></span><br><span class="line"><span class="title function_">mappages</span><span class="params">(<span class="type">pagetable_t</span> pagetable, uint64 va, uint64 size, uint64 pa, <span class="type">int</span> perm)</span></span><br><span class="line">&#123;</span><br><span class="line">  uint64 a, last;</span><br><span class="line">  <span class="type">pte_t</span> *pte;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span>(size == <span class="number">0</span>)</span><br><span class="line">    panic(<span class="string">&quot;mappages: size&quot;</span>);</span><br><span class="line"></span><br><span class="line">  a = PGROUNDDOWN(va);</span><br><span class="line">  last = PGROUNDDOWN(va + size - <span class="number">1</span>);</span><br><span class="line">  <span class="keyword">for</span>(;;)&#123;</span><br><span class="line">    <span class="keyword">if</span>((pte = walk(pagetable, a, <span class="number">1</span>)) == <span class="number">0</span>)</span><br><span class="line">      <span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">    <span class="keyword">if</span>(*pte &amp; PTE_V)</span><br><span class="line">      panic(<span class="string">&quot;mappages: remap&quot;</span>);</span><br><span class="line">    *pte = PA2PTE(pa) | perm | PTE_V;</span><br><span class="line">    <span class="keyword">if</span>(a == last)</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    a += PGSIZE;</span><br><span class="line">    pa += PGSIZE;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>walk</code>（kernel&#x2F;vm.c:81）模仿RISC-V分页硬件，查找虚拟地址的<code>PTE</code>。<code>walk</code>每次下降3级页面表9位。它使用每个级别的9位虚拟地址来查找下一级页面表或最终页面的<code>PTE</code>（kernel&#x2F;vm.c:87）。如果PTE无效，则尚未分配所需页面；如果设置了alloc参数，则walk将分配新的页表页并将其物理地址放入PTE中。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Return the address of the PTE in page table pagetable</span></span><br><span class="line"><span class="comment">// that corresponds to virtual address va.  If alloc!=0,</span></span><br><span class="line"><span class="comment">// create any required page-table pages.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// The risc-v Sv39 scheme has three levels of page-table</span></span><br><span class="line"><span class="comment">// pages. A page-table page contains 512 64-bit PTEs.</span></span><br><span class="line"><span class="comment">// A 64-bit virtual address is split into five fields:</span></span><br><span class="line"><span class="comment">//   39..63 -- must be zero.</span></span><br><span class="line"><span class="comment">//   30..38 -- 9 bits of level-2 index.</span></span><br><span class="line"><span class="comment">//   21..29 -- 9 bits of level-1 index.</span></span><br><span class="line"><span class="comment">//   12..20 -- 9 bits of level-0 index.</span></span><br><span class="line"><span class="comment">//    0..11 -- 12 bits of byte offset within the page.</span></span><br><span class="line"><span class="type">pte_t</span> *</span><br><span class="line"><span class="title function_">walk</span><span class="params">(<span class="type">pagetable_t</span> pagetable, uint64 va, <span class="type">int</span> alloc)</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="keyword">if</span>(va &gt;= MAXVA)</span><br><span class="line">    panic(<span class="string">&quot;walk&quot;</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span>(<span class="type">int</span> level = <span class="number">2</span>; level &gt; <span class="number">0</span>; level--) &#123;</span><br><span class="line">    <span class="type">pte_t</span> *pte = &amp;pagetable[PX(level, va)];</span><br><span class="line">    <span class="keyword">if</span>(*pte &amp; PTE_V) &#123;</span><br><span class="line">      pagetable = (<span class="type">pagetable_t</span>)PTE2PA(*pte);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">if</span>(!alloc || (pagetable = (<span class="type">pde_t</span>*)kalloc()) == <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">      <span class="built_in">memset</span>(pagetable, <span class="number">0</span>, PGSIZE);</span><br><span class="line">      *pte = PA2PTE(pagetable) | PTE_V;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> &amp;pagetable[PX(<span class="number">0</span>, va)];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>它返回树中最低层的<code>PTE</code>地址。以上代码依赖于物理内存被直接映射到内核虚拟地址空间中。例如，当<code>walk</code>下降页面表级别时，它从<code>PTE</code>获取下一个向下级别页面表(物理)地址，并使用该地址作为虚拟地址获取下一个向下级别的 <code>PTE </code>。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">/ Switch h/w page table <span class="keyword">register</span> to the kernel<span class="number">&#x27;</span>s page table,</span><br><span class="line"><span class="comment">// and enable paging.</span></span><br><span class="line"><span class="type">void</span></span><br><span class="line"><span class="title function_">kvminithart</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment">// wait for any previous writes to the page table memory to finish.</span></span><br><span class="line">  sfence_vma();</span><br><span class="line"></span><br><span class="line">  w_satp(MAKE_SATP(kernel_pagetable));</span><br><span class="line"></span><br><span class="line">  <span class="comment">// flush stale entries from the TLB.</span></span><br><span class="line">  sfence_vma();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>主函数调用<code>kvminithart</code>(kernel &#x2F; vm.c：62)安装内核页表。 它将根页表页的物理地址写入<code>satp</code>寄存器。之后CPU将使用内核页表翻译地址。由于内核使用身份映射，现在指令集合上一条指令对应正确的物理内存位置。</p>
<p>每个RISC-V CPU都会在转换前缓存TLB中相应信息，在xv6更改某一页时必须告诉CPU使相应的缓存TLB条目失效。如果没有这样做，那么在以后的某个时候，TLB可能会使用旧的缓存映射，指向此时已分配给另一个进程的物理页面，并且结果是进程可能能够涂写其他进程的内存。RISC-V有一种指令<code>sfence.vma</code>可以刷新当前CPU的<code>TLB</code>。Xv6在重新加载<code>satp</code>寄存器之后，在<code>kvminithart</code>中执行<code>sfence.vma</code>，并在跳板代码(kernel&#x2F;trampoline.S:79)中切换到36用户页表并返回用户空间前执行。</p>
<p>为了避免刷新完整的TLB，RISC-V CPU可以支持地址空间标识符（ASIDs）。然后内核只需清除特定地址空间的TLB条目即可</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/04/02/MIT6-S081-Operating-System-Engineering-Lecture03-OS-Organization-and-System-Call/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Plucky">
      <meta itemprop="description" content="随便记录">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Plucky">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/04/02/MIT6-S081-Operating-System-Engineering-Lecture03-OS-Organization-and-System-Call/" class="post-title-link" itemprop="url">MIT6 S081 Operating System Engineering Lecture03 OS Organization and System Call</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-04-02 14:44:05" itemprop="dateCreated datePublished" datetime="2023-04-02T14:44:05+08:00">2023-04-02</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-04-06 16:24:13" itemprop="dateModified" datetime="2023-04-06T16:24:13+08:00">2023-04-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">课程学习</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/MIT6-S081-Operating-System-Engineering/" itemprop="url" rel="index"><span itemprop="name">MIT6.S081 Operating System Engineering</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>9.2k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>17 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Topic"><a href="#Topic" class="headerlink" title="Topic"></a>Topic</h1><ul>
<li><p><strong>Isolation</strong>:Isolation是设计操作系统组织结构的驱动力</p>
</li>
<li><p><strong>System Call</strong>:System call是你的应用程序能够转换到内核执行的基本方法</p>
</li>
<li><p><strong>Kernel mode&#x2F;user mode</strong></p>
</li>
</ul>
<h1 id="Isolation"><a href="#Isolation" class="headerlink" title="Isolation"></a>Isolation</h1><h2 id="应用程序之间有隔离性"><a href="#应用程序之间有隔离性" class="headerlink" title="应用程序之间有隔离性"></a>应用程序之间有隔离性</h2><p>我们在用户空间有多个应用程序，例如<code>Shell</code>、<code>echo</code>、<code>find</code>等等。但是，如果你通过Shell运行你们的Prime代码（lab1中的一个部分）时，假设你们的代码出现了问题，Shell不应该会影响到其他的应用程序。举个反例，如果Shell出现问题时，杀掉了其他的进程，这将会非常糟糕。所以你需要在不同的应用程序之间有强隔离性。</p>
<h2 id="应用程序与操作系统之间有隔离性"><a href="#应用程序与操作系统之间有隔离性" class="headerlink" title="应用程序与操作系统之间有隔离性"></a>应用程序与操作系统之间有隔离性</h2><p>操作系统某种程度上为所有的应用程序服务。当你的应用程序出现问题时，你会希望操作系统不会因此而崩溃。比如说你向操作系统传递了一些奇怪的参数，你会希望操作系统仍然能够很好的处理它们（能较好的处理异常情况）。所以，你也需要在应用程序和操作系统之间有强隔离性。</p>
<h2 id="如果没有操作系统"><a href="#如果没有操作系统" class="headerlink" title="如果没有操作系统"></a>如果没有操作系统</h2><p>如果没有操作系统，或者操作系统只是一些库文件，比如说你在使用Python，通过import os你就可以将整个操作系统加载到你的应用程序中。那么现在，我们有一个Shell，并且我们引用了代表操作系统的库。同时，我们有一些其他的应用程序，例如echo。</p>
<p>通常来说，如果没有操作系统，应用程序会直接与硬件交互。比如，应用程序可以直接看到CPU的多个核，看到磁盘，内存。所以现在应用程序和硬件资源之间没有一个额外的抽象层。</p>
<h3 id="调度及复用隔离问题"><a href="#调度及复用隔离问题" class="headerlink" title="调度及复用隔离问题"></a>调度及复用隔离问题</h3><p>使用操作系统的一个目的是为了同时运行多个应用程序，所以时不时的，CPU会从一个应用程序切换到另一个应用程序。我们假设硬件资源里只有一个CPU核，并且我们现在在这个CPU核上运行Shell。但是时不时的，也需要让其他的应用程序也可以运行。现在我们没有操作系统来帮我们完成切换，所以Shell就需要时不时的释放CPU资源。</p>
<p>为了不变成一个恶意程序，Shell在发现自己运行了一段时间之后，需要让别的程序也有机会能运行。这种机制有时候称为协同调度（Cooperative Scheduling）。但是这里的场景并没有很好的隔离性，比如说Shell中的某个函数有一个死循环，那么Shell永远也不会释放CPU，进而其他的应用程序也不能够运行，甚至都不能运行一个第三方的程序来停止或者杀死Shell程序。所以这种场景下，我们基本上得不到真正的multiplexing（CPU在多进程同分时复用）。而这个特性是非常有用的，不论应用程序在执行什么操作，multiplexing都会迫使应用程序时不时的释放CPU，这样其他的应用程序才能运行。</p>
<h3 id="内存隔离问题"><a href="#内存隔离问题" class="headerlink" title="内存隔离问题"></a>内存隔离问题</h3><p>假设现在物理内存中的一部分被Shell使用，另一部分被echo使用。因为两个应用程序的内存之间没有边界，如果echo程序将数据存储在属于Shell的一个内存地址中，那么就echo就会覆盖Shell程序内存中的内容。</p>
<p>使用操作系统的一个原因，甚至可以说是主要原因就是为了实现multiplexing和内存隔离。如果你不使用操作系统，并且应用程序直接与硬件交互，就很难实现这两点。所以，将操作系统设计成一个库，并不是一种常见的设计。你或许可以在一些实时操作系统中看到这样的设计，因为在这些实时操作系统中，应用程序之间彼此相互信任。但是在大部分的其他操作系统中，都会强制实现硬件资源的隔离。</p>
<h2 id="从隔离的角度来看Unix接口"><a href="#从隔离的角度来看Unix接口" class="headerlink" title="从隔离的角度来看Unix接口"></a>从隔离的角度来看Unix接口</h2><p>如果我们从隔离的角度来稍微看看Unix接口，那么我们可以发现，接口被精心设计以实现资源的强隔离，也就是multiplexing和物理内存的隔离。接口通过抽象硬件资源，从而使得提供强隔离性成为可能。</p>
<h3 id="Example-1"><a href="#Example-1" class="headerlink" title="Example 1"></a>Example 1</h3><p>之前通过fork创建了进程。进程本身不是CPU，但是它们对应了CPU，它们使得你可以在CPU上运行计算任务。所以你懂的，应用程序不能直接与CPU交互，只能与进程交互。操作系统内核会完成不同进程在CPU上的切换。所以，操作系统不是直接将CPU提供给应用程序，而是向应用程序提供“进程”，进程抽象了CPU，这样操作系统才能在多个应用程序之间复用一个或者多个CPU。</p>
<p>我们在实验中使用的RISC-V处理器实际上是有4个核。所以你可以同时运行4个进程，一个进程占用一个核。但是假设你有8个应用程序，操作系统会分时复用这些CPU核，比如说对于一个进程运行100毫秒，之后内核会停止运行并将那个进程从CPU中卸载，再加载另一个应用程序并再运行100毫秒。通过这种方式使得每一个应用程序都不会连续运行超过100毫秒。这里只是一些基本概念，我们在接下来的几节课中会具体的看这里是如何实现的。</p>
<p>我们可以认为exec抽象了内存。当我们在执行exec系统调用的时候，我们会传入一个文件名，而这个文件名对应了一个应用程序的内存镜像。内存镜像里面包括了程序对应的指令，全局的数据。应用程序可以逐渐扩展自己的内存，但是应用程序并没有直接访问物理内存的权限，例如应用程序不能直接访问物理内存的1000-2000这段地址。不能直接访问的原因是，操作系统会提供内存隔离并控制内存，操作系统会在应用程序和硬件资源之间提供一个中间层。exec是这样一种系统调用，它表明了应用程序不能直接访问物理内存。</p>
<h3 id="Example-2"><a href="#Example-2" class="headerlink" title="Example 2"></a>Example 2</h3><p>files基本上来说抽象了磁盘。应用程序不会直接读写挂在计算机上的磁盘本身，并且在Unix中这也是不被允许的。在Unix中，与存储系统交互的唯一方式就是通过files。Files提供了非常方便的磁盘抽象，你可以对文件命名，读写文件等等。之后，操作系统会决定如何将文件与磁盘中的块对应，确保一个磁盘块只出现在一个文件中，并且确保用户A不能操作用户B的文件。通过files的抽象，可以实现不同用户之间和同一个用户的不同进程之间的文件强隔离。</p>
<h1 id="Defensive"><a href="#Defensive" class="headerlink" title="Defensive"></a>Defensive</h1><ul>
<li><p>防御性：当你在做内核开发时，这是一种你需要熟悉的重要思想。操作系统需要确保所有的组件都能工作，所以它需要做好准备抵御来自应用程序的攻击。如果说应用程序无意或者恶意的向系统调用传入一些错误的参数就会导致操作系统崩溃，那就太糟糕了。在这种场景下，操作系统因为崩溃了会拒绝为其他所有的应用程序提供服务。所以操作系统需要以这样一种方式来完成：操作系统需要能够应对恶意的应用程序。</p>
</li>
<li><p>隔离性：另一个需要考虑的是，应用程序不能够打破对它的隔离。应用程序非常有可能是恶意的，它或许是由攻击者写出来的，攻击者或许想要打破对应用程序的隔离，进而控制内核。一旦有了对于内核的控制能力，你可以做任何事情，因为内核控制了所有的硬件资源。</p>
</li>
</ul>
<p>所以操作系统或者说内核需要具备防御性来避免类似的事情发生。实际中，要满足这些要求还有点棘手。在Linux中，时不时的有一些内核的bug使得应用程序可以打破它的隔离域并控制内核。这里需要持续的关注，并尽可能的提供最好的防御性。当你在开发内核时，防御性是你必须掌握的一个思想。实际中的应用程序或许就是恶意的，这意味着我们需要在应用程序和操作系统之间提供强隔离性。如果操作系统需要具备防御性，那么在应用程序和操作系统之间需要有一堵厚墙，并且操作系统可以在这堵墙上执行任何它想执行的策略。</p>
<p>通常来说，需要通过硬件来实现强隔离性。这里的硬件主要包括两部分，一个是user&#x2F;kernel mode，kernel mode在RISC-V中被称为Supervisor mode但是其实是同一种东西；第二部分是page table或者虚拟内存（Virtual Memory）</p>
<p>所以，所有的处理器，如果需要运行能够支持多个应用程序的操作系统，需要同时支持user&#x2F;kernle mode和虚拟内存。具体的实现或许会有细微的差别，但是基本上来说所有的处理器需要能支持这些。</p>
<h2 id="硬件对于强隔离的支持"><a href="#硬件对于强隔离的支持" class="headerlink" title="硬件对于强隔离的支持"></a>硬件对于强隔离的支持</h2><h3 id="user-x2F-kernel-mode"><a href="#user-x2F-kernel-mode" class="headerlink" title="user&#x2F;kernel mode"></a>user&#x2F;kernel mode</h3><p>为了支持user&#x2F;kernel mode，处理器会有两种操作模式，第一种是user mode，第二种是kernel mode。当运行在kernel mode时，CPU可以运行特定权限的指令（privileged instructions）；当运行在user mode时，CPU只能运行普通权限的指令（unprivileged instructions）。</p>
<ul>
<li><p>普通权限的指令都是一些你们熟悉的指令，例如将两个寄存器相加的指令ADD、将两个寄存器相减的指令SUB、跳转指令JRC、BRANCH指令等等。这些都是普通权限指令，所有的应用程序都允许执行这些指令。</p>
</li>
<li><p>特殊权限指令主要是一些直接操纵硬件的指令和设置保护的指令，例如设置page table寄存器、关闭时钟中断。在处理器上有各种各样的状态，操作系统会使用这些状态，但是只能通过特殊权限指令来变更这些状态。</p>
</li>
</ul>
<p>举个例子，当一个应用程序尝试执行一条特殊权限指令，因为不允许在user mode执行特殊权限指令，处理器会拒绝执行这条指令。通常来说，这时会将控制权限从user mode切换到kernel mode，当操作系统拿到控制权之后，或许会杀掉进程，因为应用程序执行了不该执行的指令。</p>
<p>在处理器里面有一个flag。在处理器的一个bit，当它为1的时候是user mode，当它为0时是kernel mode。当处理器在解析指令时，如果指令是特殊权限指令，并且该bit被设置为1，处理器会拒绝执行这条指令，就像在运算时不能除以0一样。设置那个bit位的指令必须是特殊权限指令，因为应用程序不应该能够设置那个bit到kernel mode，否则的话应用程序就可以运行各种特殊权限指令了。所以那个bit是被保护的。</p>
<ul>
<li>RISC-V还有第三种模式称为machine mode。在大多数场景下，我们会忽略这种模式，所以我们实际上有三级权限user&#x2F;kernel&#x2F;machine。</li>
</ul>
<h3 id="page-table"><a href="#page-table" class="headerlink" title="page table"></a>page table</h3><p>每一个进程都会有自己独立的page table，这样的话，每一个进程只能访问出现在自己page table中的物理内存。操作系统会设置page table，使得每一个进程都有不重合的物理内存，这样一个进程就不能访问其他进程的物理内存，因为其他进程的物理内存都不在它的page table中。一个进程甚至都不能随意编造一个内存地址，然后通过这个内存地址来访问其他进程的物理内存。这样就给了我们内存的强隔离性。</p>
<p>基本上来说，page table定义了对于内存的视图，而每一个用户进程都有自己对于内存的独立视图。这给了我们非常强的内存隔离性。</p>
<h1 id="User-x2F-Kernel-mode切换"><a href="#User-x2F-Kernel-mode切换" class="headerlink" title="User&#x2F;Kernel mode切换"></a>User&#x2F;Kernel mode切换</h1><p>我们可以认为user&#x2F;kernel mode是分隔用户空间和内核空间的边界，用户空间运行的程序运行在user mode，内核空间的程序运行在kernel mode。操作系统位于内核空间。</p>
<p>当ls程序运行的时候，会调用read&#x2F;write系统调用；Shell程序会调用fork或者exec系统调用，所以必须要有一种方式可以使得用户的应用程序能够将控制权以一种协同工作的方式转移到内核，这样内核才能提供相应的服务。</p>
<h2 id="Ecall"><a href="#Ecall" class="headerlink" title="Ecall"></a>Ecall</h2><p>在RISC-V中，有一个专门的指令用来实现控制权的转换功能，叫做ECALL。ECALL接收一个数字参数，当一个用户程序想要将程序执行的控制权转移到内核，它只需要执行ECALL指令，并传入一个数字。这里的数字参数代表了应用程序想要调用的System Call。</p>
<p>ECALL会跳转到内核中一个特定，由内核控制的位置。在XV6中存在一个唯一的系统调用接入点，每一次应用程序执行ECALL指令，应用程序都会通过这个接入点进入到内核中。举个例子，不论是Shell还是其他的应用程序，当它在用户空间执行fork时，它并不是直接调用操作系统中对应的函数，而是调用ECALL指令，并将fork对应的数字作为参数传给ECALL。之后再通过ECALL跳转到内核。</p>
<p>在内核侧，有一个位于syscall.c的函数syscall，每一个从应用程序发起的系统调用都会调用到这个syscall函数，syscall函数会检查ECALL的参数，通过这个参数内核可以知道需要调用的是fork。</p>
<p>用户空间和内核空间的界限是一个硬性的界限，用户不能直接调用fork，用户的应用程序执行系统调用的唯一方法就是通过这里的ECALL指令。</p>
<p>假设我现在要执行另一个系统调用write，相应的流程是类似的，write系统调用不能直接调用内核中的write代码，而是由封装好的系统调用函数执行ECALL指令。所以write函数实际上调用的是ECALL指令，指令的参数是代表了write系统调用的数字。之后控制权到了syscall函数，syscall会实际调用write系统调用。</p>
<h1 id="宏内核和微内核（Monolithic-Kernel-and-Micro-Kernel）"><a href="#宏内核和微内核（Monolithic-Kernel-and-Micro-Kernel）" class="headerlink" title="宏内核和微内核（Monolithic Kernel and Micro Kernel）"></a>宏内核和微内核（Monolithic Kernel and Micro Kernel）</h1><p>现在，我们有了一种方法，可以通过系统调用或者说ECALL指令，将控制权从应用程序转到操作系统中。之后内核负责实现具体的功能并检查参数以确保不会被一些坏的参数所欺骗。所以内核有时候也被称为可被信任的计算空间（Trusted Computing Base），在一些安全的术语中也被称为TCB。</p>
<p>基本上来说，要被称为TCB，内核首先要是正确且没有Bug的。假设内核中有Bug，攻击者可能会利用那个Bug，并将这个Bug转变成漏洞，这个漏洞使得攻击者可以打破操作系统的隔离性并接管内核。所以内核真的是需要越少的Bug越好。</p>
<p>另一方面，内核必须要将用户应用程序或者进程当做是恶意的。内核的设计人员在编写和实现内核代码时，必须要有安全的思想。这个目标很难实现，因为当你的操作系统变得足够大的时候，很多事情就不是那么直观了。几乎每一个你用过的或者被广泛使用的操作系统，时不时的都有一个安全漏洞。就算被修复了，但是过了一段时间，又会出现一个新的漏洞。我们之后会介绍为什么很难让所有部分都正确工作，但是你要知道是内核需要做一些tricky的工作，需要操纵硬件，需要非常小心做检查，所以很容易就出现一些小的疏漏，进而触发一个Bug。这也是可以理解的。</p>
<h2 id="宏内核（Monolithic-Kernel）"><a href="#宏内核（Monolithic-Kernel）" class="headerlink" title="宏内核（Monolithic Kernel）"></a>宏内核（Monolithic Kernel）</h2><p>让整个操作系统代码都运行在kernel mode。大多数的Unix操作系统实现都运行在kernel mode。比如，XV6中，所有的操作系统服务都在kernel mode中，这种形式被称为Monolithic Kernel Design。</p>
<ul>
<li><p>在一个宏内核中，任何一个操作系统的Bug都有可能成为漏洞。因为我们现在在内核中运行了一个巨大的操作系统，出现Bug的可能性更大了。你们可以去查一些统计信息，平均每3000行代码都会有几个Bug，所以如果有许多行代码运行在内核中，那么出现严重Bug的可能性也变得更大。所以从安全的角度来说，在内核中有大量的代码是宏内核的缺点。</p>
</li>
<li><p>如果你去看一个操作系统，它包含了各种各样的组成部分，比如说文件系统，虚拟内存，进程管理，这些都是操作系统内实现了特定功能的子模块。宏内核的优势在于，因为这些子模块现在都位于同一个程序中，它们可以紧密的集成在一起，这样的集成提供很好的性能。例如Linux，它就有很不错的性能。</p>
</li>
</ul>
<h2 id="微内核（Micro-Kernel）"><a href="#微内核（Micro-Kernel）" class="headerlink" title="微内核（Micro Kernel）"></a>微内核（Micro Kernel）</h2><p>在这种模式下，希望在kernel mode中运行尽可能少的代码。所以这种设计下还是有内核，但是内核只有非常少的几个模块，例如，内核通常会有一些IPC的实现或者是Message passing；非常少的虚拟内存的支持，可能只支持了page table；以及分时复用CPU的一些支持。</p>
<p>微内核的目的在于将大部分的操作系统运行在内核之外。所以，我们还是会有user mode以及user&#x2F;kernel mode的边界。但是我们现在会将原来在内核中的其他部分，作为普通的用户程序来运行。比如文件系统可能就是个常规的用户空间程序。</p>
<p>某种程度上来说，这是一种好的设计。因为在内核中的代码的数量较小，更少的代码意味着更少的Bug。</p>
<p>但是这种设计也有相应的问题。假设我们需要让Shell能与文件系统交互，比如Shell调用了exec，必须有种方式可以接入到文件系统中。通常来说，这里工作的方式是，Shell会通过内核中的IPC系统发送一条消息，内核会查看这条消息并发现这是给文件系统的消息，之后内核会把消息发送给文件系统。</p>
<p>文件系统会完成它的工作之后会向IPC系统发送回一条消息说，这是你的exec系统调用的结果，之后IPC系统再将这条消息发送给Shell。</p>
<p>所以，这里是典型的通过消息来实现传统的系统调用。现在，对于任何文件系统的交互，都需要分别完成2次用户空间&lt;-&gt;内核空间的跳转。与宏内核对比，在宏内核中如果一个应用程序需要与文件系统交互，只需要完成1次用户空间&lt;-&gt;内核空间的跳转，所以微内核的的跳转是宏内核的两倍。通常微内核的挑战在于性能更差，这里有两个方面需要考虑：</p>
<ul>
<li><p>在user&#x2F;kernel mode反复跳转带来的性能损耗。</p>
</li>
<li><p>在一个类似宏内核的紧耦合系统，各个组成部分，例如文件系统和虚拟内存系统，可以很容易的共享page cache。而在微内核中，每个部分之间都很好的隔离开了，这种共享更难实现。进而导致更难在微内核中得到更高的性能。</p>
</li>
</ul>
<p>在实际中，两种内核设计都会出现，出于历史原因大部分的桌面操作系统是宏内核，如果你运行需要大量内核计算的应用程序，例如在数据中心服务器上的操作系统，通常也是使用的宏内核，主要的原因是Linux提供了很好的性能。但是很多嵌入式系统，例如Minix，Cell，这些都是微内核设计。这两种设计都很流行，如果你从头开始写一个操作系统，你可能会从一个微内核设计开始。但是一旦你有了类似于Linux这样的宏内核设计，将它重写到一个微内核设计将会是巨大的工作。并且这样重构的动机也不足，因为人们总是想把时间花在实现新功能上，而不是重构他们的内核。</p>
<h1 id="编译运行Kernel"><a href="#编译运行Kernel" class="headerlink" title="编译运行Kernel"></a>编译运行Kernel</h1><h2 id="代码结构"><a href="#代码结构" class="headerlink" title="代码结构"></a>代码结构</h2><ul>
<li><p>kernel：里面包含了基本上所有的内核文件。因为XV6是一个宏内核结构，这里所有的文件会被编译成一个叫做kernel的二进制文件，然后这个二进制文件会被运行在kernle mode中。</p>
</li>
<li><p>user：这基本上是运行在user mode的程序。这也是为什么一个目录称为kernel，另一个目录称为user的原因。</p>
</li>
<li><p>mkfs：它会创建一个空的文件镜像，我们会将这个镜像存在磁盘上，这样我们就可以直接使用一个空的文件系统。</p>
</li>
</ul>
<h2 id="编译过程"><a href="#编译过程" class="headerlink" title="编译过程"></a>编译过程</h2><ul>
<li><p>Makefile（XV6目录下的文件）会读取一个C文件，例如proc.c；之后调用gcc编译器，生成一个文件叫做proc.s，这是RISC-V 汇编语言文件；之后再走到汇编解释器，生成proc.o，这是汇编语言的二进制格式。</p>
</li>
<li><p>Makefile会为所有内核文件做相同的操作，比如说pipe.c，会按照同样的套路，先经过gcc编译成pipe.s，再通过汇编解释器生成pipe.o。</p>
</li>
<li><p>之后，系统加载器（Loader）会收集所有的.o文件，将它们链接在一起，并生成内核文件。</p>
</li>
<li><p>这里生成的内核文件就是我们将会在QEMU中运行的文件。同时，为了你们的方便，Makefile还会创建kernel.asm，这里包含了内核的完整汇编语言，你们可以通过查看它来定位究竟是哪个指令导致了Bug。</p>
</li>
</ul>
<h2 id="传给QEMU的几个参数"><a href="#传给QEMU的几个参数" class="headerlink" title="传给QEMU的几个参数"></a>传给QEMU的几个参数</h2><ul>
<li><p>kernel ：这里传递的是内核文件（kernel目录下的kernel文件），这是将在QEMU中运行的程序文件。</p>
</li>
<li><p>-m ：这里传递的是RISC-V虚拟机将会使用的内存数量。</p>
</li>
<li><p>smp：这里传递的是虚拟机可以使用的CPU核数</p>
</li>
<li><p>-drive：传递的是虚拟机使用的磁盘驱动，这里传入的是fs.img文件</p>
</li>
</ul>
<h1 id="QEMU"><a href="#QEMU" class="headerlink" title="QEMU"></a>QEMU</h1><p>直观来看，QEMU是一个大型的开源C程序，你可以下载或者git clone它。但是在内部，在QEMU的主循环中，只在做一件事情：</p>
<ul>
<li><p>读取4字节或者8字节的RISC-V指令。</p>
</li>
<li><p>解析RISC-V指令，并找出对应的操作码（op code）。我们之前在看kernel.asm的时候，看过一些操作码的二进制版本。通过解析，或许可以知道这是一个ADD指令，或者是一个SUB指令。</p>
</li>
<li><p>之后，在软件中执行相应的指令。</p>
</li>
</ul>
<p>这基本上就是QEMU的全部工作了，对于每个CPU核，QEMU都会运行这么一个循环。</p>
<h1 id="XV6的启动过程"><a href="#XV6的启动过程" class="headerlink" title="XV6的启动过程"></a>XV6的启动过程</h1><p>QEMU 是一个通用的开源处理器模拟器和虚拟化程序，可以用于在物理计算机上模拟设备，并运行各种操作系统，如 xv6。以下是结合 QEMU 源代码和 xv6 源代码说明启动过程的概述：</p>
<ol>
<li><p><strong>启动 QEMU</strong>：从命令行启动 QEMU，并指定要加载的操作系统映像（在这种情况下为 xv6 操作系统）。命令可能如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">qemu-system-i386 -nographic -serial mon:stdio -hdb fs.img xv6.img -s -S</span><br></pre></td></tr></table></figure>

<p>在这里，<code>qemu-system-i386</code> 是针对 x86（32 位）系统的 QEMU 模拟器，<code>-nographic</code> 参数表示不使用图形界面，<code>-serial mon:stdio</code> 表示将监视器（QEMU 控制台）连接到标准输入&#x2F;输出，<code>-hdb fs.img</code> 指定要加载的 xv6 文件系统映像，<code>xv6.img</code> 是 xv6 操作系统映像，<code>-s</code> 和 <code>-S</code> 参数用于调试。</p>
</li>
<li><p><strong>QEMU 初始化虚拟硬件</strong>：QEMU 将根据所指定的参数和配置，初始化虚拟处理器、内存、硬盘和其他硬件设备。</p>
</li>
<li><p><strong>加载引导程序</strong>：QEMU 模拟 BIOS 行为，将 xv6.img 映像中的启动扇区加载到内存中，并将控制权交给这段代码。在 xv6 的情况下，引导程序位于 <code>bootasm.S</code>（汇编代码）和 <code>bootmain.c</code>（C 代码）中。</p>
</li>
<li><p><strong>引导程序运行</strong>：接下来的步骤与实际硬件上的启动过程相同。引导程序首先切换到保护模式，然后加载 ELF 格式的 xv6 内核映像到内存中。</p>
</li>
<li><p><strong>进入 xv6 内核</strong>：引导程序找到 xv6 内核的入口点（在 <code>kernel/entry.S</code> 中），并将控制权交给内核。内核现在开始运行并执行初始化任务。</p>
</li>
<li><p><strong>内核初始化</strong>：在 <code>main.c</code> 中的 <code>main()</code> 函数中，xv6 内核执行诸如设置分页、初始化中断控制器、初始化进程调度器等初始化任务。</p>
</li>
<li><p><strong>创建初始进程</strong>：xv6 创建第一个内核进程（<code>initcode.S</code>），它是一个用户程序，负责启动其他用户进程。内核通过 <code>fork()</code> 系统调用创建新进程，并通过 <code>exec()</code> 系统调用加载并执行 <code>initcode.S</code>。</p>
</li>
<li><p><strong>运行 init 进程</strong>：<code>initcode.S</code> 调用 <code>init</code> 程序（在 <code>init.c</code> 中），<code>init</code> 是一个用户空间程序，负责启动系统的第一个正常用户进程，通常是一个 shell 程序。在 xv6 中，这个程序是 <code>sh.c</code>。</p>
</li>
<li><p><strong>运行 shell 程序</strong>：<code>init</code> 进程通过 <code>fork()</code> 和 <code>exec()</code> 创建并运行 shell 程序。这时，用户可以在 shell 中输入命令并与操作系统进行交互。</p>
</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/03/31/MIT6-S081-Operating-System-Engineering-Lecture01-Intrduction-and-Examples/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Plucky">
      <meta itemprop="description" content="随便记录">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Plucky">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/03/31/MIT6-S081-Operating-System-Engineering-Lecture01-Intrduction-and-Examples/" class="post-title-link" itemprop="url">MIT6.S081 Operating System Engineering Lecture01 Intrduction and Examples</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-03-31 14:19:09" itemprop="dateCreated datePublished" datetime="2023-03-31T14:19:09+08:00">2023-03-31</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-04-06 15:00:08" itemprop="dateModified" datetime="2023-04-06T15:00:08+08:00">2023-04-06</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">课程学习</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0/MIT6-S081-Operating-System-Engineering/" itemprop="url" rel="index"><span itemprop="name">MIT6.S081 Operating System Engineering</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>9.7k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>18 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><h2 id="课程目标"><a href="#课程目标" class="headerlink" title="课程目标"></a>课程目标</h2><ul>
<li><p>理解操作系统的设计和实现。理解整体结构和具体代码。</p>
</li>
<li><p>通过XV6操作系统获得实际动手经验。扩展操作系统，修改并提升操作系统的相关经验，并且能够通过操作系统接口，编写系统软件</p>
</li>
</ul>
<h2 id="OS的目标"><a href="#OS的目标" class="headerlink" title="OS的目标"></a>OS的目标</h2><ul>
<li><p><strong>Abstract Hardware</strong></p>
</li>
<li><p><strong>Multiplex</strong></p>
</li>
<li><p><strong>Isolation</strong></p>
</li>
<li><p><strong>Sharing</strong></p>
</li>
<li><p><strong>Preformance</strong></p>
</li>
<li><p><strong>Access Control&#x2F;Security</strong></p>
</li>
<li><p><strong>Range Of Users</strong></p>
</li>
</ul>
<h1 id="OS的结构"><a href="#OS的结构" class="headerlink" title="OS的结构"></a>OS的结构</h1><h2 id="分层思想"><a href="#分层思想" class="headerlink" title="分层思想"></a>分层思想</h2><p><img src="/2023/03/31/MIT6-S081-Operating-System-Engineering-Lecture01-Intrduction-and-Examples/OS.png" alt="OS-ORG"></p>
<h3 id="Userspace"><a href="#Userspace" class="headerlink" title="Userspace"></a>Userspace</h3><p>在架构的最上层，运行各种各样的应用程序例如文本编辑器（VI），C编辑器（CC），作为CLI存在的shell。</p>
<h3 id="Kernel"><a href="#Kernel" class="headerlink" title="Kernel"></a>Kernel</h3><p>区别于<code>userspace</code>，有一个特殊的程序总是会在运行。<code>Kernel</code>是计算机资源的守护者，当打开计算机时，<code>Kernel</code>总是第一个被启动。Kernel程序只有一个，维护数据来管理每一个用户空间进程。<code>Kernel</code>同时还维护了大量数据结构来帮助它管理各种各样的硬件资源，以供用户空间的程序使用。<code>Kernel</code>同时还会有大量内置的服务。例如，<code>Kernel</code>通常会有文件系统实现类似文件名，文件内容，目录的东西，并理解如何将文件存储在磁盘中。所以用户空间的程序会与<code>Kernel</code>中的文件系统交互，文件系统再与磁盘交互。</p>
<p>我们主要关注在<strong>Kernel、连接Kernal和用户空间程序的接口、Kernel内软件的架构</strong> 。所以我们会关心Kernel内的服务。其中一个是文件系统，另一个就是进程管理系统。</p>
<ul>
<li><p><strong>Manage Process</strong>：每一个用户空间程序都被称为一个进程，它们有自己的内存和共享的CPU时间。</p>
</li>
<li><p><strong>Allocate Memory</strong>：Kernel会管理内存的分配，不同的进程需要不同数量的内存，Kernel会复用内存、划分内存，并为所有的进程分配内存。</p>
</li>
<li><p><strong>File System</strong>：文件系统通常有一些逻辑分区。目前而言，我们可以认为文件系统的作用是管理文件内容并找出文件具体在磁盘中的哪个位置。文件系统还维护了一个独立的命名空间，其中每个文件都有文件名，并且命名空间中有一个层级的目录，每个目录包含了一些文件。所有这些都被文件系统所管理。</p>
</li>
<li><p><strong>Security&#x2F;Access Control</strong>: 当一个进程想要使用某些资源时，比如读取磁盘中的数据，使用某些内存，Kernel中的Access Control机制会决定是否允许这样的操作。对于一个分时共享的计算机，例如Athena系统，这里可能会变得很复杂。因为在Athena系统中，每一个进程可能属于不同的用户，因此会有不同Access规则来约定哪些资源可以被访问。</p>
</li>
</ul>
<p>在一个真实的完备的操作系统中，会有很多很多其他的服务，比如在不同进程之间通信的进程间通信服务，比如一大票与网络关联的软件（TCP&#x2F;IP协议栈），比如支持声卡的软件，比如支持数百种不同磁盘，不同网卡的驱动。所以在一个完备的系统中，Kernel会包含大量的内容，数百万行代码。</p>
<h2 id="Kernel-API"><a href="#Kernel-API" class="headerlink" title="Kernel API"></a>Kernel API</h2><p><code>Kernel API</code>决定了应用程序如何访问Kernel。通常来说，这里通过系统调用<code>System Call</code>来完成。系统调用与程序中的函数调用看起来是一样的，但区别是系统调用会实际运行到系统内核中，并执行内核中对于系统调用的实现。</p>
<p><code>Kernel</code>的代码总是有特殊的权限。当机器启动<code>Kernel</code>时，<code>Kernel</code>会有特殊的权限能直接访问各种各样的硬件，例如磁盘。而普通的用户程序是没有办法直接访问这些硬件的。所以，当你执行一个普通的函数调用时，你所调用的函数并没有对于硬件的特殊权限。然而，如果你触发系统调用到内核中，内核中的具体实现会具有这些特殊的权限，这样就能修改敏感的和被保护的硬件资源，比如访问硬件磁盘。</p>
<h3 id="Example-1"><a href="#Example-1" class="headerlink" title="Example 1"></a>Example 1</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fd = open(<span class="string">&quot;out&quot;</span>,<span class="number">1</span>);</span><br><span class="line">write(fd,<span class="string">&quot;hello\n&quot;</span>,<span class="number">6</span>);</span><br></pre></td></tr></table></figure>

<p>第一个系统调用<code>open</code>，它会跳到Kernel，Kernel会获取到open的参数，执行一些实现了open的Kernel代码，或许会与磁盘有一些交互，最后返回一个文件描述符对象。上图中的fd全称就是<code>file descriptor</code>。之后应用程序可以使用这个文件描述符作为handle，来表示相应打开的文件。</p>
<p>第二个系统调用<code>write</code>，你需要向write传递一个由open返回的文件描述符作为参数。你还需要向write传递一个指向要写入数据的指针（数据通常是char型序列），在C语言中，可以简单传递一个双引号表示的字符串。第三个参数是你想要写入字符的数量。第二个参数的指针，实际上是内存中的地址。所以这里实际上告诉内核，将内存中这个地址起始的6个字节数据写入到fd对应的文件中。</p>
<h3 id="Example-2"><a href="#Example-2" class="headerlink" title="Example 2"></a>Example 2</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pid = fork();</span><br></pre></td></tr></table></figure>

<p><code>fork</code>是一个系统调用，它创建了一个与调用进程一模一样的新的进程，并返回新进程的<code>Process ID/PID</code>。</p>
<p>这些系统调用看起来跟普通的函数调用一样，但是它最终会跳到系统内核中。</p>
<h1 id="操作系统的难点"><a href="#操作系统的难点" class="headerlink" title="操作系统的难点"></a>操作系统的难点</h1><ul>
<li><p>内核的编程环境比较困难。当你在编写、修改，扩展内核，或者写一个新的操作系统内核时，你实际上在提供一个基础设施让别人来运行他们的程序。当程序员在写普通的应用程序时，应用程序下面都是操作系统。而当我们在构建操作系统时，在操作系统下面就是硬件了，这些硬件通常会更难处理。</p>
</li>
<li><p>当你在设计一个操作系统时，你需要满足一些列矛盾的需求。</p>
<ul>
<li><p>你想要你的操作系统既高效又易用。高效通常意味着操作系统需要在离硬件近的low-level进行操作，而易用则要求操作系统为应用程序提供抽象的high-level可移植接口。所以，提供一个简单可移植，同时又高效的抽象接口需要一定的技巧。</p>
</li>
<li><p>我们想要提供一个非常强大的操作系统服务，这样操作系统才能分担运行应用程序的负担。同时，我们也想要有简单的接口。我们不想程序员看到数量巨多，复杂且难以理解的的内核接口。因为，如果他们不理解这些接口，他们就会很难使用这些接口。</p>
</li>
<li><p>你希望给与应用程序尽可能多的灵活性，你不会想要限制应用程序，所以你需要内核具备灵活的接口。但是另一方面，你的确需要在某种程度上限制应用程序，因为你会想要安全性。我们希望给程序员完全的自由，但是实际上又不能是真正的完全自由，因为我们不想要程序员能直接访问到硬件，干扰到其他的应用程序，或者干扰操作系统的行为。</p>
</li>
</ul>
</li>
</ul>
<h1 id="read，write，exit系统调用"><a href="#read，write，exit系统调用" class="headerlink" title="read，write，exit系统调用"></a>read，write，exit系统调用</h1><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#inclued <span class="string">&quot;kernel/types.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;user/user.h&quot;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">char</span> buf[<span class="number">64</span>];</span><br><span class="line">    <span class="keyword">while</span>(<span class="number">1</span>)&#123;</span><br><span class="line">        <span class="type">int</span> n = read(<span class="number">0</span>,buf,<span class="keyword">sizeof</span>(buf));</span><br><span class="line">        <span class="keyword">if</span>(n &lt;= <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        write(<span class="number">1</span>,buf,n);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="read系统调用"><a href="#read系统调用" class="headerlink" title="read系统调用"></a>read系统调用</h2><ul>
<li><p>第一个参数是文件描述符，实际上是对以前打开文件的引用。Shell会确保默认情况下，当一个程序启动时，文件描述符0为连接到console的输入，文件描述符1为连接到了console的输出。所以我们可以通过这个程序看到console打印我的输入。当然，这里的程序会预期文件描述符已经被Shell打开并设置好。</p>
</li>
<li><p>第二个参数是只想某段内存的指针，程序可以通过指针对应的地址读取内存中的数据，这里的指针就是代码中的buf参数。char buf[64]在栈中申请了64字节的内存，并将指针保存在buf中，这样read可以将数据保存在这64字节中。</p>
</li>
<li><p>第三个参数是代码想读取的最大长度。sizeof(buf)表示，最多读取64字节的数据，所以这里的read最多只能从连接到文件描述符0的设备，也就是console中，读取64字节的数据。</p>
<p>如果第三个参数是65字节，操作系统会拷贝65个字节到你提供的内存中（第二个参数）。但是如果栈中的第65个字节有一些其他数据，那么这些数据会被覆盖，这里是个bug，或许会导致你的代码崩溃，或者一些异常的行为。</p>
</li>
<li><p>read的返回值</p>
<ul>
<li><p>可能是读到的字节数</p>
</li>
<li><p>如果从一个文件读数据，如果到达了文件的结尾没有更多的内容了，read会返回0。</p>
</li>
<li><p>如果出现了一些错误，比如文件描述符不存在，read或许会返回-1 。</p>
</li>
</ul>
</li>
</ul>
<h2 id="write系统调用"><a href="#write系统调用" class="headerlink" title="write系统调用"></a>write系统调用</h2><p>第一个参数为文件描述符，第二个参数是数据的指针，第三个参数是要写入的字节数   </p>
<p>数据被写入到了文件描述符对应的文件中</p>
<h1 id="open系统调用"><a href="#open系统调用" class="headerlink" title="open系统调用"></a>open系统调用</h1><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;kernel/types.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;user/user.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;kernel/fcntl.h&quot;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> fd = open(<span class="string">&quot;output.txt&quot;</span>,O_WRONLY | O_CREATE);</span><br><span class="line">    write(fd, <span class="string">&quot;ooo\n&quot;</span>,<span class="number">4</span>);</span><br><span class="line">    <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这个程序会创建一个叫做<code>output.txt</code>的新文件，并向它写入一些数据，最后退出。我们看不到任何输出，因为它只是向打开的文件中写入数据，但是我们可以查看output.txt的内容，并看到<code>open</code>程序写入的“ooo”。</p>
<p>所以执行<code>open</code>系统调用，将<code>out.txt</code>作为参数传入，第二个参数是一些标志位，用来告诉open系统调用在内核中的实现，用来告诉open系统调用在内核中的实现：我们将要创建并写入一个文件。open系统调用会返回一个新分配的文件描述符，这里的文件描述符是一个小的数字，可能是2，3，4或者其他的数字。然后将文件描述符传入write中。</p>
<ul>
<li><p>文件描述符本质上对应了内核中的一个表单数据。内核维护了每个运行进程的状态，内核会为每一个运行进程保存一个表单，表单的key是文件描述符。这个表单让内核知道，每个文件描述符对应的实际内容是什么。这里比较关键的点是，每个进程都有自己独立的文件描述符空间，所以如果运行了两个不同的程序，对应两个不同的进程，如果它们都打开一个文件，它们或许可以得到相同数字的文件描述符，但是因为内核为每个进程都维护了一个独立的文件描述符空间，这里相同数字的文件描述符可能会对应到不同的文件。</p>
</li>
<li><p>C语言与Python在文件描述符中的区别：Python提供了对与open调用的较好的封装，通常来说，Python提供的是更高级的函数，比如说Python不会使用指向内存的指针，并且Python会为你做更多的错误检查。当我们在Python中打开文件或者写入文件时，你在Python中的调用最终会走到跟我们例子中一样的系统调用。</p>
</li>
</ul>
<h1 id="Shell"><a href="#Shell" class="headerlink" title="Shell"></a>Shell</h1><p><code>Shell</code>通常也是人们说的命令行接口。如果你还没有用过Shell，Shell是一种对于Unix系统管理来说非常有用的接口，它提供了很多工具来管理文件，编写程序，编写脚本。当你输入内容时，你是在告诉Shell运行相应的程序。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls</span><br></pre></td></tr></table></figure>

<p>ls的实际工作就是输出当前目录的文件列表</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls &gt; out</span><br></pre></td></tr></table></figure>

<p>Shell允许重定向IO，这里的实际意义是要求Shell允许ls命令，但是将输出重定向到一个叫做out的文件中。这里执行完成之后我们看不到任何的输出，因为输出都送到了out文件。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat out</span><br></pre></td></tr></table></figure>

<p>我们可以通过<code>cat</code>指令来读取一个文件，并显示文件的内容，之后我们可以看到ls指令相同的输出。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep x</span><br></pre></td></tr></table></figure>

<p>你也可以运行一个名为<code>grep</code>的指令，并将x作为参数传给grep。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep  x &lt; out</span><br></pre></td></tr></table></figure>

<p><code>grep x</code>会搜索输入中包含x的行，我可以告诉shell将输入重定向到文件out，这样我们就可以查看out中的x。因为out文件包含了ls的输出，所以我们可以看出有3个文件名包含了x。</p>
<blockquote>
<p>编译器如何处理系统调用？生成的汇编语言是不是会调用一些由操作系统定义的代码段？</p>
<p>有一个特殊的RISC-V指令，程序可以调用这个指令，并将控制权交给内核。所以，实际上当你运行C语言并执行例如open或者write的系统调用时，从技术上来说，open是一个C函数，但是这个函数内的指令实际上是机器指令，也就是说我们调用的open函数并不是一个C语言函数，它是由汇编语言实现，组成这个系统调用的汇编语言实际上在RISC-V中被称为ecall。这个特殊的指令将控制权转给内核。之后内核检查进程的内存和寄存器，并确定相应的参数。</p>
</blockquote>
<h1 id="fork系统调用"><a href="#fork系统调用" class="headerlink" title="fork系统调用"></a>fork系统调用</h1><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;kernel/types.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;user/user.h&quot;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="type">int</span> pid;</span><br><span class="line">    pid = fork();</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;fork() returned %d\n&quot;</span>,pid);</span><br><span class="line">    <span class="keyword">if</span>(pid == <span class="number">0</span>)&#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;child\n&quot;</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;parent\n&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;   </span><br></pre></td></tr></table></figure>

<p>fork会拷贝当前进程的内存，并创建一个新的进程，这里的内存包含了进程的指令和数据。之后我们就有了两个完全一样的内存的进程。fork系统调用在两个进程中都会返回，在原始的进程中，fork会返回大于0的整数，这个是新创建进程的ID。而在新创建的进程中，fork系统调用会返回0。所以即使两个进程的内存是完全一样的，我们还是可以通过fork的返回值区分旧进程和新进程。</p>
<blockquote>
<p>返回</p>
<p>ffoorrkk(()) rreettuuttnende d 0</p>
<p>lc9h</p>
<p>ilpda</p>
<p>rent</p>
</blockquote>
<p><code>if（pid == 0）</code>，你可以看到代码检查pid。如果pid &#x3D; 0，这必然是子进程。在我们的例子中，调用进程通常称为父进程，父进程看到的pid必然大于0.所以父进程会打印“parent”,子进程会打印”child”。之后两个进程都会退出。</p>
<p>输出结果，实际发生二点是，<code>fork</code>系统调用之后，两个进程都在同时运行。它们会同时一个字节一个字节的输出，两个进程的输出交织在一起，所以你可以看到两个f，两个o等等。在第一行最后，你可以看到0，这是子进程的输出。</p>
<p>我猜父进程返回了19，作为子进程的进程ID。通常来说，这意味着这是操作系统启动之后的第19个进程。之后一个进程输出了child，一个进程输出了parent，这两个输出交织在一起。虽然这只是对于<code>fork</code>的一个简单应用，但是我们可以清晰的从输出看到这里创建了两个运行的进程，其中一个进程打印了child，另一个打印了parent。所以，<code>fork</code>（在子父进程中）返回不同的值是比较重要的。</p>
<p>父进程与子进程除了<code>fork</code>的返回值，两个进程是一样的。两个进程的指令是一样的，数据是一样的，栈是一样的，同时，两个进程又有各自独立的地址空间，它们都认为自己的内存从0开始增长，但这里是不同的内存。 在一个更加复杂的操作系统，有一些细节，我们现在并不关心，这些细节偶尔会导致父子进程不一致，但是在XV6中，父子进程除了fork的返回值，其他都是一样的。</p>
<p>除了内存是一样的以外，文件描述符的表单也从父进程拷贝到子进程。所以如果父进程打开了一个文件，子进程可以看到同一个文件描述符，尽管子进程看到的是一个文件描述符的表单的拷贝。除了拷贝内存以外，<code>fork</code>还会拷贝文件描述符表单。</p>
<h1 id="exec，wait系统调用"><a href="#exec，wait系统调用" class="headerlink" title="exec，wait系统调用"></a>exec，wait系统调用</h1><p>fork创建了一个新的进程。当我们在shell中运行东西的时候，shell实际上会创建一个新的进程来运行你输入的每一个指令。所以，当我输入ls时，我们需要shell通过fork创建一个进程来运行ls，这里需要某种方式来让这个新的进程来运行ls程序中的指令，加载名为ls的文件中的指令，也就是exec系统调用。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// exec.c:replace a process with an executable file</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;kernel.types.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;user/user.h&quot;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">char</span> *argv[] = &#123; <span class="string">&quot;echo&quot;</span>, <span class="string">&quot;this&quot;</span>, <span class="string">&quot;is&quot;</span>, <span class="string">&quot;echo&quot;</span>, <span class="number">0</span> &#125;;</span><br><span class="line">    exec(<span class="string">&quot;echo&quot;</span>, argv);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;exec failed!\n&quot;</span>);</span><br><span class="line">    <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>代码会执行exec系统调用，这个系统调用会从指定的文件中读取并加载指令，并替代当前调用进程的指令。从某种程度上来说，这样相当于丢弃了调用进程的内存，并开始执行新加载的指令。所以系统调用exec会有这样的效果：操作系统从名为echo的文件中加载指令到当前的进程中，并替换了当前进程的内存，之后开始执行这些新加载的指令。同时，你可以传入命令行参数，exec允许你传入一个命令行参数的数组，这里就是一个C语言中的指针数组，在上面代码设置好了一个字符指针的数组，这里的字符指针本质就是一个字符串（string）</p>
<p><code>echo</code> 程序是一个常见的命令行实用程序，用于在 Unix、Linux 和类 Unix 系统（如 macOS）上显示文本。它将传递给它的命令行参数（字符串）输出到标准输出（通常是终端或控制台）。<code>echo</code> 命令通常用于编写脚本或在控制台显示消息。</p>
<p>通过 <code>exec(&quot;echo&quot;, argv);</code> 系统调用执行。在这个例子中，<code>argv</code> 数组包含以下参数：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">argv[<span class="number">0</span>] = <span class="string">&quot;echo&quot;</span></span><br><span class="line">argv[<span class="number">1</span>] = <span class="string">&quot;this&quot;</span></span><br><span class="line">argv[<span class="number">2</span>] = <span class="string">&quot;is&quot;</span></span><br><span class="line">argv[<span class="number">3</span>] = <span class="string">&quot;echo&quot;</span></span><br><span class="line">argv[<span class="number">4</span>] = <span class="literal">NULL</span> (空指针)</span><br></pre></td></tr></table></figure>

<p>通常，<code>argv[0]</code> 是程序名称（在这里是 “echo”），后面是实际要传递的命令行参数（在这里是 “this”, “is”, “echo”）。<code>argv</code> 数组以空指针（<code>NULL</code>）结尾，表示参数列表的结束。</p>
<p>当 <code>echo</code> 程序执行时，它会输出 <code>&quot;this is echo&quot;</code>。</p>
<ul>
<li><p><code>exec</code>系统调用会保留当前的文件描述符表单。所以任何在<code>exec</code>系统调用之前的文件描述符，例如0，1，2等。它们在新的程序中表示相同的东西。</p>
</li>
<li><p>通常来说<code>exec</code>系统调用不会返回，因为<code>exec</code>会完全替换当前进程的内存，相当于当前进程不复存在了，所以<code>exec</code>系统调用已经没有地方能返回了,在实例代码中，执行错误才会返回。</p>
</li>
</ul>
<p>这就是一个程序如何用文件中的另一个程序来替代自己。实际上，当我们在Shell中运行类似于“echo a b c”的指令，或者ls，或者任何命令，我们不会想要代替Shell进程，所以我们不会希望Shell执行exec系统调用。如果我们这么做了，这里会用echo指令来替代Shell进程，当echo退出了，一切就结束了。所以我们不想要echo替代Shell。实际上，Shell会执行fork，之后fork出的子进程再调用exec系统调用，这是一个非常常见的Unix程序调用风格。对于那些想要运行程序，但是还希望能拿回控制权的场景，可以先执行fork系统调用，然后在子进程中调用exec。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// forkexec.c: fork then exec</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;user/user.h&quot;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> pid, status;</span><br><span class="line">    pid = fork();</span><br><span class="line">    <span class="keyword">if</span>(pid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="type">char</span> *argv[] = &#123;<span class="string">&quot;echo&quot;</span> ,<span class="string">&quot;THIS&quot;</span> ,<span class="string">&quot;IS&quot;</span> ,<span class="string">&quot;ECHO&quot;</span>, <span class="number">0</span> &#125;;</span><br><span class="line">        exec(<span class="string">&quot;echo&quot;</span>, argv);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;exec failed!\n&quot;</span>);</span><br><span class="line">        <span class="built_in">exit</span>(<span class="number">1</span>);</span><br><span class="line">    &#125;<span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;parent waiting\n&quot;</span>);</span><br><span class="line">        wait(&amp;status);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;the child exited with status %d\n&quot;</span>,status);    </span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">exit</span>(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>fork</code>系统调用会创建一个新的子进程，是当前进程的一个副本。</p>
<p>如果<code>pid == 0</code>，即进程是子进程，则会调用<code>echo</code>程序，输出<code>&quot;THIS IS ECHO&quot;</code>，如果错误则返回1。并且子进程在<code>echo</code>程序执行结束之后就会退出。，之后继续进行父进程。</p>
<p>父进程会先输出<code>“parent waiting\n”</code>，之后使用wait系统调用，等待子进程返回，将子进程返回的状态传入<code>status</code>，<code>&amp;status</code>，是将<code>status</code>对应的地址传递给内核，内核会向这个地址写入子进程向<code>exit</code>传入的参数。</p>
<p>如果一个子进程退出成功了，那么<code>exit</code>的参数会是0，如果出现了错误，会向<code>exit</code>传入1。所以父进程读取的wait的参数取决于子进程是否成功的完成了。</p>
<h1 id="I-x2F-O-Redirect"><a href="#I-x2F-O-Redirect" class="headerlink" title="I&#x2F;O Redirect"></a>I&#x2F;O Redirect</h1><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo hello &gt; out</span><br></pre></td></tr></table></figure>

<p><code>Shell</code>会将<code>echo</code>的输出送到文件out</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cat &lt; out</span><br></pre></td></tr></table></figure>

<p>之后可以运行cat指令，并将<code>out</code>指令作为输入，之后保存在<code>out</code>文件中的内容就是<code>echo</code>指令的输出</p>
<p><code>Shell</code>首先会先<code>fork</code>然后在子进程中，<code>Shell</code>改变了文件描述符。文件描述符1用来console输出，<code>Shell</code>会将文件描述符1改为output文件，之后再运行你的指令。同时，父进程的文件描述符1并没有改变。所以这里先<code>fork</code>再改变子进程的文件描述符。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//redirect.c: run a command with output redirected</span></span><br><span class="line"><span class="type">int</span>  <span class="title function_">main</span><span class="params">()</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> pid;</span><br><span class="line">    pid = fork();</span><br><span class="line">    <span class="keyword">if</span>(pid == <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        close(<span class="number">1</span>);</span><br><span class="line">        open(<span class="string">&quot;output.txt, O_WRONLY|O_CREATE&quot;</span>);</span><br><span class="line">        <span class="type">char</span> *argv[] = &#123;<span class="string">&quot;echo&quot;</span>, <span class="string">&quot;this&quot;</span> ,<span class="string">&quot;is&quot;</span> ,<span class="string">&quot;redirect&quot;</span>, <span class="string">&quot;echo&quot;</span>, <span class="number">0</span> &#125;;</span><br><span class="line">        exec(<span class="string">&quot;echo&quot;</span>,argv);</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;exec failed!\n&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">    &#123;</span><br><span class="line">        wait((<span class="type">int</span> *) <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在<code>if(pid == 0)</code>中，先检查pid的值，如果pid为0（在子进程中），则首先<code>close(1)</code>,<code>close(1)</code>的意义是，我们希望文件描述符1指向一个其他的位置。也就是说，在子进程中我们不想使用原本指向console输出的文件描述符1，即关闭标准输出。</p>
<p>使用 <code>open(&quot;output.txt&quot;, O_WRONLY | O_CREAT, 0666);</code> 打开或创建名为 “output.txt” 的文件，以只写模式（<code>O_WRONLY</code>）打开，并设置创建模式（<code>0666</code>，表示所有用户都可以读写此文件）。这将使得新打开的文件描述符成为子进程的标准输出。</p>
<p>使用 <code>exec(&quot;echo&quot;, argv);</code> 系统调用，替换子进程的映像为 <code>echo</code> 程序，并传递 <code>argv</code> 参数列表。 如果 <code>exec</code> 调用失败，输出 “exec failed!”。</p>
<p>在父进程中，调用 <code>wait((int *)0);</code> 函数，等待子进程结束。</p>
<p>当运行此程序时，它将执行 <code>echo</code> 命令，并将输出 “this is redirect echo” 重定向到 “output.txt” 文件。如果文件已存在，它将覆盖现有内容；如果文件不存在，它将创建一个新文件。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/03/30/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%20A-Study-on-the-Security-Implications-of-Information-Leakages-in-Container-Clouds/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Plucky">
      <meta itemprop="description" content="随便记录">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Plucky">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/03/30/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%20A-Study-on-the-Security-Implications-of-Information-Leakages-in-Container-Clouds/" class="post-title-link" itemprop="url">论文阅读 A Study on the Security Implications of Information Leakages in Container Clouds</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-03-30 22:40:21" itemprop="dateCreated datePublished" datetime="2023-03-30T22:40:21+08:00">2023-03-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-04-15 13:07:00" itemprop="dateModified" datetime="2023-04-15T13:07:00+08:00">2023-04-15</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文精读</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/%E5%86%85%E6%A0%B8%E5%AE%89%E5%85%A8/" itemprop="url" rel="index"><span itemprop="name">内核安全</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>30k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>54 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p><code>Container technology</code>提供了一个轻量级的操作系统虚拟主机环境。Container technology的出现深刻的改变了多层分布式应用的开发和部署范式（paradigms of multi-tier distributed applications）。然而，由于Linux系统内核中的系统资源隔离机制没有完全实现（system resource isolation mechanisms），在一个基于container的多租户云服务（<code>multi-tenancy container-based cloud service</code>）中，一些安全问题仍然存在。在本文，我们首先介绍了可以在containers内访问的信息泄露渠道。这些渠道暴露了一系列的系统范围的主机信息给没有适当资源分区的containers。通过利用泄露的主机信息，作为租户在container cloud中的恶意的攻击者就会更容易的发起可能影响云服务的可靠性的安全攻击。我们证明了信息泄露渠道将会被利用于推断隐私数据，检测和验证<code>co-residence</code>，建立隐蔽通道，发动更高级的基于云的攻击。我们讨论了container中的信息泄露的根本原因，并提出了一个两阶段的防御方法。正如评估中所证明的，我们的防御是有效的，并且性能开销非常小。   </p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>云计算已经广泛的运用于整合计算机资源。多租户是云计算的有利特征，允许来自不同租户的计算实例在同一物理服务器上运行。在不同类型的云服务中，多租户容器云最近作为传统的以云基础设施为基础的虚拟机VM的轻量级替代品出现。容器是一种OS级的虚拟化技术，在Linux内核中有多个building blocks，包括资源隔离&#x2F;控制技术（如<code>namespace</code>和<code>cgroup</code>）和安全机制（如<code>Capabilities</code>，<code>SELinux</code>，<code>AppArmor</code>和<code>seccomp</code>）。通过避免additional abstraction layers的开销，容器能够实现接近原生的性能，并且在几乎所有方面都超过了基于虚拟机的系统。除此之外，容器管理和orchestration系统的出现，如Docker和Kubernetes，深刻的改变了在云上构建、运输和部署多层分布式应用的生态系统。</p>
<p>尽管容器服务很成功，但是在同一个操作系统内核上运行多个可能属于不同租户的容器，始终存在安全和隐私问题。为了支持容器云上的多租户，Linux内核正在进行跨容器隔离和取消特权用户级别容器的努力。现有的容器启用内核功能大大缩小了暴露给容器租户的攻击面，并且可以限制大多数现有的恶意攻击。然而，并不是所有的Linux内核的子系统都能够区分容器和主机之间的执行上下文，因此它们可能会向容器化应用程序公开系统范围的信息。一些子系统被认为对容器适应性的优先级较低。其余的子系统面临着将代码库转换成容器形式的实现困难，并且它们的维护者不愿意接受激烈的变化。为了关闭这些漏洞，当前容器运行时软件和容器云提供商通常利用访问控制策略来隐藏这些与容器无关的子系统用户内核接口。然而，这种手动和临时修复只能覆盖一小部分暴露出来的攻击面。</p>
<p>在本文中，我们系统地探索和识别可能意外暴露主机操作系统和<code>co-residence</code>容器信息的容器内泄漏通道。这些信息泄漏包括主机系统状态信息（例如功耗、性能数据、全局内核数据和异步内核事件）以及单个进程执行信息（例如进程调度、cgroups 和进程运行状态）。在特定时间点暴露的区分特征信息可以帮助唯一地识别物理机器。此外，恶意租户可以通过提前获取系统范围的知识来优化攻击策略并最大化攻击效果。我们在 Docker 和 LinuX 容器 (LXC) 上的本地测试平台上发现了这些泄漏通道，并验证了它们在五个公共商业多租户容器云服务上（部分）存在。</p>
<p>我们证明了那些信息泄露渠道存在多个安全隐患。总的来说，尽管被挂载为只读，这些通道仍然会被恶意的容器租户利用来推断同一物理机上其他容器的私有数据，检测和验证共存关系，并建立隐蔽通道以偷偷地传输信息。我们提出了几种技术，攻击者可以通过利用那些信息泄露渠道来推断<code>co-residence</code>。与基于缓存的隐蔽信道等传统方法相比，我们的方法对云环境中的噪声更具韧性。我们根据它们的风险等级对这些通道进行排名。我们发现在容器实例中的活动会影响多个通道的系统范围的内的values。通过对运行在容器中的工作负载进行专门操作，攻击者可以实现可靠和高速的隐蔽通道，以突破云部署中采用的隔离机制。例如，通过故意获取和释放锁而不产生网络活动，从而攻击者可以在容器之间隐蔽的传输比特。这些泄露的信息可以被同一物理机上的所有容器观察到。为了揭示这些泄漏通道的安全风险，我们采用不同技术构建了两个隐蔽通道，并在真实的多租户云环境中测试它们的带宽。</p>
<p>我们进一步设计出了一种先进的攻击，称为<code>synergistic power attack</code>，来利用通过这些通道的看似无害的信息。我们证明这样的信息暴露可以极大地放大攻击效果，降低攻击成本，简化攻击编排。power attacks已被证明对现有的数据中心有事实的威胁。如果没有基础云架构运行状态的信息，现有的power attack只能盲目的启动power-intensive workloads，希望高峰能够触发branch circuit breakers来导致power outages。这样的攻击可能costly并且ineffective。</p>
<p>然而，通过学习系统范围内的状态信息，攻击者可以选择</p>
<ul>
<li><p>选择最佳时机发动攻击，也就是，在现有的power峰值下，由benign workloads触发，通过增加power-intensive workload来进行攻击。</p>
</li>
<li><p>通过检测被控制的容器的proximity-residence，同步对同一物理机&#x2F;机架的多次power attacks。我们在一个真实的容器云服务上进行了proof-of-concept实验 ，并定量证明了我们的攻击能够以更低的成本产生更高的power峰值。</p>
</li>
</ul>
<p>我们进一步深入分析了这些泄漏渠道的根本原因，并发现是Linux内核中容器implementation的incomplete coverage所致。我们提出了一个两阶段的防卫机制来解决这个在容器云上的问题。特别是，为了防卫<code>synergistic power attacks</code>，我们设计并实现了一个<code>power-based namespace</code>，在Linux内核中对power进行更细粒度（容器）级别的划分。我们和准确性，安全性和性能开销的角度评估了我们的<code>power-based namespace</code>。我们的实验结果表明，我们的系统可以在很小的系统开销下抵御<code>container-based power attack</code>。</p>
<h1 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h1><h2 id="Linux-Kernel-Support-for-Container-Technology"><a href="#Linux-Kernel-Support-for-Container-Technology" class="headerlink" title="Linux Kernel Support for Container Technology"></a>Linux Kernel Support for Container Technology</h2><p>容器依赖于多个独立的Linux内核组件来实现用户空间实例之间的隔离。与基于虚拟机的虚拟化方法相比，多个容器共享同一个操作系统内核，从而消除了启动和维护虚拟机所需的额外性能开销。容器在业界受到了广泛关注，并在近年来迅速发展，以提高应用程序性能、增强开发人员效率和促进服务部署。在这里，我们介绍两种关键技术<code>namespace</code>和<code>cgroup</code>，它们使得Linux上的容器化成为可能。</p>
<h3 id="Namespace"><a href="#Namespace" class="headerlink" title="Namespace"></a>Namespace</h3><p>第一个<code>namespace</code>在Linux内核2.4.19中被引入。<code>namespace</code>的关键思想是为一组进程隔离和虚拟化系统资源，这些形成一个容器。每个进程可以与多个不同类型的<code>namespace</code>联系。内核为每个进程提供了一个基于<code>namespace</code>类型的定制化系统资源视图。对任何<code>namespace</code>系统资源的修改都会被限制在相关联的<code>namespace</code>里面，因此不会造成整个系统范围内的修改。</p>
<p>现有的内核有七种不同的<code>namespace</code>：<code>mount（MNT）namespace</code>，<code>UNIX timesharing system （UTS）namespace</code>，<code>PIDnamespace</code>， <code>network（NET） namespace</code>，<code>interprocess communications（IPC）namespace</code>，<code>USER namespace</code>，and <code>CGOUP namespace</code></p>
<ul>
<li><p><code>MNT namespace</code>：隔离一组文件系统<code>mount point</code>。在不同的MNT <code>namespace</code>中，进程对文件系统层次结构有不同的视图。</p>
</li>
<li><p><code>UTS namespace</code>：每个容器都有自己的主机名和域名，因此一个容器可以被视为独立节点。</p>
</li>
<li><p><code>PID namespace</code>：虚拟化进程标识符（<code>pids</code>），每个进程有两个<code>pid</code>：在其<code>namespace</code>中有一个<code>pid</code>，在主机上有一个（全局唯一）<code>pid</code>。</p>
</li>
<li><p><code>NET namespace</code>：包含独立的虚拟网络设备、IP地址、端口和IP路由表。IPC命名空间隔离了进程间通信资源，包括信号、管道和共享内存。</p>
</li>
<li><p><code>IPC namespace</code>：隔离进程间通信资源，包括信号、管道和共享内存。</p>
</li>
<li><p><code>USER namespace</code>：引入了用户和组ID号空间的隔离。它在容器内创建一个根用户到主机上非特权用户之间的映射关系。因此，进程可以在用户命名空间内拥有完全权限，但在主机上则被削弱了权限。</p>
</li>
<li><p><code>CGROUP namespace</code>：虚拟化<code>cgroup</code>资源，每个进程只能通过<code>cgroupfs</code>挂载和<code>/proc/self/cgroup</code>文件获得容器化的<code>cgroup</code>视图。</p>
</li>
</ul>
<h3 id="Cgroup"><a href="#Cgroup" class="headerlink" title="Cgroup"></a>Cgroup</h3><p>在Linux内核中，<code>cgroup</code>（control group）提供了一种机制，将进程和所有它们的子进程的group分层为具有可控行为的分层group。容器利用<code>cgroup</code>功能，对每个容器实例应用每个<code>cgroup</code>资源限制，从而防止单个容器耗尽主机资源。这些受控资源包括CPU、内存、块IO、网络等。在云计算的计费模型中，<code>cgroup</code>也可以用于为每个容器分配相应的资源并记录它们的使用情况。每个<code>cgroup</code>子系统提供了一个统一的sysfs接口，以简化用户空间中的<code>cgroup</code>操作。</p>
<h2 id="Container-Cloud"><a href="#Container-Cloud" class="headerlink" title="Container Cloud"></a>Container Cloud</h2><p>有了这些可用于资源隔离和管理的内核功能，Linux 内核可以在操作系统级别提供轻量级虚拟化功能。未来预计会将更多的<code>namespace</code>和 <code>cgroup </code>子系统合并到upstream Linux 内核中，以增强容器安全性。近年来，随着容器运行时软件的成熟，容器化已成为虚拟托管的流行选择。LXC 是第一个完整实现于 2008 年构建的 Linux 容器管理器。Docker 建立在 LXC（现在使用 libcontainer）之上，在最近几年已成为最受欢迎的容器管理工具。Docker 可以将应用程序及其依赖项（例如代码、运行时、系统工具和系统库）打包到镜像中，从而保证应用程序在不同平台上表现一致。许多云服务提供商已经提供了容器云服务，其中包括 Amazon ECS、IBM Bluemix、Microsoft Azure 和 Google Compute Engine 等等。对于多租户容器云服务来说，容器可以运行在裸机物理机或虚拟机上。无论是哪种情况下，不同租户的容器都与主机操作系统共享相同的 Linux 内核。</p>
<h2 id="Covert-Channels"><a href="#Covert-Channels" class="headerlink" title="Covert Channels"></a>Covert Channels</h2><p>隐蔽通道利用共享资源来打破隔离机制，从而使孤立的实体之间能够进行通信。具有隐秘性的隐蔽通道可用于检索敏感信息并绕过标准通道上的访问控制。广泛认为，即使在虚拟机和容器强制执行隔离技术的情况下，今天的云环境也容易受到隐蔽通道攻击。已经提出了各种技术来建立多租户云环境中的隐蔽通道。Ristenpart等人报告了在公共云中利用共享L2数据缓存达到0.2bps 的比特率。Xu等人使用VM之间的最后一级缓存，在Amazon EC2 环境中构建带宽为3.2bps 的隐藏信道。Wu等人通过利用内存总线上发生竞争实现110 bps 和误码率为0.75% 的隐藏信道。Masti等人成功地通过获取芯片传感器读数来构建隐藏信道，并以12.5bps 的比特率进行传输；Bartolini等人将基于温度的隐藏信道改进至相邻核心50bps 。在云环境中，除了泄露敏感数据的威胁外，隐蔽通道还可以进一步被滥用来检测和验证共存性，这是大多数基于云的攻击的前提条件。通过成功地通过隐蔽通道传输信息，攻击者可以确认两个实例是否在同一主机服务器上<code>co-residence</code>。因此，为了通过构建强大的防御机制来保护云端安全，发现新技术以构建隐蔽通道是一个重要步骤，并已经得到先前研究的密切关注。</p>
<h2 id="Power-Attacks-on-Data-Centers"><a href="#Power-Attacks-on-Data-Centers" class="headerlink" title="Power Attacks on Data Centers"></a>Power Attacks on Data Centers</h2><p><code>power attacks</code>已经被证明对现有的云基础设施有事实的威胁。考虑到升级power设施的成本，当前数据中心普遍采用<code>power oversubscription</code>来在现有电力供应能力范围内托管尽可能多的服务器。安全保障是基于这样一个假设：相邻的多个服务器同时达到峰值功耗的概率很低。虽然功率超额订阅允许部署更多服务器而不增加电源容量，但降低了电源冗余性，增加了停电可能性，这可能导致同一机架或同一配电单元（PDU）上的服务器被迫关闭。即使正常工作负载也可能产生引起停电的功率峰值。Facebook最近报告称，在2016年的六个月内预防了18次潜在停电事件。如果恶意对手故意投放“能量病毒”发动攻击，则情况将更为严重。停电带来的后果可能是灾难性的，例如Delta Airlines在2016年8月遭遇数据中心断电事件，导致大规模航班延误和取消。最近研究表明，无论是传统还是备用式数据中心都可以进行 power 攻击。</p>
<p>发起一个成功的<code>power attack</code> 需要三个关键因素：</p>
<ul>
<li><p>通过合法订阅服务得到目标数据中心的服务器访问权限</p>
</li>
<li><p>稳定的运行适度的工作负载，以增加服务器功耗至其上限。</p>
</li>
<li><p>突然切换到耗电量大的工作负载以触发功率峰值。通过在短时间窗口内引起功率峰值，断路器可以被跳闸以保护服务器免受过流或过载造成的物理损害。</p>
</li>
</ul>
<p>断路器的跳闸条件取决于power峰值的强度和持续时间。为了最大化攻击效果，攻击者需要在同一机架或者PDU所属的一组服务器上运行恶意工作负载。此外，发动攻击的时机也至关重要。如果数据中心的特定的一组服务器（例如，位于同一机架上）已经运行在其峰值功率状态下，则发动成功的<code>power attack</code>的可能性更高。</p>
<p>power 限制技术旨在防御<code>power attack</code>。在机架和PDU级别上，通过监控power消耗，数据中心可以通过基于功率的反馈环路限制服务器的功耗。在主机级别上，<code>Running Average Power Limit(RAPL)</code>是一种用于监视和限制单个服务器功耗的技术。自Sandy Bridge微体系结构以来，Intel引入了<code>RAPL</code>。它提供微秒级细粒度CPU级能源计量，并可用于限制一个包的功耗。</p>
<p>power限制机制显著缩小了功率攻击面，但它无法解决<code>power oversubscription</code>的问题，这是数据中心停电的根本原因。虽然单个服务器的主机级功率限制可以立即响应power surface，但机架或PDU级别的功率限制机制仍会遭受分钟级延迟。假设攻击者可以将电源病毒部署到物理相邻的服务器中，即使每个服务器消耗的电力低于其功率上限，所控制服务器总体聚合后的能量消耗仍可能超过供电容量并触发断路器。我们在以下章节中证明恶意容器租户可以通过控制其高能耗工作负载的部署和利用背景下良性工作负载来放大他们的<code>power attack</code>。</p>
<h1 id="Information-Leakages-In-Container-Clouds"><a href="#Information-Leakages-In-Container-Clouds" class="headerlink" title="Information Leakages In Container Clouds"></a>Information Leakages In Container Clouds</h1><p>Linux内核为容器抽象提供了大量支持以实现资源隔离和控制。这些内核机制是在多租户云上运行容器的启用技术。由于优先级和困难程度，Linux内核的某些组件尚未转化为支持容器化。我们打算系统地探索哪些部分的内核没有覆盖，根本原因是什么以及潜在对手如何利用它们。</p>
<h2 id="Container-Information-Leakages"><a href="#Container-Information-Leakages" class="headerlink" title="Container Information Leakages"></a>Container Information Leakages</h2><p>我们首先在本地安装了Docker和LXC容器，并在Linux机器上进行实验。系统设置为默认配置，所有容器都以用户特权启动，与商业容器云类似。Linux提供了两种从用户空间进程到内核的受控接口：系统调用和基于内存的伪文件系统。系统调用主要设计用于用户进程请求内核服务。这些系统调用具有严格的公共接口定义，并通常向后兼容。然而，基于内存的伪文件系统更灵活，可扩展内核功能（例如<code>ioctl</code>），访问内核数据（例如<code>procfs</code>）并调整内核参数（例如<code>sysctl</code>）。此外，这样的伪文件系统使得通过正常文件I&#x2F;O操作操纵内核数据成为可能。Linux有许多基于内存的伪文件系统（例如，<code>procfs</code>、<code>sysfs</code>、<code>devfs</code>、<code>securityfs</code>、<code>debugfs</code>等），这些文件系统服务于不同的内核操作目的。我们更感兴趣的是<code>procfs</code>和<code>sysfs</code>，默认情况下由容器运行时软件挂载。</p>
<p>如图所示，我们设计了一个交叉验证工具，自动发现这些将主机信息暴露给容器的基于内存的伪文件。关键思想是在两个执行上下文中递归探索<code>procfs</code>和<code>sysfs</code>下所有伪文件，在一个未经特权处理的容器中运行，并在主机上运行另一个。我们根据它们的路径对齐并重新排序这些文件，然后对相同内容之间进行成对差分分析。如果从特定虚拟文件访问到的系统资源没有被Linux内核<code>namespace</code>化，则主机和容器会达到相同片段（如图中❷的情况）。否则，如果正确<code>namespace</code>化，则容器可以检索到自己的私有和定制内核数据（如图中❶的情况）。使用这个交叉验证工具，我们可以快速识别可能将系统范围主机信息暴露给容器的伪文件（及其内部内核数据结构）。</p>
<p><img src="/2023/03/30/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%20A-Study-on-the-Security-Implications-of-Information-Leakages-in-Container-Clouds/Framework.png"></p>
<h2 id="Leakage-Channel-Analysis"><a href="#Leakage-Channel-Analysis" class="headerlink" title="Leakage Channel Analysis"></a>Leakage Channel Analysis</h2><p>我们在表中列出了可能泄露主机信息的所有伪文件。这些泄漏渠道包含主机信息的不同方面。容器用户可以检索内核数据结构（例如，<code>/proc/modules</code>显示加载模块列表），内核事件（例如，<code>/proc/interrupt</code>s显示每个IRQ的中断数）和硬件信息（例如，<code>/proc/cpuinfo</code>和<code>/proc/meminfo</code>分别显示CPU和内存规格）。此外，容器用户还可以通过某些通道获取性能统计数据。例如，容器可以通过<code>RAPL sysfs</code>接口获得硬件传感器数据（如果这些传感器在物理机上可用），如每个package、核心和DRAM的功耗，并通过数字温度传感器(DTS)<code>sysfs</code>接口获得每个核心的温度。此外，处理器、内存和磁盘I&#x2F;O的使用情况也暴露给容器。虽然乍一看泄露这样的信息似乎无害，但恶意对手可能利用它来发动攻击。</p>
<p>我们通过检查内核代码（在Linux内核版本4.7中）进一步调查了这些信息泄漏的根本原因。通常，泄漏问题是由于内核中<code>namespace</code>实现不完整引起的。更具体地说，我们总结了两个主要原因如下：（1）对于现有<code>namespace</code>缺少context check，以及（2）某些Linux子系统没有（完全）进行<code>namespace</code>隔离。我们提供了两个案例研究，分别是容器中的<code>net prio.ifpriomap</code>和<code>RAPL</code>，以揭示泄漏源头。</p>
<h3 id="Case-study-1-net-prio-ifpriomap"><a href="#Case-study-1-net-prio-ifpriomap" class="headerlink" title="Case study 1 - net_prio.ifpriomap"></a>Case study 1 - net_prio.ifpriomap</h3><p>伪文件<code>net prio.ifpriomap</code>（位于<code>/sys/fs/cgroup/net prio</code>下）包含了一个映射，该映射将从cgroup中的进程开始并离开系统的流量分配给不同接口。数据格式为<code>[ifname priority]</code>。我们发现，在<code>net prio.ifpriomap</code>上挂钩的内核处理程序函数不知道NET命名空间，因此它向容器化应用程序披露物理机器上所有网络接口。更具体地说，<code>net prio.ifpriomap</code>的读操作由<code>read_priomap</code>函数处理。从这个函数跟踪，我们发现它调用<code>for_each_netdev_rcu</code>，并将第一个参数设置为<code>init_net</code>地址。它迭代主机的所有网络设备，而不考虑NET命名空间。因此，在容器视图中，可以读取主机所有网络设备名称。</p>
<h3 id="Case-study-2-RAPL-in-containers"><a href="#Case-study-2-RAPL-in-containers" class="headerlink" title="Case study 2 - RAPL in containers"></a>Case study 2 - RAPL in containers</h3><p>RAPL是英特尔最近推出的用于设置单个服务器处理器包和DRAM功率限制的技术，可以在毫秒级别响应。在容器云中，<code>RAPL sysfs</code>接口位于<code>/sys/class/powercap/intel-rapl</code>，容器可以访问该接口。因此，容器租户可以通过这个sysfs接口获取主机的系统范围内电源状态，包括核心、DRAM和package等。例如，容器用户可以从伪文件energy uj中读取当前微焦耳能量计数器值。Intel RAPL Linux驱动程序中energy uj的函数处理程序是<code>get_energy_counte</code>r。该函数从<code>RAPL MSR</code>检索原始能量数据。由于尚未实现功率数据名称空间，则<code>energy_raw</code>指针引用主机的能量消耗数据。</p>
<p>我们进一步调查了采用Docker&#x2F;LXC容器引擎的容器云服务中存在的信息泄漏问题。我们选择了五个商业公共多租户容器云服务进行泄漏检测，并在表中呈现结果。在云提供商修补通道之前，我们对这些容器云服务的名称（CCi代表第i个Container Cloud）进行匿名化处理。如果结果与我们的容器实例配置不一致，则确认泄露存在。黑点表示通道不存在于该云中，而白点表示通道存在于该云中。我们发现大多数本地机器上的泄露渠道也可以在容器云服务上使用。其中一些由于缺乏特定硬件支持而无法使用（例如Sandy Bridge之前的英特尔处理器或不支持RAPL技术的AMD处理器）。对于CC5，我们发现某些通道信息与本地测试平台不同，这意味着云供应商已经定制了一些额外限制条件。例如，只有属于租户核心和内存相关信息是可用的。然而，这些渠道部分泄露主机信息仍可能被高级攻击者利用, 我们将它们标记为黑白点。</p>
<p><img src="/2023/03/30/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%20A-Study-on-the-Security-Implications-of-Information-Leakages-in-Container-Clouds/Files.png"></p>
<h2 id="Inference-of-Co-resident-Container"><a href="#Inference-of-Co-resident-Container" class="headerlink" title="Inference of Co-resident Container"></a>Inference of Co-resident Container</h2><p>我们进一步深入研究特定案例，以查看它们是否可以被利用来检测共存容器</p>
<h3 id="Co-residence-problems-in-cloud-settings"><a href="#Co-residence-problems-in-cloud-settings" class="headerlink" title="Co-residence problems in cloud settings"></a>Co-residence problems in cloud settings</h3><p><code>Co-residence</code>是云安全中一个众所周知的研究问题。为了提取受害者的信息，攻击者倾向于将恶意实例移动到与受害者相同的物理主机上。Zhang等人已经证明，攻击者可以使用共存实例劫持用户帐户并提取私钥。</p>
<p>此外，实现<code>Co-residence</code>的成本相当低。由于意图整合服务器资源和降低成本，<code>Co-residence</code>仍然是现有云中存在的问题。验证<code>Co-residence</code>的传统方法基于缓存或基于内存泄漏通道。这些方法的准确性可能会因云环境中高噪声而下降。</p>
<h3 id="Approaches-and-results-of-checking-co-resident-containers"><a href="#Approaches-and-results-of-checking-co-resident-containers" class="headerlink" title="Approaches and results of checking co-resident containers"></a>Approaches and results of checking co-resident containers</h3><p>由于容器可以通过我们发现的泄漏通道读取主机信息，因此我们倾向于测量某些通道是否可用于检查容器共存。我们定义了三个指标，即唯一性（U）、变化性（V）和操作性（M），以定量评估每个通道推断共存的能力。指标 U 表示该通道是否赋予特征数据，可以唯一地识别主机。这是确定两个容器是否位于同一主机最重要和准确的因素。我们已经发现了 17 个泄漏通道，满足这种度量标准。一般来说，我们可以将这些渠道分类为三组：</p>
<ul>
<li><p>包含唯一静态标识符的渠道。例如，在<code>/proc/sys/kernel/random</code> 下的引导 ID 是在启动时生成的随机字符串，并且对于每个运行内核都是唯一的。如果两个容器可以读取相同的引导 ID，则明显表示它们正在运行在同一个主机内核上。此组中渠道数据既是静态又是独特的。</p>
</li>
<li><p>容器租户可以动态植入独特签名到其中的渠道 。例如，在<code>/proc/sched debug</code>中 ，容器用户可以通过此接口检索所有活动进程信息的主机 。租户可以在容器内部启动一个带有独特制作的任务名称的进程。从其他容器中，他们可以通过在自己的 sched debug 中搜索此任务名称来验证共存。类似情况适用于计时器列表和锁。</p>
</li>
<li><p>包含唯一动态标识符的渠道。例如，在<code>/proc/uptime</code>中有两个数据字段：系统运行时间和自引导以来的系统空闲时间（以秒为单位）。它们是累积值，并且对于每台主机都是唯一的。同样，<code>RAPL sysfs</code> 接口中的能量 uj 是微焦耳中累积能量计数器 。从该组通道读取到 的 数据 在实时更改 ，但仍然是独特的代表主机 。我们根据其增长率对该组通道进行排名。较快的增长速度表示重复几率较低。</p>
</li>
</ul>
<p>度量V可以展示数据是否随时间变化。有了这个特性，两个容器可以同时定期地对该伪文件进行快照。然后，它们可以通过检查两个数据快照跟踪是否相互匹配来确定<code>co-residence</code>关系。例如，从同一时刻开始，在一分钟内每秒钟记录<code>/proc/meminfo</code>中的<code>MemFree</code>在两个容器中。如果这两个60点数据跟踪彼此匹配，则我们有信心认为这两个容器运行在同一个主机上。每个通道包含不同的信息推断共存的能力，可以通过联合香农熵自然地测量。我们用公式（1）定义熵H。</p>
<p>每个多重独立数据字段Xi，n表示独立数据字段的数量。每个Xi都有可能的值{xi1，· · · ，xim}。我们根据表中的熵结果对能够揭示<code>co-residence</code>能力的九个通道（其中U&#x3D;False且V&#x3D;True）进行排名。</p>
<p>指标M表示容器租户是否可以操作数据。如果租户可以直接将特制的数据嵌入通道中，我们会对其进行标记为黑色。例如，我们可以在容器内创建一个带有特殊任务名称的计时器程序。该任务名称及其关联的计时器将出现在<code>/proc/timer</code>列表中。另一个容器可以搜索计时器列表中的此特殊任务名称以验证共存性。如果租户只能间接影响此通道中的数据，则我们会标记为黑白色。例如，攻击者可以使用<code>taskset</code>命令将计算密集型工作负载绑定到特定核心，并从另一个容器检查CPU利用率、功耗或温度等信息。这些条目可能被高级攻击者利用作为隐蔽信道来传输信号。</p>
<p>对于那些没有这些 U V M 属性的通道，我们认为它们很难被利用。例如，在云数据中心中，大多数服务器可能安装了相同的操作系统分发版和相同的模块列表。虽然 <code>/proc/modules</code>泄漏了主机上加载模块的信息，但是使用此通道推断<code>co-resident</code>容器是困难的。</p>
<p><img src="/2023/03/30/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%20A-Study-on-the-Security-Implications-of-Information-Leakages-in-Container-Clouds/Leakage%20Channel.png"></p>
<h1 id="Constructing-Covert-Channels"><a href="#Constructing-Covert-Channels" class="headerlink" title="Constructing Covert Channels"></a>Constructing Covert Channels</h1><p>包含manipulation（M）的通道可以进一步利用，以在两个容器之间建立隐蔽通道。我们证明了这些信息泄漏通道中的动态标识符和性能数据都可以被滥用来传输信息。特别地，我们实现了两个通道并测试它们的吞吐量和错误率。</p>
<h2 id="Covert-channel-based-on-unique-dynamic-identifiers"><a href="#Covert-channel-based-on-unique-dynamic-identifiers" class="headerlink" title="Covert channel based on unique dynamic identifiers"></a>Covert channel based on unique dynamic identifiers</h2><p>我们以<code>/proc/locks</code>为例来演示隐蔽通道可以构建在唯一动态标识符之上。通道<code>/proc/locks</code>显示了操作系统中所有锁信息的概述，包括锁类型、相应的进程以及inode号。</p>
<p>这种泄漏也破坏了 pid命名空间，因为所有锁的全局pid都被泄露了。Linux内核的维护者在4.9版本中部分修复了<code>/proc/locks</code>。内核4.9版本中部分修复了<code>/proc/locks</code>，将当前pid命名空间中的所有pid屏蔽为零。然而，其他信息，如锁的数量和节点信息仍然在容器。</p>
<p>我们构建了一个基于<code>/proc/locks</code>的隐蔽通道。具体来说，发送方可以lock一个文件来表示1，并释放lock来表示0。虽然lock和文件不在容器之间共享，但接收器可以在<code>/proc/locks</code>中检查lock的存在。通过不断检查特定lock的状态，可以传输信息。此外，可以同时设置多个lock以传输多个比特。为了建立可靠的高带宽隐蔽信道，攻击者需要考虑几个因素。我们在算法1中详细介绍了构建基于锁的隐蔽信道的过程。</p>
<p>通道<code>/proc/locks</code>包含内部内核数据，因此它一直在更改。尤其是在存在噪声的云环境中，内容可能会发生巨大的波动。</p>
<p>可靠传输数据块的第一步是握手：接收方需要找出发送方使用的所有lock。特别地，握手过程负责：</p>
<ul>
<li><p>设置数据传输的起点.</p>
</li>
<li><p>锚定锁，用于同时传送一个block of bits.</p>
</li>
<li><p>同步发送器和接收器。</p>
</li>
</ul>
<p>我们通过为每个数据锁创建一个特定的模式来实现握手。对于一个简化的情况，发送方在短时间内不断获取和释放锁。然后，接收器检查每个数据锁的切换次数（锁定或解锁文件）。如果切换次数超过特定阈值，则接收器通过跟踪索引节点编号来记录该lock，该索引节点编号对于特定文件上的相同锁定是不变的。同时，我们使用一个额外的锁来表示传输信号，用于通知接收器每一轮传输的开始。</p>
<p>在创建特定模式之后，理论上发送方可以立即开始传输。然而，接收方的处理过程的时间是未知的和不确定的，特别是在多租户云环境中存在大量锁的情况下。如果发送方传输数据过快，则可能会丢失一个比特块。虽然发送方可以在发送下一个数据块之前等待一段时间，但这种方法将极大地影响传输速度。</p>
<p>我们进一步添加了一个ACK锁，用于同步发送方和接收方。在获得所有数据锁定之后，接收器通过设置ACK锁定来进行确认。发送器侧的ACK锁的检测类似于接收器侧的其他数据锁的检测方法。接收器在用ACK锁定进行应答之后进入准备状态，并等待数据传输。</p>
<p>对于数据传输，发送方通过获取或释放数据锁，在每一轮中发送一个数据块。例如，八个锁可以表示一个字节。接收器通过检查数据锁的状态来解码数据。一旦接收到ACK锁定，发送器就开始下一轮数据传输。</p>
<h2 id="Covert-channel-based-on-performance-data-variation"><a href="#Covert-channel-based-on-performance-data-variation" class="headerlink" title="Covert channel based on performance data variation"></a>Covert channel based on performance data variation</h2><p>通过这些信息的泄露，容器用户可以检索到主机服务器的全系统性能统计数据。例如，容器可以通过<code>/proc/stat</code>获取每个核心的CPU使用率，通过<code>/proc/meminfo</code>或<code>/proc/vmstat</code>获取内存使用率。性能数据的取值受容器运行状态的影响。尽管在云环境中，一个容器只能容纳有限的计算资源，但容器中的恶意用户可以仔细选择在容器中运行的工作负载。通过在性能通道中生成独特的模式，容器可以构建隐蔽通道来传输信息。我们建立了一个隐蔽通道，通过滥用<code>/proc/meminfo</code>中的内存使用信息。</p>
<p><code>/proc/meminfo</code>报告大量关于系统内存使用情况的有价值的信息，包括可用内存总量、系统未使用的物理RAM总量和脏内存总量。</p>
<p>这里我们利用了系统中未使用的内存量。</p>
<p>在云环境中，这个值可能有很大差异，因为每个容器用户都可能影响它。对于建立可靠的隐蔽数据传输来说，这种显著的变化是不可取的。但是，如果不运行内存密集型工作负载，使用情况可能在可接受的范围内波动。我们首先在服务器上记录一段时间的未使用内存，以获得基线值。如果该值变化不迅速且不显著，则表示可以建立隐蔽通道。然后，发送方容器可以分配不同数量的内存来表示位1和位0(例如，位1为100MB，位0为50MB)，这将导致<code>/proc/meminfo</code>中的<code>MemFree</code>字段dorp immediately。接收端可以通过监视空闲内存的变化来简单地转换数据。<code>MemFree</code>分为三个级别:基线情况、位1和位0。发送方在发送1或0后释放所有分配的内存，以便接收方可以知道上次传输的结束并为下一个比特做准备。</p>
<p>为了确保可靠的传输，握手是发送方和接收方之间的第一个必要步骤。</p>
<p>发送方可以选择发送一个固定的模式，比如8位直比特1，来发起一次传输。接收端获得握手模式后，将进入数据接收模式。具体算法见算法2。为了减少其他容器内存消耗所产生的噪声的影响，一旦<code>MemFree</code>落在预定义的范围内，接收端将标记数据传输。同时，增加内存分配量可以减少噪声的影响。但是，由于分配和释放内存需要消耗时间，因此会影响传输带宽。为了减少来自环境的干扰，用户可以进一步设计更高级别的可靠协议，例如使用校验和，以确保传输数据的完整性。</p>
<h2 id="Experiments-on-a-Multi-tenancy-Container-Cloud"><a href="#Experiments-on-a-Multi-tenancy-Container-Cloud" class="headerlink" title="Experiments on a Multi-tenancy Container Cloud"></a>Experiments on a Multi-tenancy Container Cloud</h2><p>为了测量在有真实噪声的环境下的性能，我们选择了一个商业多租户容器云来测试我们的隐蔽通道。我们反复启动容器，并通过检查惟一的静态标识符来验证共存。我们在同一物理机器上创建两个容器。</p>
<ul>
<li><p><code>Lock-based covert channel</code>: 我们在三种不同大小的数据(5,000字节、10,000字节和20,000字节)下测试了基于锁的隐蔽通道的带宽和错误率。我们还选择了四种不同数量的锁(即8、16、24、32)来衡量性能。我们根据经验为切换次数选择一个阈值，以确保所有锁都能被正确识别。握手过程的花费以秒为单位。然后，所有传输数据都是随机生成的。我们恢复接收端的所有数据，并与原始数据进行比较。</p>
<p>具有8个锁的基于锁的隐蔽通道的带宽约为5150 bps。显然，使用的锁越多，带宽就越高。在通道中使用32个数据锁(每轮传输4个字节)，带宽达到22186 bps。</p>
<p>此外，所有案例的错误率都在2%以下。结果表明，基于锁的隐蔽信道具有较高的可靠性。</p>
</li>
<li><p><code>Memory-based covert channel</code>: 对于构建在<code>/proc/meminfo</code>上的隐蔽通道，我们首先将位1和位0的内存分配分别设置为100,000KB和50,000KB。我们发送1000位来测试性能。然后我们逐渐减少内存分配，直到构建握手失败。带宽和错误率的结果如表3所示。带宽与内存分配大小成反比。但是，如果分配的内存太小，握手过程就会失败，从而导致传输中出现大量错误。最后，通过将65,000KB分配给bit 1, 35,000KB分配给bit 0，我们能够在真实的云环境中实现13.6 bps的带宽。</p>
</li>
</ul>
<p>基于锁的隐蔽通道提供了非常高的数据传输速率，同时仍然保持低错误率。虽然基于内存的隐蔽信道速度有限，但仍能可靠地传输数据。在基于内存的隐蔽信道中可以添加更多的优化方法。例如，我们可以使用更多的级别来每次传输多个比特。我们把它作为我们今后的工作。</p>
<p>值得注意的是，一旦两个容器共存于同一物理服务器上，无论使用相同的CPU包或核心，构建在信息泄漏通道上的隐蔽通道就可以工作。相反，只有当两个实例共享相同的CPU包时，基于最后一级缓存的通道才有效。另据报道，在真实的云环境中，基于内存总线的方法只能适用于近20%的<code>co-residence</code>情况。热隐蔽通道只能在两个核彼此靠近时起作用。</p>
<h1 id="Synergistic-Power-Attack"><a href="#Synergistic-Power-Attack" class="headerlink" title="Synergistic Power Attack"></a>Synergistic Power Attack</h1><p>由于procfs和sysfs在容器中都是只读挂载的，因此恶意租户只能读取这些信息，但不允许修改。我们认为，通过利用泄漏通道，攻击者可以通过学习主机的运行时状态来做出更好的决策。</p>
<p>我们将介绍潜在的<code>Synergistic Power Attack</code>，可能影响数据中心的可靠性，在power outage threats的范围内。我们证明，对手可以利用我们发现的这些信息泄漏来放大攻击效果，降低攻击成本，并促进攻击编排。所有实验都是在真实的容器云中进行的。</p>
<h2 id="Attack-Amplification"><a href="#Attack-Amplification" class="headerlink" title="Attack Amplification"></a>Attack Amplification</h2><p>发动成功的<code>power attack</code>的关键是产生短时间的高power峰值，可以超过电力设施的供应能力。正如我们在2.4节中提到的，电源攻击的根本原因是广泛采用电源<code>oversubscription</code>，这使得电源峰值超过安全阈值成为可能。此外，机架级功率封顶机制只能在分钟级时间粒度内反应，为短时间高功率峰值的发生留下了空间。在最严重的情况下，过度充电可能会跳闸分支断路器，导致停电，最终导致服务器瘫痪。能量峰值的高度主要由攻击者控制的资源决定。现有的电源攻击通过自定义电源密集型工作负载 customizing powerintensive workloads(称为电源病毒)来最大限度地提高功耗。Ganesan等人，利用遗传算法自动生成比正常stress基准消耗更多的power的power viruses。</p>
<p>根据Barroso等的报告，在真实的数据中心中，平均利用率约为20%至30%。在如此低的利用率下，不加区分地发起<code>power attack</code>而跳闸断路器的几率极低。</p>
<p>然而，虽然平均利用率较低，但在峰值需求下，数据中心仍然面临断电威胁。这说明物理服务器的功耗随着工作负载的变化会有很大的波动。</p>
<p>为了确认这一假设，我们进行了一个实验，监测容器云中8个物理服务器的整个系统功耗(通过第3节案例研究II中的<code>RAPL</code>泄漏通道)，持续一周。我们将结果显示在图中。我们首先以30秒为间隔对功率数据进行平均，并在第2天和第5天观察功率的剧烈变化。此外，我们在第2天选择一个高功耗区域，并以一秒(这是产生功率峰值的典型时间窗口)为间隔对数据进行平均。峰值功耗达到1199瓦(W)，在一周的时间内，总功耗相差34.72% (899W ~ 1199w)。</p>
<p>我们预计，如果我们能对其进行更长时间的监控，比如在黑色星期五这样的假日，当托管在云上的在线购物网站可能会产生巨大的电力激增时，功耗差异将会更大。</p>
<p>对于容器云中的<code>synergistic power attack</code>，攻击者可以通过RAPL通道监控整个系统的功耗，实时了解功耗模式的波峰和波谷，而不是不加区分地启动功耗密集型工作负载。因此，他们可以利用后台功耗(由同一主机上其他租户的良性工作负载产生)，并在服务器处于峰值运行时间时叠加他们的电源攻击。</p>
<p>这与金融市场的内幕交易现象类似——掌握更多内幕信息的人总是能在合适的时间交易。对手可以通过通过<code>RAPL</code>通道泄露的“内部”功耗信息，在已经很高的功耗基础上再增加一个更高的功耗峰值。</p>
<h2 id="Reduction-of-Attack-Costs"><a href="#Reduction-of-Attack-Costs" class="headerlink" title="Reduction of Attack Costs"></a>Reduction of Attack Costs</h2><p>从攻击者的角度来看，他们总是希望以最低的代价获得最大的攻击结果。持续运行功耗高的工作负载绝对可以捕获所有良性功耗的峰值。但是，由于几个原因，它对于真实世界的攻击可能并不实用。首先，它不是隐形的。要发起电源攻击，攻击者需要运行电源密集型工作负载。这种行为具有明显的模式，很容易被云提供商检测到。</p>
<p>其次，基于利用率的计费模式现在变得越来越流行。更多的云服务根据CPU&#x2F;内存利用率和网络流量提供更细粒度的价格。例如，Elastic Container为客户提供了基于CPU计量计费的容器。</p>
<p>IBM Cloud为云中的计算资源提供计费指标。Amazon EC2提供了Burstable性能实例，该实例偶尔会崩溃，但大多数时间不会完全运行。VMware按需定价计算器甚至给出了不同利用率水平的估计值。例如，对于一个拥有16个vcpu且平均利用率为1%的实例，它每月收费2.87美元，对于相同的服务器且利用率为100%的实例，每月收费167.25美元。在这些云计费模式下，持续的<code>power attack</code>可能最终导致昂贵的账单。</p>
<p>对于<code>synergistic power attack</code>，通过<code>RAPL</code>监视功耗几乎没有CPU占用。</p>
<p>为了达到相同的效果(功率峰值的高度)，与连续和周期性攻击相比，协同功率攻击可以显著降低攻击成本。我们比较了<code>synergistic power attack</code>和周期性攻击(每300秒发起一次<code>synergistic power attack</code>)的攻击效果。协同攻击在3000秒内只进行两次试验，就可以达到1359瓦的功率峰值，而周期性攻击则进行了9次试验，最多只能达到1280瓦。</p>
<h2 id="Attack-Orchestration"><a href="#Attack-Orchestration" class="headerlink" title="Attack Orchestration"></a>Attack Orchestration</h2><p>与传统的<code>power attack</code>不同，<code>synergistic power attack</code>的另一个独特特征是它的攻击编排。假设攻击者已经控制了一些容器实例。如果这些容器分散在数据中心的不同位置，那么它们在多个物理服务器上增加的power不会对电力设施造成压力。现有的功率封顶机制可以毫无困难地容忍来自不同位置的多个小power surges。发动实际电力攻击的唯一方法是将所有“弹药”聚集到相邻位置，同时攻击单个电源。在这里，我们将深入讨论攻击容器实例的编排。</p>
<p>正如我们在第3节中提到的，通过利用多个泄漏通道，攻击者可以将多个容器实例聚合到一个物理服务器中。具体来说，在CC1上的实验中，我们选择使用计时器列表来验证多个容器的共存。具体验证方法请参见3.3节。我们反复创建不在同一物理服务器上的容器实例和终止实例。通过这样做，我们可以轻松地在同一台服务器上部署三个容器。我们在每个容器中运行四个Prime基准测试副本，以充分利用四个分配的核心。每个容器可以贡献大约40W的功率。使用三个容器，攻击者可以轻松地将功耗提高到近230W，这比单个服务器的平均功耗高出约100W。</p>
<p>我们还发现<code>/proc/uptime</code>是另一个有趣的泄漏通道。正常运行时间包括两个数据项，物理服务器的启动时间和所有核心的空闲时间。</p>
<p>在我们的实验中，我们发现一些服务器的启动时间相似，但空闲时间不同。通常情况下，数据中心的服务器在安装和打开后不会重新启动。不同的空闲时间表明它们不是相同的物理服务器，而相似的引导时间表明它们很可能在同一时间段被安装和打开。这是强有力的证据，表明它们可能离得很近，共用同一个断路器。攻击者可以利用此通道将其攻击容器实例聚合到相邻的物理服务器中。这大大增加了他们跳闸导致停电的机会。</p>
<h1 id="Defense-Aproach"><a href="#Defense-Aproach" class="headerlink" title="Defense Aproach"></a>Defense Aproach</h1><h2 id="A-Two-Stage-Defense-Mechanism"><a href="#A-Two-Stage-Defense-Mechanism" class="headerlink" title="A Two-Stage Defense Mechanism"></a>A Two-Stage Defense Mechanism</h2><p>直观地说，解决方案应该消除所有泄漏，这样就不会通过这些渠道检索泄漏的信息。我们将防御机制划分为两个阶段:(1)屏蔽通道和(2)增强容器的资源隔离模型。</p>
<p>在第一阶段，系统管理员可以显式地拒绝对容器内通道的读访问，例如，通过AppArmor中的安全策略或挂载伪文件“不可读”。这不需要对内核代码进行任何更改(合并到上游Linux内核可能需要一些时间)，并且可以立即消除信息泄漏。此解决方案取决于容器中运行的合法应用程序是否使用这些通道。如果这些信息与容器化的应用程序正交，则屏蔽它不会对容器租户产生负面影响。我们已经向Docker和表中列出的所有云供应商报告了我们的结果，并收到了积极的回应。</p>
<p>我们与容器云供应商合作解决此信息泄漏问题，并将对容器中托管的应用程序的影响降至最低。这种屏蔽方法可以快速修复基于内存的伪文件系统中的所有泄漏，但它可能会对容器化应用程序的功能增加限制，这与容器提供通用计算平台的概念相矛盾。</p>
<p>在第二阶段，防御方法涉及修复丢失的<code>namespace</code>上下文检查和虚拟化更多的系统资源(即，实现新的<code>namespace</code>)以增强容器的隔离模型。</p>
<p>我们首先向Linux内核维护者报告了与现有<code>namespace</code>相关的信息披露错误，他们很快发布了针对其中一个问题的新补丁([CVE2017-5967])。对于没有<code>namespace</code>隔离保护的其他通道，我们需要更改内核代码，以强制使用更细粒度的系统资源分区。由于每个通道都需要单独修复，因此这种方法可能涉及大量工作。虚拟化一个特定的内核组件可能会影响多个内核子系统。另外，有些系统资源不容易精确地划分到每个容器中。但是，我们认为这是解决问题的根本办法。特别是，为了防御<code>synergistic power attack</code>，我们在Linux内核中设计并实现了一个<code>proof-of-concept power-based namespace</code>，以向每个容器显示分区的电源使用情况。</p>
<h2 id="Power-based-Namespace"><a href="#Power-based-Namespace" class="headerlink" title="Power-based Namespace"></a>Power-based Namespace</h2><p>我们提出了一个<code>power-based namespace</code>，通过未更改的<code>RAPL</code>接口向每个容器显示每个容器的power使用情况。在不泄漏整个系统功耗信息的情况下，攻击者无法推断主机的电源状态，从而消除了在良性电源峰值上叠加功耗密集型工作负载的机会。此外，有了每个容器的功率使用统计数据，我们可以动态地限制超过预定义功率阈值的容器的计算能力(或增加使用费用)。容器云管理员可以基于此基于功能的<code>namespace</code>设计粒度更细的计费模型。</p>
<p>我们的设计有三个目标。</p>
<ul>
<li><p>准确性:由于没有硬件支持每个容器的功率分区，我们基于软件的功率建模需要准确反映每个容器的功率使用情况。</p>
</li>
<li><p>透明性:容器内的应用程序不知道该命名空间外的功率变化，功率子系统的接口保持不变。</p>
</li>
<li><p>效率:功率分区不应在容器内或容器外引起重要的性能开销。</p>
</li>
</ul>
<p>我们在图中说明了系统的工作流程。我们基于功率的命名空间由三个主要组件组成:<strong>数据收集</strong>、<strong>功率建模</strong>和<strong>动态校准</strong>。我们在容器中保持相同的Intel <code>RAPL</code>接口，但是改变了处理能源使用的读取操作的实现。一旦检测到能源使用的读取操作，修改后的RAPL驱动程序检索每个容器的性能数据(数据收集)，使用检索到的数据来建模能源使用(功率建模)，最后校准建模的能源使用(动态校准)。</p>
<p>我们将在下面详细讨论每个组件。</p>
<h3 id="Data-collection"><a href="#Data-collection" class="headerlink" title="Data collection"></a>Data collection</h3><p>为了对每个容器的功耗进行建模，我们需要获得每个容器的 <code>fine-grained performance data</code>。每个容器都与一个<code>cpuacct cgroup</code>相关联。<code>cpuacct cgroup</code>表示容器的处理器核心上的CPU周期。CPU周期累计。我们只使用CPU周期来计算后面的缓存丢失率和分支丢失率。Linux内核还有一个<code>perf_event</code>子系统，它支持计算不同类型的性能事件。The granularity of<br>performance accounting 可以是单个进程或一组进程(视为一个<code>per_event cgroup</code>)。到目前为止，我们只为每个<code>perf_event cgroup</code>检索退役指令、缓存缺失和分支缺失(在下一个电源建模组件中需要)的数据。我们当前的实现是可扩展的，可以收集与未来电源建模的变化相对应的更多性能事件类型。</p>
<p>我们从<code>power-based namespace</code>的初始化监视性能事件，并创建多个<code>perf_events</code>，每个事件都与特定的性能事件类型和特定的CPU核心相关联。然后，我们将该容器的<code>perf_cgroup</code>与这些<code>perf_event</code>连接起来，开始计算。此外，我们需要将所有创建的<code>perf_event</code>的所有者设置为<code>TASK TOMBSTONE</code>，这表明这样的性能核算与任何用户进程都是分离的。</p>
<h2 id="Power-modeling"><a href="#Power-modeling" class="headerlink" title="Power modeling"></a>Power modeling</h2><p>要实现<code>power-based namespace</code>，我们需要将功率消耗归因于每个容器。RAPL不是提供瞬态功耗，而是分别为package、核心和DRAM提供累计能耗。power消耗可以通过测量时间单位窗口内的能源消耗来计算。</p>
<p>我们<code>power-based namespace</code>还以与原始RAPL接口相同的格式提供了每个容器的累计能量数据。</p>
<p>我们首先将核心的功耗归为属性。</p>
<p>传统的电源建模利用CPU利用率来确定核心的功耗。然而，Xu等证明，在相同的CPU利用率下，power消耗可能会有很大差异。底层管道和数据依赖可能导致CPU失速和功能单元空转。在相同的CPU利用率下，实际退出指令的数量是不同的。</p>
<p>图显示了退役指令和能量之间的关系。我们在四个不同的基准上进行测试:用C编写的空闲循环，prime, 462.SPECCPU2006中的libquantum，以及不同内存配置的strss。我们在主机上运行基准测试，并使用Perf来收集性能统计数据。我们可以看到，对于每个基准测试，能量消耗几乎严格地与退役指令的数量成线性。但是，随着应用类型的不同，拟合线的梯度也相应变化。为了使我们的模型更加准确，我们进一步加入cache miss rate和branch miss rate，建立一个多次多项式模型来拟合斜率。</p>
<p>对于DRAM，我们使用package失败的数量来分析power。图显示了核心实验中相同基准测试和相同配置的能耗。它清楚地表明cache miss的数量与DRAM能量近似线性。</p>
<p>在此基础上，我们利用的线性回归对DRAM能量进行建模。</p>
<p>对于package的功耗，我们将核心、DRAM和一个额外常数的值相加。具体模型如式所示，其中M为建模能量;CM、BM、C分别表示cache miss次数、branch miss次数和CPU周期;F为通过多次线性回归拟合斜率得到的函数。I是退役指令的数量。α， β， γ， λ是由图实验数据得出的常数。</p>
<img src="/2023/03/30/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%20A-Study-on-the-Security-Implications-of-Information-Leakages-in-Container-Clouds/formula1.png" title alt data-align="center">

<p>这里我们讨论浮点指令对功率建模的影响。独立的浮点指令可能比整数操作消耗更多的能量。具有高浮点指令比例的工作负载实际上可能导致整体功耗较低，因为功能单元可能被迫在管道的不同阶段处于空闲状态。为了建立一个更精细的模型，有必要考虑微架构。我们计划在今后的工作中朝着这个方向努力。此外，α、β、γ参数的选择也受结构的影响。这样的问题可以在接下来的校准步骤中得到缓解。</p>
<h3 id="On-the-fly-calibration"><a href="#On-the-fly-calibration" class="headerlink" title="On-the-fly calibration"></a>On-the-fly calibration</h3><p>我们的系统还为主机的能量数据建模，并与通过RAPL获得的实际能量数据进行交叉验证。为了尽量减小建模数据的误差，我们使用下式对每个容器的建模能量数据进行校准。Econtainer表示返回给每个容器的能量值。这种实时校准是对RAPL接口的每个读取操作进行的，可以有效地减少前一步的错误数量。</p>
<p><img src="/2023/03/30/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%20A-Study-on-the-Security-Implications-of-Information-Leakages-in-Container-Clouds/formula2.png"></p>
<p><img src="/2023/03/30/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%20A-Study-on-the-Security-Implications-of-Information-Leakages-in-Container-Clouds/workflow.png"></p>
<h1 id="Defense-Ecaluation"><a href="#Defense-Ecaluation" class="headerlink" title="Defense Ecaluation"></a>Defense Ecaluation</h1><p>我们从三个方面评估本地机器上基于功能的名称空间:准确性、安全性和性能。我们的测试平台配备了Intel i7-6700 3.40GHz 8核CPU, 16GB RAM，运行Ubuntu Linux 16.04，内核版本为4.7.0。</p>
<h2 id="Accuracy"><a href="#Accuracy" class="headerlink" title="Accuracy"></a>Accuracy</h2><p>我们使用SPECCPU2006基准来测量power建模的准确性。我们将建模的power使用情况与通过RAPL获得的ground truth进行比较。</p>
<p>功耗等于每秒的能量消耗。由于Docker容器的安全策略的限制，我们选择了SPECCPU2006基准测试的一个子集，这些基准测试可以在容器内运行，并且与用于功率建模的基准测试没有重叠。误差ξ定义如下:</p>
<p>其中ERAPL是从主机上的RAPL读取的功耗，而Mcontainer是在容器中读取的相同工作负载的建模功耗。注意，主机和容器都在空闲状态下消耗电力，差别很小。我们使用常数∆diff作为修饰符，反映主机和容器在空闲状态下的功耗差异。结果如图所示，我们的power模型是准确的，因为所有测试基准的误差值都低于0.05。</p>
<h2 id="Security"><a href="#Security" class="headerlink" title="Security"></a>Security</h2><p>我们也从安全的角度来评估我们的系统。</p>
<p>启用了<code>power-based namespace</code>后，容器应该只检索容器内消耗的功率，而不知道主机的电源状态。我们在测试平台中启动两个容器进行比较。我们在一个容器中运行SPECCPU2006基准测试，并将另一个容器闲置。我们记录容器和主机的每秒用电量。如图所示401.bzip2的结果。所有其他基准测试都表现出类似的模式。</p>
<p>当两个容器都没有工作负载时，它们的功耗与主机的功耗基本相同，从0到10s。一旦容器1在10s启动工作负载，我们可以发现容器1和主机的功耗同时激增。从10s到60s，容器1和主机的功耗基本一致，而容器2仍然处于较低的功耗水平。容器2不知道整个系统的功率波动，因为基于<code>power-based namespace</code>强制隔离。这表明我们的系统能够有效地隔离和划分多个容器的功耗。如果没有电源相关的信息，攻击者将无法发起<code>synergistic power attack</code>。</p>
<h2 id="Performance"><a href="#Performance" class="headerlink" title="Performance"></a>Performance</h2><p>我们使用UnixBench来比较启用系统前后的性能开销。表列出了所有结果。</p>
<p>正如结果所示，诸如Dhrystone(测试整数和字符串操作)和Whetstone(测试浮点算术性能)这样的CPU基准测试所产生的开销可以忽略不计。</p>
<p>其他基准测试，如shell脚本、管道吞吐量和系统调用，也会触发很少的开销。</p>
<p>在一个并行副本的情况下，基于管道的上下文切换(pip-based context swtiching)确实会产生61.53%的开销，但在8个并行副本时，它会减少到1.63%。我们预计inter-cgroup context switching涉及启用&#x2F;禁用性能事件监视器，而intra-cgroup context switching不涉及任何此类开销。</p>
<p>这解释为什么在禁用<code>power-based namespace</code>情况下，8个并行副本可以保持相似的性能水平。此外，上下文切换只占整个系统性能开销的很小一部分，因此对正常使用的影响很小。</p>
<p>在我们的系统中，对于每个新创建的容器，内核将在每个内核上创建多个<code>perf_events</code>，以收集与性能相关的数据。此测量过程仅对容器过程进行。因此，测量开销将随着容器数量的增加而线性增加。但是，容器数量的增加对系统的影响很小。使用这种机制，在创建所有进程时，内核会检查该进程是否是容器进程。这个检查进程是Unix基准测试中进程创建开销的主要原因。</p>
<p>如表的最后一行所示，UnixBench的总体性能开销对于一个并行副本是9.66%，对于8个并行副本是7.03%。</p>
<p>我们的系统性能在很大程度上依赖于perf_event cgroup的实现，并且可以随着性能监视子系统的改进而提高。</p>
<h1 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h1><h2 id="Synnergistic-Power-Attack-without-the-RAPL-Channel"><a href="#Synnergistic-Power-Attack-without-the-RAPL-Channel" class="headerlink" title="Synnergistic Power Attack without the RAPL Channel"></a>Synnergistic Power Attack without the RAPL Channel</h2><p>我们还注意到，一些容器云中的服务器没有配备RAPL或其他类似的嵌入式power meters。这些服务器仍可能面临<code>power attack</code>。如果没有像RAPL这样的power-capping工具，这些服务器在一台机器上可能容易受到<code>host-level power attacks</code>。</p>
<p>此外，如果power data不能直接获得，高级攻击者会尝试根据资源利用信息(如CPU和内存利用率)来近似电源状态，这些信息在已识别的信息泄漏中仍然可用。最好让容器租户无法使用系统范围的性能统计数据。</p>
<h2 id="Complete-Container-Implementation"><a href="#Complete-Container-Implementation" class="headerlink" title="Complete Container Implementation"></a>Complete Container Implementation</h2><p>造成信息泄漏和<code>synergistic power attack</code>的根本原因是Linux内核中隔离机制的不完整实现。最好引入更多的安全特性，比如实现更多的<code>namespace</code>和<code>cgroup</code>。但是，一些系统资源仍然难以分区，如中断、调度信息、温度等。人们还认为，完整的容器实现与虚拟机没有什么不同，并且失去了容器的所有优点。这是容器之间的权衡。如何在容器云中平衡安全性、性能和可用性的问题需要进一步研究。</p>
<h1 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h1><p>由于容器最近变得流行，研究人员对容器和硬件虚拟化之间的性能比较感到好奇。Felter等人通过使用一套涵盖CPU、内存、存储和网络资源的基准测试来比较Docker和KVM的性能。他们的结果显示，Docker在所有情况下都能达到与KVM相同或更好的性能。Spoiala等人使用Kurento媒体服务器来比较Docker和KVM上的WebRTC服务器的性能。他们还证明了Docker的性能优于KVM，可以支持实时应用。Morabito等人比较了传统管理程序和操作系统级虚拟化在计算、存储、内存和网络方面的性能。他们对Docker、LXC和KVM进行了实验，观察到磁盘I&#x2F;O仍然是KVM管理程序的瓶颈。所有这些工作都表明，基于容器的操作系统级虚拟化可以实现比硬件虚拟化更高的性能。除了性能，容器云的安全性始终是一个重要的研究领域。Gupta简要介绍了Docker的安全性。Bui也对Docker容器进行了分析，包括隔离问题和相应的内核安全机制。他们声称，Docker容器在默认配置下是相当安全的。Grattafiori等人总结了容器的各种潜在漏洞。他们还提到了基于内存的伪文件系统中的几个通道。Luo等人证明了错误配置的能力可以被利用来在Docker中建立隐蔽的通道。之前关于容器的性能和安全性的研究工作鼓励我们更多地研究容器如何能够实现与硬件虚拟化相同的安全保证，但在性能方面的折衷却微不足道。我们是第一批系统地识别容器中的信息泄露问题，并研究建立在这些泄漏渠道的基于容器的潜在的power attcak。</p>
<h2 id="Cloud-Security-and-Side-x2F-Covert-Channel-Attacks"><a href="#Cloud-Security-and-Side-x2F-Covert-Channel-Attacks" class="headerlink" title="Cloud Security and Side&#x2F;Covert Channel Attacks"></a>Cloud Security and Side&#x2F;Covert Channel Attacks</h2><p>云安全已经受到学术界和业界的广泛关注。云环境下的<code>co-residence</code>检测是与我们工作最密切相关的研究课题。<code>co-residence</code>检测最早由Ristenpart等人提出。他们证明，攻击者可以将恶意VM与目标VM <code>co-residence</code> 在同一服务器上，然后发起侧通道和隐蔽通道攻击。在现有主流云服务中实现<code>co-residence</code>仍然是可行的。为了验证在同一物理服务器上的<code>co-residence</code>，攻击者通常利用侧通道或隐蔽通道，例如，一种广泛采用的方法是使用cahe-based channel。位于同一个包上的多个实例共享最后一级缓存。通过使用一些专用的操作(如cflush)，攻击者可以通过测量缓存访问时间来检测共驻留。Liu等证明了l3缓存侧通道攻击对于跨核和跨vm攻击是可行的。Zhang等人对云进行了真实的侧通道攻击，并提出了几种防御机制来缓解这些攻击。特别是，他们证明了跨租户侧通道攻击可以成功地在PaaS中使用共存服务器进行。除了基于缓存的通道外，内存总线和内存重复数据删除也已被证明是构造隐蔽通道的有效方法。与现有的侧&#x2F;隐蔽通道研究工作不同，我们在容器云设置中发现了系统范围的信息泄漏，并设计了一种新的方法来定量评估泄漏通道的容量，以用于共居检测。另外，与最小化虚拟机的内核攻击面研究相比，我们提出了一种两级防御机制，以最小化容器云上的信息泄漏和电源攻击空间。</p>
<p>系统状态信息，如核心温度和系统功耗，也被用于构建侧&#x2F;隐蔽通道。Thiele等提出了一种基于每个核心温度的热隐蔽通道，并在局部试验台测试了容量。功耗也可能被滥用来破坏AES。在工作中，我们不使用功耗数据作为传递信息的隐蔽通道。相反，我们证明了对手可以利用主机功耗泄漏来发起更高级的<code>power attack</code>。</p>
<h2 id="Power-Modeling"><a href="#Power-Modeling" class="headerlink" title="Power Modeling"></a>Power Modeling</h2><p>在没有<code>hardware-based power meter</code>的情况下，<code>power modeling</code>是逼近功耗的一种方法。</p>
<p>Russell等和Chakrabarti等提出了指令级功率建模。他们的工作表明，分支的数量影响功耗。对虚拟机功耗的近似研究有几种。有工作证明了VM级的功耗可以通过CPU利用率和最后一级缓存失误率来估计。Mobius等将VM的功耗分为CPU、缓存、内存和磁盘。BITWATTS在细粒度流程级别上对功耗进行了建模。Shen等提出了一种power容器来计算多核系统中请求的能量消耗。我们对synergistic的防御主要是受到power modeling approach for VMs的启发。我们提出了一种新的power分区技术来近似每个容器的功耗并重用RAPL接口，从而解决了容器设置中的RAPL数据泄漏问题。</p>
<h1 id="Conlusion"><a href="#Conlusion" class="headerlink" title="Conlusion"></a>Conlusion</h1><p>容器云服务因提供轻量级操作系统级虚拟主机环境而变得流行起来。容器技术的出现深刻地改变了在云中开发和部署分布式应用程序的生态系统。但是，由于Linux内核中系统资源分区机制的不完全实现，对于共享同一个内核的多个容器租户仍然存在一些安全问题。在本文中，我们首先提出了一种系统的方法来发现可能将主机信息暴露给容器的信息泄漏通道。通过利用这些泄露的主机信息，恶意容器租户可以发起一种新型的<code>power attack</code>，这可能会危及数据中心电源系统的可靠性。此外，我们讨论了这些信息泄漏的根本原因，并提出了一个两阶段的防御机制。我们的评估表明，所提出的解决方案是有效的，并引起微不足道的性能开销。</p>
<h1 id="My"><a href="#My" class="headerlink" title="My"></a>My</h1><h2 id="Linux的incomplete-coverage"><a href="#Linux的incomplete-coverage" class="headerlink" title="Linux的incomplete coverage"></a>Linux的incomplete coverage</h2><p>Linux内核提供了对各种容器化技术的支持，使用户能够在单个主机上运行多个隔离环境。Linux内核中的容器实现主要利用一组特性，如namespace、cgroup和seccomp。然而，在Linux内核中，容器实现的某些方面可能是不完整或有限制的。以下是一些潜在的incomplete coverage范围：</p>
<ul>
<li><p>namespace：通过创建系统资源的分离视图来为容器提供隔离。虽然Linux内核支持几种命名空间（mout、PID、NET、IPC、UTS和user），但某些资源类型可能没有相应的命名空间或具有有限的支持，这可能导致不完全隔离。</p>
</li>
<li><p>control groups（cgroups）：Cgroups用于限制、记录和隔离进程组使用资源（CPU、内存、I&#x2F;O等）。虽然存在cgroups v1和v2，但某些功能可能无法在两个版本之间得到充分支持或具有局限性。这会导致容器资源管理不完整或不一致。</p>
</li>
<li><p>安全性：Linux内核提供了诸如seccomp、AppArmor和SELinux之类的安全机制来强制访问控件并限制容器可以进行哪些系统调用。但是，这些机制可能存在漏洞或限制，可能会暴露潜在的安全风险。</p>
</li>
<li><p>兼容性：容器实现的某些功能（如文件系统快照或检查点&#x2F;恢复）可能取决于特定的内核版本、存储驱动程序或文件系统。这可能导致在某些配置上出现兼容性问题和限制。</p>
</li>
<li><p>性能：虽然Linux内核为容器工作负载提供了各种优化，但仍有一些领域可以改进，例如存储I&#x2F;O或网络吞吐量。</p>
</li>
<li><p>内核更新：随着新功能和改进被添加到Linux内核中，容器实现可能需要更新以利用这些增强功能。在某些情况下，这可能会导致容器支持方面存在差距，直到它们与新的内核特性完全集成并进行测试。</p>
</li>
</ul>
<p>值得注意的是，Linux内核正在积极开发中，并且对于容器支持的改进不断被提出和实施。此外，像Docker、Kubernetes和LXC之类的容器化解决方案建立在这些内核特性之上，并提供更完整、无缝的用户体验。</p>
<h2 id="数据中心的oversubscription"><a href="#数据中心的oversubscription" class="headerlink" title="数据中心的oversubscription"></a>数据中心的oversubscription</h2><p>电力超额订阅是数据中心使用的一种策略，其中分配给服务器、存储系统和网络设备的总电源供应超过实际可用电源供应。这种方法基于一个观察结果：并非所有设备同时消耗其最大额定功率。通过利用这一点，数据中心可以托管比其电力基础设施允许更多的服务器和设备。</p>
<h2 id="Linux子系统"><a href="#Linux子系统" class="headerlink" title="Linux子系统"></a>Linux子系统</h2><p>Linux子系统是Linux内核中的一部分，负责处理特定功能或设备。例如，文件系统、网络协议栈、进程调度等都可以被认为是Linux子系统。它们通常以模块的形式实现，并在运行时加载到内核中。这些子系统允许Linux内核与硬件和外部资源进行交互，以便为上层应用程序提供所需的功能。</p>
<h2 id="执行上下文"><a href="#执行上下文" class="headerlink" title="执行上下文"></a>执行上下文</h2><p>执行上下文是操作系统在运行某个任务时的环境，它包括一个任务所需的所有状态信息。这包括程序计数器、堆栈指针、寄存器值、内存分配信息等。执行上下文使得操作系统能够在多个任务之间进行切换，以实现多任务并发执行。</p>
<h2 id="Linux子系统不能区分容器和主机之间的执行上下文，可能泄露系统信息"><a href="#Linux子系统不能区分容器和主机之间的执行上下文，可能泄露系统信息" class="headerlink" title="Linux子系统不能区分容器和主机之间的执行上下文，可能泄露系统信息"></a>Linux子系统不能区分容器和主机之间的执行上下文，可能泄露系统信息</h2><p>容器是一种轻量级的虚拟化技术，允许在同一主机上运行多个隔离的应用程序。容器与主机共享相同的内核，但每个容器都有其独立的文件系统、进程空间、网络接口等。容器技术的一个关键优势是资源隔离，这意味着每个容器只能访问分配给它的资源，而不能访问其他容器或主机的资源。</p>
<p>然而，某些Linux子系统可能无法区分容器和主机之间的执行上下文。这意味着当容器化应用程序访问这些子系统时，它们可能能够访问不应暴露给它们的系统范围信息。这可能导致安全和隐私问题，因为容器之间和容器与主机之间的隔离可能被破坏。</p>
<p>例如，如果某个Linux子系统负责处理系统范围的统计信息（如CPU使用率、内存使用情况等），那么容器内的应用程序可能能够访问这些信息，从而获取其他容器或主机的资源使用情况。这可能导致容器之间的信息泄露，破坏了它们之间的隔离。</p>
<p>为了解决这个问题，容器运行时和内核开发人员需要确保所有Linux子系统都能够正确地区分容器和主机之间的执行上下文，以实现更强大的隔离和安全性。这可能包括修改子系统的实现，以便它们能够识别和处理来自容器的请求，以及限制容器访问系统范围信息的能力。</p>
<h2 id="Namespace和cgroup以及具体实现"><a href="#Namespace和cgroup以及具体实现" class="headerlink" title="Namespace和cgroup以及具体实现"></a>Namespace和cgroup以及具体实现</h2><p>Linux中的Namespace和Cgroup是两种操作系统级别的资源管理和隔离技术。它们在容器技术（如Docker）中被广泛应用，用于实现轻量级虚拟化。</p>
<p><strong>Namespace（命名空间）</strong> 是Linux内核提供的一种隔离技术，允许创建多个独立的空间，每个空间内可以有自己的进程、文件系统、网络等资源。Namespace有以下几种类型：</p>
<ul>
<li>Mount Namespace：隔离不同命名空间的文件系统挂载点。</li>
<li>PID Namespace：隔离进程ID空间，使每个命名空间有独立的PID。</li>
<li>Network Namespace：隔离网络接口和路由表，使每个命名空间有独立的网络环境。</li>
<li>IPC Namespace：隔离System V IPC对象和POSIX消息队列。</li>
<li>UTS Namespace：隔离主机名和域名。</li>
<li>User Namespace：隔离用户和组ID。</li>
</ul>
<p><strong>Cgroup（控制组）</strong> 是Linux内核提供的一种资源管理技术，允许对一组进程进行资源限制、优先级调整等操作。Cgroup通过将进程组织到层次结构的控制组中来实现资源管理。主要有以下几类资源控制：</p>
<ul>
<li>CPU：限制进程的CPU使用率。</li>
<li>Memory：限制进程的内存使用。</li>
<li>Block I&#x2F;O：限制进程的磁盘I&#x2F;O。</li>
<li>Network：限制进程的网络带宽。</li>
</ul>
<p>以下是一个简单的Namespace和Cgroup的使用示例：</p>
<ol>
<li>安装相关工具：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install cgroup-tools</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>创建一个新的Namespace（使用<code>unshare</code>命令）：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo unshare --uts --pid --mount-proc --fork /bin/bash</span><br></pre></td></tr></table></figure>

<p>这个命令创建了一个新的Namespace，并在其中启动了一个新的bash进程。这个新的Namespace具有独立的UTS、PID和挂载的&#x2F;proc文件系统。</p>
<ol start="3">
<li>创建一个新的Cgroup（使用<code>cgcreate</code>命令）：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo cgcreate -g cpu,memory:/my_cgroup</span><br></pre></td></tr></table></figure>

<p>这个命令创建了一个名为<code>my_cgroup</code>的新Cgroup，用于管理CPU和内存资源。</p>
<ol start="4">
<li>为Cgroup分配资源限制（使用<code>cgset</code>命令）：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo cgset -r cpu.shares=512 my_cgroup</span><br><span class="line">sudo cgset -r memory.limit_in_bytes=100M my_cgroup</span><br></pre></td></tr></table></figure>

<p>这个命令为<code>my_cgroup</code>设置了CPU份额为512（相对权重）和内存限制为100MB。</p>
<ol start="5">
<li>将进程添加到Cgroup（使用<code>cgclassify</code>命令）：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo cgclassify -g cpu,memory:my_cgroup &lt;PID&gt;</span><br></pre></td></tr></table></figure>

<p>将指定的进程PID添加到<code>my_cgroup</code>中，使其受到Cgroup资源限制的约束。</p>
<p>以上示例展示了如何使用Namespace和Cgroup进行资源隔离和管理。在实际应用中，这些技术通常与容器运行时（如Docker）结合使用，以提供更高级别的抽象和管理工具。</p>
<h2 id="Namespace和Cgroup的具体使用"><a href="#Namespace和Cgroup的具体使用" class="headerlink" title="Namespace和Cgroup的具体使用"></a>Namespace和Cgroup的具体使用</h2><p><code>Namespace</code> 和 <code>cgroup</code> 是 Linux 内核提供的两个关键特性，它们在容器技术（如 Docker）中发挥着重要作用。<code>Namespace</code> 负责为容器提供独立的视图，使得容器在网络、进程、文件系统等方面与主机和其他容器隔离。而 <code>cgroup</code>（控制组）则负责限制和管理容器的资源使用（如 CPU、内存、磁盘 I&#x2F;O 等）。</p>
<p><strong>Namespace 例子：</strong></p>
<p>假设我们想要创建一个新的网络 Namespace，使容器具有独立的网络栈。我们可以使用 <code>ip</code> 命令来实现这一目标：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个新的网络 Namespace</span></span><br><span class="line">sudo ip netns add my_namespace</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将网络设备 veth0（容器端）和 veth1（主机端）添加到新的 Namespace</span></span><br><span class="line">sudo ip <span class="built_in">link</span> add veth0 <span class="built_in">type</span> veth peer name veth1</span><br><span class="line">sudo ip <span class="built_in">link</span> <span class="built_in">set</span> veth0 netns my_namespace</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置容器端网络设备</span></span><br><span class="line">sudo ip netns <span class="built_in">exec</span> my_namespace ip addr add 192.168.1.2/24 dev veth0</span><br><span class="line">sudo ip netns <span class="built_in">exec</span> my_namespace ip <span class="built_in">link</span> <span class="built_in">set</span> veth0 up</span><br><span class="line">sudo ip netns <span class="built_in">exec</span> my_namespace ip route add default via 192.168.1.1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置主机端网络设备</span></span><br><span class="line">sudo ip addr add 192.168.1.1/24 dev veth1</span><br><span class="line">sudo ip <span class="built_in">link</span> <span class="built_in">set</span> veth1 up</span><br></pre></td></tr></table></figure>

<p>在这个例子中，我们创建了一个新的网络 Namespace，并配置了一对虚拟以太网设备（<code>veth0</code> 和 <code>veth1</code>），将容器的网络与主机网络连接起来。这使得容器可以拥有独立的网络栈，与主机和其他容器隔离。</p>
<p><strong>cgroup 例子：</strong></p>
<p>假设我们想要限制容器的 CPU 和内存资源。我们可以使用 <code>cgroup</code> 来实现这一目标：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个新的 cgroup</span></span><br><span class="line">sudo <span class="built_in">mkdir</span> -p /sys/fs/cgroup/cpu/my_cgroup</span><br><span class="line">sudo <span class="built_in">mkdir</span> -p /sys/fs/cgroup/memory/my_cgroup</span><br><span class="line"></span><br><span class="line"><span class="comment"># 限制容器的 CPU 使用率为 50%</span></span><br><span class="line"><span class="built_in">echo</span> 50000 &gt; /sys/fs/cgroup/cpu/my_cgroup/cpu.cfs_quota_us</span><br><span class="line"><span class="built_in">echo</span> 100000 &gt; /sys/fs/cgroup/cpu/my_cgroup/cpu.cfs_period_us</span><br><span class="line"></span><br><span class="line"><span class="comment"># 限制容器的内存使用为 100MB</span></span><br><span class="line"><span class="built_in">echo</span> 100000000 &gt; /sys/fs/cgroup/memory/my_cgroup/memory.limit_in_bytes</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动一个新的容器，并将其添加到我们之前创建的 cgroup</span></span><br><span class="line">docker run -itd --name=my_container ubuntu:18.04</span><br><span class="line"><span class="built_in">echo</span> $(docker inspect -f <span class="string">&#x27;&#123;&#123;.State.Pid&#125;&#125;&#x27;</span> my_container) &gt; /sys/fs/cgroup/cpu/my_cgroup/cgroup.procs</span><br><span class="line"><span class="built_in">echo</span> $(docker inspect -f <span class="string">&#x27;&#123;&#123;.State.Pid&#125;&#125;&#x27;</span> my_container) &gt; /sys/fs/cgroup/memory/my_cgroup/cgroup.procs</span><br></pre></td></tr></table></figure>

<p>在这个例子中，我们创建了一个新的 CPU 和内存 <code>cgroup</code>，并限制了容器的 CPU 使用率和内存使用。然后我们启动了一个新的容器，并将其添加到我们之前创建的 <code>cgroup</code> 中，这样容器的资源使用就受到了限制。</p>
<p>综上所述，<code>Namespace</code> 和 <code>cgroup</code> 在容器技术中发挥着重要作用，使得容器可以在资源使用和隔离方面实现更精细的控制。</p>
<h2 id="Linux中的pseudo-file"><a href="#Linux中的pseudo-file" class="headerlink" title="Linux中的pseudo file"></a>Linux中的pseudo file</h2><p>在 Linux 系统中，伪文件（pseudo file）是一种特殊类型的文件，它们提供了与系统内核和设备驱动程序交互的途径。伪文件并不包含实际的文件数据，而是在用户和内核空间之间提供了一个通信接口。这些文件通常位于 <code>/proc</code> 和 <code>/sys</code> 文件系统中。</p>
<p><code>/proc</code> 文件系统是一个虚拟文件系统，包含了许多伪文件，这些伪文件可以用来监控和调整系统内核的运行状态。例如，<code>/proc/cpuinfo</code> 提供了有关处理器的详细信息，<code>/proc/meminfo</code> 提供了关于系统内存使用情况的数据。这些伪文件可以像普通文件一样使用命令行工具（如 <code>cat</code>、<code>grep</code> 等）进行查看和操作。</p>
<p><code>/sys</code> 文件系统是另一个虚拟文件系统，用于 Linux 内核的设备管理。它包含了许多伪文件，这些伪文件提供了对系统设备的配置和状态信息的访问。<code>/sys</code> 文件系统的结构更加规范化，按照设备、总线和驱动程序的层次关系进行组织。</p>
<p>总之，伪文件在 Linux 系统中提供了一种简单、统一的方法，使用户能够方便地访问和修改系统内核和设备驱动程序的状态信息。</p>
<h2 id="pseudo-file和真实文件的区别"><a href="#pseudo-file和真实文件的区别" class="headerlink" title="pseudo file和真实文件的区别"></a>pseudo file和真实文件的区别</h2><p>伪文件（pseudo file）和真实文件在 Linux 系统中具有不同的特点和用途。以下是它们之间的主要区别：</p>
<ol>
<li><p><strong>数据存储</strong>：真实文件存储在磁盘上，包含实际的文件数据。而伪文件并不包含实际的文件数据，它们通常不存在于磁盘上，而是由内核动态生成，用于在用户空间和内核空间之间提供通信接口。</p>
</li>
<li><p><strong>用途</strong>：真实文件用于存储和读取数据，例如文档、图像或程序。伪文件主要用于提供系统信息、监控和调整内核参数或设备驱动程序的状态。它们可以让用户通过文件系统接口与内核交互，而无需使用特殊的系统调用。</p>
</li>
<li><p><strong>位置</strong>：真实文件通常分布在整个文件系统中，根据目录结构进行组织。伪文件主要位于特定的虚拟文件系统中，例如 <code>/proc</code>（用于内核参数和进程信息）和 <code>/sys</code>（用于设备管理）。</p>
</li>
<li><p><strong>访问方式</strong>：伪文件和真实文件都可以使用类似的命令行工具（如 <code>cat</code>、<code>grep</code> 等）进行查看和操作。然而，伪文件通常是只读的或仅支持特定操作，它们的内容可能会随着系统状态的变化而动态改变。</p>
</li>
</ol>
<p>总之，伪文件和真实文件在数据存储、用途、位置和访问方式上存在显著差异。伪文件主要用于提供与内核和设备驱动程序的交互途径，而真实文件用于存储和读取实际数据。</p>
<h2 id="伪文件例子"><a href="#伪文件例子" class="headerlink" title="伪文件例子"></a>伪文件例子</h2><p><code>/proc/loadavg</code> 伪文件是由内核动态生成的，不在磁盘上存在。它允许用户和程序通过熟悉的文件系统接口访问负载平均值信息，而无需使用特殊的系统调用。</p>
<p>要使用 <code>/proc/loadavg</code>，您可以像读取常规文件一样简单地读取其内容。例如，您可以使用 <code>cat</code> 命令在终端中显示其内容：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cat</span> /proc/loadavg</span><br></pre></td></tr></table></figure>

<p>输出可能类似于以下内容：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.51 0.38 0.35 1/1234 5678</span><br></pre></td></tr></table></figure>

<p>这些数字分别表示 1 分钟、5 分钟和 15 分钟的负载平均值，后面的数字表示当前正在运行的进程数&#x2F;系统总进程数，以及最近分配的进程 ID。</p>
<p>总之，<code>/proc/loadavg</code> 是一个伪文件的示例，它为访问 Linux 系统中的负载平均值信息提供了一个接口，无需使用特殊的系统调用。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/03/30/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%20Demons-in-the-Shared-Kernel-Abstract-Resource-Attacks-Against/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Plucky">
      <meta itemprop="description" content="随便记录">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Plucky">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/03/30/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%20Demons-in-the-Shared-Kernel-Abstract-Resource-Attacks-Against/" class="post-title-link" itemprop="url">论文阅读 Demons in the Shared Kernel: Abstract Resource Attacks Against</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-03-30 22:06:58" itemprop="dateCreated datePublished" datetime="2023-03-30T22:06:58+08:00">2023-03-30</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-04-16 20:31:41" itemprop="dateModified" datetime="2023-04-16T20:31:41+08:00">2023-04-16</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/" itemprop="url" rel="index"><span itemprop="name">论文精读</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/%E5%86%85%E6%A0%B8%E5%AE%89%E5%85%A8/" itemprop="url" rel="index"><span itemprop="name">内核安全</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>46k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>1:23</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><strong>摘要</strong></p>
<p>由于其更快的启动速度和更好的资源利用效率，OS-level的虚拟化（virtualization）已被广泛采用，并成为云计算的一项基本技术。与硬件虚拟化相比，OS-level的虚拟化利用共享内核（shared-kernel）设计来实现高效率，并在共享内核上运行多个用户空间实例（又称容器）</p>
<p>然而，在本文中，我们揭示了一种新的攻击面，它是操作系统级虚拟化所固有的，会影响Linux、FreeBSD和Fuchsia。根本原因是操作系统级虚拟化中的共享内核设计导致容器直接或间接地共享成千上万的内核变量和数据结构。在不利用任何内核漏洞的情况下，非特权容器可以轻松耗尽共享的内核变量和数据结构实例，从而对其他容器发起DoS攻击。与物理资源相比，这些内核变量或数据结构实例(称为抽象资源)更普遍，但保护不足。</p>
<p>为了说明限制抽象资源的重要性，我们针对操作系统内核的不同方面进行了抽象资源攻击。结果表明，攻击抽象的资源是非常实用和关键的。我们进一步进行了系统分析，识别出Linux内核中脆弱的抽象资源，成功检测到1010个抽象资源，其中501个可以动态重复使用。我们还在前四家云供应商的自部署共享内核容器环境中进行了攻击实验。结果表明，所有环境都容易受到抽象资源攻击。我们得出结论，containing抽象资源是困难的，并给出了多种策略来降低风险</p>
<p><strong>CCS CONCEPTS</strong></p>
<p>Security and privacy -&gt; Virtualization and security</p>
<p><strong>KEYWORDS</strong></p>
<p>OS-level Virtualization；Shared Kernel；Abstract Resource Attack</p>
<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>OS-level虚拟化允许多个包含且隔离的用户空间环境在同一个内核上运行。与硬件虚拟化相比（虚拟机），OS-level虚拟化消除了为每个用户空间实例维护操作系统内核的负担，因此具有更快的启动速度和更好的资源利用效率。因此，OS-level虚拟化在近年来得到了广泛的应用，并成为云计算的基础技术。OS-level虚拟化中的空间实例在FreeBSD中命名为jails，在Solaris命名为Zones，在Linux中命名为containers。</p>
<p>尽管OS-level的虚拟化效率很高，但它也带来了多种安全问题。首先，由于共享内核，操作系统级虚拟化容易受到内核漏洞的攻击。因此，它不能隔离内核错误。一旦共享内核受到威胁，所有用户空间实例(称为容器)都将失去隔离和保护。此外，研究人员最近对容器技术的隔离提出了质疑，例如信息泄漏、隐蔽通道和out-of-band workloads 打破了cgroup。</p>
<p>然而，在本文中，我们揭示了OS-level虚拟化所固有的一种新的攻击面（attack surface）。与硬件虚拟化相比，OS-level虚拟化利用共享内核设计来实现高效率。在典型的OS-level虚拟化环境中，容器运行在相同的操作系统内核上，并通过300多个系统调用请求各种服务。请注意，底层OS内核包含数十万个变量和数据结构实例，用于为容器提供服务。因此，这些容器直接或间接地共享这些内核变量和数据结构实例。</p>
<p>不幸的是，这些共享的内核变量和数据结构实例是OS-level中的新攻击面。在不利用任何漏洞的情况下，非特权容器可以轻松耗尽某些内核变量和数据结构实例，从而在OS-level虚拟化环境中引起DoS攻击。因此，即使其他容器拥有足够的物理资源，但随着内核关键变量或数据结构实例的耗尽，它们仍然不能执行任何有意义的任务。与真实硬件所支持的物理资源相比，我们将这些内核变量或数据结构实例视为抽象资源，将对这些资源的用尽攻击视为抽象资源攻击（<code>abstract resource attack</code>）。</p>
<p>尽管抽象资源可以被用于DoS攻击，但它们往往得不到充分保护。内核和容器开发人员更关注保护物理资源，而不是抽象资源。例如，Linux内核提供了<code>cgroup</code>来限制每个容器实例的资源使用。但在13个<code>cgroup</code>中，有12个是物理资源<code>cgroup</code>，限制CPU、内存、存储、IO等资源的使用。只有pid cgroup是为限制抽象资源pid而设计的。因此，数百种容器共享的抽象资源没有任何限制，例如<code>global dirty ratio</code>、<code>open-file structs</code>和<code>pseudo-terminal structs</code>，这使它们容易受到DoS攻击。</p>
<p>为了展示在OS-level上限制抽象资源的重要性，我们在Linux内核上使用Docker容器进行攻击，针对操作系统服务的不同方面的抽象资源，包括进程管理、内存管理、存储管理和IO管理。</p>
<p>我们的实验证明攻击抽象资源是非常实用和关键的-它很容易地禁用新程序的执行，降低内存写入速度97.3%，使所有文件打开相关地操作崩溃，并拒绝所有新的SSH连接。更糟糕地是，它会影响操作系统服务的所有方面。此外，实验还表明，除了Linux FreeBSD和Fuchsia也容易受到抽象资源攻击。</p>
<p>遗憾的是，尽管抽象资源很重要，但由于几个基本原因，它们本身就很难contain。首先，在操作系统内核中列举所有可能的抽象资源是不切实际的。与很少的物理资源类型不同，内核中的抽象资源类型是多种多样的。第二，很容易形成导致抽象资源枯竭的条件。在内核中实现新特性时，开发人员经常关注物理资源的消耗，而很少关注抽象资源的消耗。此外，OS内核具有复杂的数据和路径依赖关系，导致内核中的抽象资源以各种方式耗尽。</p>
<p>因此，我们设计了一个基于LLVM的工具，系统地识别Linux内核中脆弱的抽象资源。我们提出了识别可共享抽象资源并分析其容器可控性的新技术。我们将我们的工具应用于新的Linux内核，并检测1010个抽象资源。其中501个可以动态地重复使用，从检测到的抽象资源中，我们根据我们的熟悉度挑选了7个影响操作系统各个方面的资源（即，我们知道耗尽该资源的影响）。我们进一步对部署在四大云供应商（包括AWS、MS Azure、谷歌cloud和阿里云）上的共享内核容器环境中的这些选定资源进行攻击实验。试验结果表明，所有环境都容易受到我们的攻击。最后给出了多种降低抽象资源攻击风险的策略。</p>
<p>本文的贡献如下：</p>
<ul>
<li><p>New Attack Surface：我们揭示了操作系统级虚拟化所固有的新的攻击面。我们提出了一种新的攻击方法，称为抽象资源攻击。我们证明了抽象资源攻击是非常实用的，并且是影响Linux、FreeBSD和Fuchsia的广泛攻击类别。</p>
</li>
<li><p>Systematic Analysis：我们设计并实现了一个基于LLVM的静态分析工具来识别Linux内核中脆弱的抽象资源，包括基于配置的分析和容器可控性分析。我们的工具检测501个可以在Linux内核中动态重复触发的抽象资源。</p>
</li>
<li><p>Practical Evaluation：我们评估了AWS、MS Azure、谷歌Cloud和阿里云上self-deployed共享内核容器环境中的7种抽象资源攻击。（目前的公共云供应商没有直接向不同的用户提供共享内核容器。公共云中的容器通常由虚拟机隔离。）所有环境都容易收到抽象资源攻击。其中有两个环境易受6 attacks，一个环境易受 5 attacks，另一个环境易受 4 attacks。我们负责地向所有云供应商披露了我们的调查结果。所有这些都证实了所确定的问题。</p>
</li>
<li><p>Community Impact：我们计划在<a target="_blank" rel="noopener" href="https://github.com/ZJU-SEC/AbstractResourceAttack">GitHub - ZJU-SEC&#x2F;AbstractResourceAttack: This repository is used to analysis the shared resources of different containers</a>中开源我们的工具和识别出的抽象资源，这样它们就可以帮助Linux内核community和容器community识别出OS-level虚拟化中资源隔离的弱点。</p>
</li>
</ul>
<h1 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h1><p>OS-level虚拟化依赖于底层操作系统内核进行资源隔离和containment。更具体地说，Linux内核为资源隔离提供了<code>namespace</code>，为资源containment提供了<code>cgroup</code>。</p>
<h2 id="Linux-Namespaces"><a href="#Linux-Namespaces" class="headerlink" title="Linux Namespaces"></a>Linux Namespaces</h2><p><code>Linux namespace</code>提供进程级资源隔离。目前，<code>Linux namespace</code>分为8种类型。根据它们的发布时间，如下：</p>
<ul>
<li><p>Mount：用于文件系统隔离</p>
</li>
<li><p>UTS：用于主机名和域名隔离</p>
</li>
<li><p>IPC：用于消息队列隔离</p>
</li>
<li><p>PID：用于进程ID隔离</p>
</li>
<li><p>Network：用于网络资源隔离</p>
</li>
<li><p>User：用于UID&#x2F;GID隔离</p>
</li>
<li><p>Cgroup：用于cgroup隔离</p>
</li>
<li><p>Time：用于时钟时间隔离</p>
</li>
</ul>
<p>一个进程可以被分配给不同类型的不同<code>namespace</code>。但是对于每种类型，它只能属于一个<code>namespace</code>。默认情况下，进程与其父进程在相同的<code>namespace</code>中。它可以在进程创建期间通过<code>pass specific flags</code>添加到新的<code>namespace</code>，或者在进程运行期间通过调用<code>setns</code>系统调用添加到新的<code>namespace</code>。理想情况下，只有同一<code>namespace</code>中的进程可以共享<code>namespace</code>隔离的资源。因此，资源是跨<code>namespace</code>隔离的。因此，一个<code>namespace</code>中的隔离资源耗尽不会影响其他<code>namespace</code>中的进程。这样的设计本质上要求<code>namespace</code>机制正确且彻底地contain资源。</p>
<p>然而，仍然有数百种抽象资源类型没有包含在<code>namespace</code>中。即使有<code>namespace</code>的保护，大型攻击面仍然存在。有人可能会主张使用<code>namespace</code>隔离所有抽象资源。然而，这是不切实际的:抽象资源的巨大数量和灵活性使得解决方案由于巨大的代码更改和高性能开销而无法接受。</p>
<h2 id="Linux-Control-Groups"><a href="#Linux-Control-Groups" class="headerlink" title="Linux Control Groups"></a>Linux Control Groups</h2><p>另一方面，<code>Linux cgroup</code>用于限制限制资源的实用。<code>cgroup</code>负责控制组内所有进程使用的资源。<code>cgroup</code>被组织成树状结构，其中<code>children</code>的资源也包括<code>parent</code>的资源。对资源使用的限制也在树上递归地强制执行，以便<code>cgroup</code>中的资源使用不应超过其所有祖先的限制。</p>
<p><code>cgroup</code>主要管理硬件资源，如CPU、内存、存储、IO等。有两个版本的<code>cgroup</code>，<code>v1</code>和<code>v2</code>，主要的区别是，<code>cgroup v1</code>对于每种类型的资源可以有一个树状层次结构，而控制组v2只有一个层次结构。<code>resource account</code>和<code>resource usage limit</code>的实现在<code>v1</code>和<code>v2</code>之间差别不大。目前默认使用<code>cgroup v1</code>，因为它更稳定，并提供更多对资源的控制。它管理13种资源类型，而v2目前只支持9种资源类型。更具体地说，在这13种资源中，有5种用于<code>CPU accouting</code>，包括<code>cpu</code>、<code>cpuacct</code>、<code>cpuset</code>、<code>freeze</code>、<code>pref_event</code>；其中3个是用于内存，包括<code>memory</code>、<code>hugetlb</code>、<code>rdma</code>；<code>blkio</code>用于storage；还有3个用于IO，包括<code>devices</code>、<code>net_cls</code>、<code>net_prio</code>。只有<code>PIDs cgroup</code>为PID的抽象资源。</p>
<p>虽然限制容器进程中共享抽象资源的使用可以减轻DoS攻击，但将<code>cgroup</code>扩展到包括所有抽象资源也是不切实际的。计算资源并对如此多类型的资源实施限制将引入不可接受的开销。</p>
<h1 id="Abstract-Resource-Attacks"><a href="#Abstract-Resource-Attacks" class="headerlink" title="Abstract Resource Attacks"></a>Abstract Resource Attacks</h1><ul>
<li><p>Threat model and assumptions：在本文中，由于我们的目标是OS-level虚拟化，所以我们假设容器运行在相同的共享内核上。容器执行最先进的保护，并在部署中遵循最安全的实践。更具体地说，容器以不同的非根用户运行，删除了所有功能。而内核则为容器强制使用尽可能多的<code>namespace</code>和<code>cgroup</code>。此外，内核还使用<code>seccomp</code>来阻止敏感的系统调用。我们进一步假设内核没有bug，所有安全机制都正常工作。</p>
<p>另一方面，攻击者控制一个容器，并试图破坏在同一内核上运行的其他容器。攻击者可以在容器内运行任何代码并调用<code>seccomp</code>允许的系统调用。但是，他&#x2F;她不允许利用内核漏洞。此外，攻击者作为非根用户处于非特权容器中，根本没有任何功能。最后，攻击者不允许升级特权或重新获得任何功能。在下面的文章中，我们展示了由于内核中的共享抽象资源，即使这样的攻击者仍然可以对其他容器发起DoS攻击。</p>
</li>
</ul>
<h2 id="Weaknesses-in-OS-level-Virtualization"><a href="#Weaknesses-in-OS-level-Virtualization" class="headerlink" title="Weaknesses in OS-level Virtualization"></a>Weaknesses in OS-level Virtualization</h2><p>在OS-level虚拟化中，容器直接或间接地共享成千上万的内核抽象资源，这使它们容易受到资源耗尽攻击。我们利用Linux内核中的一个示例来说明细节。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">percpu_counter</span> <span class="title">nr_files</span> __<span class="title">cacheline_aligner_in_smp</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">long</span> <span class="title function_">get_nr_files</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">return</span> percpu_counter_read_positive(&amp;nr_files);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> file *<span class="title function_">alloc_empty_file</span><span class="params">(<span class="type">int</span> flags, <span class="type">const</span> <span class="keyword">struct</span> cred *cred)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">static</span> <span class="type">long</span> old_max;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">file</span> *<span class="title">f</span>;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(get_nr_files() &gt;= files_stat.max_files&amp;&amp;!capable(CAP_SYS_ADMIN)</span><br><span class="line">    &#123;</span><br><span class="line">        ...</span><br><span class="line">        <span class="keyword">goto</span> over;</span><br><span class="line">    &#125;</span><br><span class="line">    f = __alloc_file(flags, cred);</span><br><span class="line">    <span class="keyword">if</span> (!IS_ERR(f))</span><br><span class="line">        percpu_counter_inc(&amp;nr_files);</span><br><span class="line">    ...</span><br><span class="line">over:</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> ERR_PTR(-ENFILE);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>它定义了一个每个CPU计数器<code>nr_files</code>，一个函数<code>get_nr_files()</code>和一个函数<code>alloc_empty_file()</code>。</p>
<ul>
<li><p><code>nr_files</code>：这是一个每个CPU计数器，用于跟踪每个CPU上分配的文件结构的数量。</p>
</li>
<li><p><code>get_nr_files()</code>：此函数通过读取<code>nr_files</code>计数器的正值，返回所有CPU上分配的文件结构的总数。</p>
</li>
<li><p><code>alloc_empty_file()</code>：此函数接受两个参数，<code>flags</code>和<code>cred</code>，并尝试分配一个空的文件结构。</p>
<ul>
<li><p>如果分配的文件结构的数量（<code>get_nr_files()</code>）大于或等于允许的最大值（<code>files_stat.max_files</code>），并且当前进程没有<code>CAP_SYS_ADMIN</code>能力，它将跳过文件分配并跳转到<code>over</code>标签。</p>
</li>
<li><p>如果满足条件，它将调用<code>__alloc_file()</code>函数来分配一个新的文件结构。</p>
</li>
<li><p>如果分配成功（即返回的指针不是错误），它会增加<code>nr_files</code>计数器。</p>
</li>
<li><p>如果分配失败或达到最大文件数且没有所需的权限，该函数将返回一个带有<code>-ENFILE</code>错误代码的错误指针。</p>
</li>
</ul>
</li>
</ul>
<p>代码显示了Linux内核中的全局变量<code>nr_files</code>和函数<code>alloc_empty_file</code>。<code>alloc_empty_file</code>分配<code>struct</code>文件(<code>f = __alloc_file(flags, cred);</code>)。对于每个分配的结构文件，<code>nr_files</code>通过增加计数器来计算(<code>ercpu_counter_inc(&amp;nr_files);</code>)。在主机Linux内核中，<code>struct</code>文件的总数受<code>files_stat</code>的限制。<code>Max_files(if(get_nr_files() &gt;= files_stat.max_files&amp;&amp;!capable(CAP_SYS_ADMIN))</code>。如果达到限制，<code>alloc_empty_file</code>返回一个错误(<code>return ERR_PTR(-ENFILE);</code>)。</p>
<p>然而，Linux内核并没有提供任何<code>namespace</code>或<code>cgroup</code>来隔离或限制<code>nr_files</code>。因此，<code>nr_files</code>是可以直接控制所有容器的–任何容器对结构文件的分配都会增加相同的共享全局变量<code>nr_files</code>。</p>
<p>这样的<code>nr_files</code>共享会导致新的攻击。在Linux中，所有东西都是一个文件。如此多的操作，如文件打开、进程创建、管道创建、新的网络连接创建，甚至计时器创建<code>(timerfd_create</code>)和事件生成(<code>eventfd</code>)，都增加了<code>nr_files</code>。恶意容器可以很容易地将nr_files弹出到其上限。实际上，在我们的实验中，<code>nr_files</code>的配额可以在几秒钟内快速耗尽。因此，所有使用<code>struct</code>文件的操作都将失败。</p>
<p>影响是严重的:受害者容器甚至不能运行命令(因为它需要打开命令文件)或执行新的二进制文件，导致程序崩溃。从上面的例子中，我们发现即使容器有足够的物理资源，比如CPU或内存，如果没有<code>nr_files</code>中的配额，它仍然不能运行任何新的程序。</p>
<p>为了证明抽象资源攻击会影响所有内核功能，我们针对Linux内核功能的每个方面(包括进程、内存、存储和IO管理)提出了一个抽象资源攻击。在本节中，我们将展示本地测试环境上的攻击结果.。</p>
<p>对于本地测试环境设置，测试机器具有Intel Core i5 CPU, 8 GB内存和500 GB HDD，运行Ubuntu 18.04和Linux内核v5.3.1。我们将其称为主机。在主机上，我们使用docker 18.06.0-ce建立了两个docker容器，分别作为攻击者容器和受害者容器使用。我们按照docker安全最佳实践设置了这两个容器，即在不同的非根用户中运行它们，删除所有功能，启用<code>namespace</code>和<code>cgroup</code>，并应用<code>seccomp</code>系统调用阻塞，如threat model中所讨论的那样。</p>
<h2 id="Attacks-on-Process-Management"><a href="#Attacks-on-Process-Management" class="headerlink" title="Attacks on Process Management"></a>Attacks on Process Management</h2><p>为了实现进程管理，Linux内核引入了一系列的抽象资源，如进程控制块<code>struct task_struct</code>、<code>pid</code>、<code>state</code>和各种数据结构来支持派生实体,如用于线程的s<code>truct thread_info</code>、<code>struct rq runqueues</code>用于调度,<code>struct shm_info</code>和<code>struct semaphore</code>用于进程间通信（IPC），<code>struct spinlock</code>和<code>struct semaphores</code>来实现同步。事实上，Linux中的进程管理引入了成千上万的抽象资源。在下面，我们介绍针对结构idr的攻击，作为一个的例子。</p>
<h3 id="Attacking-idr-of-PID"><a href="#Attacking-idr-of-PID" class="headerlink" title="Attacking idr of PID"></a>Attacking idr of PID</h3><p>Linux内核引入了用于整数ID管理的<code>struct idr</code>。进程管理也使用<code>idr</code>进行<code>pid</code>分配。代码显示了<code>alloc_pid</code>函数，该函数调用<code>idr_alloc_cyclic</code>来获得一个新的<code>pid</code>。<code>Idr_alloc_cyclic</code>在<code>idr</code>分配期间检查<code>pid_max</code>，如果<code>idr</code>增长超过<code>pid_max</code>，则返回一个负错误代码。稍后我们将展示，即使启用了<code>PID namespace</code>和<code>PID cgroup</code>，<code>idr</code>仍然可以被视为所有进程的全局共享资源。类似于<code>fork炸弹</code>，恶意容器进程可以重复<code>fork</code>耗尽所有<code>idr</code>。因此，共享内核上的所有容器都不能创建任何新的进程或线程。</p>
<p>在我们的实验中，攻击者-容器通过调用<code>fork</code>系统调用反复生成进程。结果，在受害容器中，所有与创建新进程相关的操作都失败，并报错“资源临时不可用”。即使是主机上的根用户也会遇到同样的故障。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">struct</span> pid *<span class="title function_">alloc_pid</span><span class="params">(<span class="keyword">struct</span> pid_namespace *ns,<span class="type">pid_t</span> *set_tid, <span class="type">size_t</span> set_tid_size)</span></span><br><span class="line">&#123;</span><br><span class="line">    ...</span><br><span class="line">    nr = idr_alloc_cyclic(&amp;tmp-&gt;idr, <span class="literal">NULL</span>, pid_min, pid_max, GFP_ATOMIC);</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">if</span>(nr &lt; <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        retval = (nr == ENOSPC) ? -EAGAIN : nr;</span><br><span class="line">        <span class="keyword">goto</span> out_free;</span><br><span class="line">    &#125;</span><br><span class="line">    pid-&gt;numbers[i].nr = nr;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这段C代码片段是Linux内核中的一部分，涉及到进程ID（<code>PID</code>）的分配。它定义了一个名为<code>alloc_pid</code>的函数，用于在给定的<code>namespace ns</code>中分配一个新的<code>PID</code>。</p>
<p><code>alloc_pid</code>函数接受以下参数：</p>
<ul>
<li><code>struct pid_namespace *ns</code>：进程ID的命名空间，用于将<code>PID</code>限制在特定的<code>namespace</code>范围内。</li>
<li><code>pid_t *set_tid</code>：指向一个包含线程ID的数组，这些线程ID与新分配的<code>PID</code>关联。通常用于<code>clone</code>系统调用。</li>
<li><code>size_t set_tid_size</code>：<code>set_tid</code>数组的大小。</li>
</ul>
<p>在函数的主体中：</p>
<ol>
<li><p><code>idr_alloc_cyclic()</code>函数被调用以在<code>tmp-&gt;idr</code>中分配一个新的ID，范围在<code>pid_min</code>和<code>pid_max</code>之间。<code>GFP_ATOMIC</code>标志表示内存分配应该是原子性的，即在不释放内核锁的情况下进行分配。</p>
</li>
<li><p>如果<code>nr</code>小于0，说明分配失败。根据失败的原因，<code>retval</code>被设置为<code>-EAGAIN</code>（当<code>nr</code>等于<code>ENOSPC</code>）或<code>nr</code>。然后跳转到<code>out_free</code>标签。</p>
</li>
<li><p>如果分配成功，<code>pid-&gt;numbers[i].nr</code>被设置为新分配的ID。</p>
</li>
</ol>
<p>这段代码负责在给定<code>namespace</code>中分配和管理进程ID。</p>
<h3 id="The-effectiveness-of-the-PID-namespace"><a href="#The-effectiveness-of-the-PID-namespace" class="headerlink" title="The effectiveness of the PID namespace"></a>The effectiveness of the PID namespace</h3><p>Linux v2.6.24引入了<code>PID namespace</code>，它为进程提供了一组独立的<code>PID</code>，这些<code>PID</code>来自其他<code>PID namespace</code>。但是，在<code>PID namespace</code>实现中，Linux内核会在根<code>PID namespace</code>中为其他<code>PID namespace</code>中分配的任何<code>PID</code>分配一个额外的<code>PID</code>，这样其他<code>PID namespace</code>中的所有<code>PID</code>都可以映射到根<code>PID namespace</code>。换句话说，根<code>PID namespace</code>仍然是全局共享的。因此，即使攻击者-容器处于分离的<code>PID namespace</code>中，其<code>PID</code>分配仍然会耗尽根<code>PID namespace</code>中的<code>PID</code>，从而导致victim-container和主机上的new-process-create失败。因此，即使启用了<code>PID namespace</code>，容器仍然容易受到上述<code>idr</code>耗尽攻击的攻击。</p>
<h3 id="The-effectiveness-of-the-PIDs-control-group"><a href="#The-effectiveness-of-the-PIDs-control-group" class="headerlink" title="The effectiveness of the PIDs control group"></a>The effectiveness of the PIDs control group</h3><p>最近在Linux v4.3中也引入了<code>PIDs  cgroup</code>。它的作用是用来限制分配在一个控制组中的PIDs的总数。更具体地说，PIDs控制组在进程分叉过程中检查进程的限制，如果PIDs控制组中的总进程数（<code>pids_cgroup-&gt;counter</code>）达到上限（<code>pids_cgroup -&gt;limit</code>），则返回错误并中止分叉。PIDs控制组在防御直接分叉方面是有效的。然而，它只向当前进程收取pid号。attacker-container可以欺骗内核来分叉大量的内核线程，比如频繁中止导致内核产生中断处理线程。通过这种方式，<code>idr</code>被内核线程耗尽，这就绕过了由 <code>PIDs cgroup</code>。</p>
<h2 id="Attacks-on-Memory-Management"><a href="#Attacks-on-Memory-Management" class="headerlink" title="Attacks on Memory Management"></a>Attacks on Memory Management</h2><p>Linux内核引入了各种内核数据结构，例如<code>mm_struct</code>用于保存进程的所有内存相关信息，<code>vm_area_struct</code>用于表示虚拟内存区域。此外，为了提高读写效率，Linux内核还使用内存作为缓冲区来缓存某些数据。此外，还介绍了回写方案，即只对内存进行写操作。脏内存页稍后将由内核线程写入磁盘。使用<code>write-back</code>方案，调用方只需要写入内存，而不需要等待耗时的磁盘io操作完成(即<code>wirtr-through</code>)，这大大提高了写性能。然而，我们发现内核并没有隔离或限制脏内存区域的使用，这给了攻击者耗尽所有脏内存的机会，这大大减慢了其他容器的速度。接下来，我们讨论对脏内存的攻击。</p>
<h3 id="Attacking-dirty-throttle-control-memory-dirty-ratio"><a href="#Attacking-dirty-throttle-control-memory-dirty-ratio" class="headerlink" title="Attacking dirty_throttle_control memory dirty ratio"></a>Attacking dirty_throttle_control memory dirty ratio</h3><p>Linux内核为脏区控制引入了<code>dirty_throttle_control</code>结构体，它使用<code>dirty</code>字段表示整个内核空间的<code>dirty ratio</code>。只要<code>dirty</code>值太高，内核就会唤醒后台线程，将脏内存同步到磁盘。但同时由于<code>dirty</code>比过高，内核会阻塞<code>write_back</code>，将所有写都转换为<code>write_through</code>，写性能大大降低。</p>
<p>不幸的是，内核没有为内存<code>dirty ratio</code>提供任何隔离。任何进程都可能影响全局内存dirty ratio。在我们的攻击中，攻击者-容器使用<code>dd</code>命令生成文件，快速占用所有脏内存，达到内存<code>dirty ratio</code>限制。结果，来自主机或受害者容器的所有写操作都被转换为<code>write_through</code>，这极大地降低了性能。在我们的实验中，由于攻击，受害者容器上的命令dd if&#x3D;&#x2F;dev&#x2F;zero of&#x3D;&#x2F;mnt&#x2F;test bs&#x3D;1M count&#x3D;1024的性能从1.2 GB&#x2F;s下降到32.6 MB&#x2F;s，导致97.3%的减速。</p>
<p>此外，即使是主机上的特权根用户也有96.1%的性能下降。</p>
<p>请注意，当前Linux内核没有与内存管理相关的<code>namespace</code>，内存<code>cgroup</code>用于限制内存使用，而不是限制内存<code>dirty ratio</code>。因此，无法防御针对内存<code>dirty ratio</code>的攻击。</p>
<h2 id="Attacks-on-Storage-Management"><a href="#Attacks-on-Storage-Management" class="headerlink" title="Attacks on Storage Management"></a>Attacks on Storage Management</h2><p>操作系统内核将磁盘或其他辅助存储抽象为文件，并引入各种与文件相关的抽象资源。实际上，Linux内核中的存储管理是复杂的，它涉及数千个函数和数据结构。在我们的实验中，我们发现有133个与存储相关的抽象资源可以从容器进程中访问。不幸的是，内核没有提供任何<code>namespace</code>或<code>cgroup</code>来隔离或限制这些抽象资源的使用。因此，攻击者容器可以耗尽这些抽象资源，对共享内核上的其他容器发起DoS攻击。</p>
<p>接下来，我们将说明恶意容器如何利用文件限制变量<code>nr_files</code>进行DoS攻击。</p>
<h3 id="Attacking-nr-files"><a href="#Attacking-nr-files" class="headerlink" title="Attacking nr_files"></a>Attacking nr_files</h3><p><code>nr_files</code>是Linux内核中的一个全局变量，它计算内核中打开的文件总数。更具体地说，对于每个分配的结构文件，内核将nr_files加1。不幸的是，<code>nr_files</code>是所有进程共享的。它既不受<code>namespace</code>的隔离，也不受任何<code>cgroup</code>的限制。因此，攻击容器可以很容易地耗尽<code>nr_files</code>来实现DoS攻击。</p>
<p>为了验证这种攻击的可行性，我们的攻击容器生成了数百个进程，每个进程打开1024个文件。因此，<code>nr_files</code>达到其极限。结果，在主机和受害者容器上，所有文件打开操作都失败，内核发出“系统中打开的文件太多”的警告。我们的攻击证实，即使只有几百个进程，攻击者也能够耗尽<code>nr_files</code>。而为了可用性，<code>pid cgroup</code>通常允许数千个进程。因此，即使启用了<code>pid cgroup</code>，攻击者-容器仍然可以成功地对<code>nr_files</code>进行dos攻击。更糟糕的是，<code>nr_files</code>在所有进程(包括根进程和非根进程)之间共享。</p>
<p>因此，不仅非特权容器进程受到影响，主机上的根进程也不能执行任何文件打开操作。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">percpu_counter</span> <span class="title">nr_files</span> __<span class="title">cacheline_aligner_in_smp</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">long</span> <span class="title function_">get_nr_files</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">return</span> percpu_counter_read_positive(&amp;nr_files);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> file *<span class="title function_">alloc_empty_file</span><span class="params">(<span class="type">int</span> flags, <span class="type">const</span> <span class="keyword">struct</span> cred *cred)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">static</span> <span class="type">long</span> old_max;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">file</span> *<span class="title">f</span>;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(get_nr_files() &gt;= files_stat.max_files&amp;&amp;!capable(CAP_SYS_ADMIN))</span><br><span class="line">    &#123;</span><br><span class="line">        ...</span><br><span class="line">        <span class="keyword">goto</span> over;</span><br><span class="line">    &#125;</span><br><span class="line">    f = __alloc_file(flags, cred);</span><br><span class="line">    <span class="keyword">if</span> (!IS_ERR(f))</span><br><span class="line">        percpu_counter_inc(&amp;nr_files);</span><br><span class="line">    ...</span><br><span class="line">over:</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> ERR_PTR(-ENFILE);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Attacks-on-IO-Management"><a href="#Attacks-on-IO-Management" class="headerlink" title="Attacks on IO Management"></a>Attacks on IO Management</h2><p>IO管理是操作系统的重要组成部分。为了便于管理，Linux内核将IO设备抽象到<code>/dev</code>文件中，并引入抽象资源(如<code>tty_struct</code>)来实现IO设备管理。与前面的情况类似，这些抽象资源不受任何<code>namespace</code>或控<code>cgroup</code>的隔离或限制，因此会导致新的攻击。下面，我们将介绍针对<code>pty_count</code>的攻击，它会导致SSH连接出现DoS。</p>
<h3 id="Attacking-pty-count"><a href="#Attacking-pty-count" class="headerlink" title="Attacking pty_count"></a>Attacking pty_count</h3><p>Linux内核将伪终端<code>pseudo-terminal</code>(缩写为<code>pty</code>)抽象为<code>/dev/ptmx</code>和<code>/dev/pts</code>。与此同时，内核还使用一个名为<code>pty_count</code>的全局变量来计算打开的<code>pseudo-terminal</code>的总数，每打开一次<code>/dev/ptmx</code>，<code>pseudo-terminal</code>的总数就增加1，如代码。但是，内核没有提供任何<code>namespace</code>或<code>cgroup</code>来隔离或限制<code>pty_count</code>的使用。因此，攻击者可以很容易地耗尽<code>pty_count</code>。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">static</span> <span class="type">atomic_t</span> pty_count = ATOMIC_INIT(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">devpts_new_index</span><span class="params">(<span class="keyword">struct</span> pts_fs_info *fsi)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="type">int</span> index = -ENOSPC;</span><br><span class="line">    <span class="keyword">if</span> (atomic_inc_return(&amp;pty_count) &gt;= (pty_limit - (fsi-&gt;mount_ops.reserve ? <span class="number">0</span> : pty_reserve)))</span><br><span class="line">        <span class="keyword">goto</span> out;</span><br><span class="line">    <span class="keyword">return</span> index;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">int</span> <span class="title function_">ptmx_open</span><span class="params">(<span class="keyword">struct</span> inode *inode, <span class="keyword">struct</span> file *flip)</span></span><br><span class="line">&#123;</span><br><span class="line">    ...</span><br><span class="line">    index = devpts_new_index(fsi);</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这段C代码片段是Linux内核中的一部分，涉及到伪终端（PTY）的分配和管理。它定义了一个名为<code>devpts_new_index</code>的函数，用于在给定的文件系统信息<code>fsi</code>中分配一个新的伪终端索引。此外，还展示了一个名为<code>ptmx_open</code>的函数，它在打开伪终端主设备（PTMX）时调用<code>devpts_new_index</code>。</p>
<ul>
<li><p>一个名为<code>pty_count</code>的原子变量被初始化为0。它表示当前分配的伪终端的数量。</p>
</li>
<li><p><code>devpts_new_index</code>函数接受一个参数：</p>
<ul>
<li><code>struct pts_fs_info *fsi</code>：一个指向伪终端文件系统信息的指针。</li>
</ul>
</li>
<li><p>在<code>devpts_new_index</code>函数中：</p>
<ul>
<li><p>初始化<code>index</code>为<code>-ENOSPC</code>，表示没有足够的空间分配新的索引。</p>
</li>
<li><p>增加<code>pty_count</code>的值。如果增加后的值大于等于<code>pty_limit - (fsi-&gt;mount_ops.reserve ? 0 : pty_reserve)</code>，则跳转到<code>out</code>标签。</p>
</li>
<li><p>返回<code>index</code>。</p>
</li>
</ul>
</li>
<li><p><code>ptmx_open</code>函数是在打开伪终端主设备（PTMX）时调用的。它接受两个参数：</p>
<ul>
<li><p><code>struct inode *inode</code>：表示伪终端主设备（PTMX）的inode结构。</p>
</li>
<li><p><code>struct file *flip</code>：表示伪终端主设备（PTMX）的file结构。</p>
</li>
</ul>
</li>
<li><p>在<code>ptmx_open</code>函数中，调用<code>devpts_new_index(fsi)</code>以获取一个新的伪终端索引。</p>
</li>
</ul>
<p>这段代码负责在给定的伪终端文件系统信息中分配和管理伪终端索引。当打开伪终端主设备（PTMX）时，会调用<code>devpts_new_index</code>函数以获取新的伪终端索引。</p>
<p>在我们的实验中，攻击者不断打开<code>/dev/ptmx</code>在触发<code>ptmx_open</code>，它调用<code>devpts_new_index</code>并增加<code>pty_count</code>。在几秒钟内，<code>pty_count</code>达到极限，所有接下来的<code>ptmx_open</code>操作都会失败。其后果很严重，因为<code>pty</code>设备被各种应用广泛使用，如SSH连接。结果是，由于伪终端打开失败，所有对任何其他容器的SSH连接尝试都会失败。更糟糕的是，主机无法启动任何新的容器，因为新容器的连接由于同样的错误而被拒绝。</p>
<h2 id="Attacking-FreeBSD-and-Fuchsia-Kernels"><a href="#Attacking-FreeBSD-and-Fuchsia-Kernels" class="headerlink" title="Attacking FreeBSD and Fuchsia Kernels"></a>Attacking FreeBSD and Fuchsia Kernels</h2><p>抽象资源攻击的根本原因是共享的内核数据(即抽象资源)。接下来，我们将演示共享内核数据还使FreeBSD和Fuchsia容易受到抽象资源攻击。</p>
<ul>
<li><p>Attacking FreeBSD</p>
<p>在FreeBSD内核中，在Linux内核中类似的资源之后，我们手动识别了5个共享的全局抽象资源，分别是<code>dp_dirty_total</code>、<code>numvnodes</code>、<code>openfiles</code>、<code>pid</code>和<code>pty</code>。我们的实验进一步证实了前两个可以被DoS攻击，而后三个则受到<code>rctl per-jail</code>的限制。</p>
<p>实验是在FreeBSD 13.0-RELEASE和Ezjail-admin v3.4.2上进行的，运行在具有Intel酷睿i5处理器、8GB内存和40GB硬盘的虚拟机上。<code>Ezjail</code>是一个<code>jail</code>管理框架。<code>ezjail</code>命令提供了一种使用FreeBSD的<code>jail</code>系统创建多个<code>jail</code>的简单方法。这里的<code>jail</code>类似于Linux上的容器。我们根据FreeBSD手册建立了两个<code>jail</code>，并使用<code>rctl</code>来限制每个<code>jail</code>的资源。我们使用这两个<code>jails</code>作为<code>attacker-jail</code>和<code>victim-jail</code>，这类似于§3.1中的容器设置。</p>
<p>对于脏计数器<code>dp_dirty_total</code>, FreeBSD中的<code>ZFS</code>引入了<code>dsl_pool</code>结构体来记录每个<code>ZFS</code>池的数据。<code>dsl_pool</code>结构体使用<code>dp_dirty_total</code>字段表示整个<code>ZFS</code>池脏数据。当<code>dp_dirty_total</code>达到<code>zfs_dirty_data_max</code>的限制时，ZFS将延迟即将进行的写操作，并等待脏数据同步到磁盘。不幸的是，FreeBSD没有为<code>dp_dirty_total</code>提供任何隔离。在attacker-jail中，我们运行命令<code>dd if=/dev/zero of=/mnt/test bs=1M count=1024</code>(与§3.3中的相同)来耗尽<code>dp_dirty_total</code>。因此，<code>victim-jail</code>的IO性能下降了46%。</p>
<p>对于<code>numvnode</code>s, FreeBSD使用<code>vnode</code>结构体来表示文件系统实体，例如文件或目录。FreeBSD还保留了一个全局变量<code>numvnodes</code>来记录整个内核中<code>vnode</code>的总数。极限在<code>maxvnodes</code>。在实验中，通过在<code>attacker-victim</code>中重复创建目录，我们可以很容易地耗尽主机的<code>numvnodes</code>并达到<code>maxvnodes</code>的限制。</p>
</li>
<li><p>Attacking Fushsia</p>
<p>Fuchsia使用<code>Zircon</code>内核，他引入了<code>handle</code>的概念，允许用户空间程序引用内核对象。<code>Zircon</code>维护了一个名为<code>gHandleTableArena</code>的全局数据结构，用于分配所有句柄。内核中<code>handle</code>的限制是<code>kMaxHandleCount</code>。<code>handle</code>在<code>Zircon</code>中使用非常频繁。令人惊讶的是，我们发现<code>handle</code>的创建不受限制。我们在Fuchsia模拟器上进一步确认了这个问题。具有基本权限(类似于Linux中的功能)的用户可以重复创建<code>handle</code>，耗尽所有<code>handle</code>，从而导致整个系统崩溃。我们向Fuchsia开发人员报告了这个问题。他们已经确认了这个问题，并计划在确定更多的攻击载体到本地DoS后修复这个问题。</p>
</li>
</ul>
<h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><p>从上面的讨论中，很容易看出抽象的资源攻击是非常实用的，后果是严重的。更糟糕的是，抽象资源在Linux内核中非常常见，影响Linux功能的各个方面。此外，抽象资源攻击是操作系统级虚拟化所固有的。它也适用于FreeBSD和Fuchsia内核。</p>
<h1 id="Static-Analysis-Of-Container-Exhaustible-Abstract-Resources"><a href="#Static-Analysis-Of-Container-Exhaustible-Abstract-Resources" class="headerlink" title="Static Analysis Of Container-Exhaustible Abstract Resources"></a>Static Analysis Of Container-Exhaustible Abstract Resources</h1><p>如前所述，抽象资源对容器至关重要。</p>
<p>另一方面，有成千上万的抽象资源，这使得几乎不可能列举所有这些资源。在本文中，我们迈出了识别容器共享的可耗尽抽象资源的第一步。</p>
<ul>
<li><p>Challenges</p>
<ul>
<li><p>首先，很难识别有意义的抽象资源，尤其是那些在内核中共享的资源。Linux内核中的抽象资源可以是变量或数据结构实例。然而，并非所有变量或数据结构实例都是有意义的抽象资源。我们需要找到对操作系统功能至关重要的抽象资源。此外，所识别的抽象资源需要在容器之间共享，以便一个容器可以耗尽这些资源来攻击其他容器。不幸的是，没有关于可共享抽象资源的文档。</p>
<p>为了解决这个问题，我们建议使用基于配置的分析<code>configuration-based analysis</code>和基于访问的分析<code>access-based analysis</code>来识别Linux内核中的各种共享抽象资源。</p>
</li>
<li><p>其次，决定容器是否可以用尽特定的抽象资源是一个挑战。与普通的用户空间程序不同，从容器中访问资源面临更多的限制，如<code>namespace</code>、<code>cgroup</code>和<code>seccomp</code>。此外，由于每个容器在一个单独的用户中运行，其资源消耗也受到每个用户的限制。因此，对资源消耗点的简单可达性分析不能说明容器对抽象资源的可控性。例如、对于被<code>namespace</code>隔离的抽象资源，即使容器可以消费这些抽象资源，由于<code>namespace</code>的隔离，它仍然可能不会影响其他容器。因此，为了克服这一挑战，我们提出了容器可控性分析，包括<code>seccomp</code>限制分析、<code>per-user</code>限制分析和<code>namespace</code>隔离分析，以进一步过滤容器可耗费的资源。</p>
</li>
</ul>
</li>
</ul>
<p>图显示了我们的工具的体系结构，它自动识别出容器可耗尽的抽象资源。分析工具以内核源<code>IR</code>作为输入。它首先使用§4.1中基于配置的分析和基于访问的分析来识别所有内核可共享的抽象资源。然后进行§4.2中的系统调用可达性分析和容器限制分析，包括<code>seccomp</code>、<code>per-user</code>和<code>namespace</code>限制分析，分析这些抽象资源上的容器可控性。</p>
<p>此外，我们在§4.3给出了分析结果。</p>
<p><img src="/2023/03/30/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%20Demons-in-the-Shared-Kernel-Abstract-Resource-Attacks-Against/architecture.png"></p>
<h2 id="Identification-of-Kernel-Shareable-Abstract-Resources"><a href="#Identification-of-Kernel-Shareable-Abstract-Resources" class="headerlink" title="Identification of Kernel Shareable Abstract Resources"></a>Identification of Kernel Shareable Abstract Resources</h2><p>如前所述，从成千上万的内核变量和数据结构实例中识别有意义的抽象资源具有挑战性。更困难的是，为了确保这些抽象资源在容器之间直接或间接地共享，我们需要将它们缩小到可共享的内核抽象资源。</p>
<p>为了克服这一挑战，我们利用内核编程范例并提出基于配置的分析和基于访问的分析来识别内核可共享资源。</p>
<h3 id="Configuration-based-Analysis"><a href="#Configuration-based-Analysis" class="headerlink" title="Configuration-based Analysis"></a>Configuration-based Analysis</h3><p>Linux内核在<code>/proc/sys</code>下提供<code>sysctl</code>接口，允许用户空间程序配置内核参数。我们的主要观察结果是，这些<code>sysctl</code>配置中的大多数用于抽象的资源限制，例如限制文件数<code>fs.file-nr</code>或内存大页<code>vm.nr_hugepages</code>。因此，所有容器都共享由<code>sysctl</code>配置指定的相同全局限制。这样的<code>sysctl</code>配置提供了关于容器之间可共享的抽象资源的重要线索。</p>
<p>基于上述观察，我们建议使用<code>sysctl</code>配置来识别可共享的内核抽象资源，称为基于配置的分析，它包括三个基本步骤。</p>
<ul>
<li><p>首先，它使用特定的<code>sysctl</code>数据类型来识别所有的<code>sysctl</code>相关数据结构。这些数据结构包含可配置的<code>sysctl</code>内核参数。</p>
</li>
<li><p>其次，<code>sysctl</code>数据结构通常包含在<code>/proc/sys/</code>文件夹中显示<code>sysctl</code>值的函数。因此，通过分析该函数，我们能够准确地找出该内核参数的变量。</p>
</li>
<li><p>最后，如果一个内核参数被用于限制资源消耗，它的相应变量应该出现在比较指令中。因此，我们按照使用-定义链来检查所确定的变量的使用情况，如果它在比较指令中被使用，就把它标记为抽象资源。</p>
</li>
</ul>
<p>我们在LLVM中设计并实现了一个过程间分析通道。我们在代码中使用一个示例来说明细节。具体来说，Linux内核使用类型<code>struct ctl_table</code>来配置<code>sysctl</code>内核参数，例如代码中的第1行所示的<code>fs_table</code>中的文件系统配置。</p>
<p>因此，该通道首先遍历所有的内核全局变量，收集所有的结构<code>ctl_table</code>变量，如代码中的<code>fs_table</code>。其次，<code>fs_table</code>使用<code>proc_handler</code>中的函数指针来显示<code>/proc/sys/</code>文件系统中的参数。因此，从遍历所有的内核全局变量来收集所有的结构<code>ctl_table</code>变量，如代码中的<code>fs_table</code>。</p>
<p>第二，<code>fs_table</code>使用<code>proc_handler</code>中的函数指针来显示<code>/proc/sys/</code>文件系统中的参数。因此，从<code>proc_handler</code>字段中，通证遵循其指向，启动程序间分析以获得确切的变量，其值显示在<code>sysctl</code>配置界面中。如代码第19行所示，我们的传递将nr_files标记为关键变量。</p>
<p>第三，我们的传递检查所有已识别的关键变量的使用情况。如果一个关键变量在比较指令中被使用（即<code>LLVM IR</code>中的<code>icmp</code>），我们的传递就会记录这些位置并将这个变量标记为抽象资源。例如，在代码的第25行，<code>nr_files</code>被用于比较。我们的传递进一步检测到，如果比较失败，在第25行和第27行会返回一个错误。因此，我们的传递将<code>nr_files</code>标记为一个抽象资源。通过分析所有的<code>struct ctl_table</code>，我们的传递得到一个抽象资源的集合。</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">ctl_table</span> <span class="title">fs_table</span>[] =</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">    &#123;</span><br><span class="line">        .procname = <span class="string">&quot;file-nr&quot;</span>,</span><br><span class="line">        .data = &amp;files_stat,</span><br><span class="line">        .proc_handler =proc_nr_files,</span><br><span class="line">    &#125;,</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> proc_nr_files(...)</span><br><span class="line">&#123;</span><br><span class="line">    files_stat.nr_files = get_nr_files();</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">long</span> <span class="title function_">get_nr_files</span><span class="params">(<span class="type">void</span>)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">return</span> percpu_counter_read_positive(&amp;nr_files);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">struct</span> file *<span class="title function_">alloc_empty_file</span><span class="params">(<span class="type">int</span> flags, ...)</span></span><br><span class="line">&#123;</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">if</span>(get_nr_files() &gt;= files_stat.max_files &amp;&amp; !capable(CAP_SYS_ADMIN))</span><br><span class="line">    &#123;</span><br><span class="line">        ...</span><br><span class="line">        <span class="keyword">goto</span> over;</span><br><span class="line">    &#125;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这个代码片段是一个C代码，用于管理Linux内核模块中的文件资源。它定义了一个名为<code>fs_table</code>的<code>ctl_table</code>结构数组、一个用于设置当前打开文件数量的<code>proc_nr_files</code>函数、一个返回打开文件数量的<code>get_nr_files</code>函数，以及一个在打开文件数量未超过允许的最大值时分配新文件结构的<code>alloc_empty_file</code>函数。</p>
<p>以下是各个组件的详细解释：</p>
<ol>
<li><p><code>fs_table</code>是一个<code>ctl_table</code>结构数组，用于定义<code>/proc/sys/fs/</code>目录中的sysctl条目。具有<code>procname</code>为”file-nr”的条目与当前打开文件的数量相关联。</p>
</li>
<li><p><code>proc_nr_files</code>是一个设置当前打开文件数量的函数。当调用该函数时，它会使用<code>get_nr_files()</code>函数返回的值更新<code>files_stat.nr_files</code>。</p>
</li>
<li><p><code>get_nr_files</code>是一个返回当前打开文件数量的函数。它通过从名为<code>nr_files</code>的<code>percpu_counter</code>结构中读取一个值来实现这一点。该结构用于以适用于多核系统的高效方式存储文件数量。</p>
</li>
<li><p><code>alloc_empty_file</code>是一个尝试分配空文件结构的函数。它检查当前打开文件的数量（由<code>get_nr_files()</code>返回）是否大于或等于最大允许的文件数量（存储在<code>files_stat.max_files</code>中）。如果满足此条件且调用者没有<code>CAP_SYS_ADMIN</code>能力，则跳转到标签<code>over</code>，这个标签可能处理文件数量超过最大值的情况。</p>
</li>
</ol>
<p>这个代码片段是Linux内核如何管理文件资源并对同时打开的文件数量施加限制的一个例子。</p>
<h3 id="Access-based-Analysis"><a href="#Access-based-Analysis" class="headerlink" title="Access_based Analysis"></a>Access_based Analysis</h3><p>除了sysctl配置外，Linux内核还使用锁或原子机制来保护并发访问的资源。因此，我们建议使用并发访问作为标识来标识一组可共享的抽象资源。</p>
<p>由于（race condition）竞态条件和并发性分析是一个老话题，我们采用现有的lockset检测方法。如果锁在数据结构的某个字段上，我们将该数据结构标记为抽象资源，并将该函数添加到敏感函数集中。具体来说，如果在某个数据结构的字段上使用了锁，那么可以将此数据结构标记为抽象资源，并将涉及该字段的函数添加到敏感函数集合中。这意味着这些函数可能需要特别关注，因为它们可能会受到并发访问的影响。此外，如果一个变量在lock和unlock函数之间被定量地修改，我们也将其标记为抽象资源。例如，多个线程在没有锁保护的情况下访问同一数据结构，那么可以将这组资源标记为抽象资源。如果某个变量在 lock 和 unlock 函数之间被定量地修改（即，在锁保护下发生了修改），那么也可以将其标记为抽象资源。这有助于进一步确定可能受到并发影响的资源。</p>
<p>除了锁定&#x2F;解锁，我们还观察到原子计数器和<code>percpu</code>计数器还用于保护并发访问的数据，例如<code>percpu_counter_inc</code>和<code>atomic_inc_return</code>。因此，我们实现了一个pass来分析所有原子计数器和percpu计数器的使用情况。我们的传递首先分析函数参数，并将所有具有<code>struct atomic_t</code>、<code>struct atomic64_t</code>和<code>struct percpu_counter</code>参数的函数添加到<code>原子/percpu</code>函数集中。其次，遍历所有内核函数中的所有语句，以检查<code>原子/percpu</code>函数的所有使用情况。如果一个变量被传递给一个<code>原子/percpu</code>函数，我们将它标记为一个抽象资源。</p>
<ul>
<li><p>识别具有<code>原子/percpu</code>计数器参数的函数.</p>
</li>
<li><p>遍历内核函数中的语句，检查<code>原子/percpu</code>函数的使用情况。</p>
</li>
</ul>
<p>在实现过程中，我们发现LLVM链接器合并了具有相同内存布局的结构类型，例如<code>typedef struct &#123;int counter;&#125;</code> <code>atomic_t</code>和<code>typedef struct &#123;uid_t val;&#125; kuid_t</code>。原因是uid_t的类型是unsigned int，它的大小与int相同。因此，LLVM链接器将它们合并，并错误地使用<code>kuid_t</code>代替<code>atomic_t</code>。为了解决这个问题，我们跟踪LLVM链接器，并发现<code>lib/ linker / irmove .cpp</code>中的get方法将新类型与现有类型进行比较，如果内存布局相同，则合并它们。因此，我们通过注释掉比较和合并代码来禁用合并。</p>
<h2 id="Container-Contorllability-Analysis"><a href="#Container-Contorllability-Analysis" class="headerlink" title="Container-Contorllability Analysis"></a>Container-Contorllability Analysis</h2><p>通过识别抽象资源，我们提出了容器可控性分析，以确保容器实际上可以消耗这些抽象资源。我们对容器可控性分析的想法是（two-fold）双重的。</p>
<ul>
<li><p>首先，我们需要确保容器进程可以到达§4.1中的抽象资源消耗点。为此，我们基于内核控制流图执行传统的反向控制流分析，其中基于结构类型解析间接调用。如果没有从系统调用项到抽象资源消耗点的路径，我们将该抽象资源标记为容器不可访问的。</p>
</li>
<li><p>其次，注意，单靠可达性分析是不够的，我们需要进一步确保路径上没有额外的特定于容器的限制。换句话说，我们需要检查路径上是否存在任何限制检查，以确保容器可以耗尽这些抽象资源。如前所述，与用户空间程序不同，容器面临更多限制，如<code>seccomp</code>、<code>namespace</code>、<code>cgroup</code>以及每个用户的资源限制。由于我们的可达性分析是标准的，在接下来的文章中，我们将重点关注限制分析。</p>
</li>
</ul>
<h3 id="Seccomp-Restriction-Analysis"><a href="#Seccomp-Restriction-Analysis" class="headerlink" title="Seccomp Restriction Analysis"></a>Seccomp Restriction Analysis</h3><p><code>Seccomp</code>是一种用于系统调用过滤的机制。我们对<code>seccomp</code>的限制分析如下。在我们的实现中，我们使用Docker默认的<code>seccomp</code>配置文件，它可以阻止超过50个系统调用。在从系统调用条目到资源消耗站点的所有路径中，我们过滤掉来自任何阻塞的系统调用的路径。</p>
<h3 id="Per-User-Restriction-Analysis"><a href="#Per-User-Restriction-Analysis" class="headerlink" title="Per-User Restriction Analysis"></a>Per-User Restriction Analysis</h3><p>在实际部署中，容器通常以不同的用户运行。因此，每个容器的资源消耗也受到peruser资源配额的限制。例如，Linux提供了<code>user-limits</code>命令<code>ulimit</code>，用于限制用户的资源消耗。而<code>ulimit</code>的底层实现是使用<code>rlimit</code>来设置多个每个用户的资源配额。</p>
<p>除了<code>ulimit</code>, Linux还提供了允许用户利用<code>PAM (Pluggable Authentication Module)</code>部署每个用户配额的接口。PAM使用<code>setup_limits</code>函数来设置每个用户的资源配额，该函数调用<code>setrlimit</code>来配置多个<code>rlimit</code>约束。对于<code>ulimit</code>、<code>rlimit</code>和<code>PAM</code>所限制的资源，攻击者容器不能消耗超过每个用户配额的资源。因此，它无法完全控制这些抽象资源来发起DoS攻击。由于<code>ulimit</code>和<code>PAM</code>都使用<code>rlimit</code>来设置每个用户的资源配额，因此我们需要分析<code>rlimit</code>并过滤出受其限制的抽象资源。</p>
<p>对于<code>rlimi</code>t分析，我们的关键观察是<code>rlimit</code>值通常在<code>struct rlimit</code>或<code>struct rlimit64</code>中指定。因此，我们首先遍历内核<code>IR</code>，以识别从<code>struct rlimit</code>或<code>struct rlimit64</code>加载的所有变量。然后，我们执行数据流分析，以跟踪这些变量的所有传播和使用，并在任何比较指令中使用这些函数时标记它们。在这些函数中，检查<code>rlimit</code>以限制某些资源。我们认为这些资源是攻击容器不可耗尽的，因此我们根据这些函数来过滤路径。我们的工具确定了40个检查<code>rlimit</code>的函数。</p>
<h3 id="Namespace-Isolation-Analysis"><a href="#Namespace-Isolation-Analysis" class="headerlink" title="Namespace Isolation Analysis"></a>Namespace Isolation Analysis</h3><p>如前所述，Linux内核为资源隔离引入了<code>namespace</code>。对于<code>namespace</code>隔离的资源，Linux内核在每个<code>namespace</code>下为其创建一个“<code>copy</code>”，以便一个<code>namespace</code>中的修改不会影响其他<code>namespace</code>。因此，为了确认容器的可控性，我们需要确保那些抽象资源不受<code>namespace</code>的保护。这里的挑战是，尽管Linux有关于<code>namespace</code>的文档，但没有关于哪些抽象资源由<code>namespace</code>隔离的规范。</p>
<p>因此，我们提出了<code>namespace</code>隔离分析来系统地识别受<code>namespace</code>保护的抽象资源。</p>
<p>我们的主要观察结果是，对于<code>namespace</code>隔离的资源，对应的数据结构有一个指针字段，指向它所属的<code>namespace</code>。因此，我们的工具首先遍历内核中每种数据结构类型的所有字段。如果该类型具有名称空间指针，则将其标记为隔离资源。其次，对于已识别的隔离资源，我们的工具使用它来过滤§4.1中识别的共享抽象资源。</p>
<p>请注意，由于不同<code>namesapce</code>之间的映射，一些<code>namespace</code>隔离的资源仍然容易受到抽象资源攻击。如§3.2.2所述，<code>idr</code>由<code>pid_namespace-&gt;idr</code>隔离。但是，在非根PID <code>namespace</code>中分配的每个<code>idr</code>都映射到根<code>PID namespace</code>中的一个新的<code>idr</code>，以便根<code>namespace</code>可以管理它。因此，根<code>PID namespace</code>被所有<code>PID namespace</code>中的所有容器全局共享。因此，它仍然容易受到<code>idr</code>耗尽攻击。</p>
<p>在我们的分析中，我们手动过滤掉这些资源。</p>
<h2 id="Analysis-Results"><a href="#Analysis-Results" class="headerlink" title="Analysis Results"></a>Analysis Results</h2><p>我们在LLVM 12.0中使用大约2500行c++代码实现了我们的分析工具。Linux内核<code>IR</code>是基于最新的Linux稳定版本v5.10和defconfig生成的。特别是，通过应用基于配置的分析和基于访问的分析，以及来自系统调用的可达性分析和<code>seccomp</code>限制分析，我们的工具确定了1844个容器可达的共享抽象资源。</p>
<ul>
<li><p>Resource Filtering</p>
<p>通过每个用户配额限制和<code>namespace</code>隔离分析，我们的工具可以找到342个受<code>rlimit</code>限制或具有指向<code>namespace</code>结构的指针的资源。这些资源要么对路径进行限制检查，要么对其进行<code>namespace</code>。</p>
<p>我们进一步进行手工分析。具体来说，对于已识别的抽象资源中的每个资源𝑅，我们将遍历所有检测到的𝑅或𝑅字段的修改。如果修改不是定量的，比如被赋值为布尔类型、枚举类型或字符串类型，则将此修改标记为非定量的。如果对𝑅和𝑅字段的所有修改都是非定量的，我们将𝑅标记为不可耗尽的。我们的手工分析确定了492种不可耗尽的抽象资源，经过人工分析，仍然有1010个抽象资源。</p>
</li>
<li><p>Dynamic Validation</p>
<p>为了进一步验证这1010个资源的动态耗尽，我们开发了一个资源消耗的动态验证方法。对于每个资源，我们首先从可控性分析中获得其消耗点和触发的系统调用。在此之后，我们对这些消耗站点进行测量，以监控实际的资源消耗。接下来，我们执行相应触发系统调用的测试用例，以重复触发消费并记录结果。我们利用来自Linux测试项目的1156个测试用例，并开发177个新的用例来覆盖更多的用例。我们还开发脚本来自动化上述步骤。</p>
<p>我们应用动态验证方法来测试所有1010个资源的消耗。</p>
<p>对于1010个检测到的资源，其中700个不在驱动程序文件夹中，而其他310个资源在驱动程序文件夹中，在700个非驱动资源中，有389个资源可以动态重复触发，真阳性率为55.6%。驱动程序文件夹中的资源需要特别处理，原因有两个。首先，驱动程序是特定于硬件的。如果没有相应的硬件，就无法动态触发驱动程序代码。我们的主要观察结果是，大多数硬件支持的驱动程序在<code>/dev</code>或<code>/sys/class</code>文件夹下公开特定的接口。基于这种观察，我们删除了硬件不支持的驱动程序中的92个资源。第二，LTP提供的测试用例可能不覆盖特定的驱动程序。</p>
<p>为了解决这个问题，我们修改LTP测试用例并为驱动程序开发新的测试用例。218个驱动资源中，有112个驱动资源可以重复触发，真阳性率为51.4%。</p>
<p>识别容器可耗尽抽象资源是一项非常具有挑战性的任务，因为它需要领域知识来触发抽象资源的耗尽，并且需要评估这些资源耗尽时的影响。在本文中，我们进行了初步分析。请注意，彻底的分析和风险评估需要来自Linux内核和容器社区的帮助。因此，我们计划开源我们的工具和检测到的抽象资源。我们认为这将有助于Linux内核和容器社区识别资源隔离的弱点，并开发健壮的资源遏制方案。</p>
</li>
</ul>
<h1 id="Abstract-Resource-Attacks-On-Cloud-Platforms"><a href="#Abstract-Resource-Attacks-On-Cloud-Platforms" class="headerlink" title="Abstract Resource Attacks On Cloud Platforms"></a>Abstract Resource Attacks On Cloud Platforms</h1><p>在本节中，我们将进一步评估针对公共云供应商容器环境的抽象资源攻击。我们首先介绍环境设置，然后给出结果。</p>
<h2 id="Environment-Setup-and-Ethical-Considerations"><a href="#Environment-Setup-and-Ethical-Considerations" class="headerlink" title="Environment Setup and Ethical Considerations"></a>Environment Setup and Ethical Considerations</h2><p>为了评估抽象资源攻击的有效性，我们在本地和云平台上建立了容器环境。</p>
<p>本地测试环境已在§3.1中给出。</p>
<ul>
<li><p>Ethical Considerations</p>
<p>对于云平台，我们打算尽可能减少我们的攻击对其他云用户的影响。因此，我们使用专用的虚拟服务器，如AWS EC2、Azure VM、谷歌GCE、阿里巴巴ECS来进行实验。此外，我们确保我们是该服务器的唯一用户。</p>
<p>此外，大多数容器用户利用容器编排系统来部署和管理容器。因此，我们选择了最流行的Kubernetes，并利用云供应商的Kubernetes服务在虚拟服务器上部署两个docker容器(即攻击者容器和受害者容器)。为了实现强隔离，我们为<code>attacker-container</code>和<code>victim-container</code>应用了不同的<code>Kubernetes namespace</code>。如§4.2所述，容器也受到每个用户配额的限制。为了在我们的实验中强制执行每个用户的配额，我们在不同的用户中运行攻<code>attacker-container</code>和<code>victim-container</code>，并强制执行每个用户的配额。我们还在§6中讨论了<code>PAM</code>可以部署的限制。</p>
</li>
<li><p>Amazon AWS</p>
<p>对于容器服务，我们使用Elastic Kubernetes Service (EKS)在EC2实例上部署两个容器实例。EC2实例包含4个cpu、8gb内存和20gb SSD磁盘。在容器部署期间，我们惊奇地发现“Amazon EKS默认pod安全策略”使用了EKS。特权为默认pod安全策略。请注意，此策略允许容器作为特权用户运行，还允许特权升级以及主机网络访问。</p>
<p>为了更好地演示我们提出的攻击的有效性，我们从本地测试环境采用了更强的安全策略，从EKS容器运行在非根用户中，删除所有特权，启用所有<code>namespace</code>和<code>cgroup</code>，并使用<code>docker seccomp</code>配置文件来阻止50多个敏感系统调用，包括<code>ptrace</code>、<code>pivot_root</code>等。我们对<code>attacker-container</code>和<code>victim-container</code>应用相同的安全策略。</p>
</li>
<li><p>MS Azure<br>我们使用Azure Kubernetes服务（AKS），在Azure虚拟机上部署了两个容器实例。Azure虚拟机包含2个CPU、8GB内存和120GB磁盘。为了提高部署的容器的安全性，Azure在AKS中提供了pod安全策略的最佳实践，通过在<code>yaml</code>文件中设置<code>runAsUser:1000</code>，以非root用户的身份运行容器，并通过设置<code>allowPrivilegeEscalation: false</code>，拒绝特权升级。然而，它仍然增加了两种能力，即<code>CAP_NET_ADMIN</code>和<code>CAP_SYS_TIME</code>，并且没有强制执行<code>seccomp</code>。与AWS的设置一样，我们对AKS上的容器采取了更严格的安全策略。除了最佳实践建议（即非root用户和不允许特权升级），我们以非root用户运行AKS容器，放弃所有功能，启用所有的<code>namespace</code>和<code>cgroup</code>，并使用<code>docker seccomp</code>配置文件。来阻止50多个敏感的系统调用。我们对<code>attacker-container</code>和<code>victim-container</code>应用相同的安全策略。</p>
</li>
<li><p>Google Cloud</p>
<p>对于容器服务，我们选择Kubernetes并使用谷歌Kubernetes Engine (GKE)在谷歌计算引擎实例上部署两个容器实例。我们使用的谷歌计算引擎(GCE)实例包含4个cpu、16gb内存和100gb SSD。更具体地说，我们应用一个GCE实例，并基于该GCE实例上的常规运行时部署两个容器(即<code>attacker-container</code>和<code>victim-container</code>)。</p>
<p>对于容器部署，我们遵循GKS容器设置向导。谷歌Cloud提供了操作容器的最佳实践，建议避免使用特权容器。因此，在yaml配置文件的securityContext中，我们不允许特权升级，以非特权用户运行容器，并删除所有功能。GKS设置向导默认启用6个<code>namespace</code>和13个<code>cgroup</code>。此外，我们应用docker默认的<code>seccomp</code>配置文件来过滤敏感的系统调用。</p>
<p>此外，GKE还提供了谷歌的安全容器运行时<code>- gvisor</code>，它利用名为<code>Sentry</code>的用户空间内核为来自应用程序的系统调用提供服务。哨兵调用大约50个主机系统调用，根据需要提供服务。<code>gVisor</code>被认为是容器的安全沙盒运行时。对于基于<code>gVisor</code>的容器部署，其所有安全设置(包括非特权用户、删除功能)都与GKE docker运行时设置相同。</p>
</li>
<li><p>Alibaba Cloud</p>
<p>在容器服务方面，阿里云提供了弹性容器实例、Kubernetes容器服务、容器注册和阿里云服务Mesh。我们使用Kubernetes的容器服务在一个弹性计算服务(ECS)实例上部署两个容器实例。ECS实例包含4个cpu、16gb内存和120gb SSD盘。对于容器安全性，我们遵循容器服务部署的官方指南，该指南通过将<code>runAsUser</code>设置为1000来使用非根用户运行容器。但是，它并不禁止特权升级，也不强制执行<code>seccomp</code>和<code>SELinux</code>。</p>
<p>我们采取了与以往相同的更强有力的安全政策。我们在非根用户中运行容器，删除所有功能，启用所有<code>namespace</code>和<code>cgroup</code>，并使用<code>docker seccomp</code>配置文件来阻止敏感的系统调用。我们对<code>attacker-container</code>和<code>victim-container</code>应用相同的安全策略。</p>
</li>
</ul>
<h2 id="Selection-of-Abstract-Resources"><a href="#Selection-of-Abstract-Resources" class="headerlink" title="Selection of Abstract Resources"></a>Selection of Abstract Resources</h2><p>为了进行攻击，我们需要选择有意义的抽象资源。为了演示抽象资源攻击的有效性，我们希望选择影响操作系统服务各个方面的抽象资源，包括进程管理、内存管理、存储管理和IO管理。</p>
<p>因此，我们首先根据它们的声明位置将所有标识的资源分为这四类，即用于进程、内存、存储和IO管理的资源。然后，我们根据我们的领域知识从每个类别中选择至少一个资源，即我们知道资源耗尽的影响。</p>
<p>最终，我们选择了涵盖所有四个方面的7个抽象资源，。资源名称列在表的第二列中。在所选的抽象资源中，基于访问分析识别出<code>PID idr</code>、<code>dirty ratio</code>、<code>inode</code>、<code>netns_ct-&gt;count</code>、<code>random entropy</code>个，基于配置分析识别出<code>nr_files</code>、<code>pty_count</code> 2个，如表第三列所示。我们还在表的第四列中列出了资源消耗函数，在表的最后一列中列出了用于触发攻击的系统调用。</p>
<p><img src="/2023/03/30/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%20Demons-in-the-Shared-Kernel-Abstract-Resource-Attacks-Against/Resource.png"></p>
<h2 id="Attacking-Results-on-Cloud-Platforms"><a href="#Attacking-Results-on-Cloud-Platforms" class="headerlink" title="Attacking Results on Cloud Platforms"></a>Attacking Results on Cloud Platforms</h2><p>如前一节所述，我们为我们提出的攻击设置了5个测试环境，包括本地、AWS、Azure、谷歌云和阿里云。对于每个测试环境，我们设置了两个具有严格安全策略的容器，作为<code>attacker-container</code>和<code>victim-container</code>。<code>attacker-container</code>针对某些抽象资源发起攻击。我们使用上述7个选定的抽象资源来发起攻击。在<code>victim-container</code>和主机上都运行一个基准测试，以测量它们在抽象资源攻击下的性能下降。结果如表所示。</p>
<ul>
<li><p><code>PID idr</code>攻击。<code>PID idr</code>攻击及其根源已在§3.2.1中详细介绍。针对厂商的PID攻击，所有受害容器，甚至在Local、AWS、Azure和谷歌测试环境中的主机都不能<code>fork</code>新的进程。<code>victim-container</code>甚至会被驱逐。阿里云不容易受到PID攻击。</p>
</li>
<li><p><code>dirty ratio</code>攻击。<code>dirty ratio</code>攻击已经在§3.3.1中讨论过。如果没有攻击，则认为IO性能为100%。在<code>dirty ratio</code>攻击下，受害容器在AWS、Azure和阿里云上的IO性能分别下降到6.3%、1.2%和6.7%。更糟糕的是，主机也容易受到这种攻击，其IO性能在AWS上下降到8.3%，在阿里云上下降到8.6%。这里MS Azure不提供对主机的任何访问，因此我们无法获得Azure主机IO性能。谷歌云不容易受到<code>dirty ratio</code>攻击。</p>
</li>
<li><p><code>inode</code>攻击。在<code>inode</code>攻击中，受害者容器不断分配<code>inode</code>结构。不幸的是，<code>mount namespace</code>没有隔离<code>inode</code>。Linux内核都不提供任何与<code>inode</code>相关的<code>cgroup</code>。结果，该分区上的所有<code>inode</code>都被耗尽。所有消耗<code>inode</code>的操作都会失败，包括来自<code>victim-container</code>或主机的操作。在我们的实验中，阿里云很容易受到<code>inode</code>攻击。<code>victim-container</code>甚至会被驱逐。此外，主机也不能创建任何新文件。</p>
</li>
<li><p><code>nr_files</code>攻击。<code>nr_files</code>攻击已经在§3.4.1中讨论过。<code>nr_files</code>由所有容器全局共享。没有<code>namespace</code>或<code>cgroup</code>来限制它的使用。当<code>nr_files</code>配额耗尽时，各种操作都会失败，包括打开文件、执行新程序、创建管道、创建套接字和创建计时器，因为Linux中的所有东西都是文件。我们的实验表明，所有排名前4的供应商都容易受到<code>nr_files</code>攻击。</p>
</li>
<li><p><code>pty_count</code>攻击。<code>pty_count</code>攻击已经在§3.5.1中讨论过，它会耗尽所有开放的伪终端配额。这将导致所有需要打开新的伪终端的操作失败，如SSH连接等。不幸的是，所有前4个供应商都容易受到<code>pty_count</code>攻击。</p>
</li>
<li><p><code>netns_ct-&gt;count</code>攻击。Linux内核中的<code>Netfilter</code>提供了连接跟踪功能，可以跟踪所有的逻辑网络连接。而总连接数是有限制的，由<code>struct netns_ct-&gt;count</code>来计数。主机和容器都需要维护连接。尽管容器位于不同的<code>net namespace</code>中，但它们的所有连接都需要使用<code>init_net.ct</code>。主机的<code>init net namespace</code>的计数。因此，如果在短时间内产生大量的TCP连接，就会消耗掉<code>init_net.ct</code>的所有配额。计数，导致<code>Netfilter</code>故障。在我们的实验中，<code>attacker-container</code>可以耗尽<code>init_net.ct</code>。数秒内计数，导致随机丢包。同样，前4个供应商的所有环境都容易受到结构体<code>netns_ct-&gt;count</code>攻击。</p>
</li>
<li><p><code>random entropy</code>攻击。在Linux内核中，每次读取<code>/dev/random</code>都会消耗<code>random entropy</code>。每当<code>random entropy</code>下降到阈值以下时，Linux内核就会阻塞对<code>/dev/random</code>的读取操作，并等待<code>entropy</code>增加。</p>
<p>由于没有<code>namespace</code>或<code>cgroup</code>来隔离<code>random entropy</code>，<code>attacker-container</code>很容易通过反复读取<code>/dev/random</code>来消耗所有的<code>random entropy</code>，从而导致良性的读取阻塞。最新的Linux内核v5.10通过将<code>/dev/random</code>读重定向到<code>/dev/urandom</code>修复了这个问题。然而，Azure和阿里云都容易受到这种攻击。</p>
</li>
</ul>
<p><img src="/2023/03/30/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%20Demons-in-the-Shared-Kernel-Abstract-Resource-Attacks-Against/result.png"></p>
<h2 id="Attacking-gVisor"><a href="#Attacking-gVisor" class="headerlink" title="Attacking gVisor"></a>Attacking gVisor</h2><p>我们还对gVisor进行了7种资源攻击。为了建立gVisor环境，我们在谷歌Kubernetes Engine (GKE)中选择runsc而不是runc作为容器运行时，如§5.1所述。其中<code>nr_files</code>攻击和<code>netns_ct-&gt;count</code>攻击两种攻击在<code>gVisor</code>环境下仍然有效。在接下来的文章中，我们将分析为什么这两种攻击可以在<code>gVisor</code>上工作。</p>
<p>对于<code>nr_files</code>, gVisor使用<code>Sentry</code>为系统调用服务，而Gofer为<code>Sentry</code>处理不同类型的IO。<code>Sentry</code>拦截来自容器的<code>open syscall</code>并将请求发送给Gofer。在另一边，Gofer通过调用主机操作系统的<code>openat</code>系统调用来处理该请求。最终，主机操作系统上的<code>openat</code>系统调用触发了<code>alloc_empty_file</code>函数，它消耗了<code>nr_files</code>。通过这种方式，gVisor的攻击者能够耗尽主机的nr_files。<br>对于<code>netns_ct-&gt;count</code>，<code>Sentry</code>拦截连接系统调用，并使用自己的网络堆栈将数据包转发到主机中创建的veth-peer网卡。<code>vth -peer</code>连接到主机中的虚拟网桥。当网络帧通过虚拟网桥转发时，主机上的netfilter被触发调用<code>nf_conntrack_alloc</code>函数，该函数消耗<code>netns_ct-&gt;count</code>。因此，gVisor中的攻击者仍然可以耗尽主机的<code>netns_ct-&gt;count</code>。</p>
<h2 id="Summary-1"><a href="#Summary-1" class="headerlink" title="Summary"></a>Summary</h2><p>对于自部署的共享内核容器环境，其中两个易受6次攻击，一个易受5攻击，另一个易受4攻击。令人惊讶的是，gVisor运行时也容易受到两种攻击——<code>nr_files</code>攻击和<code>netns_ct-&gt;count</code>攻击。我们已经向所有四个供应商报告了这些攻击。他们都确认了问题存在于他们的共享内核容器环境中。</p>
<p>尽管顶级供应商使用虚拟机来隔离不同租户的容器，但由于几个原因，抽象资源攻击仍然是可行的。首先，正如在Linux、FreeBSD和Fuchsia上所演示的，抽象资源攻击是操作系统级虚拟化所固有的，因此是一种广泛的攻击类型。其次，没有经验的用户可能不了解共享内核的风险，可能会使用容器进行sand-boxing。我们的论文将有助于提高对风险的认识。第三，即使在同一个租户中，竞争的团队也可能通过利用抽象资源来攻击对方。因此，监控和减轻此类攻击仍然是必要的。</p>
<h1 id="Mitigation-Discussions"><a href="#Mitigation-Discussions" class="headerlink" title="Mitigation Discussions"></a>Mitigation Discussions</h1><p>在本文中，我们揭示了除了物理资源，容器还共享底层运行内核的抽象资源。这些抽象资源很容易被攻击，后果很严重。在下面，我们给出了多种策略来降低抽象资源带来的风险。</p>
<ul>
<li><p>Using PAM for per-user quota restrictions</p>
<p>正如正如第4.2节中提到的，Linux内核提供了允许用户加载用户定制的PAM的接口。PAM能够限制18种资源，其中5种为抽象资源，包括<code>maxlogin/maxsyslogins</code>、<code>nofile</code>、<code>nproc</code>和<code>sigpending</code>。从我们与云计算供应商的沟通中，我们不知道有任何云计算供应商采用PAM。因此，我们建议对某些抽象资源的限制使用PAM。§4.2节提到的，Linux内核提供了允许用户加载用户定制的PAM的接口。<code>PAM</code>能够限制18种资源，其中5种为抽象资源，包括<code>maxlogin/maxsyslogins</code>、<code>nofile</code>、<code>nproc</code>和<code>sigpending</code>。从我们与云计算供应商的沟通中，我们不知道有任何云计算供应商采用PAM。因此，我们建议对某些抽象资源的限制使用PAM。</p>
</li>
<li><p>Using VM for strong isolation</p>
<p>对于安全关键型应用程序，我们建议不要使用多租户容器环境。更强的隔离方案，例如基于虚拟机的虚拟化，是更可取的。</p>
</li>
<li><p>Using Monitoring Tools</p>
<p>我们建议使用Kubernetes集群的监控工具，如Falco，来监控容器的资源消耗。对于敏感的抽象资源(如<code>nr_files</code>和<code>inode</code>)，用户应该自定义自己的规则来监视系统中特定的资源消耗。</p>
</li>
<li><p>Improving current isolation design</p>
<p>对于现有的<code>namespace</code>，如<code>PID namespace</code>，由于映射到根<code>namespace</code>的设计，无法防御资源耗尽攻击。如§3.2.2所述，Linux内核在根<code>PID namespace</code>中为在其他<code>PID namespace</code>中分配的任何idr分配一个额外的idr。因此，根PID namespace仍然是全局共享的。攻击者仍然可以很容易地耗尽根<code>PID namespace</code>中的PID，从而导致DoS攻击。出于类似的原因，即使被<code>NET namespace</code>隔离，<code>nf-conntrack</code> 数 <code>netns_ct-&gt;count</code>也可能被攻击。因此，Linux社区需要重新审视<code>namespace</code>的设计，消除<code>namespace</code>依赖关系以提高隔离性。</p>
</li>
<li><p>New kernel containment mechanisms</p>
<p>Linux内核社区和容器社区需要投入更多精力来保护抽象资源。实际上，我们已经向Docker安全团队报告了这个问题。反馈是“Linux容器只能使用可用的内核隔离机制。如果没有内核机制来控制限制，容器就不能做任何事情来限制它”。因此，我们首先需要对所有容器共享的抽象资源进行彻底的分析，以便我们能够理解，更重要的是，清除它们的数据依赖关系。这需要全面的内核领域知识和大量的内核代码更改。而且，Linux内核最初并不是为支持操作系统级虚拟化而设计的。它的资源隔离和遏制是不完整的。因此，需要新的<code>namespace</code>和<code>cgroup</code>。</p>
</li>
<li><p>More restrictive system call blocking</p>
<p>从容器方面来看，目前，即使执行了<code>seccomp</code>，容器中的应用程序仍然可以访问大约250个系统调用。在我们了解这些系统调用的数据依赖性之前，建议执行更严格的<code>seccomp</code>配置文件来阻止更多不必要的系统调用。容器用户可以使用技术来获得更严格的<code>seccomp</code>配置文件，以减少潜在的抽象资源攻击的可能性</p>
</li>
</ul>
<h1 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h1><h2 id="Virtualization-Techniques"><a href="#Virtualization-Techniques" class="headerlink" title="Virtualization Techniques"></a>Virtualization Techniques</h2><p>在云环境中有两种主流的虚拟化技术，基于vm的虚拟化和OS-level虚拟化。与基于vm的虚拟化相比，OS-level虚拟化越来越流行，因为它可以通过轻量级虚拟化实现完整的应用程序功能。为了充分了解性能优势，研究人员进行了一系列研究。Felter等人表明，通过使用一组涵盖多个资源的基准测试，Docker在所有情况下都可以获得比KVM更好的性能。Joy等人在性能和可伸缩性方面对Linux容器和虚拟机进行了比较。Zhang等人的研究表明，容器在大数据环境中具有比虚拟机更好的性能。</p>
<p>所有这些工作都表明，操作系统级虚拟化比传统的基于虚拟机的虚拟化具有更好的性能。然而，他们都没有注意到底层内核抽象资源的潜在影响。本文揭示了抽象资源引入的新的攻击面。</p>
<h2 id="Resource-Isolation"><a href="#Resource-Isolation" class="headerlink" title="Resource Isolation"></a>Resource Isolation</h2><p>Linux使用功能来禁止没有特定功能的进程访问相应类型的资源实例。</p>
<p>研究人员提出了基于Linux功能的方法，如Wedge ， Capsicum和ACES。这些工作执行更细粒度的能力控制，以减轻内存损坏攻击。然而，他们不能防御我们的DoS攻击，耗尽可访问的共享资源。</p>
<p>内存地址空间隔离是一种典型的资源空间隔离方案，避免内存地址资源耗尽。Linux命名空间隔离了§2.1中列出的8种资源。这些方案只能隔离有限类型的资源。资源容器建议扩展单片内核，隔离系统资源，在线程级对资源进行划分，类似于控制组。由于性能开销很大，使用资源容器来保护所有抽象资源是不切实际的。EdgeOS为边缘云部署了强隔离的操作系统。然而，采用没有硬件支持的微内核会比单片内核引入更多的开销。Faasm使用软件故障隔离(SFI)进行内存隔离，而在无服务器计算中使用名称空间隔离网络资源空间。然而，大多数共享资源仍然暴露在DoS攻击的威胁之下。</p>
<h2 id="Container-Security"><a href="#Container-Security" class="headerlink" title="Container Security"></a>Container Security</h2><p>除了资源隔离之外，还有对容器安全性的研究。Gao等人发现，可以利用&#x2F;proc或&#x2F;sys的信息泄露，发动电源攻击。而同一研究小组还进行了5次攻击，产生带外工作负载，以打破Linux控制组的资源约束。但它们主要针对信息泄露问题或攻击CPU、IO等物理资源，而不是抽象资源。</p>
<p>Lin等人表明容器不能隔离内核漏洞。另一项工作使用静态分析来分析Docker的代码，以找到漏洞和修补代码之间的差异。然而，这些工作主要针对现有的漏洞和利用。相反，我们的工作引入了针对共享抽象资源的新攻击。</p>
<p>此外，还有加固集装箱的工作。Lei等人提出了一种名为SPEAKER的容器安全机制，以减少应用程序在容器中可用的系统调用。Sun等人开发了为每个容器提供安全策略隔离的安全namespace。另一项工作使用Intel SGX保护容器，它提供了一个低性能开销的小型可信计算基础。Brady等人实现了容器图像的安全评估系统。然而，所有这些作品中的容器仍然依赖于内核提供各种服务，因此仍然容易受到抽象资源攻击。</p>
<h1 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h1><p>在本文中，我们揭示了共享内核在操作系统级虚拟化中引入的一种新的攻击面。这些容器直接或间接地共享成千上万的抽象资源，这些资源很容易被耗尽，从而导致对其他容器的DoS攻击。</p>
<p>为了显示限制抽象资源的重要性，我们进行了抽象资源攻击，针对操作系统内核的不同方面的抽象资源。结果表明，攻击抽象资源具有很强的实用性和关键性。</p>
<p>抽象资源本身就难以包含。为了了解这些攻击面，我们首先进行了一次系统分析，以识别Linux内核中易受攻击的抽象资源。我们的工具成功检测了501个动态触发的抽象资源，从中选取了7个，并在排名前4的云供应商的自部署共享内核容器环境中进行了攻击实验。结果表明，所有环境都容易受到我们的攻击。为了降低风险，我们为容器用户和开发人员提供了一些建议。</p>
<h1 id="My"><a href="#My" class="headerlink" title="My"></a>My</h1><h2 id="硬件虚拟化和OS-level虚拟化"><a href="#硬件虚拟化和OS-level虚拟化" class="headerlink" title="硬件虚拟化和OS-level虚拟化"></a>硬件虚拟化和OS-level虚拟化</h2><p>虚拟化技术通常可以分为两大类：操作系统级虚拟化（OS-level virtualization）和硬件虚拟化（hardware virtualization）。这两者的主要区别在于虚拟化层的位置以及资源分配方式。</p>
<h3 id="操作系统级虚拟化（OS-level-virtualization"><a href="#操作系统级虚拟化（OS-level-virtualization" class="headerlink" title="操作系统级虚拟化（OS-level virtualization)"></a>操作系统级虚拟化（OS-level virtualization)</h3><p>操作系统级虚拟化是一种轻量级虚拟化技术，它允许在单个操作系统内运行多个独立的、隔离的应用程序或服务。在这种方式下，所有虚拟实例共享相同的操作系统内核，但每个实例拥有自己的文件系统、进程、网络等资源。</p>
<p>详细说明：</p>
<ol>
<li>资源分配：操作系统级虚拟化使用容器（Container）技术将系统资源（如CPU、内存、磁盘、网络等）划分给各个虚拟实例。容器之间相互隔离，互不干扰。</li>
<li>性能：操作系统级虚拟化具有较低的性能开销，因为所有虚拟实例共享相同的操作系统内核，避免了多个操作系统之间的资源竞争。</li>
<li>灵活性：操作系统级虚拟化支持的操作系统类型受限于宿主机操作系统，因此在跨平台方面的灵活性较差。</li>
</ol>
<p>实现方式：</p>
<ol>
<li>Linux：LXC（Linux Containers）、Docker</li>
<li>FreeBSD：Jails</li>
<li>Solaris：Zones&#x2F;Containers</li>
</ol>
<h3 id="硬件虚拟化（Hardware-virtualization）"><a href="#硬件虚拟化（Hardware-virtualization）" class="headerlink" title="硬件虚拟化（Hardware virtualization）"></a>硬件虚拟化（Hardware virtualization）</h3><p>硬件虚拟化是一种全面的虚拟化技术，它允许在单个物理机器上运行多个独立的、完全隔离的操作系统实例。在这种方式下，虚拟化层位于操作系统和硬件之间，为每个虚拟机提供一个虚拟硬件环境。</p>
<p>详细说明：</p>
<ol>
<li>资源分配：硬件虚拟化使用虚拟机（Virtual Machine）技术将系统资源（如CPU、内存、磁盘、网络等）划分给各个虚拟实例。虚拟机之间相互隔离，互不干扰。</li>
<li>性能：硬件虚拟化具有较高的性能开销，因为每个虚拟机需要运行独立的操作系统内核，导致资源竞争和虚拟化开销。</li>
<li>灵活性：硬件虚拟化支持运行不同类型的操作系统，具有较强的跨平台灵活性。</li>
</ol>
<p>实现方式：</p>
<ol>
<li>基于软件的虚拟化：VMware Workstation、VirtualBox</li>
<li>基于硬件的虚拟化：Intel VT-x、AMD-V</li>
<li>虚拟化管理器（Hypervisor）：VMware ESXi、KVM（Kernel-based Virtual Machine）、Microsoft Hyper-V、Xen</li>
</ol>
<p>总结起来，操作系统级虚拟化和硬件虚拟化的主要区别在于虚拟化层的位置以及资源分配方式。操作系统级虚拟化通过共享相同的操作系统内核实现较低的性能开销，但跨平台灵活性较差；硬件虚拟化允许运行多个独立的操作系统实例，具有较强的跨平台灵活性，但性能开销较高。</p>
<h2 id="LLVM"><a href="#LLVM" class="headerlink" title="LLVM"></a>LLVM</h2><p>LLVM（Low Level Virtual Machine）是一个编译器基础设施项目，它提供了一系列模块化和可重用的编译器组件和工具链。LLVM的设计目标是为各种编程语言提供一个通用的中间表示（Intermediate Representation，IR），以及一套用于优化、分析和生成机器代码的编译器后端。LLVM项目包括一些子项目，如Clang（C、C++和Objective-C的编译器前端）和LLDB（一个调试器）。</p>
<p>LLVM的核心组件包括：</p>
<ol>
<li><p><strong>LLVM IR</strong>：LLVM中间表示是一种低级别、类型化、平台无关的编程语言，用于表示程序的结构和行为。LLVM IR既可以表示为人类可读的文本，也可以表示为二进制格式。</p>
</li>
<li><p><strong>编译器前端</strong>：编译器前端将源代码（如C、C++、Rust等）解析成LLVM IR。Clang是LLVM最著名的编译器前端，用于处理C、C++和Objective-C语言。其他语言也有针对LLVM的编译器前端。</p>
</li>
<li><p><strong>优化器</strong>：LLVM提供了一系列通用的代码优化和转换通道，这些通道可以在LLVM IR上进行操作，例如：常量折叠、死代码消除、循环不变式代码移动等。优化器可以根据需要配置和组合，以生成高度优化的代码。</p>
</li>
<li><p><strong>编译器后端</strong>：编译器后端将优化后的LLVM IR转换为特定架构的机器代码。LLVM支持多种目标平台，包括x86、ARM、MIPS、WebAssembly等。编译器后端还负责处理调用约定、寄存器分配和指令调度等底层细节。</p>
</li>
</ol>
<p>LLVM的优势在于其模块化、可扩展和可重用的设计。这使得LLVM可以很容易地支持新的编程语言和硬件架构，而不需要重新实现整个编译器。这也使得LLVM成为了许多编程语言（如Rust、Swift和Julia）和平台（如WebAssembly、GPUs和FPGAs）的编译器基础设施的首选。</p>
<h2 id="Linux-cgroup的组织和结构"><a href="#Linux-cgroup的组织和结构" class="headerlink" title="Linux cgroup的组织和结构"></a>Linux cgroup的组织和结构</h2><p>cgroup 是一种用于限制和控制进程资源使用的实用工具：</p>
<ol>
<li><p><strong>限制资源</strong>：Linux cgroup 的主要目的是限制进程使用的资源，如 CPU 使用率、内存、磁盘 I&#x2F;O 等。这有助于确保系统上的各个进程不会过度消耗资源，从而影响其他进程或整个系统的性能。</p>
</li>
<li><p><strong>控制组内进程</strong>：cgroup 负责管理和控制组内所有进程的资源使用。这意味着你可以将一组进程组织在一个 cgroup 中，并对整个组施加资源限制，而不是单独设置每个进程的限制。</p>
</li>
<li><p><strong>树状结构</strong>：cgroup 的组织方式是树状结构，其中每个节点（cgroup）可以包含若干子节点（子 cgroup）。这种结构允许你对资源使用进行分层管理，通过在不同层次施加不同的限制，可以更灵活地控制进程资源使用。</p>
</li>
<li><p><strong>子节点和父节点的资源关系</strong>：在 cgroup 树状结构中，子 cgroup 的资源限制包括其父 cgroup 的资源限制。这意味着子 cgroup 不能单独设置超出其父 cgroup 限制的资源使用。这有助于维护整体资源限制的一致性，并确保子 cgroup 不会因过度消耗资源而影响其父 cgroup 或整个系统。</p>
</li>
<li><p><strong>递归强制执行</strong>：cgroup 树结构中的资源限制是递归强制执行的。这意味着一个 cgroup 的资源使用限制将受到其所有祖先（父、祖父等）cgroup 限制的约束。这可以确保在整个 cgroup 树结构中，资源限制得到恰当的执行和遵守。</p>
</li>
</ol>
<p>总之，Linux cgroup 是一种用于限制和管理进程资源使用的实用工具。它采用树状结构来组织进程，允许分层管理资源，并通过递归强制执行来确保资源限制得到遵守。</p>
<h2 id="fork炸弹和idr"><a href="#fork炸弹和idr" class="headerlink" title="fork炸弹和idr"></a>fork炸弹和idr</h2><h3 id="fork炸弹"><a href="#fork炸弹" class="headerlink" title="fork炸弹"></a>fork炸弹</h3><p>Fork 炸弹是一种拒绝服务攻击（DoS攻击），其目的是通过创建大量子进程耗尽系统资源，从而导致系统崩溃或无法响应。攻击者可以编写一个简单的程序，使其反复调用 fork() 系统调用，每次调用都会创建一个新的子进程。这些子进程可能会继续创建更多子进程，从而导致进程数量迅速增加。这种攻击方法也被称为“逻辑炸弹”或“蠕虫炸弹”。</p>
<p>在 Linux 系统中，fork() 系统调用用于创建一个新进程，它是当前进程的一个副本。新进程（子进程）继承了父进程的资源（如打开的文件描述符、内存映射等），并从父进程的当前执行点开始执行。子进程拥有自己的独立地址空间和资源，并分配一个唯一的进程 ID。</p>
<h3 id="idr"><a href="#idr" class="headerlink" title="idr"></a>idr</h3><p>在 Linux 内核中，<code>IDR（ID Radix Tree）</code>是一种用于管理和查找整数类型对象标识符（如进程 ID、文件描述符等）的数据结构。<code>IDR</code> 是一种基于基数树（<code>radix tree</code>）的高效数据结构，可以快速查找、添加和删除 ID。<code>IDR</code> 用于分配唯一的 ID 给内核对象，如进程、线程、文件等，以便在内核中进行跟踪和管理。</p>
<p><code>fork</code> 炸弹会通过创建大量子进程来耗尽所有可用的进程 ID，从而导致系统无法创建新的进程。这可能会导致系统性能下降、响应缓慢甚至崩溃。为了防止这类攻击，系统管理员可以通过设置进程数资源限制（如使用 <code>ulimit</code> 命令）或在容器中使用<code>cgroup</code> 限制进程数来保护系统。</p>
<h3 id="clone系统调用"><a href="#clone系统调用" class="headerlink" title="clone系统调用"></a>clone系统调用</h3><p><code>clone()</code> 系统调用是 Linux 中用于创建进程和线程的一个底层函数。与 <code>fork()</code> 相比，<code>clone()</code> 提供了更多的选项和灵活性，因为它允许程序员指定哪些资源应该在父进程和新创建的子进程之间共享。这使得 <code>clone()</code> 适用于创建轻量级的线程以及新的独立进程。</p>
<p><code>clone()</code> 系统调用的原型如下：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">clone</span><span class="params">(<span class="type">int</span> (*fn)(<span class="type">void</span> *), <span class="type">void</span> *child_stack, <span class="type">int</span> flags, <span class="type">void</span> *arg, ...)</span>;</span><br></pre></td></tr></table></figure>

<p>参数说明：</p>
<ul>
<li><code>fn</code>：一个函数指针，指向子进程或线程开始执行的函数。子进程或线程运行结束后，这个函数应该返回一个整数值，用于表示退出状态。</li>
<li><code>child_stack</code>：指向子进程或线程的栈空间的指针。子进程或线程在执行过程中将使用这个栈空间。</li>
<li><code>flags</code>：用于指定子进程或线程的行为和资源共享的位掩码。这些标志包括 <code>CLONE_VM</code>（共享内存空间）、<code>CLONE_FS</code>（共享文件系统信息）、<code>CLONE_FILES</code>（共享文件描述符表）等。通过组合这些标志，程序员可以精细控制子进程或线程的行为。</li>
<li><code>arg</code>：传递给 <code>fn</code> 函数的参数。通常，它是一个指向某种结构或数据的指针。</li>
</ul>
<p><code>clone()</code> 系统调用的返回值在父进程和子进程中有所不同。在父进程中，<code>clone()</code> 返回新创建的子进程或线程的进程 ID（PID）。在子进程中，<code>clone()</code> 返回 0。如果创建失败，<code>clone()</code> 返回 -1，并设置相应的错误码。</p>
<p><code>clone()</code> 系统调用的使用相对复杂，通常不直接在应用程序中使用。在实践中，程序员更倾向于使用更高级别的库函数，如 <code>pthread_create()</code>（用于创建线程）或 <code>fork()</code>（用于创建进程）。这些库函数在内部使用 <code>clone()</code> 系统调用来完成进程和线程的创建。</p>
<h2 id="脏内存"><a href="#脏内存" class="headerlink" title="脏内存"></a>脏内存</h2><p>脏内存（Dirty Memory）是计算机内存管理中的一个概念，指的是已经被修改过但尚未写回到持久存储（如硬盘）的内存数据。在操作系统和应用程序中，内存（RAM）被用作缓存，以加速对数据的访问。与磁盘相比，内存访问速度要快得多，因此将数据缓存在内存中可以提高系统性能。</p>
<p>当一个程序或操作系统修改了内存中的数据，与磁盘上的原始数据不再一致时，这部分内存就被称为 “脏内存”。脏内存中的数据最终需要写回到磁盘，以确保数据的一致性和持久性。以下是脏内存产生的一些常见场景：</p>
<ol>
<li><p><strong>文件系统缓存</strong>：操作系统通常会将磁盘上的文件数据缓存在内存中，以提高文件访问速度。当一个程序修改了文件内容时，内存中的缓存数据变为脏内存。这些脏内存数据最终需要同步回磁盘，以确保文件在磁盘上的内容与内存中的内容一致。</p>
</li>
<li><p><strong>数据库缓存</strong>：数据库系统经常使用内存来缓存数据库表和索引中的数据。当数据库事务修改了表中的数据时，相应的内存缓存数据也会变为脏内存。这些脏内存数据需要在适当的时机写回到磁盘，以确保数据的一致性和持久性。</p>
</li>
<li><p><strong>虚拟内存管理</strong>：在虚拟内存管理中，操作系统通过将内存中的数据与磁盘上的交换空间（或页面文件）进行交换，来模拟更大的内存空间。当操作系统需要将内存中的数据交换出去时，如果这部分数据是脏内存，操作系统需要先将其写回到磁盘，然后才能将其交换出去。</p>
</li>
</ol>
<p>操作系统通常会使用一些策略来平衡脏内存的处理和系统性能。例如，Linux 内核通过监控脏内存占比（<code>dirty ratio</code>），在必要时触发后台线程将脏内存同步到磁盘。这样可以在提高系统性能的同时，确保数据的一致性和持久性。</p>
<h2 id="Linux处理脏内存"><a href="#Linux处理脏内存" class="headerlink" title="Linux处理脏内存"></a>Linux处理脏内存</h2><p> Linux 内核如何处理脏内存（即已修改但尚未同步到磁盘的内存）的过程。在 Linux 内核中，<code>dirty_throttle_control</code> 结构体用于管理和控制脏内存。结构体中的 <code>dirty</code> 字段表示整个内核空间的脏内存占比（<code>dirty ratio</code>）。</p>
<p>当 <code>dirty</code> 值过高时，内核会唤醒后台线程（例如 pdflush、flusher 或 kswapd），将脏内存同步到磁盘。这有助于确保数据的一致性和持久性，防止意外丢失。</p>
<p>然而，如果 <code>dirty</code> 值太高，内核会阻塞 <code>write_back</code> 操作。这意味着内核将所有写操作都转换为 <code>write_through</code> 操作，从而降低写性能。接下来，我们解释 <code>write_back</code> 和 <code>write_through</code> 之间的区别：</p>
<ul>
<li><p><strong>write_back</strong>：在 <code>write_back</code> 操作中，数据首先写入缓存（例如 CPU 缓存或文件系统缓存）。一旦数据被写入缓存，操作就被认为是完成的，即使数据尚未同步到磁盘。在后台，脏数据会在适当的时机被刷新到磁盘。<code>write_back</code> 的优势在于它可以提供较高的写性能，因为写操作可以立即返回，而不需要等待磁盘同步。</p>
</li>
<li><p><strong>write_through</strong>：在 <code>write_through</code> 操作中，数据同时写入缓存和磁盘。写操作在数据被写入磁盘之前不会被认为已完成。虽然这可以确保数据的一致性和持久性，但 <code>write_through</code> 的性能通常低于 <code>write_back</code>，因为它需要等待磁盘同步。</p>
</li>
</ul>
<p>总之，这段话描述了 Linux 内核如何在处理脏内存时在性能和数据一致性之间寻求平衡。当脏内存占比过高时，内核会采取措施降低写性能，以确保数据的一致性和持久性。</p>
<h2 id="Linux伪终端"><a href="#Linux伪终端" class="headerlink" title="Linux伪终端"></a>Linux伪终端</h2><p>Linux 内核使用 <code>/dev/ptmx</code>（主设备）和 <code>/dev/pts</code>（从设备）来实现伪终端（pseudo-terminal，简称 pty）。伪终端是一种特殊的终端设备，它不直接连接到物理设备，而是通过软件来模拟终端的输入和输出。伪终端广泛应用于远程登录（如 SSH）、终端模拟器（如 xterm）和其他需要模拟终端行为的场景。</p>
<p>以下是关于伪终端和 <code>/dev/ptmx</code> 以及 <code>/dev/pts</code> 的一些详细信息：</p>
<ol>
<li><p><strong>主设备（&#x2F;dev&#x2F;ptmx）</strong>：<code>/dev/ptmx</code> 是一个字符设备文件，用于创建伪终端的主设备。当一个进程（如 SSH 服务器或终端模拟器）需要创建一个新的伪终端时，它会打开 <code>/dev/ptmx</code> 设备文件。内核会为这个进程分配一个未使用的伪终端，并返回一个指向伪终端主设备的文件描述符。主设备用于管理伪终端，如接收从设备的输入数据、向从设备发送输出数据等。</p>
</li>
<li><p><strong>从设备（&#x2F;dev&#x2F;pts）</strong>：<code>/dev/pts</code> 是一个虚拟文件系统（通常挂载在 <code>/dev/pts</code> 目录下），用于存储伪终端的从设备。当一个伪终端被创建时，内核会在 <code>/dev/pts</code> 目录下为其从设备分配一个唯一的编号（如 <code>/dev/pts/0</code>、<code>/dev/pts/1</code> 等）。从设备用于模拟终端的输入和输出操作，如读取用户输入、显示文本输出等。通常情况下，从设备会被分配给另一个进程（如 shell），以便它可以与主设备进行通信。</p>
</li>
</ol>
<p>通过主设备和从设备的交互，伪终端实现了终端模拟器和其他类似程序与 shell、远程会话等之间的通信。这种抽象使得伪终端可以在不依赖于特定硬件的情况下，提供与物理终端类似的功能。</p>
<h2 id="FreeBSD和Fuchsia"><a href="#FreeBSD和Fuchsia" class="headerlink" title="FreeBSD和Fuchsia"></a>FreeBSD和Fuchsia</h2><p><code>FreeBSD</code>和<code>Fuchsia</code>是两种不同的操作系统。下面我们分别详细解释这两个操作系统。</p>
<h3 id="FreeBSD"><a href="#FreeBSD" class="headerlink" title="FreeBSD"></a>FreeBSD</h3><p>FreeBSD是一个类Unix的开源操作系统，它基于创建Unix的Berkeley Software Distribution（BSD）的源代码。FreeBSD成立于1993年，是BSD家族的一个成员，与NetBSD和OpenBSD等其他BSD操作系统并行发展。</p>
<p>FreeBSD的特点：</p>
<ol>
<li><strong>开源</strong>：FreeBSD的源代码可以免费获取和修改，遵循BSD许可证。这使得许多公司和开发者可以根据自己的需求定制操作系统。</li>
<li><strong>稳定性</strong>：FreeBSD以其稳定性和可靠性而闻名，使其成为服务器和关键基础设施的理想选择。</li>
<li><strong>性能</strong>：FreeBSD的性能优异，被广泛应用于高性能计算、网络服务和存储解决方案。</li>
<li><strong>安全性</strong>：FreeBSD提供了多种安全功能，如强制访问控制、安全级别和防火墙集成。</li>
<li><strong>可移植性</strong>：FreeBSD支持多种硬件平台，包括x86、x86-64、ARM、MIPS和PowerPC等。</li>
</ol>
<h3 id="Fuchsia"><a href="#Fuchsia" class="headerlink" title="Fuchsia"></a>Fuchsia</h3><p>Fuchsia是由谷歌（Google）开发的一个开源操作系统。与FreeBSD不同，Fuchsia不是基于Unix的，而是基于名为Zircon的新内核构建的。Fuchsia的开发始于2016年，目标是创建一个高度模块化、可扩展且可用于各种设备的操作系统。</p>
<p>Fuchsia的特点：</p>
<ol>
<li><strong>开源</strong>：Fuchsia是一个开源项目，遵循BSD、MIT、Apache等许可证。这意味着开发者和公司可以免费访问和修改它的源代码。</li>
<li><strong>Zircon内核</strong>：Fuchsia基于Zircon内核，这是一个微内核设计，使得操作系统更加轻量化和高度模块化。</li>
<li><strong>跨平台</strong>：Fuchsia旨在成为一个统一的操作系统，适用于各种设备，包括智能手机、平板电脑、个人电脑以及物联网（IoT）设备。</li>
<li><strong>模块化和可扩展性</strong>：Fuchsia的设计允许开发者轻松地添加和移除组件，使得操作系统能够根据需求进行定制化。</li>
<li><strong>Flutter框架</strong>：Fuchsia使用谷歌的Flutter框架构建用户界面，Flutter支持跨平台应用开发，可以使Fuchsia应用在其他操作系统上运行。</li>
</ol>
<p>总结，FreeBSD是一个基于Unix的稳定、高性能的开源操作系统，主要用于服务器和高性能计算。而Fuchsia是谷歌开发的一个全新的、基于Zircon内核的操作系统，旨在提供统一的、跨设备的体验。</p>
<h2 id="sysctl接口"><a href="#sysctl接口" class="headerlink" title="sysctl接口"></a>sysctl接口</h2><p>Linux内核通过<code>/proc/sys</code>下的<code>sysctl</code>接口为用户空间程序提供了一种方式来查询和修改内核参数。<code>sysctl</code>可以通过文件系统访问，同时也可以通过命令行工具<code>sysctl</code>进行操作。这些参数涉及到许多内核子系统和组件，包括内存管理、网络设置、安全设置等。</p>
<p>在<code>sysctl</code>配置中，有很多参数涉及到抽象资源限制。这些限制通常用于约束系统资源的分配，以防止资源耗尽或者保证系统的稳定运行。以下是一些常见的资源限制相关的<code>sysctl</code>参数：</p>
<ol>
<li><p><strong>vm.max_map_count</strong>：这个参数用于限制一个进程可以拥有的最大内存映射区域数量。这个限制有助于防止资源耗尽，尤其是在内存分配密集型的应用场景中。</p>
</li>
<li><p><strong>kernel.pid_max</strong>：这个参数用于设置系统中分配的最大进程ID。通过限制进程ID的数量，可以防止恶意软件或编程错误导致的大量僵尸进程占用系统资源。</p>
</li>
<li><p><strong>kernel.threads-max</strong>：这个参数用于限制系统中可以创建的最大线程数量。线程数量的限制可以防止过多的线程导致系统资源耗尽。</p>
</li>
<li><p><strong>net.core.somaxconn</strong>：这个参数用于设置系统中最大的已完成连接队列长度。这个限制可以保障在高并发网络服务场景下，系统能够在资源有限的情况下处理连接请求。</p>
</li>
<li><p><strong>fs.file-max</strong>：这个参数用于限制系统中可以打开的最大文件描述符数量。这个限制可以防止过多的文件描述符导致内核资源耗尽。</p>
</li>
</ol>
<p>这些<code>sysctl</code>参数通常可以在系统启动时通过配置文件设置，也可以在运行时通过命令行工具<code>sysctl</code>进行动态调整。这为管理员和开发者提供了一种灵活的方式来优化系统性能和资源分配。</p>
<h2 id="seccomp"><a href="#seccomp" class="headerlink" title="seccomp"></a>seccomp</h2><p>seccomp（secure computing mode，安全计算模式）是一种Linux内核安全特性，允许在用户空间的进程将其可用的系统调用（syscalls）限制为一个最小的集合。这样做可以降低进程被攻击者利用的风险，因为攻击者可以使用的系统调用减少了。seccomp在容器、沙箱和其他高度安全的环境中非常有用，因为它可以限制潜在的攻击面。</p>
<p>seccomp的工作原理是允许进程定义一个系统调用白名单，只有在这个白名单上的系统调用才能被进程执行。当进程试图执行不在白名单上的系统调用时，内核会阻止进程，并根据seccomp的配置执行相应的操作。这些操作可能包括：终止进程、向进程发送信号或者返回一个错误码。</p>
<p>为了使用seccomp，进程需要使用<code>prctl</code>系统调用启用seccomp模式。接着，进程可以通过<code>seccomp</code>系统调用定义一个过滤器（通常是一个BPF（Berkeley Packet Filter）程序），用于检查系统调用的编号，并根据白名单执行相应的操作。</p>
<p>以下是一个简单的seccomp示例，演示了如何使用seccomp限制一个进程只能调用<code>read</code>、<code>write</code>、<code>exit</code>和<code>rt_sigreturn</code>系统调用：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/prctl.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;linux/seccomp.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;linux/filter.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;linux/audit.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/syscall.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ALLOW_SYSCALL(syscall_nr) \</span></span><br><span class="line"><span class="meta">    BPF_JUMP(BPF_JMP + BPF_JEQ + BPF_K, syscall_nr, 0, 1), \</span></span><br><span class="line"><span class="meta">    BPF_STMT(BPF_RET + BPF_K, SECCOMP_RET_ALLOW)</span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">// 定义seccomp过滤器</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">sock_filter</span> <span class="title">filter</span>[] =</span> &#123;</span><br><span class="line">        <span class="comment">// 检查架构是否正确</span></span><br><span class="line">        BPF_STMT(BPF_LD + BPF_W + BPF_ABS, offsetof(<span class="keyword">struct</span> seccomp_data, arch)),</span><br><span class="line">        BPF_JUMP(BPF_JMP + BPF_JEQ + BPF_K, AUDIT_ARCH_X86_64, <span class="number">1</span>, <span class="number">0</span>),</span><br><span class="line">        BPF_STMT(BPF_RET + BPF_K, SECCOMP_RET_KILL),</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 加载系统调用编号</span></span><br><span class="line">        BPF_STMT(BPF_LD + BPF_W + BPF_ABS, offsetof(<span class="keyword">struct</span> seccomp_data, nr)),</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 允许白名单上的系统调用</span></span><br><span class="line">        ALLOW_SYSCALL(__NR_read),</span><br><span class="line">        ALLOW_SYSCALL(__NR_write),</span><br><span class="line">        ALLOW_SYSCALL(__NR_exit),</span><br><span class="line">        ALLOW_SYSCALL(__NR_rt_sigreturn),</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 不允许的系统调用将导致进程被终止</span></span><br><span class="line">        BPF_STMT(BPF_RET + BPF_K, SECCOMP_RET_KILL),</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 定义seccomp过滤器的元数据</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">sock_fprog</span> <span class="title">prog</span> =</span> &#123;</span><br><span class="line">        .len = (<span class="type">unsigned</span> <span class="type">short</span>)(<span class="keyword">sizeof</span>(filter) / <span class="keyword">sizeof</span>(filter[<span class="number">0</span>])),</span><br><span class="line">        .filter = filter,</span><br><span class="line">    &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 启用seccomp模式</span></span><br><span class="line">    <span class="keyword">if</span> (prctl(PR_SET_SECCOMP, SECCOMP_MODE_FILTER, &amp;prog) &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        perror(<span class="string">&quot;prctl&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 在此处执行您的程序逻辑</span></span><br><span class="line">    <span class="comment">// 如果尝试执行不在白名单上的系统调用，进程将被终止</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>请注意，这个示例使用的是seccomp的BPF过滤器，该过滤器提供了一种灵活的方式来控制系统调用。这种方法在容器和沙箱环境中非常有用，因为它可以针对特定应用程序的需求定制系统调用的限制。然而，编写BPF过滤器可能相对复杂，因此在实践中，许多开发者选择使用像libseccomp这样的库来简</p>
<p>化seccomp过滤器的创建和管理。</p>
<p>以下是使用libseccomp库的示例，实现与前面相同的功能：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;seccomp.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">int</span> <span class="title function_">main</span><span class="params">()</span> &#123;</span><br><span class="line">    <span class="comment">// 初始化一个新的seccomp上下文</span></span><br><span class="line">    scmp_filter_ctx ctx = seccomp_init(SCMP_ACT_KILL);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!ctx) &#123;</span><br><span class="line">        perror(<span class="string">&quot;seccomp_init&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 向过滤器中添加允许的系统调用</span></span><br><span class="line">    <span class="keyword">if</span> (seccomp_rule_add(ctx, SCMP_ACT_ALLOW, SCMP_SYS(read), <span class="number">0</span>) &lt; <span class="number">0</span> ||</span><br><span class="line">        seccomp_rule_add(ctx, SCMP_ACT_ALLOW, SCMP_SYS(write), <span class="number">0</span>) &lt; <span class="number">0</span> ||</span><br><span class="line">        seccomp_rule_add(ctx, SCMP_ACT_ALLOW, SCMP_SYS(<span class="built_in">exit</span>), <span class="number">0</span>) &lt; <span class="number">0</span> ||</span><br><span class="line">        seccomp_rule_add(ctx, SCMP_ACT_ALLOW, SCMP_SYS(rt_sigreturn), <span class="number">0</span>) &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        perror(<span class="string">&quot;seccomp_rule_add&quot;</span>);</span><br><span class="line">        seccomp_release(ctx);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将过滤器加载到内核中</span></span><br><span class="line">    <span class="keyword">if</span> (seccomp_load(ctx) &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        perror(<span class="string">&quot;seccomp_load&quot;</span>);</span><br><span class="line">        seccomp_release(ctx);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 释放资源</span></span><br><span class="line">    seccomp_release(ctx);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 在此处执行您的程序逻辑</span></span><br><span class="line">    <span class="comment">// 如果尝试执行不在白名单上的系统调用，进程将被终止</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这个示例使用了libseccomp库提供的API，使得创建和管理seccomp过滤器更加简单。只需通过<code>seccomp_init</code>初始化一个新的上下文，使用<code>seccomp_rule_add</code>添加允许的系统调用，然后使用<code>seccomp_load</code>将过滤器加载到内核中。最后，使用<code>seccomp_release</code>释放资源。</p>
<p>总之，seccomp是一种在Linux内核中实现安全计算模式的机制，它允许进程限制其可用的系统调用集，从而降低潜在的攻击面。在容器、沙盒和其他高度安全的环境中，seccomp非常有用。使用BPF过滤器或第三方库（如libseccomp）可以帮助开发者更轻松地创建和管理seccomp过滤器。</p>
<h2 id="inode"><a href="#inode" class="headerlink" title="inode"></a>inode</h2><h3 id="inode是什么"><a href="#inode是什么" class="headerlink" title="inode是什么"></a>inode是什么</h3><p>在文件系统中，<code>inode</code>（索引节点）是一种数据结构，用于存储有关文件和目录的元数据（如权限、大小、创建时间等），但不包括文件名和实际文件数据。每个文件或目录在文件系统中都有一个唯一的<code>inode</code>，它们通过<code>inode</code>号进行识别。不同的文件系统类型（如ext4、XFS、Btrfs等）可能会有不同的<code>inode</code>实现，但其基本概念是相同的。</p>
<p>以下是<code>inode</code>可能包含的一些元数据信息：</p>
<ul>
<li>文件类型（普通文件、目录、符号链接等）</li>
<li>文件大小</li>
<li>文件的权限（读、写、执行）</li>
<li>文件的所有者和所属组</li>
<li>创建、修改和访问时间戳</li>
<li>文件数据所在的磁盘块的位置</li>
</ul>
<p>现在让我们通过一个简单的Python脚本示例来展示如何获取文件的<code>inode</code>信息：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">file_path = <span class="string">&quot;example.txt&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取文件的 inode 信息</span></span><br><span class="line">file_stat = os.stat(file_path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印详细的 inode 信息</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;File path: <span class="subst">&#123;file_path&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Inode number: <span class="subst">&#123;file_stat.st_ino&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;File size: <span class="subst">&#123;file_stat.st_size&#125;</span> bytes&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;File owner: <span class="subst">&#123;file_stat.st_uid&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;File group: <span class="subst">&#123;file_stat.st_gid&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;File permissions: <span class="subst">&#123;<span class="built_in">oct</span>(file_stat.st_mode)[-<span class="number">4</span>:]&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;File creation time: <span class="subst">&#123;file_stat.st_ctime&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;File modification time: <span class="subst">&#123;file_stat.st_mtime&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;File access time: <span class="subst">&#123;file_stat.st_atime&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>在这个例子中，我们首先通过<code>os.stat()</code>函数获取了指定文件路径的<code>inode</code>信息。然后，我们可以从返回的<code>os.stat_result</code>对象中获取各种<code>inode</code>元数据，如文件大小、所有者、权限等。</p>
<p>需要注意的是，此示例仅适用于类Unix系统（如Linux和macOS）。在Windows系统上，文件元数据的管理方式与<code>inode</code>有所不同。可以使用Python的<code>os</code>模块的其他函数，如<code>os.path.getsize()</code>和<code>os.path.getctime()</code>等，来获取Windows系统上的文件元数据。</p>
<h3 id="inode攻击"><a href="#inode攻击" class="headerlink" title="inode攻击"></a>inode攻击</h3><p><code>inode</code>攻击是一种资源耗尽攻击，其目标是耗尽文件系统中可用的<code>inode</code>。在这种攻击中，攻击者会在受害者容器中不断创建新文件或目录，从而分配大量的<code>inode</code>结构。由于Linux内核没有针对<code>inode</code>的cgroup隔离，这种攻击会影响整个分区，导致分区上的所有<code>inode</code>都被耗尽。</p>
<p>当<code>inode</code>耗尽时，任何试图创建新文件或目录的操作都会失败，无论这些操作来自受害者容器还是主机。在这种情况下，受害者容器可能会被驱逐，而主机也不能创建任何新文件。阿里云容器服务容易受到<code>inode</code>攻击的影响。</p>
<p>为了防御<code>inode</code>攻击，可以考虑以下方法：</p>
<ol>
<li><p><strong>限制容器的存储使用</strong>：为容器设置存储配额，以限制每个容器可以使用的存储空间。这可以防止攻击者耗尽整个文件系统的<code>inode</code>。</p>
</li>
<li><p><strong>监控<code>inode</code>使用情况</strong>：定期检查文件系统的<code>inode</code>使用情况，以便在<code>inode</code>快速耗尽时发现潜在的攻击。</p>
</li>
<li><p><strong>设置警报和自动响应</strong>：在<code>inode</code>使用达到临界值时设置警报，并实施自动响应措施，例如限制或隔离可疑容器。</p>
</li>
<li><p><strong>运行时隔离</strong>：使用更高级别的运行时隔离技术，如gVisor或Kata Containers，以提供更强大的安全隔离。</p>
</li>
</ol>
<p>需要注意的是，防御<code>inode</code>攻击的方法可能会对性能产生影响，因此在实施这些措施时需要权衡安全性和性能。</p>
<h2 id="netns-ct-gt-count攻击"><a href="#netns-ct-gt-count攻击" class="headerlink" title="netns_ct-&gt;count攻击"></a>netns_ct-&gt;count攻击</h2><p>一种针对 Linux 内核中的连接跟踪功能（Netfilter）的攻击，该攻击涉及到利用 <code>netns_ct-&gt;count</code> 计数来消耗主机和容器的网络资源。这种攻击通常被称为连接消耗攻击（Connection Exhaustion Attack）或资源耗尽攻击（Resource Exhaustion Attack）。</p>
<p>攻击原理概述如下：</p>
<ol>
<li>攻击者在容器内产生大量的 TCP 连接，这些连接会被跟踪。</li>
<li>尽管这些容器位于不同的网络命名空间（net namespace）中，但它们的所有连接都需要使用主机的 <code>init_net.ct</code> 计数。</li>
<li>当攻击者在短时间内产生大量连接时，会消耗掉主机的 <code>init_net.ct</code> 计数配额。</li>
<li>一旦配额耗尽，Netfilter 功能将受到影响，可能导致随机丢包等问题。</li>
</ol>
<p>要防范这种攻击，可以采取以下措施：</p>
<ol>
<li><strong>限制容器的连接数</strong>：为每个容器设置连接数限制，以防止单个容器耗尽主机的连接资源。</li>
<li><strong>限制连接速率</strong>：使用 Netfilter 的 <code>iptables</code> 工具限制容器的连接速率。例如，可以设置每秒最多允许的新连接数，从而防止攻击者在短时间内产生大量连接。</li>
<li><strong>隔离网络命名空间</strong>：在某些情况下，可以为每个容器提供独立的网络命名空间，以降低资源争用的可能性。然而，这种方法可能会增加资源消耗和管理复杂性。</li>
<li><strong>监控和报警</strong>：实施实时网络连接监控，以便在攻击发生时迅速检测并采取相应措施。</li>
</ol>
<p>通过实施这些防范措施，可以降低容器和主机受到 <code>netns_ct-&gt;count</code> 攻击的风险。</p>
<h2 id="gVisor"><a href="#gVisor" class="headerlink" title="gVisor"></a>gVisor</h2><p><code>gVisor</code> 是一个开源的沙箱运行时，由谷歌开发，用于为容器提供隔离和安全性。<code>gVisor</code> 主要目标是为容器提供更高级别的安全性，同时保持接近原生容器的性能。它在容器与宿主机之间增加了一个用户空间内核，从而限制容器对宿主机内核的访问。这种方法降低了潜在安全漏洞对整个系统的影响。</p>
<p><code>gVisor</code> 的核心组件是名为 “Sentry” 的用户空间内核，它拦截和处理来自容器的系统调用。Sentry 为每个容器提供了一个独立的内核实例，从而限制容器之间的相互影响。此外，<code>gVisor</code> 还包括一个名为 “Gofer” 的文件系统代理，用于将容器的文件系统操作转发到宿主机。</p>
<p><code>gVisor</code> 与 Docker 和 Kubernetes 等容器运行时环境兼容，可以轻松集成到现有的容器部署中。为了在 Docker 中使用 <code>gVisor</code>，您需要安装 <code>gVisor</code> 并将其配置为 Docker 的运行时。以下是在 Docker 中使用 <code>gVisor</code> 的示例：</p>
<ol>
<li>首先，安装 <code>gVisor</code>：</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">wget https://storage.googleapis.com/gvisor/releases/nightly/latest/runsc</span><br><span class="line">wget https://storage.googleapis.com/gvisor/releases/nightly/latest/runsc.sha512</span><br><span class="line"><span class="built_in">sha512sum</span> -c runsc.sha512</span><br><span class="line"><span class="built_in">chmod</span> a+x runsc</span><br><span class="line">sudo <span class="built_in">mv</span> runsc /usr/local/bin</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>配置 Docker 使用 <code>gVisor</code>：</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">sudo <span class="built_in">mkdir</span> -p /etc/docker</span><br><span class="line"><span class="built_in">echo</span> <span class="string">&#x27;&#123;</span></span><br><span class="line"><span class="string">  &quot;runtimes&quot;: &#123;</span></span><br><span class="line"><span class="string">    &quot;runsc&quot;: &#123;</span></span><br><span class="line"><span class="string">      &quot;path&quot;: &quot;/usr/local/bin/runsc&quot;,</span></span><br><span class="line"><span class="string">      &quot;runtimeArgs&quot;: [&quot;--platform=ptrace&quot;]</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">  &#125;</span></span><br><span class="line"><span class="string">&#125;&#x27;</span> | sudo <span class="built_in">tee</span> /etc/docker/daemon.json</span><br><span class="line">sudo systemctl restart docker</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>运行一个使用 <code>gVisor</code> 的 Docker 容器：</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run --runtime=runsc -it alpine sh</span><br></pre></td></tr></table></figure>

<p>这将启动一个使用 <code>gVisor</code> 作为沙箱运行时的新容器。通过使用 <code>gVisor</code>，您可以提高容器的安全性，降低潜在安全漏洞对整个系统的影响。然而，需要注意的是，<code>gVisor</code> 可能会带来一定的性能损失，因此在实际应用中需要权衡安全性和性能。</p>
<h2 id="Per-user-quota-restrictions"><a href="#Per-user-quota-restrictions" class="headerlink" title="Per-user quota restrictions"></a>Per-user quota restrictions</h2><p>Per-user quota restrictions 是一种在文件系统层面设置的资源限制方法，用于控制每个用户所能使用的磁盘空间和文件数量。这种限制方法通常用于多用户共享同一系统资源的环境，如共享主机或服务器，以防止单个用户占用过多的磁盘空间或文件数量，从而导致其他用户无法正常使用系统资源。</p>
<p>Per-user quota restrictions 主要包括以下两种类型：</p>
<ol>
<li><p><strong>磁盘空间限制（Block Quotas）</strong>：该限制用于限制每个用户所能使用的磁盘空间。系统管理员可以为每个用户分配一定量的磁盘空间，当用户达到分配的磁盘空间上限时，将无法继续写入或创建新文件。</p>
</li>
<li><p><strong>文件数量限制（Inode Quotas）</strong>：该限制用于限制每个用户所能创建的文件数量。系统管理员可以为每个用户分配一定数量的文件（或目录）创建权限，当用户达到分配的文件数量上限时，将无法继续创建新文件或目录。</p>
</li>
</ol>
<p>在 Linux 系统中，可以通过以下步骤设置 per-user quota restrictions：</p>
<ol>
<li><p>安装 quota 工具：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install quota quotatool</span><br></pre></td></tr></table></figure>
</li>
<li><p>在 <code>/etc/fstab</code> 文件中启用用户配额。例如，为 <code>/home</code> 分区启用用户配额，可以将以下内容添加到 <code>/etc/fstab</code> 文件：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/dev/sda1 /home ext4 defaults,usrquota,grpquota 0 0</span><br></pre></td></tr></table></figure>
</li>
<li><p>重新挂载分区以应用更改：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo mount -o remount /home</span><br></pre></td></tr></table></figure>
</li>
<li><p>初始化配额文件：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo quotacheck -cug /home</span><br></pre></td></tr></table></figure>
</li>
<li><p>为特定用户设置配额限制。例如，为用户 <code>exampleuser</code> 设置 100MB 的磁盘空间限制和 1000 个文件数量限制：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo setquota -u exampleuser 100000 110000 1000 1100 /home</span><br></pre></td></tr></table></figure>
</li>
<li><p>使用 <code>quota</code> 命令查看用户配额情况：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">quota -u exampleuser</span><br></pre></td></tr></table></figure></li>
</ol>
<p>通过实施 per-user quota restrictions，系统管理员可以确保系统资源在用户之间公平地分配，防止单个用户过度使用资源。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/03/29/%E3%80%8A%E7%90%86%E6%83%B3%E5%9B%BD%E3%80%8B%E6%9F%8F%E6%8B%89%E5%9B%BE%20%E9%98%85%E8%AF%BB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Plucky">
      <meta itemprop="description" content="随便记录">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Plucky">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2023/03/29/%E3%80%8A%E7%90%86%E6%83%B3%E5%9B%BD%E3%80%8B%E6%9F%8F%E6%8B%89%E5%9B%BE%20%E9%98%85%E8%AF%BB/" class="post-title-link" itemprop="url">《理想国》柏拉图 阅读</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-03-29 11:09:42" itemprop="dateCreated datePublished" datetime="2023-03-29T11:09:42+08:00">2023-03-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-04-09 21:41:12" itemprop="dateModified" datetime="2023-04-09T21:41:12+08:00">2023-04-09</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">读书笔记</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/%E5%93%B2%E5%AD%A6/" itemprop="url" rel="index"><span itemprop="name">哲学</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>5.3k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>10 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>    《理想国》作为一本必读的哲学经典，是柏拉图在思想成熟时期所著，包含了古希腊当时个个方面的问题，包括哲学、教育、军事、政治、伦理、文艺、诗歌等等。柏拉图一步步构建出理念世界，并借苏格拉底之口讨论了哲学中的一些重要问题，苏格拉底运用“辩证法”一步步让对方发现自身观点的矛盾之处，可以说是压迫感极强，甚至说是阴阳怪气。再读《理想国》，意在让自己浅薄的思想能得到升华。本人希望通过阅读总结书中的思想，可能由于时代的局限性，某些思想在现在看来可能已经过时并且不够完善，但是我们也依然可以从中汲取智慧为自己的思想所用。</p>
<h1 id="财产-正义-节制"><a href="#财产-正义-节制" class="headerlink" title="财产 正义 节制"></a>财产 正义 节制</h1><p>开篇以苏格拉底和赛弗拉的对话开始，苏格拉底从年长者的问题入手，逐步引出财产，正义的讨论，并一步步进行了论证，反驳了当时流行的观点。</p>
<blockquote>
<p>当一个人对肉体上的享受越来越少时，那他对精神上的畅谈也就要求越多。</p>
</blockquote>
<blockquote>
<p> 我向来认为年长的人就像已经翻越千山万水的老旅客，你们曾经遇到的坎坷也可能是我之后要经历的，所以我对于过来人十分愿意与他们探讨一下旅途中的艰难险阻。</p>
</blockquote>
<h2 id="人在老年阶段是否会更艰难？"><a href="#人在老年阶段是否会更艰难？" class="headerlink" title="人在老年阶段是否会更艰难？"></a>人在老年阶段是否会更艰难？</h2><p>大部分人在年老时对年老的抱怨，在于不能像以前一样吃喝玩乐、或是体验爱情的快乐、或是美好的事物已成过往，有人埋怨至亲好友的忽视，有人埋怨年老是痛苦的根源。赛弗拉讲脱离所谓的情爱比喻成从一个暴君处脱离苦海，到了老年时代，对于情爱一事早已没了兴趣，人已经清心寡欲，有了另一种自由快乐的感受。</p>
<p>赛弗拉从此入手，论证年老时之所以会抱怨连连，不是因为年纪，而是性情。如果一个人性情是恬静的、心平气和的，那么年龄大并不是痛苦，如果不是，那么不管什么年龄都会是痛苦的。</p>
<p>苏格拉底故意激赛弗拉继续回答，苏格拉底评价赛弗拉是因为家财万贯而不是因为性情恬静，所以老年时才会快乐，之后引出财富的问题。</p>
<h2 id="你从财富上得到了什么？"><a href="#你从财富上得到了什么？" class="headerlink" title="你从财富上得到了什么？"></a>你从财富上得到了什么？</h2><blockquote>
<p>  自己赚钱的人不仅因为钱有用才喜欢它，而更是因为这是他们辛苦得来的，内心生出了一种强烈的占有欲，就像诗人爱自己的诗篇，父母疼爱自己的儿女一样。我看到这种人，就觉得他们很讨厌，他们说的内容不外乎是赞美金钱之类的。</p>
</blockquote>
<p>人从财富中获得的最大的好处就是，在赚取财富时的问心无愧，没有恐慌和忧虑。在人快死亡的时候，会有一种恐慌和忧虑，担心来世受到惩罚。如果一个人知道自己造孽颇深，就会过度悲观，惊恐万分，而问心无愧的人，便会心中坦然。</p>
<h2 id="正义是什么？"><a href="#正义是什么？" class="headerlink" title="正义是什么？"></a>正义是什么？</h2><h3 id="有话实说、欠债还债是否正义？"><a href="#有话实说、欠债还债是否正义？" class="headerlink" title="有话实说、欠债还债是否正义？"></a>有话实说、欠债还债是否正义？</h3><p>不是正义，这个观点是日常生活中某个情形下的正义行为，并不是正义的定义。如果如此定义正义，便会造成有时是正义的，有时不是正义的情形。</p>
<p>柏拉图借苏格拉底之口举例：</p>
<ul>
<li><p>你有个朋友在头脑清楚的时候，曾经把武器交给你，假如他后来疯了，再要回去，任何人都会说不能还给他，如果你还给他，这是不正义的行为。</p>
</li>
<li><p>把整个真实情况告诉疯子不是正义。</p>
</li>
<li><p>如果债主是敌人，还债是对他的帮助，则还债不是正义。</p>
</li>
</ul>
<p>即当有话实说或者欠债还债的对象不同时，根据不同情况，这种行为也有可能是不正义的。苏格拉底希望找到一种普遍的正义，我们想要看一种行为是否是正义的，不能光从自身的立场出发，还要从我们的对象能否收益来检验我们的行为是否是有利于对方的，还要判断收益的对象。</p>
<h3 id="把善给予友人，把恶给予敌人是否正义？"><a href="#把善给予友人，把恶给予敌人是否正义？" class="headerlink" title="把善给予友人，把恶给予敌人是否正义？"></a>把善给予友人，把恶给予敌人是否正义？</h3><p>把善给予友人：医生把医术给予病人，舵手在航海遇到风急浪险时维护船舶的安全。</p>
<p>把恶给予敌人：在战争中与盟友攻敌。</p>
<p>苏格拉底论证，在不生病的时候，医生是没有用处的，在人们不航海的时候，舵手是没有用处的，在不打仗的时候，正义者是没有用处的。而正义在不论任何时候都是有用处的。农名在种田时有用处，鞋匠在造鞋时有用处，但是鞋匠和农民不是正义者。</p>
<p>那么在平时什么事情上必须有正义？多人合作关系，例如订合同、立契约等等。下棋能手和正义者在下棋时，下棋能手更有用处，瓦匠和正义者在砌砖盖瓦建屋时，瓦匠更有用处，琴师和正义者在奏乐时，琴师更有用处，因此有用者并不等于正义者。这说明这样的正义定义太过狭窄。</p>
<p>事实上恰恰相反，一个正义的人和政府都是在平时就能做得很好才能保持自己和国家的久安。在涉及到金钱时，花钱与保管钱，同样都有比正义者更有用处的角色存在。</p>
<p>以此类推，如果一件事物有用，那么正义就没用，正义有用，那么这件事物就没用。是在平时就能做得很好才能保持自己和国家的久安。如果说正义平时也有用比如在替朋友保管钱财方面做到以善待友，那么就会得出钱财不用时正义有用，一旦钱财被使用了正义反而无用了。最后正义还要求“以恶对敌”这是不是意谓着还要替朋友去掠取敌人的东西呢？这样正义之举不就成了小偷行为了吗？这样的驳难看似荒唐，其实正好揭露出了这个定义本身所包含的内在矛盾。</p>
<p>    而根据命题的定义，我们有时也会混淆朋友和敌人，所谓的朋友是那些看上去好的人还是实际上真正好的人呢？你所谓的敌人是看上去坏的人还是那些看上去不坏但是真的坏人呢。如果弄错了，便会导致帮助坏人，对抗好人。这个也引出善恶的问题，柏拉图在之后也借苏格拉底之口对此进行了论证。</p>
<p>    根据讨论进一步完善定义，真正善良的朋友，报之以善，真正邪恶的敌人，报之以恶，才是正义。这个定义似乎更接近真理一些了。但是考虑如下例子：正义的人是否可以伤害他人呢？伤害他人是一件恶事，正义之人一定是善人，基于此，并考虑如下例子：善于骑马的人能够凭借其起码的技能让人不会骑马吗？音乐家能够凭借其音乐上的技能使人不懂音乐吗？正义者能以他的正义使人做不正义的事情吗？我们可以认为正义者作为一个善人不应该做伤害他人的恶事。</p>
<p>    所以根据上述的讨论，正义并非是把善给予友人，把恶给予敌人。</p>
<h3 id="正义就是强者的利益"><a href="#正义就是强者的利益" class="headerlink" title="正义就是强者的利益"></a>正义就是强者的利益</h3><p>正义就是强者的利益，区别于上述判断收益的对象以及对于友人的利益，这个命题认为正义是强者的利益，所以首先要明确的是何为”强者“。如果只是因为吃的比别人好而比别人强壮，这并不是强者，我们通常提到强者，首先想到的就是统治者，制定法律的人，违反法律的人就是不正义之人，而对于政府有利的百姓就是正义。因此，有人认为，所谓正义就是当时政府的利益，正义就是强者的利益。</p>
<p>苏格拉底对此进行了反驳。</p>
<ul>
<li><p>政府不是绝对不会出错的，如果治理得当，那么他们所立的法就是基于政府的利益的，而治理出现问题，就会与政府的利益违背，此时还是正义的吗？如果是正义的便会得到，即使与政府的利益违背，人民依旧需要服从，这仍然是正义。但是如果弱者服从了，实际上是损害了强者的利益，因此与命题相违背。</p>
</li>
<li><p>如果强者的利益指的是强者实际上的利益而不是强者心中认为的利益，并且是基于严格意义上的强者，即不会犯错误的强者。</p>
<p>苏格拉底做出了一个比喻，如果说技艺是完美的，如果技艺是不完美的，例如人的身体不完备的时候，需要医术来弥补，医术不完备的时候，需要其他的技艺来弥补。假设技艺在严格意义上是完美的不需要其他任何方式弥补的话，那么医生就不会考虑自身医术的利益，而会考虑病人的利益，骑马者不会考虑骑术的利益，而会考虑马的利益。以此类推，技艺本身是没有错误的，因此他担心的便是对象的利益，因为任何技艺都是为其对象服务的。那么不会犯错的强者可以比喻成完美的技艺，百姓可以比喻成技艺所服务的对象。那么一个统治者更多顾及的便是受统治者的利益而不是自身的利益，就像完美的技艺是为它的对象服务的。即名实相符的统治者会始终以人民的利益为前提，而不是以自己的利益为前提。</p>
</li>
</ul>
<h3 id="不正义比正义更有益"><a href="#不正义比正义更有益" class="headerlink" title="不正义比正义更有益"></a>不正义比正义更有益</h3><p>有人认为正义和正义者会白白给出利益，换言之，正义意味着强者和统治者得到利益，而弱者和被统治者失去利益。不正义与之相反。例如专制君主的暴政。</p>
<p>根据苏格拉底在上文的证明，一个名实相符的统治者，无论什么事都是以被统治者的利益为目的。</p>
<p>每种技艺除了普通的利益之外，应该要给人以特殊的利益，比如医术给人以健康的利益，航海之术给人以安渡大海的利益。除此之外，技艺应当还有特殊的功用，而这种功用不能与其他技艺的功用相混合。每种技艺的利益都不能与其他的技艺混为一谈，除了它自身的特殊功用外，具有同一功用的技艺之间必定有同一利益在其中，那么技艺者所得到得报酬，应该是技艺所附带的利益，而不是技艺本身的利益。报酬与各种技艺有连带关系，而掌握技艺饿人只要各尽所能，便可以施利于人，报酬自然在其中。凡是真正的技艺家，当他工作的时候或指挥他人的时候，是以他人的利益为中心的，而不应该掺杂自己的私欲。工作没有相当的报酬是没有人愿意尽力而为的。所以，统治者或治理者的工作也必须有报酬，他们才会尽心为人民服务。他们的报酬有三种：金钱、荣誉与不愿承担责任的惩罚。</p>
<p>金钱和荣誉可以理解，而惩罚是什么意思呢？惩罚如何能作为报酬？</p>
<p>对于高尚的人，名与利都不能使之动心。他们不愿意为拿报酬去做事，被人当佣人看待，更不愿意以阴谋的手段，假公济私，被人当强盗看待。因此，只能用损毁他们高洁的名节来惩罚他们，迫使他们不得不出来做事。也正因为这个缘故，那些急于做官的人受到轻视，而那些被逼出来做官的人则感受到莫大的尊荣。这种惩罚之所以最有效，是因为如果他们不出来，就用不如他们的人来管理他们的生活和行为。因此，这些人出来做官并不是因为他们有这个志向，也不是这里面有什么可贪图的，而是因为一时没有比他们更好的人或能力相同的人。所以，对他们来说，做官实在是刀架在脖子上，迫不得已的事。假如一个国家都是高尚的人，那么不想做官的肯定不会比今日想要做官的少。因此，真正的统治是要给他人以利益，而不是给自己以利益。如此，那么有谁会不愿意被统治，接受他人的利益呢？有谁会愿意做统治者，专门给他人以利益呢？所以，不得不以惩罚的手段迫使高尚者出来做官。</p>
<p>这进一步证明了正义不是强者的利益，初步证明了不正义不一定更有益，下面进一步证明。</p>
<p>如果能够治理国家和人民的纯粹的不正义者，会比正义者有能力得多，那么不正义者就会是明智的且有美德的，而正义便是其对立面。基于此，一个正义者不能够胜过其他的正义者即没有竞争，因为正义者是不明智的且无能的，并且所作所为不能有超过正义事业之外的事情，并且正义者获得的利益不能多于不正义者。而不正义者愿意获得比正义者更多的利益，并且愿意做正义之外的事情，所以不正义者在利益的竞争上要比正义者激烈，然后才能获取更多的利益。总结如下：正义者不愿意获得比同类更多的利益，而愿意获得比异类更多的利益；不正义者即愿意获得比同类更多的利益，也愿意获得比异类更多的利益。不正义者属于善而有智慧者的同类，正义者属于其异类。</p>
<p>我们再来看技艺家，人所拥有的技艺是不同的，例如一人为音乐家，一人为非音乐家，那么就音乐上的智慧来说，音乐家是聪明的。以此类推，医生也是这样的。音乐家在调整琴弦时不会有意想胜过别的音乐家，而会有意胜过非音乐家。医生在治病时不会做超出医生范围之外的事。再以知识与愚笨来说，有知识者的言行和其他有知识者的言行差不多，而愚笨的人会想要自己的言行超过有知识和无知识的人。有知识的人是聪明的而聪明的人是善良的（这段我无法推出，可能是由于当时的局限性对于善良，聪明等的定义并不明确，上文也出现了类似的情况），聪明又善良的人仅仅希望胜过异类，而不希望胜过同类，我们基于上文的假设得到这些结论。</p>
<p>而上文说不正义者常常想要胜过同类和异类，正义者只想胜过异类，而不想胜过同类，那么正义者则与聪明又有善德的相似，不正义者与无知而又没有善的的相似。那么现在正义者变成了聪明又有善德的人，不正义者变成了无知又没有善德的人，与上一段的结论矛盾。</p>
<h3 id="正义与不正义的性质"><a href="#正义与不正义的性质" class="headerlink" title="正义与不正义的性质"></a>正义与不正义的性质</h3><p>基于我们已经证明正义是美德和智慧，不正义是没有善德和愚蠢的。那么正义者比不正义者强是不言而喻的。现在我们假设，有一个国家或一支军队或一伙强盗或任何一些作恶的团伙，如果他们成员之间整天自相残杀，那么这个团伙一定是不能成功运作的，而如果不自相残杀，那么这些团伙的运作才能进行的更好。所以不正义会引发争端和仇恨，而正义能调和彼此之间的矛盾以达到和谐。（看到这里，我们应该也明白了，柏拉图对于正义和不正义的定义也是比较模糊的，一些证明看似有道理，但是细细思考一下，就会发现其中的纰漏）不正义既然有引发争论和仇恨的性质，那么凡是在不正义的地方，不论是努力还是自由人，他们会因此相互争斗，意见分歧，而不能有共同的行动。那么不正义在二人之间，则彼此会发生争论和激战，势必会称为仇敌，并且还会称为正义的敌人。而不正义在一个人身上，不正义会是其自相矛盾，言行前后不一，所以不正义不仅仅是正义的敌人，也是自我的敌人。所以不正义即使对个人也是有害的，一是会使人的言行不一致，二是会是人三心二意，使自己称为自己的敌人，并且也成为正义的敌人。</p>
<p>哪些共同作恶的人，之所以能够进行作恶行为，还不能算是真正的不正义者，假如他们是真正的不正义者，那么他们必定会自相残害，如果他们能够联合在一起为恶，那么还有一部分正义存在于其间，所以才能进行集体的行动。</p>
<p>凡物都有其专门独特的功能和事业，也一定会有它的一个特长，就像人的眼睛有它自身独特的功能。假如眼睛的特长不完备而有缺陷，那么眼睛就不能成就它的事业。那么有正义之心的人，自然就会生活得坦然自若，终身愉快，而不正义的人刚好相反。根据以上推论，只有正义者才能生活得安乐而幸福，不正义者则不能。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/06/23/Hello-my-blog/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Plucky">
      <meta itemprop="description" content="随便记录">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Plucky">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2022/06/23/Hello-my-blog/" class="post-title-link" itemprop="url">Hello ,my blog</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2022-06-23 14:44:47" itemprop="dateCreated datePublished" datetime="2022-06-23T14:44:47+08:00">2022-06-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-03-31 12:52:42" itemprop="dateModified" datetime="2023-03-31T12:52:42+08:00">2023-03-31</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Dairy/" itemprop="url" rel="index"><span itemprop="name">Dairy</span></a>
                </span>
            </span>

          <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>186</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>1 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Zwei Dinge erfüllen das Gemuet mit immer neuer und zunehmender Bewunderung und Ehrfurcht, je öfter und anhaltender sich das Nachdenken damit beschäftigt:: der bestirnte Himmel über mir und das moralische Gesetz in mir.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Plucky</p>
  <div class="site-description" itemprop="description">随便记录</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">37</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">17</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="mailto:p1ucky@163.com" title="E-Mail → mailto:p1ucky@163.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Plucky</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="Symbols count total">445k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">13:30</span>
</div>

<!--
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>-->

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>




  




  
<script src="/js/local-search.js"></script>











<script>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js', () => {
    mermaid.initialize({
      theme    : 'forest',
      logLevel : 3,
      flowchart: { curve     : 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 }
    });
  }, window.mermaid);
}
</script>


  

  


<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true}});</script></body>
</html>
<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/clicklove.js"></script>
